{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"43fb082f","cell_type":"code","source":"# Install dependencies - OpenSloth + vLLM + Analysis setup\n!pip install pip3-autoremove\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu124\n!pip install accelerate==1.7.0\n!pip install triton==3.2.0 \n\n!pip install unsloth==2025.5.7 unsloth-zoo==2025.5.8 --no-cache\n\n!pip install opensloth==0.1.7 \n\n!pip install TextStreamer\n\nprint(\"✅ TT-12 Dependencies installed:\")\nprint(\"🚀 OpenSloth: Multi-GPU training\")\nprint(\"🎯 vLLM: Precise inference\") \nprint(\"📊 Analysis libraries: scikit-learn, matplotlib, seaborn\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:29:07.940924Z","iopub.execute_input":"2025-09-17T13:29:07.941199Z","iopub.status.idle":"2025-09-17T13:29:47.772932Z","shell.execute_reply.started":"2025-09-17T13:29:07.941176Z","shell.execute_reply":"2025-09-17T13:29:47.772243Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip3-autoremove in /usr/local/lib/python3.11/dist-packages (2.0.1)\nRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from pip3-autoremove) (24.1.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pip3-autoremove) (25.0)\nLooking in indexes: https://download.pytorch.org/whl/cu124\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.29.post3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: accelerate==1.7.0 in /usr/local/lib/python3.11/dist-packages (1.7.0)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (2.6.0+cu124)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (0.33.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (2025.5.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.7.0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.7.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2024.2.0)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (3.2.0)\nCollecting unsloth==2025.5.7\n  Downloading unsloth-2025.5.7-py3-none-any.whl.metadata (47 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth-zoo==2025.5.8\n  Downloading unsloth_zoo-2025.5.8-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (2.6.0+cu124)\nRequirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.0.29.post3)\nCollecting bitsandbytes (from unsloth==2025.5.7)\n  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (25.0)\nCollecting tyro (from unsloth==2025.5.7)\n  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\nCollecting transformers!=4.47.0,==4.51.3 (from unsloth==2025.5.7)\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: datasets>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (3.6.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (1.7.0)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth==2025.5.7)\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.15.2)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.33.1)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.34.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.21.0+cu124)\nCollecting cut_cross_entropy (from unsloth-zoo==2025.5.8)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth-zoo==2025.5.8) (11.2.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from unsloth-zoo==2025.5.8) (2024.11.6)\nCollecting msgspec (from unsloth-zoo==2025.5.8)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (3.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (0.5.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth==2025.5.7) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth==2025.5.7) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth==2025.5.7) (1.3.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (14.0.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth==2025.5.7) (8.7.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth==2025.5.7) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth==2025.5.7)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth==2025.5.7) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (3.12.13)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (2025.6.15)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (2.19.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth==2025.5.7) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth==2025.5.7) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth==2025.5.7) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth==2025.5.7) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth==2025.5.7) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth==2025.5.7) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth==2025.5.7) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth==2025.5.7) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth==2025.5.7) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth==2025.5.7) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth==2025.5.7) (1.17.0)\nDownloading unsloth-2025.5.7-py3-none-any.whl (265 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.5.8-py3-none-any.whl (146 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.6/146.6 kB\u001b[0m \u001b[31m308.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m138.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m346.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m263.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m340.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.9.31-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m292.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m340.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, msgspec, fsspec, tyro, cut_cross_entropy, transformers, trl, unsloth-zoo, bitsandbytes, unsloth\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 fsspec-2025.3.0 msgspec-0.19.0 shtab-1.7.2 transformers-4.51.3 trl-0.15.2 tyro-0.9.31 unsloth-2025.5.7 unsloth-zoo-2025.5.8\nCollecting opensloth==0.1.7\n  Downloading opensloth-0.1.7-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: fastcore<2.0.0,>=1.7.29 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (1.7.29)\nCollecting fire<0.8.0,>=0.7.0 (from opensloth==0.1.7)\n  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\nCollecting jupyterlab<5.0.0,>=4.3.5 (from opensloth==0.1.7)\n  Downloading jupyterlab-4.4.7-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (6.0.2)\nCollecting speedy-utils<0.2.0,>=0.1.20 (from opensloth==0.1.7)\n  Downloading speedy_utils-0.1.30-py3-none-any.whl.metadata (7.2 kB)\nCollecting tensorboard<3.0.0,>=2.19.0 (from opensloth==0.1.7)\n  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting tensorboardx<3.0.0.0,>=2.6.2.2 (from opensloth==0.1.7)\n  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastcore<2.0.0,>=1.7.29->opensloth==0.1.7) (25.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire<0.8.0,>=0.7.0->opensloth==0.1.7) (3.1.0)\nCollecting async-lru>=1.0.0 (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7)\n  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\nRequirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.28.1)\nRequirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.17.1)\nRequirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.1.6)\nRequirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (5.8.1)\nCollecting jupyter-lsp>=2.0.0 (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7)\n  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.12.5)\nRequirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.27.3)\nRequirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.2.4)\nRequirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (75.2.0)\nRequirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.5.1)\nRequirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (5.7.1)\nCollecting bump2version (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7)\n  Downloading bump2version-1.0.1-py2.py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (5.5.2)\nRequirement already satisfied: debugpy in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.8.0)\nRequirement already satisfied: fastprogress in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.0.3)\nCollecting freezegun<2.0.0,>=1.5.1 (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7)\n  Downloading freezegun-1.5.5-py3-none-any.whl.metadata (13 kB)\nCollecting ipdb (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7)\n  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (8.1.5)\nCollecting json-repair<0.41.0,>=0.40.0 (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7)\n  Downloading json_repair-0.40.0-py3-none-any.whl.metadata (11 kB)\nCollecting loguru (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7)\n  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.7.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.26.4)\nCollecting packaging (from fastcore<2.0.0,>=1.7.29->opensloth==0.1.7)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.2.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.11.7)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.32.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.2.2)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.9.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.5.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (1.73.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (3.8.2)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (11.2.1)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (3.20.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (3.1.3)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from freezegun<2.0.0,>=1.5.1->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.9.0.post0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.16.0)\nRequirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (7.34.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (8.6.3)\nRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.1.7)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.6.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (7.0.0)\nRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (24.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.0.2)\nRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (25.1.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.12.0)\nRequirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.5.3)\nRequirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.4.5)\nRequirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (5.10.4)\nRequirement already satisfied: overrides in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (7.7.0)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.22.1)\nRequirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.18.1)\nRequirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.8.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.3.8)\nRequirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.17.0)\nRequirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.12.0)\nRequirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.24.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.5.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipdb->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.4.2)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.2.2)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.0.15)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.0.9)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.14.0)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.6.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.3.1)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.19.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.0.51)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.19.2)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.25.1)\nRequirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.3.0)\nRequirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.1.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.3.0)\nRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.4)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.5.1)\nRequirement already satisfied: testpath in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.6.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.13.4)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.5.13)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.21.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->freezegun<2.0.0,>=1.5.1->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.17.0)\nRequirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (21.2.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2024.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.8.4)\nRequirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.5.1)\nRequirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.0.0)\nRequirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.3.0)\nRequirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (24.11.1)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.2.13)\nRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.17.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.7)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.5.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.22)\nRequirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.9.0.20250516)\nDownloading opensloth-0.1.7-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jupyterlab-4.4.7-py3-none-any.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading speedy_utils-0.1.30-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\nDownloading freezegun-1.5.5-py3-none-any.whl (19 kB)\nDownloading json_repair-0.40.0-py3-none-any.whl (20 kB)\nDownloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bump2version-1.0.1-py2.py3-none-any.whl (22 kB)\nDownloading ipdb-0.13.13-py3-none-any.whl (12 kB)\nDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, loguru, json-repair, fire, bump2version, async-lru, freezegun, ipdb, jupyter-lsp, jupyterlab, tensorboardx, tensorboard, speedy-utils, opensloth\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: jupyter-lsp\n    Found existing installation: jupyter-lsp 1.5.1\n    Uninstalling jupyter-lsp-1.5.1:\n      Successfully uninstalled jupyter-lsp-1.5.1\n  Attempting uninstall: jupyterlab\n    Found existing installation: jupyterlab 3.6.8\n    Uninstalling jupyterlab-3.6.8:\n      Successfully uninstalled jupyterlab-3.6.8\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\njupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, but you have jupyterlab 4.4.7 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.20.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed async-lru-2.0.5 bump2version-1.0.1 fire-0.7.1 freezegun-1.5.5 ipdb-0.13.13 json-repair-0.40.0 jupyter-lsp-2.3.0 jupyterlab-4.4.7 loguru-0.7.3 opensloth-0.1.7 packaging-24.2 speedy-utils-0.1.30 tensorboard-2.20.0 tensorboardx-2.6.4\n✅ TT-12 Dependencies installed:\n🚀 OpenSloth: Multi-GPU training\n🎯 vLLM: Precise inference\n📊 Analysis libraries: scikit-learn, matplotlib, seaborn\n","output_type":"stream"}],"execution_count":7},{"id":"d1abd6fa-8fb9-4f22-a2d5-ccbf78335172","cell_type":"code","source":"import unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:29:57.911217Z","iopub.execute_input":"2025-09-17T13:29:57.911786Z","iopub.status.idle":"2025-09-17T13:30:49.965972Z","shell.execute_reply.started":"2025-09-17T13:29:57.911750Z","shell.execute_reply":"2025-09-17T13:30:49.965391Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-09-17 13:30:18.388049: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758115818.734513      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758115818.832098      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":8},{"id":"b11239ed","cell_type":"markdown","source":"# 1. Configuration and Data Setup","metadata":{}},{"id":"a2d63f89","cell_type":"code","source":"%%writefile constants.py\n# Using base Qwen3 1.7B model from Kaggle input (no internet needed)\nBASE_MODEL_PATH = \"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\"  # Update this path as needed\nLORA_PATH = \"qwen3_1.7b_opensloth_lora_validation/\"  # OpenSloth LoRA output path for validation\nDATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules/\"\n\n# TT-12 Validation Parameters\nTRAINING_DATA_PERCENTAGE = .3  # Controllable % of training data (0.1 = 10%, 1.0 = 100%)\nUSE_STRATIFIED_SAMPLING = True  # Maintain rule distribution when sampling\n\nPOSITIVE_ANSWER = \"Yes\"\nNEGATIVE_ANSWER = \"No\"\nCOMPLETE_PHRASE = \"Answer:\"\nBASE_PROMPT = '''You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.'''\n\nprint(\"✅ Using Qwen3 1.7B model from local Kaggle input\")\nprint(f\"🎯 TT-12: OpenSloth training + vLLM inference with {TRAINING_DATA_PERCENTAGE*100:.0f}% of data\")\nprint(f\"📊 Stratified sampling: {USE_STRATIFIED_SAMPLING}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:28:30.356182Z","iopub.execute_input":"2025-09-17T13:28:30.356467Z","iopub.status.idle":"2025-09-17T13:28:30.362108Z","shell.execute_reply.started":"2025-09-17T13:28:30.356445Z","shell.execute_reply":"2025-09-17T13:28:30.361489Z"}},"outputs":[{"name":"stdout","text":"Overwriting constants.py\n","output_type":"stream"}],"execution_count":4},{"id":"75e2fad7","cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\nfrom datasets import Dataset, load_from_disk\nfrom constants import POSITIVE_ANSWER, NEGATIVE_ANSWER, COMPLETE_PHRASE, BASE_PROMPT, TRAINING_DATA_PERCENTAGE, USE_STRATIFIED_SAMPLING, DATA_PATH\nimport random, numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom unsloth import FastLanguageModel\nfrom trl import SFTConfig, SFTTrainer\nimport os\nrandom.seed(42)\nnp.random.seed(42)\n\n\ndef build_prompt(row):\n    return f\"\"\"\n{BASE_PROMPT}\n\nSubreddit: r/{row[\"subreddit\"]}\nRule: {row[\"rule\"]}\nExamples:\n1) {row[\"positive_example\"]}\n{COMPLETE_PHRASE} Yes\n\n2) {row[\"negative_example\"]}\n{COMPLETE_PHRASE} No\n\n---\nComment: {row[\"body\"]}\n{COMPLETE_PHRASE}\"\"\"\n\n\ndef get_example_based_training_data(data_path):\n    \"\"\"\n    TT-12: Create training data from examples (like test-time training)\n    This trains the model on examples, not actual comments\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Sample data if needed while maintaining rule distribution\n    if TRAINING_DATA_PERCENTAGE < 1.0:\n        if USE_STRATIFIED_SAMPLING:\n            # Stratified sampling to maintain rule distribution\n            train_dataset = train_dataset.groupby('rule', group_keys=False).apply(\n                lambda x: x.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42)\n            ).reset_index(drop=True)\n            print(f\"📊 Stratified sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n        else:\n            # Simple random sampling\n            train_dataset = train_dataset.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42).reset_index(drop=True)\n            print(f\"📊 Random sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n    \n    print(f\"📊 Training data size: {len(train_dataset)} samples\")\n    print(f\"📊 Rule distribution: {train_dataset['rule'].value_counts().to_dict()}\")\n    \n    flatten = []\n    \n    # Create training data from examples (similar to test-time training)\n    for violation_type in [\"positive\", \"negative\"]:\n        for i in range(1, 3):\n            sub_dataset = train_dataset[[\"rule\",\"subreddit\",\n                                        \"positive_example_1\",\"positive_example_2\",\n                                        \"negative_example_1\",\"negative_example_2\"]].copy()\n\n            if violation_type == \"positive\":\n                # Use positive example as the \"body\" to classify\n                body_col = f\"positive_example_{i}\"\n                other_positive_col = f\"positive_example_{3-i}\"  # other positive\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"positive_example\"] = sub_dataset[other_positive_col]\n                # negative_example randomly selected\n                sub_dataset[\"negative_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"negative_example_1\"],\n                    sub_dataset[\"negative_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 1  # Positive examples violate rules\n\n            else:  # violation_type == \"negative\"\n                # Use negative example as the \"body\" to classify\n                body_col = f\"negative_example_{i}\"\n                other_negative_col = f\"negative_example_{3-i}\"\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"negative_example\"] = sub_dataset[other_negative_col]\n                sub_dataset[\"positive_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"positive_example_1\"],\n                    sub_dataset[\"positive_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 0  # Negative examples don't violate rules\n\n            # Drop original candidate columns\n            sub_dataset.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                                      \"negative_example_1\",\"negative_example_2\"], inplace=True)\n\n            flatten.append(sub_dataset)\n\n    # Merge all DataFrames\n    example_training_df = pd.concat(flatten, axis=0)\n    example_training_df = example_training_df.drop_duplicates(ignore_index=True)\n    \n    print(f\"📊 Example-based training dataset: {len(example_training_df)} samples\")\n    print(f\"📊 Positive examples: {sum(example_training_df['rule_violation'] == 1)}\")\n    print(f\"📊 Negative examples: {sum(example_training_df['rule_violation'] == 0)}\")\n    \n    return example_training_df\n\n\ndef get_real_comment_validation_data(data_path):\n    \"\"\"\n    TT-12: Get real comments with labels for validation\n    This is what we actually want to predict\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Use actual comments and their labels for validation\n    validation_df = train_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\",\n                                  \"positive_example_1\",\"positive_example_2\",\n                                  \"negative_example_1\",\"negative_example_2\"]].copy()\n\n    # Randomly select positive_example and negative_example for prompts\n    validation_df[\"positive_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"positive_example_1\"],\n        validation_df[\"positive_example_2\"]\n    )\n    validation_df[\"negative_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"negative_example_1\"],\n        validation_df[\"negative_example_2\"]\n    )\n\n    # Drop original candidate columns\n    validation_df.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                               \"negative_example_1\",\"negative_example_2\"], inplace=True)\n    \n    print(f\"📊 Real comment validation dataset: {len(validation_df)} samples\")\n    print(f\"📊 Rule violations: {sum(validation_df['rule_violation'] == 1)} positive, {sum(validation_df['rule_violation'] == 0)} negative\")\n    \n    return validation_df\n\n\ndef build_dataset_for_opensloth(dataframe, tokenizer):\n    \"\"\"Build dataset for OpenSloth training with proper text formatting\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    \n    # OpenSloth uses a text field\n    dataframe[\"text\"] = dataframe.apply(lambda row: \n        tokenizer.apply_chat_template(\n            [\n                {\"role\": \"user\", \"content\": row[\"prompt\"]},\n                {\"role\": \"assistant\", \"content\": POSITIVE_ANSWER if row[\"rule_violation\"] == 1 else NEGATIVE_ANSWER},\n            ],\n            tokenize=False,\n            add_generation_prompt=False,\n        ),\n        axis=1\n    )\n    \n    dataset = Dataset.from_pandas(dataframe[[\"text\"]])\n    return dataset\n\n\ndef build_validation_dataset(dataframe):\n    \"\"\"Build dataset for validation (keep labels for evaluation)\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    dataframe = dataframe[[\"prompt\", \"rule_violation\"]]  # Keep true labels for evaluation\n    dataset = Dataset.from_pandas(dataframe)\n    return dataset\n\ndef cache_dataset(cache_path):\n    if os.path.exists(cache_path):\n        print(f\"💾 Loading cached dataset from {cache_path}\")\n        return\n\n    print(f\"💾 Caching dataset to {cache_path}\")\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\",\n        max_seq_length=2048,\n        load_in_4bit=True,\n    )\n    \n    print(tokeinzer.chat_template)\n    tokenizer.chat_template = \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|im_start|>user\\n' + message['content'] + '<|im_end|>\\n<|im_start|>assistant\\n' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + '<|im_end|>' }}{% endif %}{% endfor %}\"\n    \n    \n    train_df = get_example_based_training_data(DATA_PATH)\n    dataset = build_dataset_for_opensloth(train_df, tokenizer)\n    \n    # This is a bit of a hack. SFTTrainer is used for its dataset processing\n    trainer = SFTTrainer(\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=dataset,\n        args=SFTConfig(\n            dataset_text_field=\"text\",\n            max_seq_length=2048,\n            dataset_num_proc=2,\n            packing=True,\n        ),\n    )\n    \n    trainer.train_dataset.save_to_disk(cache_path)\n    print(f\"✅ Dataset cached to {cache_path}\")\n\ndef get_cached_dataset(cache_path):\n    if not os.path.exists(cache_path):\n        raise RuntimeError(\"Dataset cache not found. Please run the caching step first.\")\n    return load_from_disk(cache_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:28:39.497544Z","iopub.execute_input":"2025-09-17T13:28:39.497891Z","iopub.status.idle":"2025-09-17T13:28:39.506575Z","shell.execute_reply.started":"2025-09-17T13:28:39.497869Z","shell.execute_reply":"2025-09-17T13:28:39.505787Z"}},"outputs":[{"name":"stdout","text":"Writing utils.py\n","output_type":"stream"}],"execution_count":5},{"id":"60f8a561-d945-4781-be7c-a8ddbf0f045b","cell_type":"code","source":"from transformers import TextStreamer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:32:20.861531Z","iopub.execute_input":"2025-09-17T13:32:20.861806Z","iopub.status.idle":"2025-09-17T13:32:20.866154Z","shell.execute_reply.started":"2025-09-17T13:32:20.861784Z","shell.execute_reply":"2025-09-17T13:32:20.865424Z"}},"outputs":[],"execution_count":10},{"id":"ae027499","cell_type":"code","source":"from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\",\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\nprint(tokenizer.chat_template)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:32:29.772621Z","iopub.execute_input":"2025-09-17T13:32:29.773097Z","iopub.status.idle":"2025-09-17T13:32:54.854621Z","shell.execute_reply.started":"2025-09-17T13:32:29.773071Z","shell.execute_reply":"2025-09-17T13:32:54.853879Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0].role == 'system' %}\n        {{- messages[0].content + '\\n\\n' }}\n    {%- endif %}\n    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0].role == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n{%- for forward_message in messages %}\n    {%- set index = (messages|length - 1) - loop.index0 %}\n    {%- set message = messages[index] %}\n    {%- set tool_start = '<tool_response>' %}\n    {%- set tool_start_length = tool_start|length %}\n    {%- set start_of_message = message.content[:tool_start_length] %}\n    {%- set tool_end = '</tool_response>' %}\n    {%- set tool_end_length = tool_end|length %}\n    {%- set start_pos = (message.content|length) - tool_end_length %}\n    {%- if start_pos < 0 %}\n        {%- set start_pos = 0 %}\n    {%- endif %}\n    {%- set end_of_message = message.content[start_pos:] %}\n    {%- if ns.multi_step_tool and message.role == \"user\" and not(start_of_message == tool_start and end_of_message == tool_end) %}\n        {%- set ns.multi_step_tool = false %}\n        {%- set ns.last_query_index = index %}\n    {%- endif %}\n{%- endfor %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {%- set content = message.content %}\n        {%- set reasoning_content = '' %}\n        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n            {%- set reasoning_content = message.reasoning_content %}\n        {%- else %}\n            {%- if '</think>' in message.content %}\n                {%- set content = (message.content.split('</think>')|last).lstrip('\\n') %}\n                {%- set reasoning_content = (message.content.split('</think>')|first).rstrip('\\n') %}\n                {%- set reasoning_content = (reasoning_content.split('<think>')|last).lstrip('\\n') %}\n            {%- endif %}\n        {%- endif %}\n        {%- if loop.index0 > ns.last_query_index %}\n            {%- if loop.last or (not loop.last and reasoning_content) %}\n                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n            {%- else %}\n                {{- '<|im_start|>' + message.role + '\\n' + content }}\n            {%- endif %}\n        {%- else %}\n            {{- '<|im_start|>' + message.role + '\\n' + content }}\n        {%- endif %}\n        {%- if message.tool_calls %}\n            {%- for tool_call in message.tool_calls %}\n                {%- if (loop.first and content) or (not loop.first) %}\n                    {{- '\\n' }}\n                {%- endif %}\n                {%- if tool_call.function %}\n                    {%- set tool_call = tool_call.function %}\n                {%- endif %}\n                {{- '<tool_call>\\n{\"name\": \"' }}\n                {{- tool_call.name }}\n                {{- '\", \"arguments\": ' }}\n                {%- if tool_call.arguments is string %}\n                    {{- tool_call.arguments }}\n                {%- else %}\n                    {{- tool_call.arguments | tojson }}\n                {%- endif %}\n                {{- '}\\n</tool_call>' }}\n            {%- endfor %}\n        {%- endif %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n    {%- if enable_thinking is defined and enable_thinking is false %}\n        {{- '<think>\\n\\n</think>\\n\\n' }}\n    {%- endif %}\n{%- endif %}\n","output_type":"stream"}],"execution_count":12},{"id":"38d2447b","cell_type":"code","source":"from utils import *\ntrain_df = get_example_based_training_data(DATA_PATH)\ndataset = build_dataset_for_opensloth(train_df, tokenizer)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:33:48.721088Z","iopub.execute_input":"2025-09-17T13:33:48.721750Z","iopub.status.idle":"2025-09-17T13:33:49.202280Z","shell.execute_reply.started":"2025-09-17T13:33:48.721717Z","shell.execute_reply":"2025-09-17T13:33:49.201517Z"}},"outputs":[{"name":"stdout","text":"✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: OpenSloth training + vLLM inference with 30% of data\n📊 Stratified sampling: True\n📊 Stratified sampling: 609 samples (30%)\n📊 Training data size: 609 samples\n📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 305, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 304}\n📊 Example-based training dataset: 2435 samples\n📊 Positive examples: 1218\n📊 Negative examples: 1217\n","output_type":"stream"}],"execution_count":13},{"id":"cfbe3537","cell_type":"code","source":"print(dataset[9])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:34:13.603075Z","iopub.execute_input":"2025-09-17T13:34:13.603348Z","iopub.status.idle":"2025-09-17T13:34:13.607960Z","shell.execute_reply.started":"2025-09-17T13:34:13.603327Z","shell.execute_reply":"2025-09-17T13:34:13.607243Z"}},"outputs":[{"name":"stdout","text":"{'text': '<|im_start|>user\\n\\nYou are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.\\n\\nSubreddit: r/The_Donald\\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nExamples:\\n1) Free paypal cards here!! https://www.pointsprizes.com/ref/13226\\nAnswer: Yes\\n\\n2) **HD** Stream [English 1](http://www.zifootball.us/p/channel1.html) | [English 2](http://www.zifootball.us/p/channel2.html) | Ad Overlays: 4  | Mobile : Yes\\n\\nUpvote if you like the streams\\nAnswer: No\\n\\n---\\nComment: bad hookers waiting for you here http://cbvidfree.com/?id44838\\nAnswer:<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\nYes<|im_end|>\\n'}\n","output_type":"stream"}],"execution_count":15},{"id":"913d205b","cell_type":"code","source":"FastLanguageModel.for_inference(model) # Enable native 2x faster inference\ntext_streamer = TextStreamer(tokenizer)\ninputs = tokenizer(dataset[666]['text'], return_tensors=\"pt\").to(\"cuda\")\n\noutput = model.generate( **inputs ,streamer = text_streamer, max_new_tokens = 512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:45:02.522335Z","iopub.execute_input":"2025-09-17T13:45:02.523031Z","iopub.status.idle":"2025-09-17T13:45:02.675895Z","shell.execute_reply.started":"2025-09-17T13:45:02.522996Z","shell.execute_reply":"2025-09-17T13:45:02.675057Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>user\n\nYou are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\nAnswer:<|im_end|>\n<|im_start|>assistant\n<think>\n\n</think>\n\nYes<|im_end|>\n<|endoftext|>\n","output_type":"stream"}],"execution_count":33},{"id":"a7083c80","cell_type":"code","source":"\n# Decode the full output to readable text\ndecoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(\"\\n\" + \"=\"*50)\nprint(\"🎯 Full Decoded Output (including thinking):\")\nprint(decoded_output)\nprint(\"=\"*512)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:45:05.486062Z","iopub.execute_input":"2025-09-17T13:45:05.486365Z","iopub.status.idle":"2025-09-17T13:45:05.492695Z","shell.execute_reply.started":"2025-09-17T13:45:05.486342Z","shell.execute_reply":"2025-09-17T13:45:05.491884Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\n🎯 Full Decoded Output (including thinking):\nuser\n\nYou are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\nAnswer:\nassistant\n<think>\n\n</think>\n\nYes\n\n================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n","output_type":"stream"}],"execution_count":34},{"id":"8402a971-332b-4ef7-a273-b985a94638cf","cell_type":"markdown","source":"Trying Thinking","metadata":{}},{"id":"c0f69c75-8049-4d14-adb8-ba8bb08b8f9f","cell_type":"code","source":"\n# Thinking prompt (replace with your dataset[0]['text'] if needed)\nthinking_prompt = \"\"\"You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule.\n\nFirst, think step-by-step about the comment and the rule.\nThen, conclude with your Single final answer: 'Answer: Yes' or 'Answer: No'.Full stop after answer.Say nothing after giving out the answer.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\n\n\"\"\"\nmessages = [\n    {\"role\": \"user\", \"content\": thinking_prompt},\n    {\"role\": \"assistant\", \"content\": \"<think>\"}\n]\nthinking_input = tokenizer.apply_chat_template(messages, tokenize=False)\n# Tokenize the input\ninputs = tokenizer(thinking_prompt, return_tensors=\"pt\").to(\"cuda\")\n\n# Generate with Qwen Thinking Mode settings\ntext_streamer = TextStreamer(tokenizer)\noutput = model.generate(\n    **inputs,\n    streamer=text_streamer,\n    max_new_tokens=500,  # Allow room for thinking\n    temperature=0.6,     # Qwen Thinking Mode: Balanced creativity\n    top_p=0.95,          # Qwen Thinking Mode: Diverse selection\n    top_k=20,            # Qwen Thinking Mode: Limit to top 20 tokens\n    min_p=0.0,           # Qwen Thinking Mode: No minimum probability threshold\n    do_sample=True,      # Enable sampling for creativity\n    #stop=[\"\\n\"],         # Stop after newline to prevent repetition\n    pad_token_id=tokenizer.eos_token_id,\n)\n\n# Decode the full output to readable text\ndecoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(\"\\n\" + \"=\"*500)\nprint(\"🎯 Full Decoded Output (with thinking):\")\nprint(decoded_output)\nprint(\"=\"*500)\n\n# Optional: Extract just the new part (after the prompt)\nnew_part = decoded_output[len(thinking_prompt):].strip()\nprint(\"\\n🎯 New Generated Part:\")\nprint(new_part)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T14:06:35.941075Z","iopub.execute_input":"2025-09-17T14:06:35.941369Z","iopub.status.idle":"2025-09-17T14:06:59.068604Z","shell.execute_reply.started":"2025-09-17T14:06:35.941345Z","shell.execute_reply":"2025-09-17T14:06:59.067704Z"}},"outputs":[{"name":"stdout","text":"You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule.\n\nFirst, think step-by-step about the comment and the rule.\nThen, conclude with your Single final answer: 'Answer: Yes' or 'Answer: No'.Full stop after answer.Say nothing after giving out the answer.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\n\nAnswer:\nStep 1: Identify the key elements in the comment.\nThe comment starts with \"39 http://MySexFind.com - find girl for sex now 39!\" which includes a URL and the phrase \"find girl for sex now\".\n\nStep 2: Determine if the comment contains any prohibited content.\nThe URL is a referral link, and the comment promotes a service for finding girls for sex, which is likely adult content.\n\nStep 3: Compare with the rule.\nThe rule prohibits unsolicited advertising and promotional content, including referral links and adult content.\n\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2997580609.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Generate with Qwen Thinking Mode settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mtext_streamer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextStreamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m output = model.generate(\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mstreamer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_streamer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36munsloth_fast_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     \u001b[0;31m# Mixed precision autocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1582\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3434\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3436\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     ) -> Union[Tuple, CausalLMOutputWithPast]:\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             outputs = fast_forward_inference(\n\u001b[0m\u001b[1;32m   1034\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaModel_fast_forward_inference_custom\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# residual = X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m             X = fast_rms_layernorm_inference(\n\u001b[0m\u001b[1;32m    978\u001b[0m                 \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfast_rms_layernorm_inference\u001b[0;34m(self, X, XX, XX2, variance)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mXX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":51},{"id":"142e8d6c","cell_type":"code","source":"%%writefile train_opensloth.py\nfrom opensloth.opensloth_config import (\n    FastModelArgs,\n    LoraArgs,\n    OpenSlothConfig,\n    TrainingArguments,\n)\nfrom opensloth.scripts.opensloth_sft_trainer import run_mp_training, setup_envs\nfrom constants import BASE_MODEL_PATH, LORA_PATH\nimport torch\n\n# OpenSloth Configuration for 2 GPUs\nGLOBAL_BZ = 16\nDEVICES = [i for i in range(torch.cuda.device_count())]\nBZ = 2  # Batch size per device\n\nopensloth_config = OpenSlothConfig(\n    data_cache_path=\"data/cache_qwen3_dataset_for_opensloth/\",\n    devices=DEVICES,\n    fast_model_args=FastModelArgs(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,\n        load_in_4bit=True,\n        local_files_only=True,\n        trust_remote_code=True,\n    ),\n    lora_args=LoraArgs(\n        r=16,\n        lora_alpha=16,\n        target_modules=[\n            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n            \"gate_proj\", \"up_proj\", \"down_proj\",\n        ],\n        lora_dropout=0,\n        bias=\"none\",\n        use_rslora=False,\n    ),\n    sequence_packing=True,\n)\n\ntraining_config = TrainingArguments(\n    output_dir=LORA_PATH,\n    per_device_train_batch_size=BZ,\n    gradient_accumulation_steps=GLOBAL_BZ // (len(DEVICES) * BZ) if DEVICES else 1,\n    learning_rate=1e-5,\n    logging_steps=1,\n    num_train_epochs=1, # Using max_steps instead\n    max_steps=60,\n    lr_scheduler_type=\"linear\",\n    warmup_steps=5,\n    save_total_limit=2,\n    save_strategy=\"steps\",\n    save_steps=20,\n    weight_decay=0.01,\n    optim=\"adamw_8bit\",\n    seed=3407,\n    report_to=\"none\",\n)\n\n\nif __name__ == \"__main__\":\n    import os\n\n    print(f\"Global batch size: {len(DEVICES) * BZ * training_config.gradient_accumulation_steps}\")\n    print(f\"Gradient accumulation steps: {training_config.gradient_accumulation_steps}\")\n\n    setup_envs(opensloth_config, training_config)\n    run_mp_training(opensloth_config.devices, opensloth_config, training_config)\n    \n    print(f\"✅ OpenSloth training completed! LoRA adapters saved to: {LORA_PATH}\")\n    print(\"🎯 Ready for vLLM inference!\")\n","metadata":{},"outputs":[],"execution_count":null},{"id":"8d69f944","cell_type":"markdown","source":"# 🎯 2x T4 GPU Optimization Guide\n\n## ⚡ **Multi-GPU Configuration for TT-11**\n\n### **Your Setup: 2x T4 (28GB Total VRAM)**\n- **GPU 0**: ~14GB VRAM\n- **GPU 1**: ~14GB VRAM\n- **Total**: 28GB available for training\n\n### **Optimizations Applied:**\n\n#### **1. Model Distribution**\n```python\ndevice_map=\"auto\"  # Automatic distribution across GPUs\nmax_memory={0: \"13GB\", 1: \"13GB\"}  # Reserve 1GB per GPU for operations\n```\n\n#### **2. Batch Size Scaling**\n```python\nper_device_train_batch_size=4,  # 4 samples per GPU (8 total)\ngradient_accumulation_steps=2,  # Effective batch = 4*2*2 = 16\n```\n\n#### **3. Memory Optimizations**\n```python\nload_in_4bit=True,              # 4-bit quantization saves ~75% memory\nuse_gradient_checkpointing=True, # Trade compute for memory\ndataloader_pin_memory=False,     # Let Unsloth handle memory\n```\n\n#### **4. Multi-GPU Training**\n```python\ndataloader_num_workers=4,        # Parallel data loading\nddp_find_unused_parameters=False, # DDP optimization\nddp_broadcast_buffers=False,     # Reduce communication\n```\n\n### **Expected Performance:**\n- **Training Speed**: 3x-6x faster than single GPU\n- **Memory Usage**: ~12-13GB per GPU\n- **Effective Batch**: 16 samples (vs 4 on single GPU)\n- **Total Time**: 5-8 minutes for full training\n\n### **Troubleshooting 2x T4:**\n\n#### **If you get OOM (Out of Memory):**\n```python\n# Reduce batch size\nper_device_train_batch_size=2,   # 2 per GPU instead of 4\ngradient_accumulation_steps=4,   # Keep effective batch size\n\n# Or reduce sequence length\nmax_seq_length=1024,             # Shorter sequences\n```\n\n#### **If training is slower than expected:**\n```python\n# Check GPU utilization\nnvidia-smi  # Should show ~90%+ on both GPUs\n\n# Increase batch size if memory allows\nper_device_train_batch_size=6,   # Try larger batches\n```\n\n#### **Memory Distribution Check:**\n```python\nprint(f\"Available GPUs: {torch.cuda.device_count()}\")\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_properties(i).total_memory // 1024**3}GB\")\n```","metadata":{}},{"id":"910e6893","cell_type":"code","source":"%%writefile validation_vllm.py\nimport os\nos.environ[\"VLLM_USE_V1\"] = \"0\"\n\nimport vllm\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\nfrom vllm.lora.request import LoRARequest\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_vllm():\n    \"\"\"Run validation using OpenSloth-trained model with vLLM for precise AUC\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"🔍 Running validation on {len(val_dataset)} real comments\")\n    \n    # 🎯 VLLM: Initialize with OpenSloth LoRA support for precise probabilities\n    llm = vllm.LLM(\n        BASE_MODEL_PATH,\n        tensor_parallel_size=torch.cuda.device_count(),\n        gpu_memory_utilization=0.90,\n        trust_remote_code=True,\n        dtype=\"half\",\n        enforce_eager=True,\n        max_model_len=512,\n        disable_log_stats=True,\n        enable_prefix_caching=True,\n        enable_lora=True,\n        max_lora_rank=64,\n        local_files_only=True,\n    )\n\n    tokenizer = llm.get_tokenizer()\n\n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n\n    # 🎯 VLLM: Generate with OpenSloth LoRA for most accurate probabilities\n    outputs = llm.generate(\n        texts,\n        vllm.SamplingParams(\n            skip_special_tokens=True,\n            max_tokens=1,\n            logprobs=20,\n        ),\n        use_tqdm=True,\n        lora_request=LoRARequest(\"opensloth_lora\", 1, LORA_PATH)  # Load OpenSloth LoRA\n    )\n\n    # Extract predictions and probabilities with vLLM precision\n    predictions = []\n    probabilities = []\n    \n    yes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\n    no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n    \n    for out in outputs:\n        log_probs = out.outputs[0].logprobs[0]\n        \n        log_prob_yes = log_probs.get(yes_token_id)\n        log_prob_no = log_probs.get(no_token_id)\n        \n        if log_prob_yes is not None and log_prob_no is not None:\n            if log_prob_yes.logprob > log_prob_no.logprob:\n                predictions.append(1)\n            else:\n                predictions.append(0)\n            \n            exp_pos = np.exp(log_prob_yes.logprob)\n            exp_neg = np.exp(log_prob_no.logprob)\n            prob_positive = exp_pos / (exp_pos + exp_neg)\n            probabilities.append(prob_positive)\n        else:\n            predictions.append(0)\n            probabilities.append(0.5)\n\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"📊 TT-12 VALIDATION RESULTS (OpenSloth + vLLM)\")\n    print(\"=\" * 60)\n    print(f\"🎯 Accuracy:  {accuracy:.4f}\")\n    print(f\"🎯 F1 Score:  {f1:.4f}\")\n    print(f\"🎯 Precision: {precision:.4f}\")\n    print(f\"🎯 Recall:    {recall:.4f}\")\n    print(f\"🎯 AUC Score: {auc:.4f} (High-precision vLLM)\")\n    print(\"=\" * 60)\n    \n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n📈 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    print(\"\\n📋 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy, 'f1': f1, 'precision': precision,\n        'recall': recall, 'auc': auc, 'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-12: OpenSloth Training + vLLM Validation Results', fontsize=16, fontweight='bold')\n    \n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (vLLM High-Precision)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    pos_probs = [p for p, t in zip(probabilities, true_labels) if t == 1]\n    neg_probs = [p for p, t in zip(probabilities, true_labels) if t == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (vLLM Precision)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics[k] for k in ['accuracy', 'f1', 'precision', 'recall', 'auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (OpenSloth + vLLM)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt12_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n📊 PERFORMANCE BY RULE (vLLM High-Precision AUC):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        rule_auc = roc_auc_score(rule_true, rule_prob) if len(np.unique(rule_true)) > 1 else np.nan\n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\\n  Samples: {len(rule_data)}\\n  Accuracy: {rule_acc:.3f}\\n  F1 Score: {rule_f1:.3f}\\n  AUC Score: {rule_auc:.3f}\\n\")\n        \n        rule_metrics.append({'rule': rule, 'samples': len(rule_data), 'accuracy': rule_acc, 'f1': rule_f1, 'auc': rule_auc})\n    \n    analysis_df.to_csv('/kaggle/working/tt12_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt12_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"🔬 TT-12: OpenSloth Training + vLLM Validation\")\n    print(\"🚀 Multi-GPU training + High-precision inference!\")\n    print(\"=\" * 70)\n    \n    true_labels, predictions, probabilities, val_df = run_validation_vllm()\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"✅ TT-12 Validation completed!\")\n    print(\"📈 Visualizations saved: /kaggle/working/tt12_validation_results.png\")\n    print(\"📊 Detailed results: /kaggle/working/tt12_detailed_results.csv\")\n    print(\"📋 Rule metrics: /kaggle/working/tt12_rule_metrics.csv\")\n    \nif __name__ == \"__main__\":\n    main()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"7fd0717c","cell_type":"code","source":"%%writefile validation_transformers.py\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\nfrom tqdm import tqdm\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_transformers():\n    \"\"\"Run validation using standard transformers with OpenSloth LoRA - Universal compatibility\"\"\"\n    \n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"🔍 Running validation on {len(val_dataset)} real comments (Transformers)\")\n    \n    print(\"📥 Loading base model and tokenizer...\")\n    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True, local_files_only=True)\n    model = AutoModelForCausalLM.from_pretrained(\n        BASE_MODEL_PATH,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        local_files_only=True,\n    )\n    \n    print(\"🔗 Loading OpenSloth LoRA adapters...\")\n    model = PeftModel.from_pretrained(model, LORA_PATH)\n    model = model.merge_and_unload()\n    model.eval()\n    \n    yes_token_id = tokenizer.encode(\"Yes\", add_special_tokens=False)[0]\n    no_token_id = tokenizer.encode(\"No\", add_special_tokens=False)[0]\n    \n    print(f\"🎯 Token IDs: Yes={yes_token_id}, No={no_token_id}\")\n    \n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n    \n    predictions, probabilities = [], []\n    batch_size = 8\n    \n    print(\"🚀 Running inference...\")\n    \n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch_texts = texts[i:i+batch_size]\n        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n            next_token_logits = outputs.logits[:, -1, :]\n            \n            yes_logits = next_token_logits[:, yes_token_id]\n            no_logits = next_token_logits[:, no_token_id]\n            \n            combined_logits = torch.stack([no_logits, yes_logits], dim=1)\n            probs = torch.softmax(combined_logits, dim=1)\n            \n            predictions.extend(torch.argmax(probs, dim=1).cpu().tolist())\n            probabilities.extend(probs[:, 1].cpu().tolist())\n    \n    print(\"✅ Inference completed!\")\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"📊 TT-12 VALIDATION RESULTS (OpenSloth + Transformers)\")\n    print(\"=\" * 60)\n    print(f\"🎯 Accuracy:  {accuracy:.4f}\")\n    print(f\"🎯 F1 Score:  {f1:.4f}\")\n    print(f\"🎯 Precision: {precision:.4f}\")\n    print(f\"🎯 Recall:    {recall:.4f}\")\n    print(f\"🎯 AUC Score: {auc:.4f} (Standard Transformers)\")\n    print(\"=\" * 60)\n    \n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n📈 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    print(\"\\n📋 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall, 'auc': auc, 'confusion_matrix': cm}\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-12: OpenSloth Training + Transformers Validation Results', fontsize=16, fontweight='bold')\n    \n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (Transformers)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    pos_probs = [p for p, t in zip(probabilities, true_labels) if t == 1]\n    neg_probs = [p for p, t in zip(probabilities, true_labels) if t == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (Transformers)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics[k] for k in ['accuracy', 'f1', 'precision', 'recall', 'auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (OpenSloth + Transformers)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt12_transformers_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n📊 PERFORMANCE BY RULE (Transformers):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        rule_auc = roc_auc_score(rule_true, rule_prob) if len(np.unique(rule_true)) > 1 else np.nan\n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\\n  Samples: {len(rule_data)}\\n  Accuracy: {rule_acc:.3f}\\n  F1 Score: {rule_f1:.3f}\\n  AUC Score: {rule_auc:.3f}\\n\")\n        \n        rule_metrics.append({'rule': rule, 'samples': len(rule_data), 'accuracy': rule_acc, 'f1': rule_f1, 'auc': rule_auc})\n    \n    analysis_df.to_csv('/kaggle/working/tt12_transformers_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt12_transformers_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"🔬 TT-12: OpenSloth Training + Transformers Validation\")\n    print(\"🚀 Multi-GPU training + Universal compatibility!\")\n    print(\"=\" * 70)\n    \n    true_labels, predictions, probabilities, val_df = run_validation_transformers()\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"✅ TT-12 Transformers Validation completed!\")\n    print(\"📈 Visualizations saved: /kaggle/working/tt12_transformers_validation_results.png\")\n    print(\"📊 Detailed results: /kaggle/working/tt12_transformers_detailed_results.csv\")\n    print(\"📋 Rule metrics: /kaggle/working/tt12_transformers_rule_metrics.csv\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"12b04fb3","cell_type":"code","source":"from utils import cache_dataset\ncache_dataset(cache_path=\"data/cache_qwen3_dataset_for_opensloth/\")","metadata":{},"outputs":[],"execution_count":null},{"id":"e6f23a14","cell_type":"code","source":"!python train_opensloth.py","metadata":{},"outputs":[],"execution_count":null},{"id":"096ef5eb","cell_type":"markdown","source":"# Appendix: View Results","metadata":{}},{"id":"d7ef0067","cell_type":"code","source":"#@title **Run Validation**\n#@markdown Choose your validation method:\nVALIDATION_METHOD = \"vLLM\" #@param [\"vLLM\", \"Transformers\"]\n\nif VALIDATION_METHOD == \"vLLM\":\n    print(\"🚀 Running vLLM validation for maximum speed and precision...\")\n    !python validation_vllm.py\nelse:\n    print(\"⚙️ Running Transformers validation for universal compatibility...\")\n    !python validation_transformers.py","metadata":{},"outputs":[],"execution_count":null},{"id":"0d85e3f4","cell_type":"code","source":"from IPython.display import Image, display\n\n# Display the validation results image\nif VALIDATION_METHOD == \"vLLM\":\n    display(Image(filename='/kaggle/working/tt12_validation_results.png'))\nelse:\n    display(Image(filename='/kaggle/working/tt12_transformers_validation_results.png'))","metadata":{},"outputs":[],"execution_count":null},{"id":"681bab57","cell_type":"code","source":"import pandas as pd\n\n# Display the detailed results CSV\nif VALIDATION_METHOD == \"vLLM\":\n    df_detailed = pd.read_csv('/kaggle/working/tt12_detailed_results.csv')\nelse:\n    df_detailed = pd.read_csv('/kaggle/working/tt12_transformers_detailed_results.csv')\n\ndf_detailed.head()","metadata":{},"outputs":[],"execution_count":null}]}