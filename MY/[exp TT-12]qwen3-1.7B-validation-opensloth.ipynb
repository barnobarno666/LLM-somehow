{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":583951,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":436166,"modelId":452934}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"43fb082f","cell_type":"code","source":"# Install dependencies - OpenSloth + vLLM + Analysis setup\n!pip install pip3-autoremove\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu124\n!pip install accelerate==1.7.0\n!pip install triton==3.2.0 \n\n!pip install unsloth==2025.5.7 unsloth-zoo==2025.5.8 --no-cache\n\n!pip install opensloth==0.1.7 \n\n!pip install TextStreamer\n\nprint(\"✅ TT-12 Dependencies installed:\")\nprint(\"🚀 OpenSloth: Multi-GPU training\")\nprint(\"🎯 vLLM: Precise inference\") \nprint(\"📊 Analysis libraries: scikit-learn, matplotlib, seaborn\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:51:22.871347Z","iopub.execute_input":"2025-09-18T12:51:22.872003Z","iopub.status.idle":"2025-09-18T12:51:44.895293Z","shell.execute_reply.started":"2025-09-18T12:51:22.871969Z","shell.execute_reply":"2025-09-18T12:51:44.894395Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip3-autoremove in /usr/local/lib/python3.11/dist-packages (2.0.1)\nRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from pip3-autoremove) (24.1.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pip3-autoremove) (24.2)\nLooking in indexes: https://download.pytorch.org/whl/cu124\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.29.post3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: accelerate==1.7.0 in /usr/local/lib/python3.11/dist-packages (1.7.0)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (2.6.0+cu124)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (0.33.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (2025.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.7.0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.7.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2024.2.0)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (3.2.0)\nRequirement already satisfied: unsloth==2025.5.7 in /usr/local/lib/python3.11/dist-packages (2025.5.7)\nRequirement already satisfied: unsloth-zoo==2025.5.8 in /usr/local/lib/python3.11/dist-packages (2025.5.8)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (2.6.0+cu124)\nRequirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.0.29.post3)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.47.0)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (24.2)\nRequirement already satisfied: tyro in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.9.31)\nRequirement already satisfied: transformers!=4.47.0,==4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (4.51.3)\nRequirement already satisfied: datasets>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (3.6.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (1.7.0)\nRequirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.15.2)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.15.2)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.33.1)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.34.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.21.0+cu124)\nRequirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (from unsloth-zoo==2025.5.8) (25.1.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth-zoo==2025.5.8) (11.2.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from unsloth-zoo==2025.5.8) (2024.11.6)\nRequirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth-zoo==2025.5.8) (0.19.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (3.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (0.5.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (2025.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth==2025.5.7) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth==2025.5.7) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth==2025.5.7) (1.3.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (14.0.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth==2025.5.7) (8.7.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth==2025.5.7) (0.16)\nRequirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth==2025.5.7) (1.7.2)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth==2025.5.7) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (3.12.13)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (2025.6.15)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (2.19.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth==2025.5.7) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth==2025.5.7) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth==2025.5.7) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth==2025.5.7) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth==2025.5.7) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth==2025.5.7) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth==2025.5.7) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth==2025.5.7) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth==2025.5.7) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth==2025.5.7) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth==2025.5.7) (1.17.0)\nRequirement already satisfied: opensloth==0.1.7 in /usr/local/lib/python3.11/dist-packages (0.1.7)\nRequirement already satisfied: fastcore<2.0.0,>=1.7.29 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (1.7.29)\nRequirement already satisfied: fire<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (0.7.1)\nRequirement already satisfied: jupyterlab<5.0.0,>=4.3.5 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (4.4.7)\nRequirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (6.0.2)\nRequirement already satisfied: speedy-utils<0.2.0,>=0.1.20 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (0.1.30)\nRequirement already satisfied: tensorboard<3.0.0,>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (2.20.0)\nRequirement already satisfied: tensorboardx<3.0.0.0,>=2.6.2.2 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (2.6.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastcore<2.0.0,>=1.7.29->opensloth==0.1.7) (24.2)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire<0.8.0,>=0.7.0->opensloth==0.1.7) (3.1.0)\nRequirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.0.5)\nRequirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.28.1)\nRequirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.17.1)\nRequirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.1.6)\nRequirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (5.8.1)\nRequirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.3.0)\nRequirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.12.5)\nRequirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.27.3)\nRequirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.2.4)\nRequirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (75.2.0)\nRequirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.5.1)\nRequirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (5.7.1)\nRequirement already satisfied: bump2version in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.0.1)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (5.5.2)\nRequirement already satisfied: debugpy in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.8.0)\nRequirement already satisfied: fastprogress in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.0.3)\nRequirement already satisfied: freezegun<2.0.0,>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.5.5)\nRequirement already satisfied: ipdb in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.13.13)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (8.1.5)\nRequirement already satisfied: json-repair<0.41.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.40.0)\nRequirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.7.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.7.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.2.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.11.7)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.32.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.2.2)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.9.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.5.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (1.73.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (3.8.2)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (11.2.1)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (3.20.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (3.1.3)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from freezegun<2.0.0,>=1.5.1->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.9.0.post0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.16.0)\nRequirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (7.34.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (8.6.3)\nRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.1.7)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.6.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (7.0.0)\nRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (24.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.0.2)\nRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (25.1.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.12.0)\nRequirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.5.3)\nRequirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.4.5)\nRequirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (5.10.4)\nRequirement already satisfied: overrides in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (7.7.0)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.22.1)\nRequirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.18.1)\nRequirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.8.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.3.8)\nRequirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.17.0)\nRequirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.12.0)\nRequirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.24.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.5.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipdb->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.4.2)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.2.2)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.0.15)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.0.9)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.14.0)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.6.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.3.1)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.19.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.0.51)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.19.2)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.25.1)\nRequirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.3.0)\nRequirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.1.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.3.0)\nRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.4)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.5.1)\nRequirement already satisfied: testpath in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.6.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.13.4)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.5.13)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.21.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->freezegun<2.0.0,>=1.5.1->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.17.0)\nRequirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (21.2.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2024.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.8.4)\nRequirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.5.1)\nRequirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.0.0)\nRequirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.3.0)\nRequirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (24.11.1)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.2.13)\nRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.17.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.7)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.5.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.22)\nRequirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.9.0.20250516)\n\u001b[31mERROR: Could not find a version that satisfies the requirement TextStreamer (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for TextStreamer\u001b[0m\u001b[31m\n\u001b[0m✅ TT-12 Dependencies installed:\n🚀 OpenSloth: Multi-GPU training\n🎯 vLLM: Precise inference\n📊 Analysis libraries: scikit-learn, matplotlib, seaborn\n","output_type":"stream"}],"execution_count":2},{"id":"d1abd6fa-8fb9-4f22-a2d5-ccbf78335172","cell_type":"code","source":"import unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:51:44.897152Z","iopub.execute_input":"2025-09-18T12:51:44.897441Z","iopub.status.idle":"2025-09-18T12:52:22.634606Z","shell.execute_reply.started":"2025-09-18T12:51:44.897416Z","shell.execute_reply":"2025-09-18T12:52:22.634041Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-09-18 12:51:58.086166: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758199918.305956      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758199918.369715      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"id":"b11239ed","cell_type":"markdown","source":"# 1. Configuration and Data Setup","metadata":{}},{"id":"a2d63f89","cell_type":"code","source":"%%writefile constants.py\n# Using base Qwen3 1.7B model from Kaggle input (no internet needed)\nBASE_MODEL_PATH = \"/kaggle/input/qwen3-1.7b-base-unsloth-bnb-4bit/transformers/default/1\"  # Update this path as needed\nLORA_PATH = \"qwen3_1.7b_opensloth_lora_validation/\"  # OpenSloth LoRA output path for validation\nDATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules/\"\n\n# TT-12 Validation Parameters\nTRAINING_DATA_PERCENTAGE = .3  # Controllable % of training data (0.1 = 10%, 1.0 = 100%)\nUSE_STRATIFIED_SAMPLING = True  # Maintain rule distribution when sampling\n\nPOSITIVE_ANSWER = \"Yes\"\nNEGATIVE_ANSWER = \"No\"\nCOMPLETE_PHRASE = \"Answer:\"\nBASE_PROMPT = '''You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.'''\n\nprint(\"✅ Using Qwen3 1.7B model from local Kaggle input\")\nprint(f\"🎯 TT-12: OpenSloth training + vLLM inference with {TRAINING_DATA_PERCENTAGE*100:.0f}% of data\")\nprint(f\"📊 Stratified sampling: {USE_STRATIFIED_SAMPLING}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:22.635286Z","iopub.execute_input":"2025-09-18T12:52:22.635573Z","iopub.status.idle":"2025-09-18T12:52:22.641354Z","shell.execute_reply.started":"2025-09-18T12:52:22.635547Z","shell.execute_reply":"2025-09-18T12:52:22.640489Z"}},"outputs":[{"name":"stdout","text":"Writing constants.py\n","output_type":"stream"}],"execution_count":4},{"id":"75e2fad7","cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\nfrom datasets import Dataset, load_from_disk\nfrom constants import POSITIVE_ANSWER, NEGATIVE_ANSWER, COMPLETE_PHRASE, BASE_PROMPT, TRAINING_DATA_PERCENTAGE, USE_STRATIFIED_SAMPLING, DATA_PATH\nimport random, numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom unsloth import FastLanguageModel\nfrom trl import SFTConfig, SFTTrainer\nimport os\nrandom.seed(42)\nnp.random.seed(42)\n\n\ndef build_prompt(row):\n    return f\"\"\"\n{BASE_PROMPT}\n\nSubreddit: r/{row[\"subreddit\"]}\nRule: {row[\"rule\"]}\nExamples:\n1) {row[\"positive_example\"]}\n{COMPLETE_PHRASE} Yes\n\n2) {row[\"negative_example\"]}\n{COMPLETE_PHRASE} No\n\n---\nComment: {row[\"body\"]}\n{COMPLETE_PHRASE}\"\"\"\n\n\ndef get_example_based_training_data(data_path):\n    \"\"\"\n    TT-12: Create training data from examples (like test-time training)\n    This trains the model on examples, not actual comments\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Sample data if needed while maintaining rule distribution\n    if TRAINING_DATA_PERCENTAGE < 1.0:\n        if USE_STRATIFIED_SAMPLING:\n            # Stratified sampling to maintain rule distribution\n            train_dataset = train_dataset.groupby('rule', group_keys=False).apply(\n                lambda x: x.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42)\n            ).reset_index(drop=True)\n            print(f\"📊 Stratified sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n        else:\n            # Simple random sampling\n            train_dataset = train_dataset.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42).reset_index(drop=True)\n            print(f\"📊 Random sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n    \n    print(f\"📊 Training data size: {len(train_dataset)} samples\")\n    print(f\"📊 Rule distribution: {train_dataset['rule'].value_counts().to_dict()}\")\n    \n    flatten = []\n    \n    # Create training data from examples (similar to test-time training)\n    for violation_type in [\"positive\", \"negative\"]:\n        for i in range(1, 3):\n            sub_dataset = train_dataset[[\"rule\",\"subreddit\",\n                                        \"positive_example_1\",\"positive_example_2\",\n                                        \"negative_example_1\",\"negative_example_2\"]].copy()\n\n            if violation_type == \"positive\":\n                # Use positive example as the \"body\" to classify\n                body_col = f\"positive_example_{i}\"\n                other_positive_col = f\"positive_example_{3-i}\"  # other positive\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"positive_example\"] = sub_dataset[other_positive_col]\n                # negative_example randomly selected\n                sub_dataset[\"negative_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"negative_example_1\"],\n                    sub_dataset[\"negative_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 1  # Positive examples violate rules\n\n            else:  # violation_type == \"negative\"\n                # Use negative example as the \"body\" to classify\n                body_col = f\"negative_example_{i}\"\n                other_negative_col = f\"negative_example_{3-i}\"\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"negative_example\"] = sub_dataset[other_negative_col]\n                sub_dataset[\"positive_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"positive_example_1\"],\n                    sub_dataset[\"positive_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 0  # Negative examples don't violate rules\n\n            # Drop original candidate columns\n            sub_dataset.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                                      \"negative_example_1\",\"negative_example_2\"], inplace=True)\n\n            flatten.append(sub_dataset)\n\n    # Merge all DataFrames\n    example_training_df = pd.concat(flatten, axis=0)\n    example_training_df = example_training_df.drop_duplicates(ignore_index=True)\n    \n    print(f\"📊 Example-based training dataset: {len(example_training_df)} samples\")\n    print(f\"📊 Positive examples: {sum(example_training_df['rule_violation'] == 1)}\")\n    print(f\"📊 Negative examples: {sum(example_training_df['rule_violation'] == 0)}\")\n    \n    return example_training_df\n\n\ndef get_real_comment_validation_data(data_path):\n    \"\"\"\n    TT-12: Get real comments with labels for validation\n    This is what we actually want to predict\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Use actual comments and their labels for validation\n    validation_df = train_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\",\n                                  \"positive_example_1\",\"positive_example_2\",\n                                  \"negative_example_1\",\"negative_example_2\"]].copy()\n\n    # Randomly select positive_example and negative_example for prompts\n    validation_df[\"positive_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"positive_example_1\"],\n        validation_df[\"positive_example_2\"]\n    )\n    validation_df[\"negative_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"negative_example_1\"],\n        validation_df[\"negative_example_2\"]\n    )\n\n    # Drop original candidate columns\n    validation_df.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                               \"negative_example_1\",\"negative_example_2\"], inplace=True)\n    \n    print(f\"📊 Real comment validation dataset: {len(validation_df)} samples\")\n    print(f\"📊 Rule violations: {sum(validation_df['rule_violation'] == 1)} positive, {sum(validation_df['rule_violation'] == 0)} negative\")\n    \n    return validation_df\n\n\ndef build_dataset_for_opensloth(dataframe, tokenizer):\n    \"\"\"Build dataset for OpenSloth training with proper text formatting\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    \n    # OpenSloth uses a text field\n    dataframe[\"text\"] = dataframe.apply(lambda row: \n        tokenizer.apply_chat_template(\n            [\n                {\"role\": \"user\", \"content\": row[\"prompt\"]},\n                {\"role\": \"assistant\", \"content\": POSITIVE_ANSWER if row[\"rule_violation\"] == 1 else NEGATIVE_ANSWER},\n            ],\n            tokenize=False,\n            add_generation_prompt=False,\n        ),\n        axis=1\n    )\n    \n    dataset = Dataset.from_pandas(dataframe[[\"text\"]])\n    return dataset\n\n\ndef build_validation_dataset(dataframe):\n    \"\"\"Build dataset for validation (keep labels for evaluation)\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    dataframe = dataframe[[\"prompt\", \"rule_violation\"]]  # Keep true labels for evaluation\n    dataset = Dataset.from_pandas(dataframe)\n    return dataset\n\ndef cache_dataset(cache_path):\n    if os.path.exists(cache_path):\n        print(f\"💾 Loading cached dataset from {cache_path}\")\n        return\n\n    print(f\"💾 Caching dataset to {cache_path}\")\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\",\n        max_seq_length=2048,\n        load_in_4bit=True,\n    )\n    \n    print(tokeinzer.chat_template)\n    tokenizer.chat_template = \"{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|im_start|>user\\n' + message['content'] + '<|im_end|>\\n<|im_start|>assistant\\n' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + '<|im_end|>' }}{% endif %}{% endfor %}\"\n    \n    \n    train_df = get_example_based_training_data(DATA_PATH)\n    dataset = build_dataset_for_opensloth(train_df, tokenizer)\n    \n    # This is a bit of a hack. SFTTrainer is used for its dataset processing\n    trainer = SFTTrainer(\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=dataset,\n        args=SFTConfig(\n            dataset_text_field=\"text\",\n            max_seq_length=2048,\n            dataset_num_proc=2,\n            packing=True,\n        ),\n    )\n    \n    trainer.train_dataset.save_to_disk(cache_path)\n    print(f\"✅ Dataset cached to {cache_path}\")\n\ndef get_cached_dataset(cache_path):\n    if not os.path.exists(cache_path):\n        raise RuntimeError(\"Dataset cache not found. Please run the caching step first.\")\n    return load_from_disk(cache_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:22.642731Z","iopub.execute_input":"2025-09-18T12:52:22.642965Z","iopub.status.idle":"2025-09-18T12:52:22.659637Z","shell.execute_reply.started":"2025-09-18T12:52:22.642943Z","shell.execute_reply":"2025-09-18T12:52:22.658968Z"}},"outputs":[{"name":"stdout","text":"Writing utils.py\n","output_type":"stream"}],"execution_count":5},{"id":"60f8a561-d945-4781-be7c-a8ddbf0f045b","cell_type":"code","source":"from transformers import TextStreamer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:22.660349Z","iopub.execute_input":"2025-09-18T12:52:22.660686Z","iopub.status.idle":"2025-09-18T12:52:22.674203Z","shell.execute_reply.started":"2025-09-18T12:52:22.660660Z","shell.execute_reply":"2025-09-18T12:52:22.673654Z"}},"outputs":[],"execution_count":6},{"id":"ae027499","cell_type":"code","source":"from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"/kaggle/input/qwen3-1.7b-base-unsloth-bnb-4bit/transformers/default/1\",\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:51.888987Z","iopub.execute_input":"2025-09-18T12:52:51.889563Z","iopub.status.idle":"2025-09-18T12:52:56.679249Z","shell.execute_reply.started":"2025-09-18T12:52:51.889536Z","shell.execute_reply":"2025-09-18T12:52:56.678451Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nNone\n","output_type":"stream"}],"execution_count":8},{"id":"6b4f6986-b802-49e1-a692-187ec41bf2d1","cell_type":"code","source":"tokenizer.apply_chat_template(\n            [\n                {\"role\": \"user\", \"content\": row[\"prompt\"]},\n                {\"role\": \"assistant\", \"content\": POSITIVE_ANSWER if row[\"rule_violation\"] == 1 else NEGATIVE_ANSWER},\n            ],\n            tokenize=False,\n            add_generation_prompt=False,\n        ),\nprint(tokenizer.chat_template)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:54:36.842159Z","iopub.execute_input":"2025-09-18T12:54:36.842880Z","iopub.status.idle":"2025-09-18T12:54:36.867596Z","shell.execute_reply.started":"2025-09-18T12:54:36.842854Z","shell.execute_reply":"2025-09-18T12:54:36.866768Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3912607496.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer.apply_chat_template(\n\u001b[1;32m      2\u001b[0m             [\n\u001b[0;32m----> 3\u001b[0;31m                 \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPOSITIVE_ANSWER\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rule_violation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNEGATIVE_ANSWER\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             ],\n","\u001b[0;31mNameError\u001b[0m: name 'row' is not defined"],"ename":"NameError","evalue":"name 'row' is not defined","output_type":"error"}],"execution_count":11},{"id":"38d2447b","cell_type":"code","source":"from utils import *\ntrain_df = get_example_based_training_data(DATA_PATH)\ndataset = build_dataset_for_opensloth(train_df, tokenizer)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:54:47.979484Z","iopub.execute_input":"2025-09-18T12:54:47.980053Z","iopub.status.idle":"2025-09-18T12:54:48.081806Z","shell.execute_reply.started":"2025-09-18T12:54:47.980028Z","shell.execute_reply":"2025-09-18T12:54:48.080594Z"}},"outputs":[{"name":"stdout","text":"📊 Stratified sampling: 609 samples (30%)\n📊 Training data size: 609 samples\n📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 305, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 304}\n📊 Example-based training dataset: 2435 samples\n📊 Positive examples: 1218\n📊 Negative examples: 1217\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3174172548.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_example_based_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dataset_for_opensloth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/utils.py\u001b[0m in \u001b[0;36mbuild_dataset_for_opensloth\u001b[0;34m(dataframe, tokenizer)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# OpenSloth uses a text field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     dataframe[\"text\"] = dataframe.apply(lambda row: \n\u001b[0m\u001b[1;32m    147\u001b[0m         tokenizer.apply_chat_template(\n\u001b[1;32m    148\u001b[0m             [\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# OpenSloth uses a text field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     dataframe[\"text\"] = dataframe.apply(lambda row: \n\u001b[0;32m--> 147\u001b[0;31m         tokenizer.apply_chat_template(\n\u001b[0m\u001b[1;32m    148\u001b[0m             [\n\u001b[1;32m    149\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mapply_chat_template\u001b[0;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m             \u001b[0mtokenizer_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m         \u001b[0mchat_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chat_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_assistant_tokens_mask\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\{\\%-?\\s*generation\\s*-?\\%\\}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mget_chat_template\u001b[0;34m(self, chat_template, tools)\u001b[0m\n\u001b[1;32m   1820\u001b[0m                 \u001b[0mchat_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1823\u001b[0m                     \u001b[0;34m\"Cannot use chat template functions because tokenizer.chat_template is not set and no template \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;34m\"argument was passed! For information about writing templates and setting the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating"],"ename":"ValueError","evalue":"Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating","output_type":"error"}],"execution_count":12},{"id":"cfbe3537","cell_type":"code","source":"print(dataset[9])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:34:13.603075Z","iopub.execute_input":"2025-09-17T13:34:13.603348Z","iopub.status.idle":"2025-09-17T13:34:13.607960Z","shell.execute_reply.started":"2025-09-17T13:34:13.603327Z","shell.execute_reply":"2025-09-17T13:34:13.607243Z"}},"outputs":[{"name":"stdout","text":"{'text': '<|im_start|>user\\n\\nYou are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.\\n\\nSubreddit: r/The_Donald\\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nExamples:\\n1) Free paypal cards here!! https://www.pointsprizes.com/ref/13226\\nAnswer: Yes\\n\\n2) **HD** Stream [English 1](http://www.zifootball.us/p/channel1.html) | [English 2](http://www.zifootball.us/p/channel2.html) | Ad Overlays: 4  | Mobile : Yes\\n\\nUpvote if you like the streams\\nAnswer: No\\n\\n---\\nComment: bad hookers waiting for you here http://cbvidfree.com/?id44838\\nAnswer:<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\nYes<|im_end|>\\n'}\n","output_type":"stream"}],"execution_count":15},{"id":"913d205b","cell_type":"code","source":"FastLanguageModel.for_inference(model) # Enable native 2x faster inference\ntext_streamer = TextStreamer(tokenizer)\ninputs = tokenizer(dataset[666]['text'], return_tensors=\"pt\").to(\"cuda\")\n\noutput = model.generate( **inputs ,streamer = text_streamer, max_new_tokens = 512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:53:47.974006Z","iopub.execute_input":"2025-09-18T12:53:47.974291Z","iopub.status.idle":"2025-09-18T12:53:48.037683Z","shell.execute_reply.started":"2025-09-18T12:53:47.974269Z","shell.execute_reply":"2025-09-18T12:53:48.036692Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3636307452.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mFastLanguageModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Enable native 2x faster inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext_streamer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextStreamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m666\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mstreamer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_streamer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"],"ename":"NameError","evalue":"name 'dataset' is not defined","output_type":"error"}],"execution_count":9},{"id":"cf034a4e-b301-4b5c-ac24-9c9ab40fa4b4","cell_type":"code","source":"\nyes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\nno_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n\nlog_probs = out.outputs[0].logprobs[0]   \nlog_prob_yes = log_probs.get(yes_token_id)\nlog_prob_no = log_probs.get(no_token_id)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a7083c80","cell_type":"code","source":"\n# Decode the full output to readable text\ndecoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(\"\\n\" + \"=\"*50)\nprint(\"🎯 Full Decoded Output (including thinking):\")\nprint(decoded_output)\nprint(\"=\"*512)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:45:05.486062Z","iopub.execute_input":"2025-09-17T13:45:05.486365Z","iopub.status.idle":"2025-09-17T13:45:05.492695Z","shell.execute_reply.started":"2025-09-17T13:45:05.486342Z","shell.execute_reply":"2025-09-17T13:45:05.491884Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\n🎯 Full Decoded Output (including thinking):\nuser\n\nYou are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\nAnswer:\nassistant\n<think>\n\n</think>\n\nYes\n\n================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n","output_type":"stream"}],"execution_count":34},{"id":"8402a971-332b-4ef7-a273-b985a94638cf","cell_type":"markdown","source":"Trying Thinking","metadata":{}},{"id":"c0f69c75-8049-4d14-adb8-ba8bb08b8f9f","cell_type":"code","source":"\n# Thinking prompt (replace with your dataset[0]['text'] if needed)\nthinking_prompt = \"\"\"You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule.\n\nFirst, think step-by-step about the comment and the rule.\nThen, conclude with your Single final answer: 'Answer: Yes' or 'Answer: No'.Full stop after answer.Say nothing after giving out the answer.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\n\n\"\"\"\nmessages = [\n    {\"role\": \"user\", \"content\": thinking_prompt},\n    {\"role\": \"assistant\", \"content\": \"<think>\"}\n]\nthinking_input = tokenizer.apply_chat_template(messages, tokenize=False)\n# Tokenize the input\ninputs = tokenizer(thinking_prompt, return_tensors=\"pt\").to(\"cuda\")\n\n# Generate with Qwen Thinking Mode settings\ntext_streamer = TextStreamer(tokenizer)\noutput = model.generate(\n    **inputs,\n    streamer=text_streamer,\n    max_new_tokens=500,  # Allow room for thinking\n    temperature=0.6,     # Qwen Thinking Mode: Balanced creativity\n    top_p=0.95,          # Qwen Thinking Mode: Diverse selection\n    top_k=20,            # Qwen Thinking Mode: Limit to top 20 tokens\n    min_p=0.0,           # Qwen Thinking Mode: No minimum probability threshold\n    do_sample=True,      # Enable sampling for creativity\n    #stop=[\"\\n\"],         # Stop after newline to prevent repetition\n    pad_token_id=tokenizer.eos_token_id,\n)\n\n# Decode the full output to readable text\ndecoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(\"\\n\" + \"=\"*500)\nprint(\"🎯 Full Decoded Output (with thinking):\")\nprint(decoded_output)\nprint(\"=\"*500)\n\n# Optional: Extract just the new part (after the prompt)\nnew_part = decoded_output[len(thinking_prompt):].strip()\nprint(\"\\n🎯 New Generated Part:\")\nprint(new_part)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T14:06:35.941075Z","iopub.execute_input":"2025-09-17T14:06:35.941369Z","iopub.status.idle":"2025-09-17T14:06:59.068604Z","shell.execute_reply.started":"2025-09-17T14:06:35.941345Z","shell.execute_reply":"2025-09-17T14:06:59.067704Z"}},"outputs":[{"name":"stdout","text":"You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule.\n\nFirst, think step-by-step about the comment and the rule.\nThen, conclude with your Single final answer: 'Answer: Yes' or 'Answer: No'.Full stop after answer.Say nothing after giving out the answer.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\n\nAnswer:\nStep 1: Identify the key elements in the comment.\nThe comment starts with \"39 http://MySexFind.com - find girl for sex now 39!\" which includes a URL and the phrase \"find girl for sex now\".\n\nStep 2: Determine if the comment contains any prohibited content.\nThe URL is a referral link, and the comment promotes a service for finding girls for sex, which is likely adult content.\n\nStep 3: Compare with the rule.\nThe rule prohibits unsolicited advertising and promotional content, including referral links and adult content.\n\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\nAnswer: Yes\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2997580609.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Generate with Qwen Thinking Mode settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mtext_streamer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextStreamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m output = model.generate(\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mstreamer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_streamer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36munsloth_fast_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     \u001b[0;31m# Mixed precision autocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1582\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3434\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3436\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     ) -> Union[Tuple, CausalLMOutputWithPast]:\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             outputs = fast_forward_inference(\n\u001b[0m\u001b[1;32m   1034\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaModel_fast_forward_inference_custom\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# residual = X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m             X = fast_rms_layernorm_inference(\n\u001b[0m\u001b[1;32m    978\u001b[0m                 \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfast_rms_layernorm_inference\u001b[0;34m(self, X, XX, XX2, variance)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mXX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":51},{"id":"142e8d6c","cell_type":"code","source":"%%writefile train_opensloth.py\nfrom opensloth.opensloth_config import (\n    FastModelArgs,\n    LoraArgs,\n    OpenSlothConfig,\n    TrainingArguments,\n)\nfrom opensloth.scripts.opensloth_sft_trainer import run_mp_training, setup_envs\nfrom constants import BASE_MODEL_PATH, LORA_PATH\nimport torch\n\n# OpenSloth Configuration for 2 GPUs\nGLOBAL_BZ = 16\nDEVICES = [i for i in range(torch.cuda.device_count())]\nBZ = 2  # Batch size per device\n\nopensloth_config = OpenSlothConfig(\n    data_cache_path=\"data/cache_qwen3_dataset_for_opensloth/\",\n    devices=DEVICES,\n    fast_model_args=FastModelArgs(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,\n        load_in_4bit=True,\n        local_files_only=True,\n        trust_remote_code=True,\n    ),\n    lora_args=LoraArgs(\n        r=16,\n        lora_alpha=16,\n        target_modules=[\n            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n            \"gate_proj\", \"up_proj\", \"down_proj\",\n        ],\n        lora_dropout=0,\n        bias=\"none\",\n        use_rslora=False,\n    ),\n    sequence_packing=True,\n)\n\ntraining_config = TrainingArguments(\n    output_dir=LORA_PATH,\n    per_device_train_batch_size=BZ,\n    gradient_accumulation_steps=GLOBAL_BZ // (len(DEVICES) * BZ) if DEVICES else 1,\n    learning_rate=1e-5,\n    logging_steps=1,\n    num_train_epochs=1, # Using max_steps instead\n    max_steps=60,\n    lr_scheduler_type=\"linear\",\n    warmup_steps=5,\n    save_total_limit=2,\n    save_strategy=\"steps\",\n    save_steps=20,\n    weight_decay=0.01,\n    optim=\"adamw_8bit\",\n    seed=3407,\n    report_to=\"none\",\n)\n\n\nif __name__ == \"__main__\":\n    import os\n\n    print(f\"Global batch size: {len(DEVICES) * BZ * training_config.gradient_accumulation_steps}\")\n    print(f\"Gradient accumulation steps: {training_config.gradient_accumulation_steps}\")\n\n    setup_envs(opensloth_config, training_config)\n    run_mp_training(opensloth_config.devices, opensloth_config, training_config)\n    \n    print(f\"✅ OpenSloth training completed! LoRA adapters saved to: {LORA_PATH}\")\n    print(\"🎯 Ready for vLLM inference!\")\n","metadata":{},"outputs":[],"execution_count":null},{"id":"8d69f944","cell_type":"markdown","source":"# 🎯 2x T4 GPU Optimization Guide\n\n## ⚡ **Multi-GPU Configuration for TT-11**\n\n### **Your Setup: 2x T4 (28GB Total VRAM)**\n- **GPU 0**: ~14GB VRAM\n- **GPU 1**: ~14GB VRAM\n- **Total**: 28GB available for training\n\n### **Optimizations Applied:**\n\n#### **1. Model Distribution**\n```python\ndevice_map=\"auto\"  # Automatic distribution across GPUs\nmax_memory={0: \"13GB\", 1: \"13GB\"}  # Reserve 1GB per GPU for operations\n```\n\n#### **2. Batch Size Scaling**\n```python\nper_device_train_batch_size=4,  # 4 samples per GPU (8 total)\ngradient_accumulation_steps=2,  # Effective batch = 4*2*2 = 16\n```\n\n#### **3. Memory Optimizations**\n```python\nload_in_4bit=True,              # 4-bit quantization saves ~75% memory\nuse_gradient_checkpointing=True, # Trade compute for memory\ndataloader_pin_memory=False,     # Let Unsloth handle memory\n```\n\n#### **4. Multi-GPU Training**\n```python\ndataloader_num_workers=4,        # Parallel data loading\nddp_find_unused_parameters=False, # DDP optimization\nddp_broadcast_buffers=False,     # Reduce communication\n```\n\n### **Expected Performance:**\n- **Training Speed**: 3x-6x faster than single GPU\n- **Memory Usage**: ~12-13GB per GPU\n- **Effective Batch**: 16 samples (vs 4 on single GPU)\n- **Total Time**: 5-8 minutes for full training\n\n### **Troubleshooting 2x T4:**\n\n#### **If you get OOM (Out of Memory):**\n```python\n# Reduce batch size\nper_device_train_batch_size=2,   # 2 per GPU instead of 4\ngradient_accumulation_steps=4,   # Keep effective batch size\n\n# Or reduce sequence length\nmax_seq_length=1024,             # Shorter sequences\n```\n\n#### **If training is slower than expected:**\n```python\n# Check GPU utilization\nnvidia-smi  # Should show ~90%+ on both GPUs\n\n# Increase batch size if memory allows\nper_device_train_batch_size=6,   # Try larger batches\n```\n\n#### **Memory Distribution Check:**\n```python\nprint(f\"Available GPUs: {torch.cuda.device_count()}\")\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_properties(i).total_memory // 1024**3}GB\")\n```","metadata":{}},{"id":"910e6893","cell_type":"code","source":"%%writefile validation_vllm.py\nimport os\nos.environ[\"VLLM_USE_V1\"] = \"0\"\n\nimport vllm\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\nfrom vllm.lora.request import LoRARequest\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_vllm():\n    \"\"\"Run validation using OpenSloth-trained model with vLLM for precise AUC\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"🔍 Running validation on {len(val_dataset)} real comments\")\n    \n    # 🎯 VLLM: Initialize with OpenSloth LoRA support for precise probabilities\n    llm = vllm.LLM(\n        BASE_MODEL_PATH,\n        tensor_parallel_size=torch.cuda.device_count(),\n        gpu_memory_utilization=0.90,\n        trust_remote_code=True,\n        dtype=\"half\",\n        enforce_eager=True,\n        max_model_len=512,\n        disable_log_stats=True,\n        enable_prefix_caching=True,\n        enable_lora=True,\n        max_lora_rank=64,\n        local_files_only=True,\n    )\n\n    tokenizer = llm.get_tokenizer()\n\n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n\n    # 🎯 VLLM: Generate with OpenSloth LoRA for most accurate probabilities\n    outputs = llm.generate(\n        texts,\n        vllm.SamplingParams(\n            skip_special_tokens=True,\n            max_tokens=1,\n            logprobs=20,\n        ),\n        use_tqdm=True,\n        lora_request=LoRARequest(\"opensloth_lora\", 1, LORA_PATH)  # Load OpenSloth LoRA\n    )\n\n    # Extract predictions and probabilities with vLLM precision\n    predictions = []\n    probabilities = []\n    \n    yes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\n    no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n    \n    for out in outputs:\n        log_probs = out.outputs[0].logprobs[0]\n        \n        log_prob_yes = log_probs.get(yes_token_id)\n        log_prob_no = log_probs.get(no_token_id)\n        \n        if log_prob_yes is not None and log_prob_no is not None:\n            if log_prob_yes.logprob > log_prob_no.logprob:\n                predictions.append(1)\n            else:\n                predictions.append(0)\n            \n            exp_pos = np.exp(log_prob_yes.logprob)\n            exp_neg = np.exp(log_prob_no.logprob)\n            prob_positive = exp_pos / (exp_pos + exp_neg)\n            probabilities.append(prob_positive)\n        else:\n            predictions.append(0)\n            probabilities.append(0.5)\n\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"📊 TT-12 VALIDATION RESULTS (OpenSloth + vLLM)\")\n    print(\"=\" * 60)\n    print(f\"🎯 Accuracy:  {accuracy:.4f}\")\n    print(f\"🎯 F1 Score:  {f1:.4f}\")\n    print(f\"🎯 Precision: {precision:.4f}\")\n    print(f\"🎯 Recall:    {recall:.4f}\")\n    print(f\"🎯 AUC Score: {auc:.4f} (High-precision vLLM)\")\n    print(\"=\" * 60)\n    \n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n📈 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    print(\"\\n📋 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy, 'f1': f1, 'precision': precision,\n        'recall': recall, 'auc': auc, 'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-12: OpenSloth Training + vLLM Validation Results', fontsize=16, fontweight='bold')\n    \n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (vLLM High-Precision)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    pos_probs = [p for p, t in zip(probabilities, true_labels) if t == 1]\n    neg_probs = [p for p, t in zip(probabilities, true_labels) if t == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (vLLM Precision)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics[k] for k in ['accuracy', 'f1', 'precision', 'recall', 'auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (OpenSloth + vLLM)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt12_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n📊 PERFORMANCE BY RULE (vLLM High-Precision AUC):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        rule_auc = roc_auc_score(rule_true, rule_prob) if len(np.unique(rule_true)) > 1 else np.nan\n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\\n  Samples: {len(rule_data)}\\n  Accuracy: {rule_acc:.3f}\\n  F1 Score: {rule_f1:.3f}\\n  AUC Score: {rule_auc:.3f}\\n\")\n        \n        rule_metrics.append({'rule': rule, 'samples': len(rule_data), 'accuracy': rule_acc, 'f1': rule_f1, 'auc': rule_auc})\n    \n    analysis_df.to_csv('/kaggle/working/tt12_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt12_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"🔬 TT-12: OpenSloth Training + vLLM Validation\")\n    print(\"🚀 Multi-GPU training + High-precision inference!\")\n    print(\"=\" * 70)\n    \n    true_labels, predictions, probabilities, val_df = run_validation_vllm()\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"✅ TT-12 Validation completed!\")\n    print(\"📈 Visualizations saved: /kaggle/working/tt12_validation_results.png\")\n    print(\"📊 Detailed results: /kaggle/working/tt12_detailed_results.csv\")\n    print(\"📋 Rule metrics: /kaggle/working/tt12_rule_metrics.csv\")\n    \nif __name__ == \"__main__\":\n    main()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"7fd0717c","cell_type":"code","source":"%%writefile validation_transformers.py\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\nfrom tqdm import tqdm\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_transformers():\n    \"\"\"Run validation using standard transformers with OpenSloth LoRA - Universal compatibility\"\"\"\n    \n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"🔍 Running validation on {len(val_dataset)} real comments (Transformers)\")\n    \n    print(\"📥 Loading base model and tokenizer...\")\n    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True, local_files_only=True)\n    model = AutoModelForCausalLM.from_pretrained(\n        BASE_MODEL_PATH,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        local_files_only=True,\n    )\n    \n    print(\"🔗 Loading OpenSloth LoRA adapters...\")\n    model = PeftModel.from_pretrained(model, LORA_PATH)\n    model = model.merge_and_unload()\n    model.eval()\n    \n    yes_token_id = tokenizer.encode(\"Yes\", add_special_tokens=False)[0]\n    no_token_id = tokenizer.encode(\"No\", add_special_tokens=False)[0]\n    \n    print(f\"🎯 Token IDs: Yes={yes_token_id}, No={no_token_id}\")\n    \n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n    \n    predictions, probabilities = [], []\n    batch_size = 8\n    \n    print(\"🚀 Running inference...\")\n    \n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch_texts = texts[i:i+batch_size]\n        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n            next_token_logits = outputs.logits[:, -1, :]\n            \n            yes_logits = next_token_logits[:, yes_token_id]\n            no_logits = next_token_logits[:, no_token_id]\n            \n            combined_logits = torch.stack([no_logits, yes_logits], dim=1)\n            probs = torch.softmax(combined_logits, dim=1)\n            \n            predictions.extend(torch.argmax(probs, dim=1).cpu().tolist())\n            probabilities.extend(probs[:, 1].cpu().tolist())\n    \n    print(\"✅ Inference completed!\")\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"📊 TT-12 VALIDATION RESULTS (OpenSloth + Transformers)\")\n    print(\"=\" * 60)\n    print(f\"🎯 Accuracy:  {accuracy:.4f}\")\n    print(f\"🎯 F1 Score:  {f1:.4f}\")\n    print(f\"🎯 Precision: {precision:.4f}\")\n    print(f\"🎯 Recall:    {recall:.4f}\")\n    print(f\"🎯 AUC Score: {auc:.4f} (Standard Transformers)\")\n    print(\"=\" * 60)\n    \n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n📈 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    print(\"\\n📋 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall, 'auc': auc, 'confusion_matrix': cm}\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-12: OpenSloth Training + Transformers Validation Results', fontsize=16, fontweight='bold')\n    \n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (Transformers)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    pos_probs = [p for p, t in zip(probabilities, true_labels) if t == 1]\n    neg_probs = [p for p, t in zip(probabilities, true_labels) if t == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (Transformers)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics[k] for k in ['accuracy', 'f1', 'precision', 'recall', 'auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (OpenSloth + Transformers)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt12_transformers_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n📊 PERFORMANCE BY RULE (Transformers):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        rule_auc = roc_auc_score(rule_true, rule_prob) if len(np.unique(rule_true)) > 1 else np.nan\n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\\n  Samples: {len(rule_data)}\\n  Accuracy: {rule_acc:.3f}\\n  F1 Score: {rule_f1:.3f}\\n  AUC Score: {rule_auc:.3f}\\n\")\n        \n        rule_metrics.append({'rule': rule, 'samples': len(rule_data), 'accuracy': rule_acc, 'f1': rule_f1, 'auc': rule_auc})\n    \n    analysis_df.to_csv('/kaggle/working/tt12_transformers_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt12_transformers_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"🔬 TT-12: OpenSloth Training + Transformers Validation\")\n    print(\"🚀 Multi-GPU training + Universal compatibility!\")\n    print(\"=\" * 70)\n    \n    true_labels, predictions, probabilities, val_df = run_validation_transformers()\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"✅ TT-12 Transformers Validation completed!\")\n    print(\"📈 Visualizations saved: /kaggle/working/tt12_transformers_validation_results.png\")\n    print(\"📊 Detailed results: /kaggle/working/tt12_transformers_detailed_results.csv\")\n    print(\"📋 Rule metrics: /kaggle/working/tt12_transformers_rule_metrics.csv\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"12b04fb3","cell_type":"code","source":"from utils import cache_dataset\ncache_dataset(cache_path=\"data/cache_qwen3_dataset_for_opensloth/\")","metadata":{},"outputs":[],"execution_count":null},{"id":"e6f23a14","cell_type":"code","source":"!python train_opensloth.py","metadata":{},"outputs":[],"execution_count":null},{"id":"096ef5eb","cell_type":"markdown","source":"# Appendix: View Results","metadata":{}},{"id":"d7ef0067","cell_type":"code","source":"#@title **Run Validation**\n#@markdown Choose your validation method:\nVALIDATION_METHOD = \"vLLM\" #@param [\"vLLM\", \"Transformers\"]\n\nif VALIDATION_METHOD == \"vLLM\":\n    print(\"🚀 Running vLLM validation for maximum speed and precision...\")\n    !python validation_vllm.py\nelse:\n    print(\"⚙️ Running Transformers validation for universal compatibility...\")\n    !python validation_transformers.py","metadata":{},"outputs":[],"execution_count":null},{"id":"0d85e3f4","cell_type":"code","source":"from IPython.display import Image, display\n\n# Display the validation results image\nif VALIDATION_METHOD == \"vLLM\":\n    display(Image(filename='/kaggle/working/tt12_validation_results.png'))\nelse:\n    display(Image(filename='/kaggle/working/tt12_transformers_validation_results.png'))","metadata":{},"outputs":[],"execution_count":null},{"id":"681bab57","cell_type":"code","source":"import pandas as pd\n\n# Display the detailed results CSV\nif VALIDATION_METHOD == \"vLLM\":\n    df_detailed = pd.read_csv('/kaggle/working/tt12_detailed_results.csv')\nelse:\n    df_detailed = pd.read_csv('/kaggle/working/tt12_transformers_detailed_results.csv')\n\ndf_detailed.head()","metadata":{},"outputs":[],"execution_count":null}]}