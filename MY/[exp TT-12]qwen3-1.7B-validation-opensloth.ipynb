{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":583951,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":436166,"modelId":452934},{"sourceId":579809,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":432662,"modelId":449553}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"43fb082f","cell_type":"code","source":"# Install dependencies - OpenSloth + vLLM + Analysis setup\n!pip install pip3-autoremove\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu124\n!pip install accelerate==1.7.0\n!pip install triton==3.2.0 \n\n!pip install unsloth==2025.5.7 unsloth-zoo==2025.5.8 --no-cache\n\n!pip install opensloth==0.1.7 \n\n!pip install TextStreamer\n\nprint(\"笨 TT-12 Dependencies installed:\")\nprint(\"泅 OpenSloth: Multi-GPU training\")\nprint(\"沁ｯ vLLM: Precise inference\") \nprint(\"沒 Analysis libraries: scikit-learn, matplotlib, seaborn\")\nimport unsloth\nfrom transformers import AutoTokenizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:54:25.158043Z","iopub.execute_input":"2025-09-18T14:54:25.158318Z","iopub.status.idle":"2025-09-18T14:57:18.415880Z","shell.execute_reply.started":"2025-09-18T14:54:25.158291Z","shell.execute_reply":"2025-09-18T14:57:18.415066Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting pip3-autoremove\n  Downloading pip3_autoremove-2.0.1-py2.py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from pip3-autoremove) (24.1.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pip3-autoremove) (25.0)\nDownloading pip3_autoremove-2.0.1-py2.py3-none-any.whl (12 kB)\nInstalling collected packages: pip3-autoremove\nSuccessfully installed pip3-autoremove-2.0.1\nLooking in indexes: https://download.pytorch.org/whl/cu124\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nCollecting xformers\n  Downloading https://download.pytorch.org/whl/cu124/xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading https://download.pytorch.org/whl/cu124/xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, xformers\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xformers-0.0.29.post3\nCollecting accelerate==1.7.0\n  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (2.6.0+cu124)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (0.33.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (2025.5.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.7.0) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.7.0) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.7.0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.7.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.7.0) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate==1.7.0) (2024.2.0)\nDownloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.8.1\n    Uninstalling accelerate-1.8.1:\n      Successfully uninstalled accelerate-1.8.1\nSuccessfully installed accelerate-1.7.0\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (3.2.0)\nCollecting unsloth==2025.5.7\n  Downloading unsloth-2025.5.7-py3-none-any.whl.metadata (47 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth-zoo==2025.5.8\n  Downloading unsloth_zoo-2025.5.8-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (2.6.0+cu124)\nRequirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.0.29.post3)\nCollecting bitsandbytes (from unsloth==2025.5.7)\n  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (25.0)\nCollecting tyro (from unsloth==2025.5.7)\n  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\nCollecting transformers!=4.47.0,==4.51.3 (from unsloth==2025.5.7)\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: datasets>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (3.6.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (1.7.0)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth==2025.5.7)\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.15.2)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.33.1)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.34.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth==2025.5.7) (0.21.0+cu124)\nCollecting cut_cross_entropy (from unsloth-zoo==2025.5.8)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth-zoo==2025.5.8) (11.2.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from unsloth-zoo==2025.5.8) (2024.11.6)\nCollecting msgspec (from unsloth-zoo==2025.5.8)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (3.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (0.5.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth==2025.5.7) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth==2025.5.7) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth==2025.5.7) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth==2025.5.7) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth==2025.5.7) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth==2025.5.7) (1.3.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (14.0.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth==2025.5.7) (8.7.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth==2025.5.7) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth==2025.5.7)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth==2025.5.7) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (3.12.13)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth==2025.5.7) (2025.6.15)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (2.19.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth==2025.5.7) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth==2025.5.7) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth==2025.5.7) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth==2025.5.7) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth==2025.5.7) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth==2025.5.7) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth==2025.5.7) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth==2025.5.7) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth==2025.5.7) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth==2025.5.7) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth==2025.5.7) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth==2025.5.7) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth==2025.5.7) (1.17.0)\nDownloading unsloth-2025.5.7-py3-none-any.whl (265 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.5.8-py3-none-any.whl (146 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m146.6/146.6 kB\u001b[0m \u001b[31m292.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m157.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m338.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m211.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m356.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.9.31-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m327.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m348.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, msgspec, fsspec, tyro, cut_cross_entropy, transformers, trl, unsloth-zoo, bitsandbytes, unsloth\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 fsspec-2025.3.0 msgspec-0.19.0 shtab-1.7.2 transformers-4.51.3 trl-0.15.2 tyro-0.9.31 unsloth-2025.5.7 unsloth-zoo-2025.5.8\nCollecting opensloth==0.1.7\n  Downloading opensloth-0.1.7-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: fastcore<2.0.0,>=1.7.29 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (1.7.29)\nCollecting fire<0.8.0,>=0.7.0 (from opensloth==0.1.7)\n  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\nCollecting jupyterlab<5.0.0,>=4.3.5 (from opensloth==0.1.7)\n  Downloading jupyterlab-4.4.7-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from opensloth==0.1.7) (6.0.2)\nCollecting speedy-utils<0.2.0,>=0.1.20 (from opensloth==0.1.7)\n  Downloading speedy_utils-0.1.30-py3-none-any.whl.metadata (7.2 kB)\nCollecting tensorboard<3.0.0,>=2.19.0 (from opensloth==0.1.7)\n  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting tensorboardx<3.0.0.0,>=2.6.2.2 (from opensloth==0.1.7)\n  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastcore<2.0.0,>=1.7.29->opensloth==0.1.7) (25.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire<0.8.0,>=0.7.0->opensloth==0.1.7) (3.1.0)\nCollecting async-lru>=1.0.0 (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7)\n  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\nRequirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.28.1)\nRequirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.17.1)\nRequirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.1.6)\nRequirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (5.8.1)\nCollecting jupyter-lsp>=2.0.0 (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7)\n  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.12.5)\nRequirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.27.3)\nRequirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.2.4)\nRequirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (75.2.0)\nRequirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.5.1)\nRequirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (5.7.1)\nCollecting bump2version (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7)\n  Downloading bump2version-1.0.1-py2.py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (5.5.2)\nRequirement already satisfied: debugpy in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.8.0)\nRequirement already satisfied: fastprogress in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.0.3)\nCollecting freezegun<2.0.0,>=1.5.1 (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7)\n  Downloading freezegun-1.5.5-py3-none-any.whl.metadata (13 kB)\nCollecting ipdb (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7)\n  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (8.1.5)\nCollecting json-repair<0.41.0,>=0.40.0 (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7)\n  Downloading json_repair-0.40.0-py3-none-any.whl.metadata (11 kB)\nCollecting loguru (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7)\n  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.7.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.26.4)\nCollecting packaging (from fastcore<2.0.0,>=1.7.29->opensloth==0.1.7)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.2.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.11.7)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.32.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.2.2)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.9.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.5.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (1.73.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (3.8.2)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (11.2.1)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (3.20.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0.0,>=2.19.0->opensloth==0.1.7) (3.1.3)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from freezegun<2.0.0,>=1.5.1->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.9.0.post0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.16.0)\nRequirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (7.34.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (8.6.3)\nRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.1.7)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.6.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (7.0.0)\nRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (24.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.0.2)\nRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (25.1.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.12.0)\nRequirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.5.3)\nRequirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.4.5)\nRequirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (5.10.4)\nRequirement already satisfied: overrides in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (7.7.0)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.22.1)\nRequirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.18.1)\nRequirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.8.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.3.8)\nRequirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.17.0)\nRequirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.12.0)\nRequirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.24.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.5.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipdb->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.4.2)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.2.2)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.0.15)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.0.9)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (4.14.0)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (0.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (3.6.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.3.1)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.19.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.0.51)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.19.2)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.25.1)\nRequirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.3.0)\nRequirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.1.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.3.0)\nRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.4)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (6.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.5.1)\nRequirement already satisfied: testpath in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.6.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (4.13.4)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.5.13)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.21.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->freezegun<2.0.0,>=1.5.1->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.17.0)\nRequirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (21.2.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->speedy-utils<0.2.0,>=0.1.20->opensloth==0.1.7) (2024.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.8.4)\nRequirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.5.1)\nRequirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (3.0.0)\nRequirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.3.0)\nRequirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (24.11.1)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.2.13)\nRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.17.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.7)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (0.5.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.22)\nRequirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab<5.0.0,>=4.3.5->opensloth==0.1.7) (2.9.0.20250516)\nDownloading opensloth-0.1.7-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jupyterlab-4.4.7-py3-none-any.whl (12.3 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading speedy_utils-0.1.30-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\nDownloading freezegun-1.5.5-py3-none-any.whl (19 kB)\nDownloading json_repair-0.40.0-py3-none-any.whl (20 kB)\nDownloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bump2version-1.0.1-py2.py3-none-any.whl (22 kB)\nDownloading ipdb-0.13.13-py3-none-any.whl (12 kB)\nDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, loguru, json-repair, fire, bump2version, async-lru, freezegun, ipdb, jupyter-lsp, jupyterlab, tensorboardx, tensorboard, speedy-utils, opensloth\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: jupyter-lsp\n    Found existing installation: jupyter-lsp 1.5.1\n    Uninstalling jupyter-lsp-1.5.1:\n      Successfully uninstalled jupyter-lsp-1.5.1\n  Attempting uninstall: jupyterlab\n    Found existing installation: jupyterlab 3.6.8\n    Uninstalling jupyterlab-3.6.8:\n      Successfully uninstalled jupyterlab-3.6.8\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\njupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, but you have jupyterlab 4.4.7 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.20.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed async-lru-2.0.5 bump2version-1.0.1 fire-0.7.1 freezegun-1.5.5 ipdb-0.13.13 json-repair-0.40.0 jupyter-lsp-2.3.0 jupyterlab-4.4.7 loguru-0.7.3 opensloth-0.1.7 packaging-24.2 speedy-utils-0.1.30 tensorboard-2.20.0 tensorboardx-2.6.4\n\u001b[31mERROR: Could not find a version that satisfies the requirement TextStreamer (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for TextStreamer\u001b[0m\u001b[31m\n\u001b[0m笨 TT-12 Dependencies installed:\n泅 OpenSloth: Multi-GPU training\n沁ｯ vLLM: Precise inference\n沒 Analysis libraries: scikit-learn, matplotlib, seaborn\n洶･ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-09-18 14:56:48.011249: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758207408.369397      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758207408.468583      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"洶･ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":1},{"id":"b11239ed","cell_type":"markdown","source":"# 1. Configuration and Data Setup","metadata":{}},{"id":"a2d63f89","cell_type":"code","source":"%%writefile constants.py\nfrom unsloth import FastLanguageModel\n# Using base Qwen3 1.7B model from Kaggle input (no internet needed)\nBASE_MODEL_PATH = \"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\"  # Update this path as needed\nLORA_PATH = \"qwen3_1.7b_opensloth_lora_validation/\"  # OpenSloth LoRA output path for validation\nDATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules/\"\n\n_ , tokenizer = FastLanguageModel.from_pretrained(\n    model_name=BASE_MODEL_PATH,\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\nCHAt_TEMPLATE = tokenizer.chat_template\n\n# TT-12 Validation Parameters\nTRAINING_DATA_PERCENTAGE = .3  # Controllable % of training data (0.1 = 10%, 1.0 = 100%)\nUSE_STRATIFIED_SAMPLING = True  # Maintain rule distribution when sampling\n\nPOSITIVE_ANSWER = \"Yes\"\nNEGATIVE_ANSWER = \"No\"\nCOMPLETE_PHRASE = \"Answer:\"\nBASE_PROMPT = '''You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.'''\n\nprint(\"笨 Using Qwen3 1.7B model from local Kaggle input\")\nprint(f\"沁ｯ TT-12: OpenSloth training + vLLM inference with {TRAINING_DATA_PERCENTAGE*100:.0f}% of data\")\nprint(f\"沒 Stratified sampling: {USE_STRATIFIED_SAMPLING}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:57:18.419240Z","iopub.execute_input":"2025-09-18T14:57:18.419441Z","iopub.status.idle":"2025-09-18T14:57:18.424713Z","shell.execute_reply.started":"2025-09-18T14:57:18.419419Z","shell.execute_reply":"2025-09-18T14:57:18.423954Z"}},"outputs":[{"name":"stdout","text":"Writing constants.py\n","output_type":"stream"}],"execution_count":2},{"id":"f76e5f0a-d6a2-4d76-b9f3-3b51c643d488","cell_type":"code","source":"!python constants.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:57:18.425472Z","iopub.execute_input":"2025-09-18T14:57:18.425725Z","iopub.status.idle":"2025-09-18T14:57:53.843113Z","shell.execute_reply.started":"2025-09-18T14:57:18.425701Z","shell.execute_reply":"2025-09-18T14:57:53.842380Z"}},"outputs":[{"name":"stdout","text":"洶･ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-18 14:57:25.094818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758207445.116329     180 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758207445.123073     180 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n洶･ Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n笨 Using Qwen3 1.7B model from local Kaggle input\n沁ｯ TT-12: OpenSloth training + vLLM inference with 30% of data\n沒 Stratified sampling: True\n","output_type":"stream"}],"execution_count":3},{"id":"96e665e3-1b2e-41e7-9075-b430579f7323","cell_type":"code","source":"from constants import CHAt_TEMPLATE\nprint(CHAt_TEMPLATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:57:53.844061Z","iopub.execute_input":"2025-09-18T14:57:53.844274Z","iopub.status.idle":"2025-09-18T14:57:58.736060Z","shell.execute_reply.started":"2025-09-18T14:57:53.844253Z","shell.execute_reply":"2025-09-18T14:57:58.735143Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n笨 Using Qwen3 1.7B model from local Kaggle input\n沁ｯ TT-12: OpenSloth training + vLLM inference with 30% of data\n沒 Stratified sampling: True\n{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0].role == 'system' %}\n        {{- messages[0].content + '\\n\\n' }}\n    {%- endif %}\n    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0].role == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n{%- for forward_message in messages %}\n    {%- set index = (messages|length - 1) - loop.index0 %}\n    {%- set message = messages[index] %}\n    {%- set tool_start = '<tool_response>' %}\n    {%- set tool_start_length = tool_start|length %}\n    {%- set start_of_message = message.content[:tool_start_length] %}\n    {%- set tool_end = '</tool_response>' %}\n    {%- set tool_end_length = tool_end|length %}\n    {%- set start_pos = (message.content|length) - tool_end_length %}\n    {%- if start_pos < 0 %}\n        {%- set start_pos = 0 %}\n    {%- endif %}\n    {%- set end_of_message = message.content[start_pos:] %}\n    {%- if ns.multi_step_tool and message.role == \"user\" and not(start_of_message == tool_start and end_of_message == tool_end) %}\n        {%- set ns.multi_step_tool = false %}\n        {%- set ns.last_query_index = index %}\n    {%- endif %}\n{%- endfor %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {%- set content = message.content %}\n        {%- set reasoning_content = '' %}\n        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n            {%- set reasoning_content = message.reasoning_content %}\n        {%- else %}\n            {%- if '</think>' in message.content %}\n                {%- set content = (message.content.split('</think>')|last).lstrip('\\n') %}\n                {%- set reasoning_content = (message.content.split('</think>')|first).rstrip('\\n') %}\n                {%- set reasoning_content = (reasoning_content.split('<think>')|last).lstrip('\\n') %}\n            {%- endif %}\n        {%- endif %}\n        {%- if loop.index0 > ns.last_query_index %}\n            {%- if loop.last or (not loop.last and reasoning_content) %}\n                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n            {%- else %}\n                {{- '<|im_start|>' + message.role + '\\n' + content }}\n            {%- endif %}\n        {%- else %}\n            {{- '<|im_start|>' + message.role + '\\n' + content }}\n        {%- endif %}\n        {%- if message.tool_calls %}\n            {%- for tool_call in message.tool_calls %}\n                {%- if (loop.first and content) or (not loop.first) %}\n                    {{- '\\n' }}\n                {%- endif %}\n                {%- if tool_call.function %}\n                    {%- set tool_call = tool_call.function %}\n                {%- endif %}\n                {{- '<tool_call>\\n{\"name\": \"' }}\n                {{- tool_call.name }}\n                {{- '\", \"arguments\": ' }}\n                {%- if tool_call.arguments is string %}\n                    {{- tool_call.arguments }}\n                {%- else %}\n                    {{- tool_call.arguments | tojson }}\n                {%- endif %}\n                {{- '}\\n</tool_call>' }}\n            {%- endfor %}\n        {%- endif %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n    {%- if enable_thinking is defined and enable_thinking is false %}\n        {{- '<think>\\n\\n</think>\\n\\n' }}\n    {%- endif %}\n{%- endif %}\n","output_type":"stream"}],"execution_count":4},{"id":"75e2fad7","cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\nfrom datasets import Dataset, load_from_disk\nfrom constants import CHAt_TEMPLATE ,POSITIVE_ANSWER, NEGATIVE_ANSWER, COMPLETE_PHRASE, BASE_PROMPT, TRAINING_DATA_PERCENTAGE, USE_STRATIFIED_SAMPLING, DATA_PATH\nimport random, numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom unsloth import FastLanguageModel\nfrom trl import SFTConfig, SFTTrainer\nimport os\nimport shutil\nrandom.seed(42)\nnp.random.seed(42)\n\n\ndef build_prompt(row):\n    return f\"\"\"\n{BASE_PROMPT}\n\nSubreddit: r/{row[\"subreddit\"]}\nRule: {row[\"rule\"]}\nExamples:\n1) {row[\"positive_example\"]}\n{COMPLETE_PHRASE} Yes\n\n2) {row[\"negative_example\"]}\n{COMPLETE_PHRASE} No\n\n---\nComment: {row[\"body\"]}\n{COMPLETE_PHRASE}\"\"\"\n\n\ndef get_example_based_training_data(data_path):\n    \"\"\"\n    TT-12: Create training data from examples (like test-time training)\n    This trains the model on examples, not actual comments\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Sample data if needed while maintaining rule distribution\n    if TRAINING_DATA_PERCENTAGE < 1.0:\n        if USE_STRATIFIED_SAMPLING:\n            # Stratified sampling to maintain rule distribution\n            train_dataset = train_dataset.groupby('rule', group_keys=False).apply(\n                lambda x: x.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42)\n            ).reset_index(drop=True)\n            print(f\"沒 Stratified sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n        else:\n            # Simple random sampling\n            train_dataset = train_dataset.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42).reset_index(drop=True)\n            print(f\"沒 Random sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n    \n    print(f\"沒 Training data size: {len(train_dataset)} samples\")\n    print(f\"沒 Rule distribution: {train_dataset['rule'].value_counts().to_dict()}\")\n    \n    flatten = []\n    \n    # Create training data from examples (similar to test-time training)\n    for violation_type in [\"positive\", \"negative\"]:\n        for i in range(1, 3):\n            sub_dataset = train_dataset[[\"rule\",\"subreddit\",\n                                        \"positive_example_1\",\"positive_example_2\",\n                                        \"negative_example_1\",\"negative_example_2\"]].copy()\n\n            if violation_type == \"positive\":\n                # Use positive example as the \"body\" to classify\n                body_col = f\"positive_example_{i}\"\n                other_positive_col = f\"positive_example_{3-i}\"  # other positive\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"positive_example\"] = sub_dataset[other_positive_col]\n                # negative_example randomly selected\n                sub_dataset[\"negative_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"negative_example_1\"],\n                    sub_dataset[\"negative_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 1  # Positive examples violate rules\n\n            else:  # violation_type == \"negative\"\n                # Use negative example as the \"body\" to classify\n                body_col = f\"negative_example_{i}\"\n                other_negative_col = f\"negative_example_{3-i}\"\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"negative_example\"] = sub_dataset[other_negative_col]\n                sub_dataset[\"positive_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"positive_example_1\"],\n                    sub_dataset[\"positive_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 0  # Negative examples don't violate rules\n\n            # Drop original candidate columns\n            sub_dataset.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                                      \"negative_example_1\",\"negative_example_2\"], inplace=True)\n\n            flatten.append(sub_dataset)\n\n    # Merge all DataFrames\n    example_training_df = pd.concat(flatten, axis=0)\n    example_training_df = example_training_df.drop_duplicates(ignore_index=True)\n    \n    print(f\"沒 Example-based training dataset: {len(example_training_df)} samples\")\n    print(f\"沒 Positive examples: {sum(example_training_df['rule_violation'] == 1)}\")\n    print(f\"沒 Negative examples: {sum(example_training_df['rule_violation'] == 0)}\")\n    \n    return example_training_df\n\n\ndef get_real_comment_validation_data(data_path):\n    \"\"\"\n    TT-12: Get real comments with labels for validation\n    This is what we actually want to predict\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Use actual comments and their labels for validation\n    validation_df = train_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\",\n                                  \"positive_example_1\",\"positive_example_2\",\n                                  \"negative_example_1\",\"negative_example_2\"]].copy()\n\n    # Randomly select positive_example and negative_example for prompts\n    validation_df[\"positive_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"positive_example_1\"],\n        validation_df[\"positive_example_2\"]\n    )\n    validation_df[\"negative_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"negative_example_1\"],\n        validation_df[\"negative_example_2\"]\n    )\n\n    # Drop original candidate columns\n    validation_df.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                               \"negative_example_1\",\"negative_example_2\"], inplace=True)\n    \n    print(f\"沒 Real comment validation dataset: {len(validation_df)} samples\")\n    print(f\"沒 Rule violations: {sum(validation_df['rule_violation'] == 1)} positive, {sum(validation_df['rule_violation'] == 0)} negative\")\n    \n    return validation_df\n\n\ndef build_dataset_for_opensloth(dataframe, tokenizer):\n    \"\"\"Build dataset for OpenSloth training with proper text formatting\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    \n    # OpenSloth uses a text field\n    dataframe[\"text\"] = dataframe.apply(lambda row: \n        tokenizer.apply_chat_template(\n            [\n                {\"role\": \"user\", \"content\": row[\"prompt\"]},\n                {\"role\": \"assistant\", \"content\": POSITIVE_ANSWER if row[\"rule_violation\"] == 1 else NEGATIVE_ANSWER},\n            ],\n            tokenize=False,\n            add_generation_prompt=False,\n        ),\n        axis=1\n    )\n    \n    dataset = Dataset.from_pandas(dataframe[[\"text\"]])\n    return dataset\n\ndef build_dataset_unsloth(dataframe):\n    \"\"\"Build dataset for Unsloth training with proper text formatting\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    \n    # Unsloth expects \"text\" field with full prompt + completion\n    dataframe[\"text\"] = dataframe.apply(lambda row: \n        row[\"prompt\"] + \" \" + (POSITIVE_ANSWER if row[\"rule_violation\"] == 1 else NEGATIVE_ANSWER), \n        axis=1\n    )\n    \n    dataframe = dataframe[[\"text\"]]\n    dataset = Dataset.from_pandas(dataframe)\n    return dataset\n\n\ndef build_validation_dataset(dataframe):\n    \"\"\"Build dataset for validation (keep labels for evaluation)\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    dataframe = dataframe[[\"prompt\", \"rule_violation\"]]  # Keep true labels for evaluation\n    dataset = Dataset.from_pandas(dataframe)\n    return dataset\n\ndef cache_dataset(cache_path):\n    if os.path.exists(cache_path):\n        print(f\"泓托ｸ Deleting existing cache folder at {cache_path}\")\n        shutil.rmtree(cache_path)  # Recursively delete the folder and its contents\n\n    print(f\"汳ｾ Caching dataset to {cache_path}\")\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\",\n        max_seq_length=2048,\n        load_in_4bit=True,\n    )\n    \n    # 笨 ADD: Configure LoRA adapters for the quantized model\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r=16,\n        target_modules=[\n            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n            \"gate_proj\", \"up_proj\", \"down_proj\",\n        ],\n        lora_alpha=16,\n        lora_dropout=0,\n        bias=\"none\",\n        use_gradient_checkpointing=\"unsloth\",\n        random_state=3407,\n    )\n    \n    # Set chat template\n    tokenizer.chat_template = CHAt_TEMPLATE\n    \n    train_df = get_example_based_training_data(DATA_PATH)\n    dataset = build_dataset_for_opensloth(train_df, tokenizer)\n    \n    # Now SFTTrainer will work with LoRA-enabled model\n    trainer = SFTTrainer(\n        model=model,  # 竊 Now has LoRA adapters\n        tokenizer=tokenizer,\n        train_dataset=dataset,\n        args=SFTConfig(\n            dataset_text_field=\"text\",\n            max_seq_length=2048,\n            dataset_num_proc=2,\n            packing=True,\n        ),\n    )\n    \n    trainer.train_dataset.save_to_disk(cache_path)\n    print(f\"笨 Dataset cached to {cache_path}\")\n\n\ndef get_cached_dataset(cache_path):\n    if not os.path.exists(cache_path):\n        raise RuntimeError(\"Dataset cache not found. Please run the caching step first.\")\n    return load_from_disk(cache_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T15:21:02.900854Z","iopub.execute_input":"2025-09-18T15:21:02.901209Z","iopub.status.idle":"2025-09-18T15:21:02.911930Z","shell.execute_reply.started":"2025-09-18T15:21:02.901181Z","shell.execute_reply":"2025-09-18T15:21:02.911199Z"}},"outputs":[{"name":"stdout","text":"Overwriting utils.py\n","output_type":"stream"}],"execution_count":23},{"id":"f9aab218-387b-448c-b279-95c81f733380","cell_type":"code","source":"if os.path.exists(cache_path):\n        print(f\"汳ｾ Loading cached dataset from {cache_path}\")\n\nprint(f\"汳ｾ Caching dataset to {cache_path}\")\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\",\n        max_seq_length=2048,\n        load_in_4bit=True,\n    )\n    \n    # Set chat template\ntokenizer.chat_template = CHAt_TEMPLATE\n    \ntrain_df = get_example_based_training_data(DATA_PATH)\ndataset = build_dataset_for_opensloth(train_df, tokenizer)\n    \n    # 笨 Save dataset directly without SFTTrainer\ndataset.save_to_disk(cache_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:26:54.334089Z","iopub.execute_input":"2025-09-18T14:26:54.334784Z","iopub.status.idle":"2025-09-18T14:26:59.790147Z","shell.execute_reply.started":"2025-09-18T14:26:54.334757Z","shell.execute_reply":"2025-09-18T14:26:59.789554Z"}},"outputs":[{"name":"stdout","text":"汳ｾ Caching dataset to ass\n==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n沒 Stratified sampling: 609 samples (30%)\n沒 Training data size: 609 samples\n沒 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 305, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 304}\n沒 Example-based training dataset: 2435 samples\n沒 Positive examples: 1218\n沒 Negative examples: 1217\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/2435 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95aa6e321ee64320b1517b7d9b3dcc64"}},"metadata":{}}],"execution_count":65},{"id":"60f8a561-d945-4781-be7c-a8ddbf0f045b","cell_type":"code","source":"from transformers import TextStreamer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:06:47.141562Z","iopub.execute_input":"2025-09-18T14:06:47.141841Z","iopub.status.idle":"2025-09-18T14:06:47.146285Z","shell.execute_reply.started":"2025-09-18T14:06:47.141809Z","shell.execute_reply":"2025-09-18T14:06:47.145667Z"}},"outputs":[],"execution_count":33},{"id":"103a61ae-a43b-4f98-bf64-c454e09c1699","cell_type":"code","source":"import unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T13:49:18.041549Z","iopub.execute_input":"2025-09-18T13:49:18.042011Z","iopub.status.idle":"2025-09-18T13:49:46.697872Z","shell.execute_reply.started":"2025-09-18T13:49:18.041986Z","shell.execute_reply":"2025-09-18T13:49:46.696770Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3279665559.py:1: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n\nPlease restructure your imports with 'import unsloth' at the top of your file.\n  import unsloth\n/usr/local/lib/python3.11/dist-packages/unsloth/__init__.py:177: UserWarning: Unsloth: Running `ldconfig /usr/lib64-nvidia` to link CUDA.\n  warnings.warn(\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/usr/local/lib/python3.11/dist-packages/unsloth/__init__.py:211: UserWarning: Unsloth: CUDA is not linked properly.\nTry running `python -m bitsandbytes` then `python -m xformers.info`\nWe tried running `ldconfig /usr/lib64-nvidia` ourselves, but it didn't work.\nYou need to run in your terminal `sudo ldconfig /usr/lib64-nvidia` yourself, then import Unsloth.\nAlso try `sudo ldconfig /usr/local/cuda-xx.x` - find the latest cuda version.\nUnsloth will still run for now, but maybe it might crash - let's hope it works!\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"洶･ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-09-18 13:49:25.710919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758203366.050247      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758203366.150830      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"洶･ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3279665559.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0munsloth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mllama\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mFastLlamaModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m    \u001b[0;32mimport\u001b[0m \u001b[0mFastLanguageModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFastVisionModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFastTextModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFastModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmistral\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mFastMistralModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0m_prepare_4d_causal_attention_mask_for_sdpa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mHAS_FLASH_ATTENTION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m from .cross_entropy_loss import (\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mfast_cross_entropy_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpost_patch_loss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/cross_entropy_loss.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtriton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from .utils import (\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mcalculate_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mMAX_FUSED_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# https://github.com/bitsandbytes-foundation/bitsandbytes/pull/1330/files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mHAS_CUDA_STREAM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.43.3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mget_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ptr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'bitsandbytes' has no attribute 'functional'"],"ename":"AttributeError","evalue":"module 'bitsandbytes' has no attribute 'functional'","output_type":"error"}],"execution_count":14},{"id":"ae027499","cell_type":"code","source":"from unsloth import FastLanguageModel\nmodel , tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\",\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:06:02.724238Z","iopub.execute_input":"2025-09-18T14:06:02.724513Z","iopub.status.idle":"2025-09-18T14:06:07.658948Z","shell.execute_reply.started":"2025-09-18T14:06:02.724493Z","shell.execute_reply":"2025-09-18T14:06:07.658304Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":30},{"id":"c94b7da6-869f-4cf4-b53e-4018b18a84ad","cell_type":"code","source":"print(tokenizer.chat_template)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T13:56:04.876971Z","iopub.execute_input":"2025-09-18T13:56:04.877274Z","iopub.status.idle":"2025-09-18T13:56:04.881500Z","shell.execute_reply.started":"2025-09-18T13:56:04.877252Z","shell.execute_reply":"2025-09-18T13:56:04.880749Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0].role == 'system' %}\n        {{- messages[0].content + '\\n\\n' }}\n    {%- endif %}\n    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0].role == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n{%- for forward_message in messages %}\n    {%- set index = (messages|length - 1) - loop.index0 %}\n    {%- set message = messages[index] %}\n    {%- set tool_start = '<tool_response>' %}\n    {%- set tool_start_length = tool_start|length %}\n    {%- set start_of_message = message.content[:tool_start_length] %}\n    {%- set tool_end = '</tool_response>' %}\n    {%- set tool_end_length = tool_end|length %}\n    {%- set start_pos = (message.content|length) - tool_end_length %}\n    {%- if start_pos < 0 %}\n        {%- set start_pos = 0 %}\n    {%- endif %}\n    {%- set end_of_message = message.content[start_pos:] %}\n    {%- if ns.multi_step_tool and message.role == \"user\" and not(start_of_message == tool_start and end_of_message == tool_end) %}\n        {%- set ns.multi_step_tool = false %}\n        {%- set ns.last_query_index = index %}\n    {%- endif %}\n{%- endfor %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {%- set content = message.content %}\n        {%- set reasoning_content = '' %}\n        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n            {%- set reasoning_content = message.reasoning_content %}\n        {%- else %}\n            {%- if '</think>' in message.content %}\n                {%- set content = (message.content.split('</think>')|last).lstrip('\\n') %}\n                {%- set reasoning_content = (message.content.split('</think>')|first).rstrip('\\n') %}\n                {%- set reasoning_content = (reasoning_content.split('<think>')|last).lstrip('\\n') %}\n            {%- endif %}\n        {%- endif %}\n        {%- if loop.index0 > ns.last_query_index %}\n            {%- if loop.last or (not loop.last and reasoning_content) %}\n                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n            {%- else %}\n                {{- '<|im_start|>' + message.role + '\\n' + content }}\n            {%- endif %}\n        {%- else %}\n            {{- '<|im_start|>' + message.role + '\\n' + content }}\n        {%- endif %}\n        {%- if message.tool_calls %}\n            {%- for tool_call in message.tool_calls %}\n                {%- if (loop.first and content) or (not loop.first) %}\n                    {{- '\\n' }}\n                {%- endif %}\n                {%- if tool_call.function %}\n                    {%- set tool_call = tool_call.function %}\n                {%- endif %}\n                {{- '<tool_call>\\n{\"name\": \"' }}\n                {{- tool_call.name }}\n                {{- '\", \"arguments\": ' }}\n                {%- if tool_call.arguments is string %}\n                    {{- tool_call.arguments }}\n                {%- else %}\n                    {{- tool_call.arguments | tojson }}\n                {%- endif %}\n                {{- '}\\n</tool_call>' }}\n            {%- endfor %}\n        {%- endif %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- message.content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\\n' }}\n    {%- if enable_thinking is defined and enable_thinking is false %}\n        {{- '<think>\\n\\n</think>\\n\\n' }}\n    {%- endif %}\n{%- endif %}\n","output_type":"stream"}],"execution_count":12},{"id":"28d34314-f34b-4459-a7c4-6c7770613acf","cell_type":"code","source":"from transformers import AutoTokenizer\ntok=AutoTokenizer.from_pretrained(r\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\")\ntok.chat_template\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T13:57:19.731894Z","iopub.execute_input":"2025-09-18T13:57:19.732328Z","iopub.status.idle":"2025-09-18T13:57:20.227830Z","shell.execute_reply.started":"2025-09-18T13:57:19.732293Z","shell.execute_reply":"2025-09-18T13:57:20.227032Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0].role == \\'system\\' %}\\n        {{- messages[0].content + \\'\\\\n\\\\n\\' }}\\n    {%- endif %}\\n    {{- \"# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0].role == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0].content + \\'<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\\n{%- for forward_message in messages %}\\n    {%- set index = (messages|length - 1) - loop.index0 %}\\n    {%- set message = messages[index] %}\\n    {%- set tool_start = \\'<tool_response>\\' %}\\n    {%- set tool_start_length = tool_start|length %}\\n    {%- set start_of_message = message.content[:tool_start_length] %}\\n    {%- set tool_end = \\'</tool_response>\\' %}\\n    {%- set tool_end_length = tool_end|length %}\\n    {%- set start_pos = (message.content|length) - tool_end_length %}\\n    {%- if start_pos < 0 %}\\n        {%- set start_pos = 0 %}\\n    {%- endif %}\\n    {%- set end_of_message = message.content[start_pos:] %}\\n    {%- if ns.multi_step_tool and message.role == \"user\" and not(start_of_message == tool_start and end_of_message == tool_end) %}\\n        {%- set ns.multi_step_tool = false %}\\n        {%- set ns.last_query_index = index %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {%- set content = message.content %}\\n        {%- set reasoning_content = \\'\\' %}\\n        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\\n            {%- set reasoning_content = message.reasoning_content %}\\n        {%- else %}\\n            {%- if \\'</think>\\' in message.content %}\\n                {%- set content = (message.content.split(\\'</think>\\')|last).lstrip(\\'\\\\n\\') %}\\n                {%- set reasoning_content = (message.content.split(\\'</think>\\')|first).rstrip(\\'\\\\n\\') %}\\n                {%- set reasoning_content = (reasoning_content.split(\\'<think>\\')|last).lstrip(\\'\\\\n\\') %}\\n            {%- endif %}\\n        {%- endif %}\\n        {%- if loop.index0 > ns.last_query_index %}\\n            {%- if loop.last or (not loop.last and reasoning_content) %}\\n                {{- \\'<|im_start|>\\' + message.role + \\'\\\\n<think>\\\\n\\' + reasoning_content.strip(\\'\\\\n\\') + \\'\\\\n</think>\\\\n\\\\n\\' + content.lstrip(\\'\\\\n\\') }}\\n            {%- else %}\\n                {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + content }}\\n            {%- endif %}\\n        {%- else %}\\n            {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + content }}\\n        {%- endif %}\\n        {%- if message.tool_calls %}\\n            {%- for tool_call in message.tool_calls %}\\n                {%- if (loop.first and content) or (not loop.first) %}\\n                    {{- \\'\\\\n\\' }}\\n                {%- endif %}\\n                {%- if tool_call.function %}\\n                    {%- set tool_call = tool_call.function %}\\n                {%- endif %}\\n                {{- \\'<tool_call>\\\\n{\"name\": \"\\' }}\\n                {{- tool_call.name }}\\n                {{- \\'\", \"arguments\": \\' }}\\n                {%- if tool_call.arguments is string %}\\n                    {{- tool_call.arguments }}\\n                {%- else %}\\n                    {{- tool_call.arguments | tojson }}\\n                {%- endif %}\\n                {{- \\'}\\\\n</tool_call>\\' }}\\n            {%- endfor %}\\n        {%- endif %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n    {%- if enable_thinking is defined and enable_thinking is false %}\\n        {{- \\'<think>\\\\n\\\\n</think>\\\\n\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}'"},"metadata":{}}],"execution_count":13},{"id":"e88a6fdb-2982-492f-bc61-42c16a51d943","cell_type":"code","source":"merge","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"aec6eddd-6794-4500-bf2c-7326e6d1aeaa","cell_type":"markdown","source":"> ","metadata":{}},{"id":"6b4f6986-b802-49e1-a692-187ec41bf2d1","cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T13:05:12.140086Z","iopub.execute_input":"2025-09-18T13:05:12.140633Z","iopub.status.idle":"2025-09-18T13:05:12.167184Z","shell.execute_reply.started":"2025-09-18T13:05:12.140606Z","shell.execute_reply":"2025-09-18T13:05:12.166251Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2308695852.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tokenizer.apply_chat_template(\n\u001b[0m\u001b[1;32m      2\u001b[0m             [\n\u001b[1;32m      3\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPOSITIVE_ANSWER\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"rule_violation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNEGATIVE_ANSWER\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             ],\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mapply_chat_template\u001b[0;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m             \u001b[0mtokenizer_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m         \u001b[0mchat_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chat_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_assistant_tokens_mask\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\{\\%-?\\s*generation\\s*-?\\%\\}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mget_chat_template\u001b[0;34m(self, chat_template, tools)\u001b[0m\n\u001b[1;32m   1820\u001b[0m                 \u001b[0mchat_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1823\u001b[0m                     \u001b[0;34m\"Cannot use chat template functions because tokenizer.chat_template is not set and no template \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;34m\"argument was passed! For information about writing templates and setting the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating"],"ename":"ValueError","evalue":"Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating","output_type":"error"}],"execution_count":15},{"id":"e2d4d6d8-0008-4996-9b36-8cf0815e17fd","cell_type":"markdown","source":"#TESTING SECTION","metadata":{}},{"id":"5bf446ec-7516-425b-9167-918be6108a6e","cell_type":"code","source":"print(tokenizer.chat_template)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T13:01:58.577623Z","iopub.execute_input":"2025-09-18T13:01:58.577900Z","iopub.status.idle":"2025-09-18T13:01:58.582136Z","shell.execute_reply.started":"2025-09-18T13:01:58.577877Z","shell.execute_reply":"2025-09-18T13:01:58.581345Z"}},"outputs":[{"name":"stdout","text":"None\n","output_type":"stream"}],"execution_count":14},{"id":"38d2447b","cell_type":"code","source":"from utils import *\ntrain_df = get_example_based_training_data(DATA_PATH)\ndataset = build_dataset_for_opensloth(train_df, tokenizer)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:05:36.381547Z","iopub.execute_input":"2025-09-18T14:05:36.381862Z","iopub.status.idle":"2025-09-18T14:05:36.887643Z","shell.execute_reply.started":"2025-09-18T14:05:36.381811Z","shell.execute_reply":"2025-09-18T14:05:36.887060Z"}},"outputs":[{"name":"stdout","text":"沒 Stratified sampling: 609 samples (30%)\n沒 Training data size: 609 samples\n沒 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 305, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 304}\n沒 Example-based training dataset: 2435 samples\n沒 Positive examples: 1218\n沒 Negative examples: 1217\n","output_type":"stream"}],"execution_count":28},{"id":"a22dd19a-f1cb-489d-aad5-9c9724f9598d","cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:13:13.897179Z","iopub.execute_input":"2025-09-18T14:13:13.897462Z","iopub.status.idle":"2025-09-18T14:13:13.901306Z","shell.execute_reply.started":"2025-09-18T14:13:13.897440Z","shell.execute_reply":"2025-09-18T14:13:13.900596Z"}},"outputs":[],"execution_count":42},{"id":"28796082-1b53-4631-8e52-e6bb34d1d626","cell_type":"code","source":"try:\n    model = PeftModel.from_pretrained(model, LORA_PATH)\n    model = model.merge_and_unload()\nexcept:\n    pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:17:02.974409Z","iopub.execute_input":"2025-09-18T14:17:02.974893Z","iopub.status.idle":"2025-09-18T14:17:02.979587Z","shell.execute_reply.started":"2025-09-18T14:17:02.974854Z","shell.execute_reply":"2025-09-18T14:17:02.978798Z"}},"outputs":[],"execution_count":45},{"id":"cfbe3537","cell_type":"code","source":"print(dataset[666])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:06:33.714721Z","iopub.execute_input":"2025-09-18T14:06:33.715174Z","iopub.status.idle":"2025-09-18T14:06:33.719558Z","shell.execute_reply.started":"2025-09-18T14:06:33.715143Z","shell.execute_reply":"2025-09-18T14:06:33.718638Z"}},"outputs":[{"name":"stdout","text":"{'text': \"<|im_start|>user\\n\\nYou are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.\\n\\nSubreddit: r/news\\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nExamples:\\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\\nAnswer: Yes\\n\\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\\nAnswer: No\\n\\n---\\nComment: 39 http://MySexFind.com - find girl for sex now 39!\\nAnswer:<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\nYes<|im_end|>\\n\"}\n","output_type":"stream"}],"execution_count":31},{"id":"913d205b","cell_type":"code","source":"# Enable inference mode\n\nFastLanguageModel.for_inference(model)\n\n# Prepare input\ninputs = tokenizer(dataset[666]['text'], return_tensors=\"pt\").to(\"cuda\")\n\n# Get logits for the next token (without generating)\nwith torch.no_grad():\n    outputs = model(**inputs)\n    next_token_logits = outputs.logits[0, -1, :]  # Last token's logits\n\n# Get Yes/No token IDs\nyes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\nno_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n\n# Extract logits for Yes/No tokens\nyes_logit = next_token_logits[yes_token_id]\nno_logit = next_token_logits[no_token_id]\n\n# Convert to probabilities\nimport torch.nn.functional as F\ncombined_logits = torch.stack([no_logit, yes_logit])  # [No, Yes]\nprobabilities = F.softmax(combined_logits, dim=0)\n\nprob_no = probabilities[0].item()\nprob_yes = probabilities[1].item()\n\nprint(f\"Probability of 'No': {prob_no:.4f}\")\nprint(f\"Probability of 'Yes': {prob_yes:.4f}\")\nprint(f\"Prediction: {'Yes' if prob_yes > prob_no else 'No'}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:13:18.636665Z","iopub.execute_input":"2025-09-18T14:13:18.637162Z","iopub.status.idle":"2025-09-18T14:13:18.797357Z","shell.execute_reply.started":"2025-09-18T14:13:18.637140Z","shell.execute_reply":"2025-09-18T14:13:18.796475Z"}},"outputs":[{"name":"stdout","text":"Probability of 'No': 0.0000\nProbability of 'Yes': 1.0000\nPrediction: Yes\n","output_type":"stream"}],"execution_count":43},{"id":"796888b0-2f24-4d8f-9185-1bf60e1ad19c","cell_type":"code","source":"# Some versions support returning logits\nFastLanguageModel.for_inference(model)\ninputs = tokenizer(dataset[666]['text'], return_tensors=\"pt\").to(\"cuda\")\n\n# Generate with output_scores=True\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=1,  # Only generate 1 token\n    output_scores=True,\n    return_dict_in_generate=True,\n    do_sample=False,  # Greedy decoding\n    pad_token_id=tokenizer.eos_token_id\n)\n\nif hasattr(outputs, 'scores') and outputs.scores:\n    # Get the logits for the first (and only) generated token\n    next_token_logits = outputs.scores[0][0]  # [batch_size=1, vocab_size]\n    \n    yes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\n    no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n    \n    yes_logit = next_token_logits[yes_token_id]\n    no_logit = next_token_logits[no_token_id]\n    \n    # Convert to probabilities\n    combined_logits = torch.stack([no_logit, yes_logit])\n    probabilities = F.softmax(combined_logits, dim=0)\n    \n    prob_no = probabilities[0].item()\n    prob_yes = probabilities[1].item()\n    \n    print(f\"Probability of 'No': {prob_no:.4f}\")\n    print(f\"Probability of 'Yes': {prob_yes:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:14:57.016437Z","iopub.execute_input":"2025-09-18T14:14:57.016728Z","iopub.status.idle":"2025-09-18T14:14:57.165245Z","shell.execute_reply.started":"2025-09-18T14:14:57.016706Z","shell.execute_reply":"2025-09-18T14:14:57.164372Z"}},"outputs":[{"name":"stdout","text":"Probability of 'No': 0.0000\nProbability of 'Yes': 1.0000\n","output_type":"stream"}],"execution_count":44},{"id":"a7083c80","cell_type":"code","source":"\n# Decode the full output to readable text\ndecoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(\"\\n\" + \"=\"*50)\nprint(\"沁ｯ Full Decoded Output (including thinking):\")\nprint(decoded_output)\nprint(\"=\"*512)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:45:05.486062Z","iopub.execute_input":"2025-09-17T13:45:05.486365Z","iopub.status.idle":"2025-09-17T13:45:05.492695Z","shell.execute_reply.started":"2025-09-17T13:45:05.486342Z","shell.execute_reply":"2025-09-17T13:45:05.491884Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\n==================================================\n沁ｯ Full Decoded Output (including thinking):\nuser\n\nYou are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\nAnswer:\nassistant\n<think>\n\n</think>\n\nYes\n\n================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n","output_type":"stream"}],"execution_count":34},{"id":"8402a971-332b-4ef7-a273-b985a94638cf","cell_type":"markdown","source":"Trying Thinking","metadata":{}},{"id":"c0f69c75-8049-4d14-adb8-ba8bb08b8f9f","cell_type":"code","source":"\n# Thinking prompt (replace with your dataset[0]['text'] if needed)\nthinking_prompt = \"\"\"You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule.\n\nFirst, think step-by-step about the comment and the rule.\nThen, conclude with your Single final answer: 'Answer: Yes' or 'Answer: No'.Full stop after answer.Say nothing after giving out the answer.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\n\n\"\"\"\nmessages = [\n    {\"role\": \"user\", \"content\": thinking_prompt},\n    {\"role\": \"assistant\", \"content\": \"<think>\"}\n]\nthinking_input = tokenizer.apply_chat_template(messages, tokenize=False)\n# Tokenize the input\ninputs = tokenizer(thinking_prompt, return_tensors=\"pt\").to(\"cuda\")\n\n# Generate with Qwen Thinking Mode settings\ntext_streamer = TextStreamer(tokenizer)\noutput = model.generate(\n    **inputs,\n    streamer=text_streamer,\n    max_new_tokens=500,  # Allow room for thinking\n    temperature=0.6,     # Qwen Thinking Mode: Balanced creativity\n    top_p=0.95,          # Qwen Thinking Mode: Diverse selection\n    top_k=20,            # Qwen Thinking Mode: Limit to top 20 tokens\n    min_p=0.0,           # Qwen Thinking Mode: No minimum probability threshold\n    do_sample=True,      # Enable sampling for creativity\n    #stop=[\"\\n\"],         # Stop after newline to prevent repetition\n    pad_token_id=tokenizer.eos_token_id,\n)\n\n# Decode the full output to readable text\ndecoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(\"\\n\" + \"=\"*500)\nprint(\"沁ｯ Full Decoded Output (with thinking):\")\nprint(decoded_output)\nprint(\"=\"*500)\n\n# Optional: Extract just the new part (after the prompt)\nnew_part = decoded_output[len(thinking_prompt):].strip()\nprint(\"\\n沁ｯ New Generated Part:\")\nprint(new_part)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:07:13.776643Z","iopub.execute_input":"2025-09-18T14:07:13.777455Z","iopub.status.idle":"2025-09-18T14:07:37.673410Z","shell.execute_reply.started":"2025-09-18T14:07:13.777430Z","shell.execute_reply":"2025-09-18T14:07:37.672755Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"name":"stdout","text":"You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule.\n\nFirst, think step-by-step about the comment and the rule.\nThen, conclude with your Single final answer: 'Answer: Yes' or 'Answer: No'.Full stop after answer.Say nothing after giving out the answer.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\n\nAnswer: Yes\n\nAnswer: No\nAnswer: Yes\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\n\n\n====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n沁ｯ Full Decoded Output (with thinking):\nYou are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule.\n\nFirst, think step-by-step about the comment and the rule.\nThen, conclude with your Single final answer: 'Answer: Yes' or 'Answer: No'.Full stop after answer.Say nothing after giving out the answer.\n\nSubreddit: r/news\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\nExamples:\n1) [SANDERS SUPPORTERS DON'T WORRY. LENDING TREE IS WILLING TO MAKE LOANS OF UP TO 32000 DOLLARS SO YOU CAN DONATE TO YOUR LORD AND SAVIOR](https://www.lendingtree.com/personal-loans-index)\nAnswer: Yes\n\n2) **HD** [ German Stream ](http://www.sportonline-tv.com/stream3.php) | Mobile : Yes\nAnswer: No\n\n---\nComment: 39 http://MySexFind.com - find girl for sex now 39!\n\nAnswer: Yes\n\nAnswer: No\nAnswer: Yes\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\n\n====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n\n沁ｯ New Generated Part:\nAnswer: Yes\n\nAnswer: No\nAnswer: Yes\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\nAnswer: No\n","output_type":"stream"}],"execution_count":35},{"id":"142e8d6c","cell_type":"code","source":"%%writefile train_opensloth.py\nfrom opensloth.opensloth_config import (\n    FastModelArgs,\n    LoraArgs,\n    OpenSlothConfig,\n    TrainingArguments,\n)\nfrom opensloth.scripts.opensloth_sft_trainer import run_mp_training, setup_envs\nfrom constants import BASE_MODEL_PATH, LORA_PATH\nimport torch\n\n# 笨 FIXED: Use developer's proven configuration\nGLOBAL_BZ = 16  # Reduced from 32 for 1.7B model\nDEVICES = [0, 1]  # Explicit device list like developer\nBZ = 1  # 笨 CRITICAL: Use 1 with sequence packing (from developer)\n\nopensloth_config = OpenSlothConfig(\n    data_cache_path=\"data/cache_qwen3_dataset_for_opensloth/\",\n    devices=DEVICES,\n    fast_model_args=FastModelArgs(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,  # Keep your sequence length for memory\n        load_in_4bit=True,\n        # 笨 REMOVE: local_files_only and trust_remote_code (not in developer config)\n    ),\n    lora_args=LoraArgs(\n        r=8,  # 笨 REDUCED: Use developer's smaller rank\n        lora_alpha=16,  # 笨 MATCH: Developer's alpha\n        target_modules=[\n            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n            \"gate_proj\", \"up_proj\", \"down_proj\",\n        ],\n        lora_dropout=0,\n        bias=\"none\",\n        use_rslora=False,\n    ),\n    sequence_packing=True,\n    dataset_text_field=\"text\"\n    # 笨 NOTE: dataset_text_field is handled automatically by OpenSloth when using SFTTrainer-cached data\n)\n\ntraining_config = TrainingArguments(\n    output_dir=LORA_PATH,\n    per_device_train_batch_size=BZ,  # 笨 BZ=1 with packing\n    gradient_accumulation_steps=GLOBAL_BZ // (len(DEVICES) * BZ),  # 16/2 = 8\n    learning_rate=1e-5,\n    logging_steps=1,\n    num_train_epochs=1,\n    max_steps=60,\n    lr_scheduler_type=\"linear\",\n    warmup_steps=5,\n    save_total_limit=1,\n    weight_decay=0.01,\n    optim=\"adamw_8bit\",\n    seed=3407,\n    report_to=\"none\",\n)\n\nif __name__ == \"__main__\":\n    print(f\"Global batch size: {len(DEVICES) * BZ * training_config.gradient_accumulation_steps}\")\n    print(f\"Gradient accumulation steps: {training_config.gradient_accumulation_steps}\")\n\n    setup_envs(opensloth_config, training_config)\n    run_mp_training(opensloth_config.devices, opensloth_config, training_config)\n    \n    print(f\"笨 OpenSloth training completed! LoRA adapters saved to: {LORA_PATH}\")\n    print(\"沁ｯ Ready for vLLM inference!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T15:11:54.341163Z","iopub.execute_input":"2025-09-18T15:11:54.341491Z","iopub.status.idle":"2025-09-18T15:11:54.348866Z","shell.execute_reply.started":"2025-09-18T15:11:54.341466Z","shell.execute_reply":"2025-09-18T15:11:54.348236Z"}},"outputs":[{"name":"stdout","text":"Overwriting train_opensloth.py\n","output_type":"stream"}],"execution_count":15},{"id":"1a7fe130-3837-43ce-82cc-fb0c9d777207","cell_type":"code","source":"%%writefile train_unsloth.py\nimport pandas as pd\nimport torch\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom utils import build_dataset_unsloth, get_example_based_training_data\nfrom constants import DATA_PATH, BASE_MODEL_PATH, LORA_PATH\n\n\ndef main():\n    # TT-11: Get example-based training data (train on examples, not real comments)\n    train_df = get_example_based_training_data(DATA_PATH)\n    train_dataset = build_dataset_unsloth(train_df)\n    \n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n    \n    # 泅 UNSLOTH: Load model with 4-bit quantization (2x T4 optimized)\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,  # Adjust based on your max sequence length\n        dtype=None,  # Auto-detect (will use float16)\n        load_in_4bit=True,  # Enable 4-bit quantization\n        trust_remote_code=True,\n        local_files_only=True,\n        device_map=\"balanced\"\n    )\n    print(\"笨 Unsloth model loaded with 4-bit quantization across 2x T4\")\n    \n    # 泅 UNSLOTH: Add LoRA adapters (automatic and optimized)\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r=16,  # LoRA rank (can try 8, 16, 32, 64, 128)\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n        lora_alpha=32,  # LoRA alpha (typically equal to r for Unsloth)\n        lora_dropout=0,  # 0 for faster training with Unsloth\n        bias=\"none\",\n        #use_gradient_checkpointing=False,  # Enable for memory efficiency\n        random_state=3407,  # For reproducibility\n        use_rslora=True,  # Can try True for better stability\n        loftq_config=None,  # LoftQ for even better quality\n        use_gradient_checkpointing = \"unsloth\"\n    )\n    print(\"笨 Unsloth LoRA adapters added\")\n    \n    # 泅 UNSLOTH: Optimized training arguments for 2x T4 GPUs (28GB total)\n    training_args = TrainingArguments(\n        per_device_train_batch_size=16,  # Larger batches with 2x T4 (28GB total)\n        gradient_accumulation_steps=8,  # Effective batch size = 4*2*2 = 16\n        warmup_steps=5,  # Quick warmup with Unsloth\n        #max_steps=250,  # Unsloth converges much faster (adjust based on data size)\n        num_train_epochs=1 , \n        learning_rate=2e-4,  # Higher LR works better with Unsloth\n        fp16=not torch.cuda.is_bf16_supported(),\n        bf16=torch.cuda.is_bf16_supported(),\n        logging_steps=1,  # Frequent logging for monitoring\n        optim=\"adamw_8bit\",  # 8-bit optimizer for memory efficiency\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",  # Simple linear decay\n        seed=666,\n        output_dir=LORA_PATH,\n        report_to=\"none\",\n        save_strategy=\"steps\",\n        save_steps=20,  # Save frequently for monitoring\n        save_total_limit=2,  # Keep only recent checkpoints\n        dataloader_pin_memory=False,  # Unsloth handles this\n        # Multi-GPU optimizations for 2x T4\n        dataloader_num_workers=4,  # Parallel data loading\n        remove_unused_columns=False,  # Keep all data\n        ddp_find_unused_parameters=False,  # DDP optimization\n        ddp_broadcast_buffers=False,  # Reduce communication overhead\n    )\n    print(\"笨 Unsloth training arguments configured for 2x T4\")\n    \n    # 泅 UNSLOTH: Use SFTTrainer with Unsloth model\n    trainer = SFTTrainer(\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=train_dataset,\n        dataset_text_field=\"text\",  # Unsloth expects \"text\" field\n        max_seq_length=2048,\n        dataset_num_proc=4,  # More parallel processing for 2x T4\n        packing=False,  # Can try True for even faster training\n        args=training_args,\n    )\n    \n    print(\"泅 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\")\n    \n    # 泅 UNSLOTH: Train with optimized loop\n    trainer_stats = trainer.train()\n    \n    print(\"笨 Unsloth training completed!\")\n    print(f\"Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\n    print(f\"Samples/second: {trainer_stats.metrics['train_samples_per_second']:.2f}\")\n    print(f\"GPU utilization optimized for 2x T4 setup\")\n    \n    # 泅 UNSLOTH: Save LoRA adapters in vLLM-compatible format\n    print(\"汳ｾ Saving LoRA adapters for vLLM compatibility...\")\n    \n    # Save tokenizer\n    tokenizer.save_pretrained(LORA_PATH)\n    \n    # Save model in PEFT format (vLLM compatible)\n    model.save_pretrained(LORA_PATH)\n    #model.save_pretrained(...)  \n    #tokenizer.save_pretrained(...)\n    folder=\"16 bit\"\n    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"forced_merged_4bit\",)\n    \n\n    \n    print(f\"笨 LoRA adapters saved to: {LORA_PATH} , model saved \")\n    print(\"沁ｯ Ready for vLLM inference!\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T15:21:29.214943Z","iopub.execute_input":"2025-09-18T15:21:29.215214Z","iopub.status.idle":"2025-09-18T15:21:29.223198Z","shell.execute_reply.started":"2025-09-18T15:21:29.215195Z","shell.execute_reply":"2025-09-18T15:21:29.222439Z"}},"outputs":[{"name":"stdout","text":"Overwriting train_unsloth.py\n","output_type":"stream"}],"execution_count":24},{"id":"8d69f944","cell_type":"markdown","source":"# 沁ｯ 2x T4 GPU Optimization Guide\n\n## 笞｡ **Multi-GPU Configuration for TT-11**\n\n### **Your Setup: 2x T4 (28GB Total VRAM)**\n- **GPU 0**: ~14GB VRAM\n- **GPU 1**: ~14GB VRAM\n- **Total**: 28GB available for training\n\n### **Optimizations Applied:**\n\n#### **1. Model Distribution**\n```python\ndevice_map=\"auto\"  # Automatic distribution across GPUs\nmax_memory={0: \"13GB\", 1: \"13GB\"}  # Reserve 1GB per GPU for operations\n```\n\n#### **2. Batch Size Scaling**\n```python\nper_device_train_batch_size=4,  # 4 samples per GPU (8 total)\ngradient_accumulation_steps=2,  # Effective batch = 4*2*2 = 16\n```\n\n#### **3. Memory Optimizations**\n```python\nload_in_4bit=True,              # 4-bit quantization saves ~75% memory\nuse_gradient_checkpointing=True, # Trade compute for memory\ndataloader_pin_memory=False,     # Let Unsloth handle memory\n```\n\n#### **4. Multi-GPU Training**\n```python\ndataloader_num_workers=4,        # Parallel data loading\nddp_find_unused_parameters=False, # DDP optimization\nddp_broadcast_buffers=False,     # Reduce communication\n```\n\n### **Expected Performance:**\n- **Training Speed**: 3x-6x faster than single GPU\n- **Memory Usage**: ~12-13GB per GPU\n- **Effective Batch**: 16 samples (vs 4 on single GPU)\n- **Total Time**: 5-8 minutes for full training\n\n### **Troubleshooting 2x T4:**\n\n#### **If you get OOM (Out of Memory):**\n```python\n# Reduce batch size\nper_device_train_batch_size=2,   # 2 per GPU instead of 4\ngradient_accumulation_steps=4,   # Keep effective batch size\n\n# Or reduce sequence length\nmax_seq_length=1024,             # Shorter sequences\n```\n\n#### **If training is slower than expected:**\n```python\n# Check GPU utilization\nnvidia-smi  # Should show ~90%+ on both GPUs\n\n# Increase batch size if memory allows\nper_device_train_batch_size=6,   # Try larger batches\n```\n\n#### **Memory Distribution Check:**\n```python\nprint(f\"Available GPUs: {torch.cuda.device_count()}\")\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_properties(i).total_memory // 1024**3}GB\")\n```","metadata":{}},{"id":"910e6893","cell_type":"code","source":"%%writefile validation_vllm.py\nimport os\nos.environ[\"VLLM_USE_V1\"] = \"0\"\n\nimport vllm\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\nfrom vllm.lora.request import LoRARequest\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_vllm():\n    \"\"\"Run validation using OpenSloth-trained model with vLLM for precise AUC\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"沐 Running validation on {len(val_dataset)} real comments\")\n    \n    # 沁ｯ VLLM: Initialize with OpenSloth LoRA support for precise probabilities\n    llm = vllm.LLM(\n        BASE_MODEL_PATH,\n        tensor_parallel_size=torch.cuda.device_count(),\n        gpu_memory_utilization=0.90,\n        trust_remote_code=True,\n        dtype=\"half\",\n        enforce_eager=True,\n        max_model_len=512,\n        disable_log_stats=True,\n        enable_prefix_caching=True,\n        enable_lora=True,\n        max_lora_rank=64,\n        local_files_only=True,\n    )\n\n    tokenizer = llm.get_tokenizer()\n\n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n\n    # 沁ｯ VLLM: Generate with OpenSloth LoRA for most accurate probabilities\n    outputs = llm.generate(\n        texts,\n        vllm.SamplingParams(\n            skip_special_tokens=True,\n            max_tokens=1,\n            logprobs=20,\n        ),\n        use_tqdm=True,\n        lora_request=LoRARequest(\"opensloth_lora\", 1, LORA_PATH)  # Load OpenSloth LoRA\n    )\n\n    # Extract predictions and probabilities with vLLM precision\n    predictions = []\n    probabilities = []\n    \n    yes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\n    no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n    \n    for out in outputs:\n        log_probs = out.outputs[0].logprobs[0]\n        \n        log_prob_yes = log_probs.get(yes_token_id)\n        log_prob_no = log_probs.get(no_token_id)\n        \n        if log_prob_yes is not None and log_prob_no is not None:\n            if log_prob_yes.logprob > log_prob_no.logprob:\n                predictions.append(1)\n            else:\n                predictions.append(0)\n            \n            exp_pos = np.exp(log_prob_yes.logprob)\n            exp_neg = np.exp(log_prob_no.logprob)\n            prob_positive = exp_pos / (exp_pos + exp_neg)\n            probabilities.append(prob_positive)\n        else:\n            predictions.append(0)\n            probabilities.append(0.5)\n\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"沒 TT-12 VALIDATION RESULTS (OpenSloth + vLLM)\")\n    print(\"=\" * 60)\n    print(f\"沁ｯ Accuracy:  {accuracy:.4f}\")\n    print(f\"沁ｯ F1 Score:  {f1:.4f}\")\n    print(f\"沁ｯ Precision: {precision:.4f}\")\n    print(f\"沁ｯ Recall:    {recall:.4f}\")\n    print(f\"沁ｯ AUC Score: {auc:.4f} (High-precision vLLM)\")\n    print(\"=\" * 60)\n    \n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n沒 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    print(\"\\n沒 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy, 'f1': f1, 'precision': precision,\n        'recall': recall, 'auc': auc, 'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-12: OpenSloth Training + vLLM Validation Results', fontsize=16, fontweight='bold')\n    \n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (vLLM High-Precision)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    pos_probs = [p for p, t in zip(probabilities, true_labels) if t == 1]\n    neg_probs = [p for p, t in zip(probabilities, true_labels) if t == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (vLLM Precision)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics[k] for k in ['accuracy', 'f1', 'precision', 'recall', 'auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (OpenSloth + vLLM)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt12_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n沒 PERFORMANCE BY RULE (vLLM High-Precision AUC):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        rule_auc = roc_auc_score(rule_true, rule_prob) if len(np.unique(rule_true)) > 1 else np.nan\n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\\n  Samples: {len(rule_data)}\\n  Accuracy: {rule_acc:.3f}\\n  F1 Score: {rule_f1:.3f}\\n  AUC Score: {rule_auc:.3f}\\n\")\n        \n        rule_metrics.append({'rule': rule, 'samples': len(rule_data), 'accuracy': rule_acc, 'f1': rule_f1, 'auc': rule_auc})\n    \n    analysis_df.to_csv('/kaggle/working/tt12_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt12_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"沐ｬ TT-12: OpenSloth Training + vLLM Validation\")\n    print(\"泅 Multi-GPU training + High-precision inference!\")\n    print(\"=\" * 70)\n    \n    true_labels, predictions, probabilities, val_df = run_validation_vllm()\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"笨 TT-12 Validation completed!\")\n    print(\"沒 Visualizations saved: /kaggle/working/tt12_validation_results.png\")\n    print(\"沒 Detailed results: /kaggle/working/tt12_detailed_results.csv\")\n    print(\"沒 Rule metrics: /kaggle/working/tt12_rule_metrics.csv\")\n    \nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:58:39.201319Z","iopub.execute_input":"2025-09-18T14:58:39.202054Z","iopub.status.idle":"2025-09-18T14:58:39.210240Z","shell.execute_reply.started":"2025-09-18T14:58:39.202027Z","shell.execute_reply":"2025-09-18T14:58:39.209505Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Writing validation_vllm.py\n","output_type":"stream"}],"execution_count":7},{"id":"12b04fb3","cell_type":"code","source":"from utils import cache_dataset\ncache_dataset(cache_path=\"data/cache_qwen3_dataset_for_opensloth/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:59:13.203961Z","iopub.execute_input":"2025-09-18T14:59:13.204530Z","iopub.status.idle":"2025-09-18T14:59:26.888214Z","shell.execute_reply.started":"2025-09-18T14:59:13.204502Z","shell.execute_reply":"2025-09-18T14:59:26.887558Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"泓托ｸ Deleting existing cache folder at data/cache_qwen3_dataset_for_opensloth/\n汳ｾ Caching dataset to data/cache_qwen3_dataset_for_opensloth/\n==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n沒 Stratified sampling: 609 samples (30%)\n沒 Training data size: 609 samples\n沒 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 305, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 304}\n沒 Example-based training dataset: 2435 samples\n沒 Positive examples: 1218\n沒 Negative examples: 1217\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/2435 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"313120e6b7364b49b225d82fccc48fe7"}},"metadata":{}},{"name":"stdout","text":"Unsloth: Hugging Face's packing is currently buggy - we're disabling it for now!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/2435 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67fb13225cac436eab7708aca3ebd12a"}},"metadata":{}},{"name":"stdout","text":"笨 Dataset cached to data/cache_qwen3_dataset_for_opensloth/\n","output_type":"stream"}],"execution_count":10},{"id":"7fd0717c","cell_type":"code","source":"%%writefile validation_transformers.py\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\nfrom tqdm import tqdm\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_transformers():\n    \"\"\"Run validation using standard transformers with OpenSloth LoRA - Universal compatibility\"\"\"\n    \n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"沐 Running validation on {len(val_dataset)} real comments (Transformers)\")\n    \n    print(\"沒･ Loading base model and tokenizer...\")\n    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True, local_files_only=True)\n    model = AutoModelForCausalLM.from_pretrained(\n        BASE_MODEL_PATH,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        local_files_only=True,\n    )\n    \n    print(\"沐 Loading OpenSloth LoRA adapters...\")\n    model = PeftModel.from_pretrained(model, LORA_PATH)\n    model = model.merge_and_unload()\n    model.eval()\n    \n    yes_token_id = tokenizer.encode(\"Yes\", add_special_tokens=False)[0]\n    no_token_id = tokenizer.encode(\"No\", add_special_tokens=False)[0]\n    \n    print(f\"沁ｯ Token IDs: Yes={yes_token_id}, No={no_token_id}\")\n    \n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n    \n    predictions, probabilities = [], []\n    batch_size = 8\n    \n    print(\"泅 Running inference...\")\n    \n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch_texts = texts[i:i+batch_size]\n        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n            next_token_logits = outputs.logits[:, -1, :]\n            \n            yes_logits = next_token_logits[:, yes_token_id]\n            no_logits = next_token_logits[:, no_token_id]\n            \n            combined_logits = torch.stack([no_logits, yes_logits], dim=1)\n            probs = torch.softmax(combined_logits, dim=1)\n            \n            predictions.extend(torch.argmax(probs, dim=1).cpu().tolist())\n            probabilities.extend(probs[:, 1].cpu().tolist())\n    \n    print(\"笨 Inference completed!\")\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"沒 TT-12 VALIDATION RESULTS (OpenSloth + Transformers)\")\n    print(\"=\" * 60)\n    print(f\"沁ｯ Accuracy:  {accuracy:.4f}\")\n    print(f\"沁ｯ F1 Score:  {f1:.4f}\")\n    print(f\"沁ｯ Precision: {precision:.4f}\")\n    print(f\"沁ｯ Recall:    {recall:.4f}\")\n    print(f\"沁ｯ AUC Score: {auc:.4f} (Standard Transformers)\")\n    print(\"=\" * 60)\n    \n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n沒 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    print(\"\\n沒 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall, 'auc': auc, 'confusion_matrix': cm}\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-12: OpenSloth Training + Transformers Validation Results', fontsize=16, fontweight='bold')\n    \n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (Transformers)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    pos_probs = [p for p, t in zip(probabilities, true_labels) if t == 1]\n    neg_probs = [p for p, t in zip(probabilities, true_labels) if t == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (Transformers)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics[k] for k in ['accuracy', 'f1', 'precision', 'recall', 'auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (OpenSloth + Transformers)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt12_transformers_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n沒 PERFORMANCE BY RULE (Transformers):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        rule_auc = roc_auc_score(rule_true, rule_prob) if len(np.unique(rule_true)) > 1 else np.nan\n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\\n  Samples: {len(rule_data)}\\n  Accuracy: {rule_acc:.3f}\\n  F1 Score: {rule_f1:.3f}\\n  AUC Score: {rule_auc:.3f}\\n\")\n        \n        rule_metrics.append({'rule': rule, 'samples': len(rule_data), 'accuracy': rule_acc, 'f1': rule_f1, 'auc': rule_auc})\n    \n    analysis_df.to_csv('/kaggle/working/tt12_transformers_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt12_transformers_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"沐ｬ TT-12: OpenSloth Training + Transformers Validation\")\n    print(\"泅 Multi-GPU training + Universal compatibility!\")\n    print(\"=\" * 70)\n    \n    true_labels, predictions, probabilities, val_df = run_validation_transformers()\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"笨 TT-12 Transformers Validation completed!\")\n    print(\"沒 Visualizations saved: /kaggle/working/tt12_transformers_validation_results.png\")\n    print(\"沒 Detailed results: /kaggle/working/tt12_transformers_detailed_results.csv\")\n    print(\"沒 Rule metrics: /kaggle/working/tt12_transformers_rule_metrics.csv\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T14:58:45.444339Z","iopub.execute_input":"2025-09-18T14:58:45.445008Z","iopub.status.idle":"2025-09-18T14:58:45.453360Z","shell.execute_reply.started":"2025-09-18T14:58:45.444980Z","shell.execute_reply":"2025-09-18T14:58:45.452639Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Writing validation_transformers.py\n","output_type":"stream"}],"execution_count":8},{"id":"e6f23a14","cell_type":"code","source":"!python train_opensloth.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T15:12:01.604229Z","iopub.execute_input":"2025-09-18T15:12:01.604722Z","iopub.status.idle":"2025-09-18T15:12:54.322079Z","shell.execute_reply.started":"2025-09-18T15:12:01.604701Z","shell.execute_reply":"2025-09-18T15:12:54.321281Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"洶･ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-18 15:12:09.129503: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758208329.151014     551 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758208329.157677     551 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n洶･ Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n笨 Using Qwen3 1.7B model from local Kaggle input\n沁ｯ TT-12: OpenSloth training + vLLM inference with 30% of data\n沒 Stratified sampling: True\nGlobal batch size: 16\nGradient accumulation steps: 8\nGlobal batch size: 16\n[MP] Running on 2 GPUs\n洶･ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n洶･ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-18 15:12:30.718078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758208350.739707     591 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758208350.746575     591 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-09-18 15:12:30.786377: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758208350.808511     590 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758208350.815251     590 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n洶･ Unsloth Zoo will now patch everything to make training faster!\n洶･ Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n笨 Using Qwen3 1.7B model from local Kaggle input\n沁ｯ TT-12: OpenSloth training + vLLM inference with 30% of data\n沒 Stratified sampling: True\n笨 Using Qwen3 1.7B model from local Kaggle input\n沁ｯ TT-12: OpenSloth training + vLLM inference with 30% of data\n沒 Stratified sampling: True\n\u001b[32m15:12:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mopensloth_sft_trainer.py:41\u001b[0m | \u001b[1mTraining on GPU 0 with output_dir qwen3_1.7b_opensloth_lora_validation/\u001b[0m\n\u001b[32m15:12:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mGPU0\u001b[0m | \u001b[36mopensloth_sft_trainer.py:44\u001b[0m | \u001b[1m泅 Starting total training timer\u001b[0m\nUsing compiler location: .cache/unsloth_compiled_cache_1\nUsing compiler location: .cache/unsloth_compiled_cache_0\nProcess Process-2:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/local/lib/python3.11/dist-packages/opensloth/scripts/opensloth_sft_trainer.py\", line 49, in train_on_single_gpu\n    trainer, model, tokenizer = setup_model_and_training(\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/opensloth/opensloth_trainer_setup.py\", line 59, in setup_model_and_training\n    model, tokenizer = init_model_and_tokenizer(opensloth_config)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/opensloth/init_modules.py\", line 32, in init_model_and_tokenizer\n    model, tokenizer = FastModel.from_pretrained(\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/loader.py\", line 697, in from_pretrained\n    model_types, supports_sdpa = unsloth_compile_transformers(\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\", line 1199, in unsloth_compile_transformers\n    _unsloth_compile_transformers(\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth_zoo/compiler.py\", line 2133, in unsloth_compile_transformers\n    exec(f\"{model_location}.{module} = combined_module.{module}\", globals(), locals())\n  File \"<string>\", line 1, in <module>\nAttributeError: module 'unsloth_compiled_module_qwen3' has no attribute 'Qwen3RotaryEmbedding'\nProcess Process-1:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/local/lib/python3.11/dist-packages/opensloth/scripts/opensloth_sft_trainer.py\", line 49, in train_on_single_gpu\n    trainer, model, tokenizer = setup_model_and_training(\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/opensloth/opensloth_trainer_setup.py\", line 59, in setup_model_and_training\n    model, tokenizer = init_model_and_tokenizer(opensloth_config)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/opensloth/init_modules.py\", line 32, in init_model_and_tokenizer\n    model, tokenizer = FastModel.from_pretrained(\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/loader.py\", line 697, in from_pretrained\n    model_types, supports_sdpa = unsloth_compile_transformers(\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\", line 1199, in unsloth_compile_transformers\n    _unsloth_compile_transformers(\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth_zoo/compiler.py\", line 2133, in unsloth_compile_transformers\n    exec(f\"{model_location}.{module} = combined_module.{module}\", globals(), locals())\n  File \"<string>\", line 1, in <module>\nAttributeError: module 'unsloth_compiled_module_qwen3' has no attribute 'Qwen3RotaryEmbedding'\nTraceback (most recent call last):\n  File \"/kaggle/working/train_opensloth.py\", line 63, in <module>\n    run_mp_training(opensloth_config.devices, opensloth_config, training_config)\n  File \"/usr/local/lib/python3.11/dist-packages/opensloth/scripts/opensloth_sft_trainer.py\", line 256, in run_mp_training\n    raise Exception(\"Error in training\")\nException: Error in training\n","output_type":"stream"}],"execution_count":16},{"id":"7fdab6c5-c83c-492c-8e94-d0b0aeb7f30f","cell_type":"code","source":"!python train_unsloth.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T15:21:33.833507Z","iopub.execute_input":"2025-09-18T15:21:33.834243Z","iopub.status.idle":"2025-09-18T15:22:10.979350Z","shell.execute_reply.started":"2025-09-18T15:21:33.834217Z","shell.execute_reply":"2025-09-18T15:22:10.978139Z"}},"outputs":[{"name":"stdout","text":"洶･ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-18 15:21:40.508616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758208900.531111     804 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758208900.538182     804 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n洶･ Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n笨 Using Qwen3 1.7B model from local Kaggle input\n沁ｯ TT-12: OpenSloth training + vLLM inference with 30% of data\n沒 Stratified sampling: True\n沒 Stratified sampling: 609 samples (30%)\n沒 Training data size: 609 samples\n沒 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 305, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 304}\n沒 Example-based training dataset: 2435 samples\n沒 Positive examples: 1218\n沒 Negative examples: 1217\nTraining dataset size: 2435 samples\nAvailable GPUs: 2\nUnsloth: WARNING `trust_remote_code` is True.\nAre you certain you want to do remote code execution?\n==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n笨 Unsloth model loaded with 4-bit quantization across 2x T4\nUnsloth 2025.5.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n笨 Unsloth LoRA adapters added\n笨 Unsloth training arguments configured for 2x T4\nUnsloth: Tokenizing [\"text\"] (num_proc=4): 100%|笆| 2435/2435 [00:02<00:00, 1153.\n泅 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n   \\\\   /|    Num examples = 2,435 | Num Epochs = 1 | Total steps = 19\nO^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 8 x 1) = 128\n \"-____-\"     Trainable parameters = 17,432,576/7,000,000,000 (0.25% trained)\n  0%|                                                    | 0/19 [00:00<?, ?it/s]Traceback (most recent call last):\n  File \"/kaggle/working/train_unsloth.py\", line 117, in <module>\n    main()\n  File \"/kaggle/working/train_unsloth.py\", line 90, in main\n    trainer_stats = trainer.train()\n                    ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2245, in train\n    return inner_training_loop(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 268, in _fast_inner_training_loop\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth_zoo/loss_utils.py\", line 273, in _unsloth_get_batch_samples\n    batch_samples += [next(epoch_iterator)]\n                      ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\", line 566, in __iter__\n    current_batch = next(dataloader_iter)\n                    ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n    data = self._next_data()\n           ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1480, in _next_data\n    return self._process_data(data)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1505, in _process_data\n    data.reraise()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_utils.py\", line 733, in reraise\n    raise exception\nValueError: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 777, in convert_to_tensors\n    tensor = as_tensor(value)\n             ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 739, in as_tensor\n    return torch.tensor(value)\n           ^^^^^^^^^^^^^^^^^^^\nValueError: too many dimensions 'str'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\", line 46, in __call__\n    return self.torch_call(features)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\", line 1013, in torch_call\n    batch = pad_without_fast_tokenizer_warning(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\", line 67, in pad_without_fast_tokenizer_warning\n    padded = tokenizer.pad(*pad_args, **pad_kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3407, in pad\n    return BatchEncoding(batch_outputs, tensor_type=return_tensors)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 241, in __init__\n    self.convert_to_tensors(tensor_type=tensor_type, prepend_batch_axis=prepend_batch_axis)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 793, in convert_to_tensors\n    raise ValueError(\nValueError: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`text` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n\n  0%|          | 0/19 [00:01<?, ?it/s]                                          \n","output_type":"stream"}],"execution_count":25},{"id":"096ef5eb","cell_type":"markdown","source":"# Appendix: View Results","metadata":{}},{"id":"d7ef0067","cell_type":"code","source":"#@title **Run Validation**\n#@markdown Choose your validation method:\nVALIDATION_METHOD = \"vLLM\" #@param [\"vLLM\", \"Transformers\"]\n\nif VALIDATION_METHOD == \"vLLM\":\n    print(\"泅 Running vLLM validation for maximum speed and precision...\")\n    !python validation_vllm.py\nelse:\n    print(\"笞呻ｸ Running Transformers validation for universal compatibility...\")\n    !python validation_transformers.py","metadata":{},"outputs":[],"execution_count":null},{"id":"0d85e3f4","cell_type":"code","source":"from IPython.display import Image, display\n\n# Display the validation results image\nif VALIDATION_METHOD == \"vLLM\":\n    display(Image(filename='/kaggle/working/tt12_validation_results.png'))\nelse:\n    display(Image(filename='/kaggle/working/tt12_transformers_validation_results.png'))","metadata":{},"outputs":[],"execution_count":null},{"id":"681bab57","cell_type":"code","source":"import pandas as pd\n\n# Display the detailed results CSV\nif VALIDATION_METHOD == \"vLLM\":\n    df_detailed = pd.read_csv('/kaggle/working/tt12_detailed_results.csv')\nelse:\n    df_detailed = pd.read_csv('/kaggle/working/tt12_transformers_detailed_results.csv')\n\ndf_detailed.head()","metadata":{},"outputs":[],"execution_count":null}]}