{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":12726948,"sourceType":"datasetVersion","datasetId":8044304},{"sourceId":12762469,"sourceType":"datasetVersion","datasetId":8067935},{"sourceId":252850661,"sourceType":"kernelVersion"},{"sourceId":252853424,"sourceType":"kernelVersion"},{"sourceId":259545323,"sourceType":"kernelVersion"},{"sourceId":171496,"sourceType":"modelInstanceVersion","modelInstanceId":145960,"modelId":164048},{"sourceId":171638,"sourceType":"modelInstanceVersion","modelInstanceId":146086,"modelId":164048},{"sourceId":363131,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":301511,"modelId":322000},{"sourceId":363132,"sourceType":"modelInstanceVersion","modelInstanceId":301512,"modelId":322000},{"sourceId":391623,"sourceType":"modelInstanceVersion","modelInstanceId":322459,"modelId":322000},{"sourceId":426330,"sourceType":"modelInstanceVersion","modelInstanceId":347541,"modelId":368803},{"sourceId":523492,"sourceType":"modelInstanceVersion","modelInstanceId":411182,"modelId":429004},{"sourceId":363124,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":301506,"modelId":322000}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"7afaf01d","cell_type":"markdown","source":"# Qwen3 1.7B Training Notebook (4-bit BitsAndBytes + QLoRA Fine-tuning)\n\nThis notebook fine-tunes Qwen3-1.7B (base model) on training data only using 4-bit quantization via BitsAndBytes with QLoRA and saves the model for later use.\n\n**Key Changes from DoRA Version:**\n- Uses `Qwen/Qwen3-1.7B` (base model) from local Kaggle input\n- Uses BitsAndBytes 4-bit NF4 quantization for QLoRA\n- Uses standard QLoRA (no DoRA)\n- Trains only on training data (no test-time training)\n- Saves the fine-tuned model for later loading\n\n**Benefits of 4-bit + QLoRA:**\n- **Lower VRAM**: ~8-10GB per GPU\n- **Faster training**: Efficient with 4-bit quantization\n- **Better compatibility**: Full PEFT ecosystem support\n- `r=16` - Rank from TT-1 config\n- `lora_alpha=32` - Alpha from TT-1 config\n- `lora_dropout=0.1` - Dropout from TT-1 config","metadata":{}},{"id":"4794db06","cell_type":"code","source":"# Install dependencies - BitsAndBytes + QLoRA setup\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'trl==0.21.0' 'optimum==1.27.0' 'bitsandbytes==0.46.1' 'deepspeed==0.17.4' 'logits-processor-zoo==0.2.1' 'vllm==0.10.0'\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'triton==3.2.0'\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'clean-text'\n# Install latest PEFT for QLoRA support (ensure v0.10.0+) - No auto-gptq needed!\n!uv pip install --system --no-index -U --no-deps --find-links='/kaggle/input/jigsaw-packages2/whls/' 'peft' 'accelerate' 'datasets'\n\n# Note: Removed auto-gptq dependency as we're using BitsAndBytes quantization\nprint(\"‚úÖ Dependencies installed for 4-bit BitsAndBytes + QLoRA setup\")\nprint(\"üìÅ Model will be loaded from local Kaggle input: /kaggle/working/qwen3-1.7b\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:30:26.142012Z","iopub.execute_input":"2025-09-11T17:30:26.142191Z","iopub.status.idle":"2025-09-11T17:31:16.612185Z","shell.execute_reply.started":"2025-09-11T17:30:26.142174Z","shell.execute_reply":"2025-09-11T17:31:16.611374Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.11 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m164 packages\u001b[0m \u001b[2min 712ms\u001b[0m\u001b[0m                                       \u001b[0m\n\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                          \n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m68 packages\u001b[0m \u001b[2min 39.69s\u001b[0m\u001b[0m                                           \n\u001b[2mUninstalled \u001b[1m27 packages\u001b[0m \u001b[2min 2.99s\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m68 packages\u001b[0m \u001b[2min 429ms\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mastor\u001b[0m\u001b[2m==0.8.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.46.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mblake3\u001b[0m\u001b[2m==1.0.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcbor2\u001b[0m\u001b[2m==5.7.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcompressed-tensors\u001b[0m\u001b[2m==0.10.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdeepspeed\u001b[0m\u001b[2m==0.17.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdepyf\u001b[0m\u001b[2m==0.19.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.116.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cli\u001b[0m\u001b[2m==0.0.10\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cloud-cli\u001b[0m\u001b[2m==0.1.5\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgguf\u001b[0m\u001b[2m==0.17.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.1.9\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhjson\u001b[0m\u001b[2m==3.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.6.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.31.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.34.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1minteregular\u001b[0m\u001b[2m==0.3.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.2.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllguidance\u001b[0m\u001b[2m==0.7.30\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.43.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.44.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlm-format-enforcer\u001b[0m\u001b[2m==0.10.12\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlogits-processor-zoo\u001b[0m\u001b[2m==0.2.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmistral-common\u001b[0m\u001b[2m==1.8.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.19.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.60.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.61.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.9.0.13\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.4.0.6\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.11.1.6\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.10.19\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.4.40\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.9.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.9.41\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.6.85\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.70.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.90.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moptimum\u001b[0m\u001b[2m==1.27.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moutlines-core\u001b[0m\u001b[2m==0.2.10\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpartial-json-parser\u001b[0m\u001b[2m==0.2.1.1.post6\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mprometheus-fastapi-instrumentator\u001b[0m\u001b[2m==7.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpycountry\u001b[0m\u001b[2m==24.6.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpydantic-extra-types\u001b[0m\u001b[2m==2.10.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==24.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrich-toolkit\u001b[0m\u001b[2m==0.15.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrignore\u001b[0m\u001b[2m==0.6.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.47.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124 (from https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.22.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.51.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.56.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.35.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mvllm\u001b[0m\u001b[2m==0.10.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.31\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxgrammar\u001b[0m\u001b[2m==0.1.21\u001b[0m\n\u001b[2mUsing Python 3.11.11 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m                                            \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 3.65s\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n\u001b[2mUsing Python 3.11.11 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m4 packages\u001b[0m \u001b[2min 601ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                               \n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 638ms\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mclean-text\u001b[0m\u001b[2m==0.6.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==2.14.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==1.7.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n\u001b[2mUsing Python 3.11.11 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m3 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 52ms\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m3 packages\u001b[0m \u001b[2min 102ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.5.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.10.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==3.6.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.0.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.14.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.17.1\u001b[0m\n‚úÖ Dependencies installed for 4-bit BitsAndBytes + QLoRA setup\nüìÅ Model will be loaded from local Kaggle input: /kaggle/working/qwen3-1.7b\n","output_type":"stream"}],"execution_count":1},{"id":"465b2e16","cell_type":"markdown","source":"# 1. Train Qwen3 1.7B with 4-bit Quantization + QLoRA","metadata":{}},{"id":"2e7c70df","cell_type":"code","source":"%%writefile constants.py\n# Using base Qwen3 1.7B model from Kaggle input (no internet needed)\n# Model is pre-loaded in Kaggle environment\nBASE_MODEL_PATH = \"/kaggle/input/qwen-3/transformers/0.6b/1\"  # Local Kaggle path\nprint(\"‚úÖ Using model from local Kaggle input (no internet required)\")\n\nLORA_PATH = \"qwen3_1.7b_4bit_qlora_output/\"  # 4-bit QLoRA output path\nFINAL_MODEL_PATH = \"qwen3_1.7b_4bit_finetuned/\"  # Path for merged final model\nDATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules/\"\n\nPOSITIVE_ANSWER = \"Yes\"\nNEGATIVE_ANSWER = \"No\"\nCOMPLETE_PHRASE = \"Answer:\"\nBASE_PROMPT = '''You are a moderator of subreddit.  given a comment from reddit and a rule. Your task is to classify with reasoning whether the comment violates the rule. Only respond Yes/No.'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:31:16.613044Z","iopub.execute_input":"2025-09-11T17:31:16.613249Z","iopub.status.idle":"2025-09-11T17:31:16.619670Z","shell.execute_reply.started":"2025-09-11T17:31:16.613227Z","shell.execute_reply":"2025-09-11T17:31:16.618775Z"}},"outputs":[{"name":"stdout","text":"Writing constants.py\n","output_type":"stream"}],"execution_count":2},{"id":"b2ec67ce","cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\nfrom datasets import Dataset\nfrom constants import POSITIVE_ANSWER, NEGATIVE_ANSWER, COMPLETE_PHRASE, BASE_PROMPT\nimport random, numpy as np\nrandom.seed(42)\nnp.random.seed(42)\n\n\ndef build_prompt(row):\n    return f\"\"\"\n{BASE_PROMPT}\n\nSubreddit: r/{row[\"subreddit\"]}\nRule: {row[\"rule\"]}\nExamples:\n1) {row[\"positive_example\"]}\n{COMPLETE_PHRASE} Yes\n\n2) {row[\"negative_example\"]}\n{COMPLETE_PHRASE} No\n\n---\nComment: {row[\"body\"]}\n{COMPLETE_PHRASE}\"\"\"\n\n\ndef get_dataframe_to_train(data_path, training_only=True):\n    \"\"\"Modified: Only use training data when training_only=True\"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    flatten = []\n\n    # ---------- Process training data ----------\n    train_df = train_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\",\n                              \"positive_example_1\",\"positive_example_2\",\n                              \"negative_example_1\",\"negative_example_2\"]].copy()\n\n    # Randomly select positive_example and negative_example\n    train_df[\"positive_example\"] = np.where(\n        np.random.rand(len(train_df)) < 0.5,\n        train_df[\"positive_example_1\"],\n        train_df[\"positive_example_2\"]\n    )\n    train_df[\"negative_example\"] = np.where(\n        np.random.rand(len(train_df)) < 0.5,\n        train_df[\"negative_example_1\"],\n        train_df[\"negative_example_2\"]\n    )\n\n    # Drop original candidate columns\n    train_df.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                           \"negative_example_1\",\"negative_example_2\"], inplace=True)\n\n    flatten.append(train_df)\n    \n    # Changed: Skip test data processing when training_only=True\n    if not training_only:\n        test_dataset = pd.read_csv(f\"{data_path}/test.csv\").sample(frac=0.5, random_state=42).reset_index(drop=True)\n        \n        # ---------- Process test data ----------\n        for violation_type in [\"positive\", \"negative\"]:\n            for i in range(1, 3):\n                sub_dataset = test_dataset[[\"rule\",\"subreddit\",\n                                            \"positive_example_1\",\"positive_example_2\",\n                                            \"negative_example_1\",\"negative_example_2\"]].copy()\n\n                if violation_type == \"positive\":\n                    body_col = f\"positive_example_{i}\"\n                    other_positive_col = f\"positive_example_{3-i}\"\n                    sub_dataset[\"body\"] = sub_dataset[body_col]\n                    sub_dataset[\"positive_example\"] = sub_dataset[other_positive_col]\n                    sub_dataset[\"negative_example\"] = np.where(\n                        np.random.rand(len(sub_dataset)) < 0.5,\n                        sub_dataset[\"negative_example_1\"],\n                        sub_dataset[\"negative_example_2\"]\n                    )\n                    sub_dataset[\"rule_violation\"] = 1\n\n                else:  # violation_type == \"negative\"\n                    body_col = f\"negative_example_{i}\"\n                    other_negative_col = f\"negative_example_{3-i}\"\n                    sub_dataset[\"body\"] = sub_dataset[body_col]\n                    sub_dataset[\"negative_example\"] = sub_dataset[other_negative_col]\n                    sub_dataset[\"positive_example\"] = np.where(\n                        np.random.rand(len(sub_dataset)) < 0.5,\n                        sub_dataset[\"positive_example_1\"],\n                        sub_dataset[\"positive_example_2\"]\n                    )\n                    sub_dataset[\"rule_violation\"] = 0\n\n                sub_dataset.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                                          \"negative_example_1\",\"negative_example_2\"], inplace=True)\n\n                flatten.append(sub_dataset)\n\n    # Merge all DataFrames\n    dataframe = pd.concat(flatten, axis=0)\n    dataframe = dataframe.drop_duplicates(ignore_index=True)\n\n    return dataframe\n\n\ndef build_dataset(dataframe):\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n\n    columns = [\"prompt\"]\n    if \"rule_violation\" in dataframe:\n        dataframe[\"completion\"] = dataframe[\"rule_violation\"].map(\n            {\n                1: POSITIVE_ANSWER,\n                0: NEGATIVE_ANSWER,\n            }\n        )\n        columns.append(\"completion\")\n\n    dataframe = dataframe[columns]\n    dataset = Dataset.from_pandas(dataframe)\n    dataset.to_pandas().to_csv(\"/kaggle/working/training_dataset.csv\", index=False)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:31:16.622031Z","iopub.execute_input":"2025-09-11T17:31:16.622933Z","iopub.status.idle":"2025-09-11T17:31:18.924162Z","shell.execute_reply.started":"2025-09-11T17:31:16.622902Z","shell.execute_reply":"2025-09-11T17:31:18.923373Z"}},"outputs":[{"name":"stdout","text":"Writing utils.py\n","output_type":"stream"}],"execution_count":3},{"id":"5957683e","cell_type":"code","source":"%%writefile train.py\nimport pandas as pd\nimport torch\n\nfrom trl import SFTTrainer, SFTConfig\nfrom peft import LoraConfig, get_peft_model, PeftModel  # Added PeftModel for saving\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig  # Added BitsAndBytesConfig\nfrom tqdm.auto import tqdm\nfrom transformers.utils import is_torch_bf16_gpu_available\nfrom utils import build_dataset, get_dataframe_to_train\nfrom constants import DATA_PATH, BASE_MODEL_PATH, LORA_PATH, FINAL_MODEL_PATH\n\n\ndef main():\n    # Changed: Only use training data (training_only=True)\n    dataframe = get_dataframe_to_train(DATA_PATH, training_only=True)\n    train_dataset = build_dataset(dataframe)\n    \n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    \n    # BitsAndBytes 4-bit quantization config for QLoRA\n    quantization_config = BitsAndBytesConfig(\n        load_in_4bit=True,  # Enable 4-bit quantization\n        bnb_4bit_compute_dtype=torch.float16,  # Compute in FP16\n        bnb_4bit_use_double_quant=True,  # Use double quantization for better quality\n        bnb_4bit_quant_type=\"nf4\"  # Use NF4 quantization (standard for QLoRA)\n    )\n    print(\"‚úÖ BitsAndBytes 4-bit quantization config created\")\n    \n    # QLoRA configuration with settings from TT-1\n    lora_config = LoraConfig(\n        r=16,  # From TT-1 config\n        lora_alpha=32,  # From TT-1 config\n        lora_dropout=0.05,  # From TT-1 config\n        bias=\"none\",\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n        task_type=\"CAUSAL_LM\",\n        use_dora=True\n        # Removed use_dora=True for standard QLoRA\n    )\n    print(\"‚úÖ QLoRA config created with TT-1 settings\")\n    \n    # Optimized training config for 4-bit + QLoRA\n    training_args = SFTConfig(\n        num_train_epochs=1,  # Keep same epochs\n        \n        # Increased batch sizes due to lower memory usage with 4-bit\n        per_device_train_batch_size=4,\n        gradient_accumulation_steps=4,  # Reduced from 8 to 4 (effective batch size = 4*4*2 = 32)\n        \n        optim=\"paged_adamw_8bit\",  # Keep 8-bit optimizer for memory efficiency\n        learning_rate=1e-4,  # Keep same learning rate\n        weight_decay=0.01,\n        max_grad_norm=1.0,\n        \n        lr_scheduler_type=\"cosine\",\n        warmup_ratio=0.05,           \n        \n        bf16=is_torch_bf16_gpu_available(),\n        fp16=not is_torch_bf16_gpu_available(),\n        dataloader_pin_memory=True,\n        \n        gradient_checkpointing=True,\n        gradient_checkpointing_kwargs={\"use_reentrant\": False},\n    \n        save_strategy=\"epoch\",\n        save_steps=500,\n        output_dir=LORA_PATH,\n        logging_steps=50,\n        report_to=\"none\",\n    \n        completion_only_loss=True,\n        packing=False,\n        remove_unused_columns=False,\n    )\n    print(\"‚úÖ Training config created with optimized batch sizes for 4-bit\")\n    \n    # Load the model with BitsAndBytes quantization (local Kaggle input only)\n    base_model = AutoModelForCausalLM.from_pretrained(\n        BASE_MODEL_PATH,\n        quantization_config=quantization_config,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        local_files_only=True,  # Use only local files (no internet)\n    )\n    print(\"‚úÖ Base model loaded from local Kaggle input\")\n    \n    # Create SFTTrainer with the loaded model (remove model_init_kwargs)\n    trainer = SFTTrainer(\n        model=base_model,  # Pass the loaded model directly\n        args=training_args,\n        train_dataset=train_dataset,\n        peft_config=lora_config,\n    )\n    \n    print(\"üöÄ Starting 4-bit BitsAndBytes + QLoRA training...\")\n    trainer.train()\n    \n    # Save the LoRA adapters\n    trainer.save_model(LORA_PATH)\n    print(f\"‚úÖ 4-bit QLoRA adapters saved to: {LORA_PATH}\")\n    \n    # Merge and save the final model for easier loading\n    print(\"üîÑ Merging 4-bit QLoRA adapters with base model...\")\n    \n    # Load base model with same quantization for merging (local only)\n    base_model = AutoModelForCausalLM.from_pretrained(\n        BASE_MODEL_PATH,\n        quantization_config=quantization_config,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        local_files_only=True,  # Use only local files\n    )\n    print(\"‚úÖ Base model loaded for merging from local Kaggle input\")\n    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True, local_files_only=True)\n    \n    # Load and merge LoRA adapters\n    peft_model = PeftModel.from_pretrained(base_model, LORA_PATH)\n    merged_model = peft_model.merge_and_unload()\n    \n    # Save merged model\n    merged_model.save_pretrained(FINAL_MODEL_PATH)\n    tokenizer.save_pretrained(FINAL_MODEL_PATH)\n    \n    print(f\"‚úÖ Final 4-bit + QLoRA merged model saved to: {FINAL_MODEL_PATH}\")\n    print(\"üéâ 4-bit BitsAndBytes + QLoRA training completed successfully!\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:47:43.659974Z","iopub.execute_input":"2025-09-11T17:47:43.660514Z","iopub.status.idle":"2025-09-11T17:47:43.667216Z","shell.execute_reply.started":"2025-09-11T17:47:43.660489Z","shell.execute_reply":"2025-09-11T17:47:43.666384Z"}},"outputs":[{"name":"stdout","text":"Overwriting train.py\n","output_type":"stream"}],"execution_count":12},{"id":"d8a42e34","cell_type":"code","source":"%%writefile accelerate_config.yaml\ncompute_environment: LOCAL_MACHINE\ndebug: false\ndeepspeed_config:\n  gradient_accumulation_steps: 4\n  gradient_clipping: 1.0\n  train_batch_size: 64\n  train_micro_batch_size_per_gpu: 4\n  \n  zero_stage: 2\n  offload_optimizer_device: none\n  offload_param_device: none\n  zero3_init_flag: false\n  \n  stage3_gather_16bit_weights_on_model_save: false\n  stage3_max_live_parameters: 1e8\n  stage3_max_reuse_distance: 1e8\n  stage3_prefetch_bucket_size: 5e7\n  stage3_param_persistence_threshold: 1e5\n  \n  zero_allow_untested_optimizer: true\n  zero_force_ds_cpu_optimizer: false\n  \n  fp16:\n    enabled: true\n    loss_scale: 0\n    initial_scale_power: 16\n    loss_scale_window: 1000\n    hysteresis: 2\n    min_loss_scale: 1\n  \ndistributed_type: DEEPSPEED\ndowncast_bf16: 'no'\ndynamo_config:\n  dynamo_backend: INDUCTOR\n  dynamo_use_fullgraph: false\n  dynamo_use_dynamic: false\nenable_cpu_affinity: false\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 1\nnum_processes: 2\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:47:45.086281Z","iopub.execute_input":"2025-09-11T17:47:45.086728Z","iopub.status.idle":"2025-09-11T17:47:45.091386Z","shell.execute_reply.started":"2025-09-11T17:47:45.086706Z","shell.execute_reply":"2025-09-11T17:47:45.090609Z"}},"outputs":[{"name":"stdout","text":"Overwriting accelerate_config.yaml\n","output_type":"stream"}],"execution_count":13},{"id":"9ca93ac3","cell_type":"code","source":"!accelerate launch --config_file accelerate_config.yaml train.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:50:29.949445Z","iopub.execute_input":"2025-09-11T17:50:29.949751Z","iopub.status.idle":"2025-09-11T18:09:57.815494Z","shell.execute_reply.started":"2025-09-11T17:50:29.949732Z","shell.execute_reply":"2025-09-11T18:09:57.814580Z"}},"outputs":[{"name":"stdout","text":"[2025-09-11 17:50:36,695] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-11 17:50:38,293] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n2025-09-11 17:50:38.577075: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757613038.599128     521 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757613038.606191     521 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0911 17:50:42.549000 521 torch/distributed/run.py:766] \nW0911 17:50:42.549000 521 torch/distributed/run.py:766] *****************************************\nW0911 17:50:42.549000 521 torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \nW0911 17:50:42.549000 521 torch/distributed/run.py:766] *****************************************\n[W911 17:50:50.112743282 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W911 17:50:58.115329063 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n2025-09-11 17:51:04.510704: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757613064.532333     579 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-09-11 17:51:04.532827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nE0000 00:00:1757613064.539118     579 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757613064.554698     578 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757613064.562102     578 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n‚úÖ Using model from local Kaggle input (no internet required)\n‚úÖ Using model from local Kaggle input (no internet required)\nTraining dataset size: 2029 samples\n‚úÖ BitsAndBytes 4-bit quantization config created\n‚úÖ QLoRA config created with TT-1 settings\nTraining dataset size: 2029 samples\n‚úÖ BitsAndBytes 4-bit quantization config created\n‚úÖ QLoRA config created with TT-1 settings\n[2025-09-11 17:51:10,198] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-11 17:51:10,198] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-11 17:51:11,622] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n[2025-09-11 17:51:11,626] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n[2025-09-11 17:51:11,646] [INFO] [comm.py:821:init_distributed] cdb=None\n[2025-09-11 17:51:11,652] [INFO] [comm.py:821:init_distributed] cdb=None\n[2025-09-11 17:51:11,652] [INFO] [comm.py:852:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n[W911 17:51:19.210157989 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W911 17:51:19.216185176 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W911 17:51:27.212288988 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W911 17:51:35.214275710 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n‚úÖ Training config created with optimized batch sizes for 4-bit‚úÖ Training config created with optimized batch sizes for 4-bit\n\n`torch_dtype` is deprecated! Use `dtype` instead!\n`torch_dtype` is deprecated! Use `dtype` instead!\n‚úÖ Base model loaded from local Kaggle input\n‚úÖ Base model loaded from local Kaggle input\nAdding EOS to train dataset: 100%|‚ñà| 2029/2029 [00:00<00:00, 23333.19 examples/s\nTokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2029/2029 [00:03<00:00, 524.62 examples/s]\nTruncating train dataset: 100%|‚ñà‚ñà| 2029/2029 [00:00<00:00, 120762.34 examples/s]\nAdding EOS to train dataset:   0%|              | 0/2029 [00:00<?, ? examples/s]üöÄ Starting 4-bit BitsAndBytes + QLoRA training...\nThe tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\nAdding EOS to train dataset: 100%|‚ñà| 2029/2029 [00:00<00:00, 23363.10 examples/s\nTokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2029/2029 [00:03<00:00, 594.76 examples/s]\nTruncating train dataset: 100%|‚ñà‚ñà| 2029/2029 [00:00<00:00, 123951.22 examples/s]\nüöÄ Starting 4-bit BitsAndBytes + QLoRA training...\nThe tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n[2025-09-11 17:51:48,644] [WARNING] [engine.py:1373:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n  0%|                                                    | 0/64 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n{'loss': 2.4784, 'grad_norm': 2.6060609817504883, 'learning_rate': 1.4644660940672627e-05, 'num_tokens': 354166.0, 'mean_token_accuracy': 0.6565625, 'epoch': 0.79}\n{'train_runtime': 1073.5678, 'train_samples_per_second': 1.89, 'train_steps_per_second': 0.06, 'train_loss': 2.001221224665642, 'num_tokens': 446764.0, 'mean_token_accuracy': 0.8692129629629629, 'epoch': 1.0}\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64/64 [17:53<00:00, 16.77s/it]\n‚úÖ 4-bit QLoRA adapters saved to: qwen3_1.7b_4bit_qlora_output/\nüîÑ Merging 4-bit QLoRA adapters with base model...\n‚úÖ 4-bit QLoRA adapters saved to: qwen3_1.7b_4bit_qlora_output/\nüîÑ Merging 4-bit QLoRA adapters with base model...\n‚úÖ Base model loaded for merging from local Kaggle input\n‚úÖ Base model loaded for merging from local Kaggle input\n/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n‚úÖ Final 4-bit + QLoRA merged model saved to: qwen3_1.7b_4bit_finetuned/\nüéâ 4-bit BitsAndBytes + QLoRA training completed successfully!\n‚úÖ Final 4-bit + QLoRA merged model saved to: qwen3_1.7b_4bit_finetuned/\nüéâ 4-bit BitsAndBytes + QLoRA training completed successfully!\n[rank0]:[W911 18:09:52.238960606 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n","output_type":"stream"}],"execution_count":14},{"id":"baff9618","cell_type":"code","source":"# Check training output and model files\nimport os\nprint(\"4-bit QLoRA adapter files:\")\n!ls -la qwen3_1.7b_4bit_qlora_output/\nprint(\"\\nFinal 4-bit merged model files:\")\n!ls -la qwen3_1.7b_4bit_finetuned/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T18:09:57.817128Z","iopub.execute_input":"2025-09-11T18:09:57.817447Z","iopub.status.idle":"2025-09-11T18:09:58.061766Z","shell.execute_reply.started":"2025-09-11T18:09:57.817414Z","shell.execute_reply":"2025-09-11T18:09:58.061141Z"}},"outputs":[{"name":"stdout","text":"4-bit QLoRA adapter files:\ntotal 36020\ndrwxr-xr-x 3 root root     4096 Sep 11 18:09 .\ndrwxr-xr-x 6 root root     4096 Sep 11 18:09 ..\n-rw-r--r-- 1 root root      951 Sep 11 18:09 adapter_config.json\n-rw-r--r-- 1 root root 20952456 Sep 11 18:09 adapter_model.safetensors\n-rw-r--r-- 1 root root      707 Sep 11 18:09 added_tokens.json\n-rw-r--r-- 1 root root     4116 Sep 11 18:09 chat_template.jinja\ndrwxr-xr-x 3 root root     4096 Sep 11 18:09 checkpoint-64\n-rw-r--r-- 1 root root  1671853 Sep 11 18:09 merges.txt\n-rw-r--r-- 1 root root     1541 Sep 11 18:09 README.md\n-rw-r--r-- 1 root root      613 Sep 11 18:09 special_tokens_map.json\n-rw-r--r-- 1 root root     5404 Sep 11 18:09 tokenizer_config.json\n-rw-r--r-- 1 root root 11422654 Sep 11 18:09 tokenizer.json\n-rw-r--r-- 1 root root     7505 Sep 11 18:09 training_args.bin\n-rw-r--r-- 1 root root  2776833 Sep 11 18:09 vocab.json\n\nFinal 4-bit merged model files:\ntotal 541804\ndrwxr-xr-x 2 root root      4096 Sep 11 18:09 .\ndrwxr-xr-x 6 root root      4096 Sep 11 18:09 ..\n-rw-r--r-- 1 root root       707 Sep 11 18:09 added_tokens.json\n-rw-r--r-- 1 root root      4116 Sep 11 18:09 chat_template.jinja\n-rw-r--r-- 1 root root      1839 Sep 11 18:09 config.json\n-rw-r--r-- 1 root root       214 Sep 11 18:09 generation_config.json\n-rw-r--r-- 1 root root   1671853 Sep 11 18:09 merges.txt\n-rw-r--r-- 1 root root 538883093 Sep 11 18:09 model.safetensors\n-rw-r--r-- 1 root root       613 Sep 11 18:09 special_tokens_map.json\n-rw-r--r-- 1 root root      5404 Sep 11 18:09 tokenizer_config.json\n-rw-r--r-- 1 root root  11422654 Sep 11 18:09 tokenizer.json\n-rw-r--r-- 1 root root   2776833 Sep 11 18:09 vocab.json\n","output_type":"stream"}],"execution_count":15},{"id":"2f04c9a7","cell_type":"code","source":"# Create a compressed archive for easier upload to Kaggle datasets\n!tar -czf qwen3_1.7b_4bit_qlora_model.tar.gz qwen3_1.7b_4bit_finetuned/\nprint(\"4-bit QLoRA model archived as: qwen3_1.7b_4bit_qlora_model.tar.gz\")\nprint(\"Upload this file to Kaggle as a dataset for use in the inference notebook.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T18:10:24.761804Z","iopub.execute_input":"2025-09-11T18:10:24.762106Z","iopub.status.idle":"2025-09-11T18:11:14.617521Z","shell.execute_reply.started":"2025-09-11T18:10:24.762080Z","shell.execute_reply":"2025-09-11T18:11:14.616795Z"}},"outputs":[{"name":"stdout","text":"4-bit QLoRA model archived as: qwen3_1.7b_4bit_qlora_model.tar.gz\nUpload this file to Kaggle as a dataset for use in the inference notebook.\n","output_type":"stream"}],"execution_count":16},{"id":"49348a5c","cell_type":"markdown","source":"# ‚ö° Speed Optimization Guide for 2x T4 GPUs (28GB Total VRAM) - 4-bit QLoRA Edition\n\n## Current Settings Status: ‚úÖ **EXCELLENT** for 2x T4 GPUs with 4-bit\n- **Memory**: 1.7B model (4-bit) + QLoRA fits in ~8-10GB per GPU\n- **Batch Size**: 4 per device √ó 4 accumulation = 32 effective batch size\n- **DeepSpeed**: ZeRO Stage 2 with FP16 - optimal for this setup\n- **Speed**: Efficient with 4-bit quantization\n\n## üöÄ Additional Speed Optimizations for 4-bit QLoRA:\n\n### **Quick Wins (Even Better with 4-bit):**\n1. **Increase Batch Size Further** (Cell 7 - `train.py`):\n   ```python\n   per_device_train_batch_size=6,  # Can go higher with 4-bit (4‚Üí6-8)\n   gradient_accumulation_steps=3,   # Adjust accordingly (4‚Üí2-3)\n   ```\n   \n2. **Faster Optimizer** (Cell 7 - `train.py`):\n   ```python\n   optim=\"adamw_torch_fused\",  # Even faster with 4-bit\n   ```\n\n3. **Reduce QLoRA Rank** (Cell 7 - `train.py`):\n   ```python\n   r=8,              # Can use lower rank with 4-bit efficiency\n   lora_alpha=16,     # Adjust proportionally\n   ```\n\n## üí° **Why 4-bit BitsAndBytes + QLoRA is Superior:**\n1. **Standard QLoRA**: Reliable and well-tested\n2. **Memory Efficient**: 4-bit NF4 uses less memory\n3. **Faster**: Dynamic quantization is optimized for training\n4. **Flexible**: Easy to adjust quantization settings\n5. **Future-Proof**: Better PEFT ecosystem support","metadata":{}}]}