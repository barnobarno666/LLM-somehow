{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12726948,"sourceType":"datasetVersion","datasetId":8044304},{"sourceId":12762469,"sourceType":"datasetVersion","datasetId":8067935},{"sourceId":252850661,"sourceType":"kernelVersion"},{"sourceId":252853424,"sourceType":"kernelVersion"},{"sourceId":259545323,"sourceType":"kernelVersion"},{"sourceId":171496,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":145960,"modelId":164048},{"sourceId":171638,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":146086,"modelId":164048},{"sourceId":426330,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":347541,"modelId":368803},{"sourceId":523492,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":411182,"modelId":429004},{"sourceId":579809,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":432662,"modelId":449553}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b1f53c33","cell_type":"markdown","source":"# Alternative Validation Options\n\n## 🔧 **Choose Your Validation Method:**\n\nThis notebook now provides **two validation approaches**:\n\n### **Option 1: vLLM Validation (Original)**\n- **Pros**: Fastest inference, most precise probability calculations\n- **Cons**: Hardware compatibility issues with certain GPU/model combinations\n- **Use when**: You have compatible hardware and need maximum speed\n\n### **Option 2: Standard Transformers Validation (New)**\n- **Pros**: Universal compatibility, works with any Unsloth model, reliable\n- **Cons**: Slower than vLLM, but still faster than training\n- **Use when**: vLLM has compatibility issues or you want guaranteed reliability\n\n**Both methods produce identical metrics and visualizations** - the choice is purely based on your hardware compatibility and speed requirements.","metadata":{}},{"id":"4ef0213e","cell_type":"markdown","source":"# TT-11: Validation-Focused Training with Unsloth + vLLM\n\nThis notebook implements the same validation-focused approach as TT-10, but optimized for **maximum speed and accuracy**:\n\n**Key Improvements over TT-10:**\n- **🚀 Unsloth Training**: 2x-5x faster fine-tuning than standard PEFT\n- **🎯 vLLM Inference**: Most accurate AUC calculations with precise log probabilities\n- **💾 Memory Efficient**: Optimized for 2x T4 GPU setup\n- **⚡ Best Performance**: Fastest training + most accurate validation\n\n**Methodology:**\n- **Training**: Model learns from positive/negative examples using Unsloth (like test-time training)\n- **Validation**: Model predicts on real `body` comments with vLLM for precise probabilities\n- **Analysis**: Comprehensive metrics to understand generalization from examples to real data\n\n**Features:**\n- **Stratified Sampling**: Controllable % of training data while maintaining rule distribution\n- **Example-Based Training**: Similar to test-time training approach with Unsloth speed\n- **Real Comment Validation**: Test on actual comments with vLLM precision\n- **Comprehensive Metrics**: AUC, F1, Recall, Precision, Confusion Matrix\n- **Visualizations**: Performance plots and analysis\n- **4-bit + LoRA**: Memory-efficient training, vLLM-compatible inference\n\n**Benefits:**\n- **Fastest Training**: Unsloth provides 2x-5x speed improvement\n- **Most Accurate AUC**: vLLM gives precise probability calculations\n- **Best of Both Worlds**: Speed + Accuracy optimized workflow","metadata":{}},{"id":"4c705040","cell_type":"code","source":"# Install dependencies - Unsloth + vLLM + Analysis setup\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'trl==0.21.0' 'optimum==1.27.0' 'bitsandbytes==0.46.1' 'deepspeed==0.17.4' 'logits-processor-zoo==0.2.1' 'vllm==0.10.0'\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'triton==3.2.0'\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'clean-text'\n# Install PEFT for LoRA support\n!uv pip install --system --no-index -U --no-deps --find-links='/kaggle/input/jigsaw-packages2/whls/' 'peft' 'accelerate' 'datasets'\n# Install Unsloth for ultra-fast training\n#!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'unsloth'\n# Install analysis libraries\n#!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'scikit-learn' 'matplotlib' 'seaborn'\n\nprint(\"✅ TT-11 Dependencies installed:\")\nprint(\"🚀 Unsloth: Ultra-fast training\")\nprint(\"🎯 vLLM: Precise inference\") \nprint(\"📊 Analysis libraries: scikit-learn, matplotlib, seaborn\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:06:53.117789Z","iopub.execute_input":"2025-09-18T18:06:53.118224Z","iopub.status.idle":"2025-09-18T18:07:38.897596Z","shell.execute_reply.started":"2025-09-18T18:06:53.118206Z","shell.execute_reply":"2025-09-18T18:07:38.896857Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m164 packages\u001b[0m \u001b[2min 606ms\u001b[0m\u001b[0m                                       \u001b[0m\n\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                          \n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m63 packages\u001b[0m \u001b[2min 28.69s\u001b[0m\u001b[0m                                           \n\u001b[2mUninstalled \u001b[1m26 packages\u001b[0m \u001b[2min 2.00s\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m63 packages\u001b[0m \u001b[2min 1.95s\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mastor\u001b[0m\u001b[2m==0.8.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.46.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mblake3\u001b[0m\u001b[2m==1.0.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcbor2\u001b[0m\u001b[2m==5.7.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcompressed-tensors\u001b[0m\u001b[2m==0.10.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdeepspeed\u001b[0m\u001b[2m==0.17.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdepyf\u001b[0m\u001b[2m==0.19.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cli\u001b[0m\u001b[2m==0.0.10\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cloud-cli\u001b[0m\u001b[2m==0.1.5\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.5.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgguf\u001b[0m\u001b[2m==0.17.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhjson\u001b[0m\u001b[2m==3.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.6.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.33.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.34.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1minteregular\u001b[0m\u001b[2m==0.3.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.2.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllguidance\u001b[0m\u001b[2m==0.7.30\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.43.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.44.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlm-format-enforcer\u001b[0m\u001b[2m==0.10.12\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlogits-processor-zoo\u001b[0m\u001b[2m==0.2.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmistral-common\u001b[0m\u001b[2m==1.8.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.19.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.60.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.61.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.11.1.6\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.6.85\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.91.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.90.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moptimum\u001b[0m\u001b[2m==1.27.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moutlines-core\u001b[0m\u001b[2m==0.2.10\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpartial-json-parser\u001b[0m\u001b[2m==0.2.1.1.post6\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mprometheus-fastapi-instrumentator\u001b[0m\u001b[2m==7.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpycountry\u001b[0m\u001b[2m==24.6.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpydantic-extra-types\u001b[0m\u001b[2m==2.10.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==24.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrich-toolkit\u001b[0m\u001b[2m==0.15.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrignore\u001b[0m\u001b[2m==0.6.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124 (from https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.22.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.52.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.56.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mvllm\u001b[0m\u001b[2m==0.10.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.31\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxgrammar\u001b[0m\u001b[2m==0.1.21\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 3.57s\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 14ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m4 packages\u001b[0m \u001b[2min 6.64s\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                               \n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 665ms\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mclean-text\u001b[0m\u001b[2m==0.6.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==2.14.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==1.7.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m3 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 42ms\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m3 packages\u001b[0m \u001b[2min 59ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.8.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.10.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==3.6.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.0.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.15.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.17.1\u001b[0m\n✅ TT-11 Dependencies installed:\n🚀 Unsloth: Ultra-fast training\n🎯 vLLM: Precise inference\n📊 Analysis libraries: scikit-learn, matplotlib, seaborn\n","output_type":"stream"}],"execution_count":1},{"id":"dfd03d10-6426-41a4-8620-213cfd3402c3","cell_type":"code","source":"!pip install unsloth \n!pip install vllm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:07:38.898504Z","iopub.execute_input":"2025-09-18T18:07:38.898773Z","iopub.status.idle":"2025-09-18T18:08:06.759969Z","shell.execute_reply.started":"2025-09-18T18:07:38.898739Z","shell.execute_reply":"2025-09-18T18:08:06.759201Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.9.6-py3-none-any.whl.metadata (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.9.7 (from unsloth)\n  Downloading unsloth_zoo-2025.9.8-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.7.1)\nRequirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.0.31)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.46.1)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\nCollecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3 (from unsloth)\n  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting datasets<4.0.0,>=3.4.1 (from unsloth)\n  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.10.1)\nRequirement already satisfied: trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.17.1)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.4)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.22.1)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2025.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth) (2024.11.6)\nCollecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth)\n  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: torchao in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.7->unsloth) (0.10.0)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.9.7->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.7->unsloth) (11.2.1)\nRequirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.7->unsloth) (0.19.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (14.0.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.13)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.6.15)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.9.6-py3-none-any.whl (312 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.6/312.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.9.8-py3-none-any.whl (230 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.2/230.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.9.31-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nInstalling collected packages: triton, shtab, tyro, tokenizers, cut_cross_entropy, transformers, datasets, unsloth_zoo, unsloth\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.22.0\n    Uninstalling tokenizers-0.22.0:\n      Successfully uninstalled tokenizers-0.22.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.56.0\n    Uninstalling transformers-4.56.0:\n      Successfully uninstalled transformers-4.56.0\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.0.0\n    Uninstalling datasets-4.0.0:\n      Successfully uninstalled datasets-4.0.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cut_cross_entropy-25.1.1 datasets-3.6.0 shtab-1.7.2 tokenizers-0.21.4 transformers-4.55.4 triton-3.3.1 tyro-0.9.31 unsloth-2025.9.6 unsloth_zoo-2025.9.8\nRequirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.10.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from vllm) (2024.11.6)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.4)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\nRequirement already satisfied: blake3 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.0.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\nRequirement already satisfied: transformers>=4.53.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.55.4)\nRequirement already satisfied: huggingface-hub>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.33.0->vllm) (0.34.4)\nRequirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.4)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (3.20.3)\nRequirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.13)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.12.13)\nRequirement already satisfied: openai<=1.90.0,>=1.87.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.90.0)\nRequirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.7)\nRequirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.22.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\nRequirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (7.1.0)\nRequirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\nRequirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.12)\nRequirement already satisfied: llguidance<0.8.0,>=0.7.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.7.30)\nRequirement already satisfied: outlines_core==0.2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.10)\nRequirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.11/dist-packages (from vllm) (5.6.3)\nRequirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.2.2)\nRequirement already satisfied: xgrammar==0.1.21 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.1.21)\nRequirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.14.0)\nRequirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\nRequirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.1.1.post6)\nRequirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (27.0.2)\nRequirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\nRequirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.17.1)\nRequirement already satisfied: mistral_common>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from mistral_common[audio,image]>=1.8.2->vllm) (1.8.4)\nRequirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\nRequirement already satisfied: compressed-tensors==0.10.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.2)\nRequirement already satisfied: depyf==0.19.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\nRequirement already satisfied: watchfiles in /usr/local/lib/python3.11/dist-packages (from vllm) (1.1.0)\nRequirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.3)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from vllm) (1.11.1.4)\nRequirement already satisfied: pybase64 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.4.2)\nRequirement already satisfied: cbor2 in /usr/local/lib/python3.11/dist-packages (from vllm) (5.7.0)\nRequirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.61.2)\nRequirement already satisfied: ray!=2.44.*,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (2.47.1)\nRequirement already satisfied: torch==2.7.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.7.1)\nRequirement already satisfied: torchaudio==2.7.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.7.1)\nRequirement already satisfied: torchvision==0.22.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.22.1)\nRequirement already satisfied: xformers==0.0.31 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.0.31)\nRequirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.8.1)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.3.8)\nRequirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba==0.61.2->vllm) (0.44.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (1.11.1.6)\nRequirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.3.1)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch==2.7.1->vllm) (75.2.0)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\nRequirement already satisfied: fastapi-cli>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.10)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\nRequirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\nRequirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.3)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (25.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (1.1.5)\nRequirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer<0.11,>=0.10.11->vllm) (0.3.3)\nRequirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.24.0)\nRequirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.10.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2.4.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (0.10.0)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (1.3.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.4.1)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.2.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.1)\nRequirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.6.15)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->vllm) (0.5.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.1)\nRequirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\nRequirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.16.0)\nRequirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.0)\nRequirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.1->vllm) (3.0.2)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.25.1)\nRequirement already satisfied: pycountry>=23 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (24.6.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.1->vllm) (1.3.0)\nRequirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\nRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\nRequirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\nRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.13.1)\nRequirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.5.0.post1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->vllm) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->vllm) (2024.2.0)\nRequirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\nRequirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.31.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->vllm) (2024.2.0)\nRequirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.0.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.17.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.22)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n","output_type":"stream"}],"execution_count":2},{"id":"c3a2c92f","cell_type":"markdown","source":"# 1. Configuration and Data Setup","metadata":{}},{"id":"32680ff1","cell_type":"code","source":"%%writefile constants.py\n# Using base Qwen3 1.7B model from Kaggle input (no internet needed)\nBASE_MODEL_PATH = \"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\"  # Update this path as needed\nLORA_PATH = \"qwen3_1.7b_unsloth_lora_validation/\"  # Unsloth LoRA output path for validation\nDATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules/\"\n\n# TT-11 Validation Parameters\nTRAINING_DATA_PERCENTAGE = 0.1  # Controllable % of training data (0.1 = 10%, 1.0 = 100%)\nUSE_STRATIFIED_SAMPLING = True  # Maintain rule distribution when sampling\n\nPOSITIVE_ANSWER = \"Yes\"\nNEGATIVE_ANSWER = \"No\"\nCOMPLETE_PHRASE = \"Answer:\"\nBASE_PROMPT = '''You are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.'''\n\nprint(\"✅ Using Qwen3 1.7B model from local Kaggle input\")\nprint(f\"🎯 TT-11: Unsloth training + vLLM inference with {TRAINING_DATA_PERCENTAGE*100:.0f}% of data\")\nprint(f\"📊 Stratified sampling: {USE_STRATIFIED_SAMPLING}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:08:06.762034Z","iopub.execute_input":"2025-09-18T18:08:06.762284Z","iopub.status.idle":"2025-09-18T18:08:06.768633Z","shell.execute_reply.started":"2025-09-18T18:08:06.762263Z","shell.execute_reply":"2025-09-18T18:08:06.767886Z"}},"outputs":[{"name":"stdout","text":"Writing constants.py\n","output_type":"stream"}],"execution_count":3},{"id":"b5b4fc8e","cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\nfrom datasets import Dataset\nfrom constants import POSITIVE_ANSWER, NEGATIVE_ANSWER, COMPLETE_PHRASE, BASE_PROMPT, TRAINING_DATA_PERCENTAGE, USE_STRATIFIED_SAMPLING\nimport random, numpy as np\nfrom sklearn.model_selection import train_test_split\nrandom.seed(42)\nnp.random.seed(42)\n\n\ndef build_prompt(row):\n    return f\"\"\"\n{BASE_PROMPT}\n\nSubreddit: r/{row[\"subreddit\"]}\nRule: {row[\"rule\"]}\nExamples:\n1) {row[\"positive_example\"]}\n{COMPLETE_PHRASE} Yes\n\n2) {row[\"negative_example\"]}\n{COMPLETE_PHRASE} No\n\n---\nComment: {row[\"body\"]}\n{COMPLETE_PHRASE}\"\"\"\n\n\ndef get_example_based_training_data(data_path):\n    \"\"\"\n    TT-11: Create training data from examples (like test-time training)\n    This trains the model on examples, not actual comments\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Sample data if needed while maintaining rule distribution\n    if TRAINING_DATA_PERCENTAGE < 1.0:\n        if USE_STRATIFIED_SAMPLING:\n            # Stratified sampling to maintain rule distribution\n            train_dataset = train_dataset.groupby('rule', group_keys=False).apply(\n                lambda x: x.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42)\n            ).reset_index(drop=True)\n            print(f\"📊 Stratified sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n        else:\n            # Simple random sampling\n            train_dataset = train_dataset.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42).reset_index(drop=True)\n            print(f\"📊 Random sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n    \n    print(f\"📊 Training data size: {len(train_dataset)} samples\")\n    print(f\"📊 Rule distribution: {train_dataset['rule'].value_counts().to_dict()}\")\n    \n    flatten = []\n    \n    # Create training data from examples (similar to test-time training)\n    for violation_type in [\"positive\", \"negative\"]:\n        for i in range(1, 3):\n            sub_dataset = train_dataset[[\"rule\",\"subreddit\",\n                                        \"positive_example_1\",\"positive_example_2\",\n                                        \"negative_example_1\",\"negative_example_2\"]].copy()\n\n            if violation_type == \"positive\":\n                # Use positive example as the \"body\" to classify\n                body_col = f\"positive_example_{i}\"\n                other_positive_col = f\"positive_example_{3-i}\"  # other positive\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"positive_example\"] = sub_dataset[other_positive_col]\n                # negative_example randomly selected\n                sub_dataset[\"negative_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"negative_example_1\"],\n                    sub_dataset[\"negative_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 1  # Positive examples violate rules\n\n            else:  # violation_type == \"negative\"\n                # Use negative example as the \"body\" to classify\n                body_col = f\"negative_example_{i}\"\n                other_negative_col = f\"negative_example_{3-i}\"\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"negative_example\"] = sub_dataset[other_negative_col]\n                sub_dataset[\"positive_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"positive_example_1\"],\n                    sub_dataset[\"positive_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 0  # Negative examples don't violate rules\n\n            # Drop original candidate columns\n            sub_dataset.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                                      \"negative_example_1\",\"negative_example_2\"], inplace=True)\n\n            flatten.append(sub_dataset)\n\n    # Merge all DataFrames\n    example_training_df = pd.concat(flatten, axis=0)\n    example_training_df = example_training_df.drop_duplicates(ignore_index=True)\n    \n    print(f\"📊 Example-based training dataset: {len(example_training_df)} samples\")\n    print(f\"📊 Positive examples: {sum(example_training_df['rule_violation'] == 1)}\")\n    print(f\"📊 Negative examples: {sum(example_training_df['rule_violation'] == 0)}\")\n    \n    return example_training_df\n\n\ndef get_real_comment_validation_data(data_path):\n    \"\"\"\n    TT-11: Get real comments with labels for validation\n    This is what we actually want to predict\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Use actual comments and their labels for validation\n    validation_df = train_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\",\n                                  \"positive_example_1\",\"positive_example_2\",\n                                  \"negative_example_1\",\"negative_example_2\"]].copy()\n\n    # Randomly select positive_example and negative_example for prompts\n    validation_df[\"positive_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"positive_example_1\"],\n        validation_df[\"positive_example_2\"]\n    )\n    validation_df[\"negative_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"negative_example_1\"],\n        validation_df[\"negative_example_2\"]\n    )\n\n    # Drop original candidate columns\n    validation_df.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                               \"negative_example_1\",\"negative_example_2\"], inplace=True)\n    \n    print(f\"📊 Real comment validation dataset: {len(validation_df)} samples\")\n    print(f\"📊 Rule violations: {sum(validation_df['rule_violation'] == 1)} positive, {sum(validation_df['rule_violation'] == 0)} negative\")\n    \n    return validation_df\n\n\ndef build_dataset_unsloth(dataframe):\n    \"\"\"Build dataset for Unsloth training with proper text formatting\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    \n    # Unsloth expects \"text\" field with full prompt + completion\n    dataframe[\"text\"] = dataframe.apply(lambda row: \n        row[\"prompt\"] +\" \" + (POSITIVE_ANSWER if row[\"rule_violation\"] == 1 else NEGATIVE_ANSWER), #i removed the space after the prompt\n        axis=1\n    )\n    \n    dataframe = dataframe[[\"text\"]]\n    dataset = Dataset.from_pandas(dataframe)\n    return dataset\n\n\ndef build_validation_dataset(dataframe):\n    \"\"\"Build dataset for validation (keep labels for evaluation)\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    dataframe = dataframe[[\"prompt\", \"rule_violation\"]]  # Keep true labels for evaluation\n    dataset = Dataset.from_pandas(dataframe)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:08:31.323559Z","iopub.execute_input":"2025-09-18T18:08:31.324280Z","iopub.status.idle":"2025-09-18T18:08:31.331926Z","shell.execute_reply.started":"2025-09-18T18:08:31.324255Z","shell.execute_reply":"2025-09-18T18:08:31.331085Z"}},"outputs":[{"name":"stdout","text":"Writing utils.py\n","output_type":"stream"}],"execution_count":4},{"id":"772886cb","cell_type":"code","source":"%%writefile train_unsloth.py\nimport pandas as pd\nimport torch\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom utils import build_dataset_unsloth, get_example_based_training_data\nfrom constants import DATA_PATH, BASE_MODEL_PATH, LORA_PATH\n\n\ndef main():\n    # TT-11: Get example-based training data (train on examples, not real comments)\n    train_df = get_example_based_training_data(DATA_PATH)\n    train_dataset = build_dataset_unsloth(train_df)\n    \n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n    \n    # 🚀 UNSLOTH: Load model with 4-bit quantization (2x T4 optimized)\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,  # Adjust based on your max sequence length\n        dtype=None,  # Auto-detect (will use float16)\n        load_in_4bit=True,  # Enable 4-bit quantization\n        trust_remote_code=True,\n        local_files_only=True,\n        device_map=\"balanced\"\n    )\n    print(\"✅ Unsloth model loaded with 4-bit quantization across 2x T4\")\n    \n    # 🚀 UNSLOTH: Add LoRA adapters (automatic and optimized)\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r=16,  # LoRA rank (can try 8, 16, 32, 64, 128)\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n        lora_alpha=16,  # LoRA alpha (typically equal to r for Unsloth)\n        lora_dropout=0,  # 0 for faster training with Unsloth\n        bias=\"none\",\n        #use_gradient_checkpointing=False,  # Enable for memory efficiency\n        random_state=3407,  # For reproducibility\n        use_rslora=False,  # Can try True for better stability\n        loftq_config=None,  # LoftQ for even better quality\n        use_gradient_checkpointing = \"unsloth\"\n    )\n    print(\"✅ Unsloth LoRA adapters added\")\n    \n    # 🚀 UNSLOTH: Optimized training arguments for 2x T4 GPUs (28GB total)\n    training_args = TrainingArguments(\n        per_device_train_batch_size=8,  # Larger batches with 2x T4 (28GB total)\n        gradient_accumulation_steps=8,  # Effective batch size = 4*2*2 = 16\n        warmup_steps=5,  # Quick warmup with Unsloth\n        #max_steps=50,  # Unsloth converges much faster (adjust based on data size)\n        num_train_epochs=1 , \n        learning_rate=2e-4,  # Higher LR works better with Unsloth\n        fp16=not torch.cuda.is_bf16_supported(),\n        bf16=torch.cuda.is_bf16_supported(),\n        logging_steps=1,  # Frequent logging for monitoring\n        optim=\"adamw_8bit\",  # 8-bit optimizer for memory efficiency\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",  # Simple linear decay\n        seed=666,\n        output_dir=LORA_PATH,\n        report_to=\"none\",\n        save_strategy=\"steps\",\n        save_steps=20,  # Save frequently for monitoring\n        save_total_limit=2,  # Keep only recent checkpoints\n        dataloader_pin_memory=False,  # Unsloth handles this\n        # Multi-GPU optimizations for 2x T4\n        dataloader_num_workers=4,  # Parallel data loading\n        remove_unused_columns=False,  # Keep all data\n        ddp_find_unused_parameters=False,  # DDP optimization\n        ddp_broadcast_buffers=False,  # Reduce communication overhead\n    )\n    print(\"✅ Unsloth training arguments configured for 2x T4\")\n    \n    # 🚀 UNSLOTH: Use SFTTrainer with Unsloth model\n    trainer = SFTTrainer(\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=train_dataset,\n        dataset_text_field=\"text\",  # Unsloth expects \"text\" field\n        max_seq_length=2048,\n        dataset_num_proc=4,  # More parallel processing for 2x T4\n        packing=False,  # Can try True for even faster training\n        args=training_args,\n    )\n    \n    print(\"🚀 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\")\n    \n    # 🚀 UNSLOTH: Train with optimized loop\n    trainer_stats = trainer.train()\n    \n    print(\"✅ Unsloth training completed!\")\n    print(f\"Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\n    print(f\"Samples/second: {trainer_stats.metrics['train_samples_per_second']:.2f}\")\n    print(f\"GPU utilization optimized for 2x T4 setup\")\n    \n    # 🚀 UNSLOTH: Save LoRA adapters in vLLM-compatible format\n    print(\"💾 Saving LoRA adapters for vLLM compatibility...\")\n    \n    # Save tokenizer\n    tokenizer.save_pretrained(LORA_PATH)\n    \n    # Save model in PEFT format (vLLM compatible)\n    model.save_pretrained(LORA_PATH)\n    #model.save_pretrained(...)  \n    #tokenizer.save_pretrained(...)\n    folder=\"16 bit\"\n    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"forced_merged_4bit\",)\n    \n\n    \n    print(f\"✅ LoRA adapters saved to: {LORA_PATH} , model saved \")\n    print(\"🎯 Ready for vLLM inference!\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:08:40.521876Z","iopub.execute_input":"2025-09-18T18:08:40.522156Z","iopub.status.idle":"2025-09-18T18:08:40.529314Z","shell.execute_reply.started":"2025-09-18T18:08:40.522135Z","shell.execute_reply":"2025-09-18T18:08:40.528597Z"}},"outputs":[{"name":"stdout","text":"Writing train_unsloth.py\n","output_type":"stream"}],"execution_count":5},{"id":"5195dc58","cell_type":"markdown","source":"# 🎯 2x T4 GPU Optimization Guide\n\n## ⚡ **Multi-GPU Configuration for TT-11**\n\n### **Your Setup: 2x T4 (28GB Total VRAM)**\n- **GPU 0**: ~14GB VRAM\n- **GPU 1**: ~14GB VRAM\n- **Total**: 28GB available for training\n\n### **Optimizations Applied:**\n\n#### **1. Model Distribution**\n```python\ndevice_map=\"auto\"  # Automatic distribution across GPUs\nmax_memory={0: \"13GB\", 1: \"13GB\"}  # Reserve 1GB per GPU for operations\n```\n\n#### **2. Batch Size Scaling**\n```python\nper_device_train_batch_size=4,  # 4 samples per GPU (8 total)\ngradient_accumulation_steps=2,  # Effective batch = 4*2*2 = 16\n```\n\n#### **3. Memory Optimizations**\n```python\nload_in_4bit=True,              # 4-bit quantization saves ~75% memory\nuse_gradient_checkpointing=True, # Trade compute for memory\ndataloader_pin_memory=False,     # Let Unsloth handle memory\n```\n\n#### **4. Multi-GPU Training**\n```python\ndataloader_num_workers=4,        # Parallel data loading\nddp_find_unused_parameters=False, # DDP optimization\nddp_broadcast_buffers=False,     # Reduce communication\n```\n\n### **Expected Performance:**\n- **Training Speed**: 3x-6x faster than single GPU\n- **Memory Usage**: ~12-13GB per GPU\n- **Effective Batch**: 16 samples (vs 4 on single GPU)\n- **Total Time**: 5-8 minutes for full training\n\n### **Troubleshooting 2x T4:**\n\n#### **If you get OOM (Out of Memory):**\n```python\n# Reduce batch size\nper_device_train_batch_size=2,   # 2 per GPU instead of 4\ngradient_accumulation_steps=4,   # Keep effective batch size\n\n# Or reduce sequence length\nmax_seq_length=1024,             # Shorter sequences\n```\n\n#### **If training is slower than expected:**\n```python\n# Check GPU utilization\nnvidia-smi  # Should show ~90%+ on both GPUs\n\n# Increase batch size if memory allows\nper_device_train_batch_size=6,   # Try larger batches\n```\n\n#### **Memory Distribution Check:**\n```python\nprint(f\"Available GPUs: {torch.cuda.device_count()}\")\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_properties(i).total_memory // 1024**3}GB\")\n```","metadata":{}},{"id":"9c272316-1b10-4ccd-bc25-ea7e46e2fdd1","cell_type":"code","source":"!export VLLM_LOGGING_LEVEL=DEBUG\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T15:30:55.179978Z","iopub.execute_input":"2025-09-18T15:30:55.180228Z","iopub.status.idle":"2025-09-18T15:30:55.295403Z","shell.execute_reply.started":"2025-09-18T15:30:55.180206Z","shell.execute_reply":"2025-09-18T15:30:55.294688Z"}},"outputs":[],"execution_count":6},{"id":"09a9ce47-01e2-499f-bac9-49a3fc60aa31","cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T12:50:03.641772Z","iopub.execute_input":"2025-09-15T12:50:03.642051Z","iopub.status.idle":"2025-09-15T12:50:03.649916Z","shell.execute_reply.started":"2025-09-15T12:50:03.642031Z","shell.execute_reply":"2025-09-15T12:50:03.649026Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2768232158.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLORA_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'LORA_PATH' is not defined"],"ename":"NameError","evalue":"name 'LORA_PATH' is not defined","output_type":"error"}],"execution_count":59},{"id":"94fc07a4","cell_type":"code","source":"%%writefile validation_vllm.py\nimport os\nos.environ[\"TRITON_NUM_STAGES\"] = \"3\"  # Reduce stages\nos.environ[\"VLLM_USE_V1\"] = \"1\"\nimport vllm\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\nfrom vllm.lora.request import LoRARequest\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_vllm():\n    \"\"\"Run validation using Unsloth-trained model with vLLM for precise AUC\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"🔍 Running validation on {len(val_dataset)} real comments\")\n    model=\"/kaggle/working/qwen3_1.7b_merged\"\n    # 🎯 VLLM: Initialize with Unsloth LoRA support for precise probabilities\n    llm = vllm.LLM(\n        model= model,\n        tensor_parallel_size=1,\n        gpu_memory_utilization=0.90, # Reduced to prevent OOM\n        trust_remote_code=True,\n        dtype=\"half\" ,\n        quantization=\"bitsandbytes\",\n        #load_format=\"bitsandbytes\" ,\n        enforce_eager=True,\n        max_model_len=700,  # Reduced from 2048 to fix Triton shared memory error on T4\n        disable_log_stats=True,\n        enable_prefix_caching=True,\n        enable_lora=True,\n        max_lora_rank=64,  # Support Unsloth's LoRA rank\n        block_size=16,\n        num_gpu_blocks_override=512\n        \n\n        \n    )\n\n    # In validation_vllm.py, modify the LLM initialization:\n    # llm = vllm.LLM(\n    #     BASE_MODEL_PATH,\n    #     tensor_parallel_size=1,\n    #     gpu_memory_utilization=0.90,\n    #     trust_remote_code=True,\n    #     dtype=\"half\",  # Use half precision instead of quantization\n    #     enforce_eager=True,\n    #     max_model_len=512,\n    #     disable_log_stats=True,\n    #     enable_prefix_caching=True,\n    #     enable_lora=True,\n    #     max_lora_rank=64,\n    # )\n\n    tokenizer = llm.get_tokenizer()\n\n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n\n    # 🎯 VLLM: Generate with Unsloth LoRA for most accurate probabilities\n    # We remove the logits_processor and decrease logprobs to get token probabilities\n    outputs = llm.generate(\n        texts,\n        vllm.SamplingParams(\n            skip_special_tokens=True,\n            max_tokens=1,\n            logprobs=20,  # Request top 20 logprobs to find \"Yes\" and \"No\"\n        ),\n        use_tqdm=True,\n        lora_request=LoRARequest(\"unsloth_lora\", 1, LORA_PATH)  # Load Unsloth LoRA\n    )\n\n    # Extract predictions and probabilities with vLLM precision\n    predictions = []\n    probabilities = []  # High-precision probabilities for AUC\n    \n    # Get token IDs for \"Yes\" and \"No\"\n    yes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\n    no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n    \n    for out in outputs:\n        # Safely get log probabilities for \"Yes\" and \"No\"\n        log_probs = out.outputs[0].logprobs[0]\n        \n        log_prob_yes = log_probs.get(yes_token_id)\n        log_prob_no = log_probs.get(no_token_id)\n        \n        # Handle cases where tokens might not be in the top logprobs\n        if log_prob_yes is not None and log_prob_no is not None:\n            if log_prob_yes.logprob > log_prob_no.logprob:\n                predictions.append(1)\n            else:\n                predictions.append(0)\n            \n            # Calculate precise probability for AUC\n            exp_pos = np.exp(log_prob_yes.logprob)\n            exp_neg = np.exp(log_prob_no.logprob)\n            prob_positive = exp_pos / (exp_pos + exp_neg)\n            probabilities.append(prob_positive)\n        else:\n            # Fallback if one of the tokens is not in the top 20 logprobs\n            # This is unlikely but a safe fallback\n            predictions.append(0)\n            probabilities.append(0.5)\n\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    # Basic metrics\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"📊 TT-11 VALIDATION RESULTS (Unsloth + vLLM)\")\n    print(\"=\" * 60)\n    print(f\"🎯 Accuracy:  {accuracy:.4f}\")\n    print(f\"🎯 F1 Score:  {f1:.4f}\")\n    print(f\"🎯 Precision: {precision:.4f}\")\n    print(f\"🎯 Recall:    {recall:.4f}\")\n    print(f\"🎯 AUC Score: {auc:.4f} (High-precision vLLM)\")\n    print(\"=\" * 60)\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n📈 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    # Classification report\n    print(\"\\n📋 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'auc': auc,\n        'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-11: Unsloth Training + vLLM Validation Results', fontsize=16, fontweight='bold')\n    \n    # 1. Confusion Matrix Heatmap\n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    # 2. ROC Curve\n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (vLLM High-Precision)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # 3. Probability Distribution\n    pos_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 1]\n    neg_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (vLLM Precision)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    # 4. Metrics Bar Chart\n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics['accuracy'], metrics['f1'], metrics['precision'], metrics['recall'], metrics['auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (Unsloth + vLLM)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt11_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    # Add predictions to dataframe\n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n📊 PERFORMANCE BY RULE (vLLM High-Precision AUC):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        if len(np.unique(rule_true)) > 1:  # Check if both classes exist\n            rule_auc = roc_auc_score(rule_true, rule_prob)\n        else:\n            rule_auc = np.nan\n            \n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\")\n        print(f\"  Samples: {len(rule_data)}\")\n        print(f\"  Accuracy: {rule_acc:.3f}\")\n        print(f\"  F1 Score: {rule_f1:.3f}\" if not np.isnan(rule_f1) else \"  F1 Score: N/A\")\n        print(f\"  AUC Score: {rule_auc:.3f}\" if not np.isnan(rule_auc) else \"  AUC Score: N/A\")\n        print()\n        \n        rule_metrics.append({\n            'rule': rule,\n            'samples': len(rule_data),\n            'accuracy': rule_acc,\n            'f1': rule_f1,\n            'auc': rule_auc\n        })\n    \n    # Save detailed results\n    analysis_df.to_csv('/kaggle/working/tt11_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt11_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"🔬 TT-11: Unsloth Training + vLLM Validation\")\n    print(\"🚀 Ultra-fast training + High-precision inference!\")\n    print(\"📚 Training: Model learned from examples with Unsloth speed\")\n    print(\"🧪 Validation: Testing on real comments with vLLM precision\")\n    print(\"=\" * 70)\n    \n    # Run validation\n    true_labels, predictions, probabilities, val_df = run_validation_vllm()\n    \n    # Calculate metrics\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    \n    # Create visualizations\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    \n    # Analyze by rule\n    rule_metrics = analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"✅ TT-11 Validation completed!\")\n    print(\"📈 Visualizations saved: /kaggle/working/tt11_validation_results.png\")\n    print(\"📊 Detailed results: /kaggle/working/tt11_detailed_results.csv\")\n    print(\"📋 Rule metrics: /kaggle/working/tt11_rule_metrics.csv\")\n    print(\"🎯 Best of both worlds: Unsloth speed + vLLM precision!\")\n    \n    return metrics, rule_metrics\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:08:50.136136Z","iopub.execute_input":"2025-09-18T18:08:50.136436Z","iopub.status.idle":"2025-09-18T18:08:50.146998Z","shell.execute_reply.started":"2025-09-18T18:08:50.136411Z","shell.execute_reply":"2025-09-18T18:08:50.146271Z"}},"outputs":[{"name":"stdout","text":"Writing validation_vllm.py\n","output_type":"stream"}],"execution_count":6},{"id":"07ec1ce0","cell_type":"code","source":"%%writefile validation_transformers.py\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom unsloth import FastLanguageModel  # Add this import\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_transformers():\n    \"\"\"Run validation using Unsloth fast inference with merged LoRA - Maximum speed!\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"🔍 Running validation on {len(val_dataset)} real comments (Unsloth Fast Inference)\")\n    \n    # 🚀 UNSLOTH: Load merged model with fast inference support\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=\"/kaggle/working/qwen3_1.7b_merged\",  # Use merged model path\n        max_seq_length=2048,\n        load_in_4bit=True,  # Keep 4-bit for speed\n        dtype=None,\n    )\n    \n    # 🚀 UNSLOTH: Enable fast inference mode\n    FastLanguageModel.for_inference(model)\n    \n    # Get token IDs for \"Yes\" and \"No\"\n    yes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\n    no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n    \n    print(f\"🎯 Token IDs: Yes={yes_token_id}, No={no_token_id}\")\n    \n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n    \n    # 🚀 UNSLOTH: Fast batch inference\n    predictions = []\n    probabilities = []\n    batch_size = 16  # Larger batches with Unsloth optimization\n    \n    print(\"🚀 Running fast inference with Unsloth...\")\n    \n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch_texts = texts[i:i+batch_size]\n        \n        # 🚀 UNSLOTH: Optimized tokenization and inference\n        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            # 🚀 UNSLOTH: Fast forward pass\n            outputs = model(**inputs)\n            next_token_logits = outputs.logits[:, -1, :]  # Get last token logits\n            \n            # Get probabilities for \"Yes\" and \"No\" tokens\n            yes_logits = next_token_logits[:, yes_token_id]\n            no_logits = next_token_logits[:, no_token_id]\n            \n            # Convert to probabilities using softmax over Yes/No only\n            combined_logits = torch.stack([no_logits, yes_logits], dim=1)  # [batch, 2]\n            probs = torch.softmax(combined_logits, dim=1)  # [batch, 2]\n            \n            # Extract predictions and probabilities\n            batch_predictions = torch.argmax(probs, dim=1).cpu().numpy()\n            batch_probabilities = probs[:, 1].cpu().numpy()  # Probability of \"Yes\" (violation)\n            \n            predictions.extend(batch_predictions.tolist())\n            probabilities.extend(batch_probabilities.tolist())\n    \n    print(\"✅ Fast inference completed!\")\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    # Basic metrics\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"📊 TT-11 VALIDATION RESULTS (Unsloth + Transformers)\")\n    print(\"=\" * 60)\n    print(f\"🎯 Accuracy:  {accuracy:.4f}\")\n    print(f\"🎯 F1 Score:  {f1:.4f}\")\n    print(f\"🎯 Precision: {precision:.4f}\")\n    print(f\"🎯 Recall:    {recall:.4f}\")\n    print(f\"🎯 AUC Score: {auc:.4f} (Standard Transformers)\")\n    print(\"=\" * 60)\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n📈 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    # Classification report\n    print(\"\\n📋 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'auc': auc,\n        'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-11: Unsloth Training + Transformers Validation Results', fontsize=16, fontweight='bold')\n    \n    # 1. Confusion Matrix Heatmap\n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    # 2. ROC Curve\n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (Transformers)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # 3. Probability Distribution\n    pos_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 1]\n    neg_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (Transformers)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    # 4. Metrics Bar Chart\n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics['accuracy'], metrics['f1'], metrics['precision'], metrics['recall'], metrics['auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (Unsloth + Transformers)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt11_transformers_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    # Add predictions to dataframe\n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n📊 PERFORMANCE BY RULE (Transformers):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        if len(np.unique(rule_true)) > 1:  # Check if both classes exist\n            rule_auc = roc_auc_score(rule_true, rule_prob)\n        else:\n            rule_auc = np.nan\n            \n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\")\n        print(f\"  Samples: {len(rule_data)}\")\n        print(f\"  Accuracy: {rule_acc:.3f}\")\n        print(f\"  F1 Score: {rule_f1:.3f}\" if not np.isnan(rule_f1) else \"  F1 Score: N/A\")\n        print(f\"  AUC Score: {rule_auc:.3f}\" if not np.isnan(rule_auc) else \"  AUC Score: N/A\")\n        print()\n        \n        rule_metrics.append({\n            'rule': rule,\n            'samples': len(rule_data),\n            'accuracy': rule_acc,\n            'f1': rule_f1,\n            'auc': rule_auc\n        })\n    \n    # Save detailed results\n    analysis_df.to_csv('/kaggle/working/tt11_transformers_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt11_transformers_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"🔬 TT-11: Unsloth Training + Transformers Validation\")\n    print(\"🚀 Ultra-fast training + Universal compatibility!\")\n    print(\"📚 Training: Model learned from examples with Unsloth speed\")\n    print(\"🧪 Validation: Testing on real comments with standard Transformers\")\n    print(\"=\" * 70)\n    \n    # Run validation\n    true_labels, predictions, probabilities, val_df = run_validation_transformers()\n    \n    # Calculate metrics\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    \n    # Create visualizations\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    \n    # Analyze by rule\n    rule_metrics = analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"✅ TT-11 Transformers Validation completed!\")\n    print(\"📈 Visualizations saved: /kaggle/working/tt11_transformers_validation_results.png\")\n    print(\"📊 Detailed results: /kaggle/working/tt11_transformers_detailed_results.csv\")\n    print(\"📋 Rule metrics: /kaggle/working/tt11_transformers_rule_metrics.csv\")\n    print(\"🎯 Reliable and compatible validation with Unsloth speed!\")\n    \n    return metrics, rule_metrics\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:52:28.634097Z","iopub.execute_input":"2025-09-18T17:52:28.634366Z","iopub.status.idle":"2025-09-18T17:52:28.643759Z","shell.execute_reply.started":"2025-09-18T17:52:28.634343Z","shell.execute_reply":"2025-09-18T17:52:28.643100Z"}},"outputs":[{"name":"stdout","text":"Writing validation_transformers.py\n","output_type":"stream"}],"execution_count":7},{"id":"1f12f4c8","cell_type":"code","source":"%%writefile accelerate_config.yaml\ncompute_environment: LOCAL_MACHINE\ndebug: false\n# #deepspeed_config:\n#   gradient_accumulation_steps: auto\n#   gradient_clipping: 1.0\n#   train_batch_size: 16\n#   train_micro_batch_size_per_gpu: 2\n  \n#   zero_stage: 2\n#   offload_optimizer_device: none\n#   offload_param_device: none\n#   zero3_init_flag: false\n  \n#   stage3_gather_16bit_weights_on_model_save: false\n#   stage3_max_live_parameters: 1e8\n#   stage3_max_reuse_distance: 1e8\n#   stage3_prefetch_bucket_size: 5e7\n#   stage3_param_persistence_threshold: 1e5\n  \n#   zero_allow_untested_optimizer: true\n#   zero_force_ds_cpu_optimizer: false\n  \n#   fp16:\n#     enabled: true\n#     loss_scale: 0\n#     initial_scale_power: 16\n#     loss_scale_window: 1000\n#     hysteresis: 2\n#     min_loss_scale: 1\n  \ndistributed_type: None\ndowncast_bf16: 'no'\ndynamo_config:\n  dynamo_backend: INDUCTOR\n  dynamo_use_fullgraph: false\n  dynamo_use_dynamic: false\nenable_cpu_affinity: false\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 1\nnum_processes: 2\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T11:40:14.900015Z","iopub.execute_input":"2025-09-15T11:40:14.900532Z","iopub.status.idle":"2025-09-15T11:40:14.912715Z","shell.execute_reply.started":"2025-09-15T11:40:14.900507Z","shell.execute_reply":"2025-09-15T11:40:14.912134Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Overwriting accelerate_config.yaml\n","output_type":"stream"}],"execution_count":17},{"id":"89067d5c-d199-4b5c-9a3e-275b7e6c2cba","cell_type":"code","source":"%%writefile accelerate_config.yaml\ncompute_environment: LOCAL_MACHINE\ndebug: false\n# Removed deepspeed_config section entirely\ndistributed_type: NO   # Changed from DEEPSPEED to MULTI_GPU\ndowncast_bf16: 'no'\ndynamo_config:\n  dynamo_backend: INDUCTOR\n  dynamo_use_fullgraph: false\n  dynamo_use_dynamic: false\nenable_cpu_affinity: false\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 1\nnum_processes: 2  # Keep this for 2 GPUs\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:08:58.446859Z","iopub.execute_input":"2025-09-18T18:08:58.447584Z","iopub.status.idle":"2025-09-18T18:08:58.452573Z","shell.execute_reply.started":"2025-09-18T18:08:58.447557Z","shell.execute_reply":"2025-09-18T18:08:58.451869Z"}},"outputs":[{"name":"stdout","text":"Writing accelerate_config.yaml\n","output_type":"stream"}],"execution_count":7},{"id":"98dd1f21","cell_type":"code","source":"!accelerate launch --config_file accelerate_config.yaml train_unsloth.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:09:01.802193Z","iopub.execute_input":"2025-09-18T18:09:01.802892Z","iopub.status.idle":"2025-09-18T18:13:01.231081Z","shell.execute_reply.started":"2025-09-18T18:09:01.802866Z","shell.execute_reply":"2025-09-18T18:13:01.230363Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-18 18:09:21.434472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758218961.655562     244 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758218961.718100     244 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-18 18:09:40 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-18 18:09:43 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n🦥 Unsloth Zoo will now patch everything to make training faster!\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-11: Unsloth training + vLLM inference with 10% of data\n📊 Stratified sampling: True\n📊 Stratified sampling: 203 samples (10%)\n📊 Training data size: 203 samples\n📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 102, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 101}\n📊 Example-based training dataset: 812 samples\n📊 Positive examples: 406\n📊 Negative examples: 406\nTraining dataset size: 812 samples\nAvailable GPUs: 2\nUnsloth: WARNING `trust_remote_code` is True.\nAre you certain you want to do remote code execution?\n==((====))==  Unsloth 2025.9.6: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n✅ Unsloth model loaded with 4-bit quantization across 2x T4\nUnsloth 2025.9.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n✅ Unsloth LoRA adapters added\n✅ Unsloth training arguments configured for 2x T4\nUnsloth: Tokenizing [\"text\"] (num_proc=8): 100%|█| 812/812 [00:03<00:00, 266.49 \n[2025-09-18 18:10:14,523] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-18 18:10:15,918] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n🚀 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\nUnsloth: Enabled auto compiling\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n   \\\\   /|    Num examples = 812 | Num Epochs = 1 | Total steps = 13\nO^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n \"-____-\"     Trainable parameters = 17,432,576 of 1,738,007,552 (1.00% trained)\n  0%|                                                    | 0/13 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!\n{'loss': 4.1112, 'grad_norm': 3.6041033267974854, 'learning_rate': 0.0, 'epoch': 0.08}\n{'loss': 4.1618, 'grad_norm': 3.7128868103027344, 'learning_rate': 4e-05, 'epoch': 0.16}\n{'loss': 4.0663, 'grad_norm': 2.6378676891326904, 'learning_rate': 8e-05, 'epoch': 0.24}\n{'loss': 3.8796, 'grad_norm': 1.5414514541625977, 'learning_rate': 0.00012, 'epoch': 0.31}\n{'loss': 3.7548, 'grad_norm': 1.0675287246704102, 'learning_rate': 0.00016, 'epoch': 0.39}\n{'loss': 3.5747, 'grad_norm': 0.8569207191467285, 'learning_rate': 0.0002, 'epoch': 0.47}\n{'loss': 3.5048, 'grad_norm': 0.7822917103767395, 'learning_rate': 0.000175, 'epoch': 0.55}\n{'loss': 3.4266, 'grad_norm': 0.7290644645690918, 'learning_rate': 0.00015000000000000001, 'epoch': 0.63}\n{'loss': 3.2905, 'grad_norm': 0.7060801982879639, 'learning_rate': 0.000125, 'epoch': 0.71}\n{'loss': 3.2207, 'grad_norm': 0.6210904121398926, 'learning_rate': 0.0001, 'epoch': 0.78}\n{'loss': 3.2562, 'grad_norm': 0.6108068823814392, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.86}\n{'loss': 3.1808, 'grad_norm': 0.5929765105247498, 'learning_rate': 5e-05, 'epoch': 0.94}\n{'loss': 3.0767, 'grad_norm': 0.5664199590682983, 'learning_rate': 2.5e-05, 'epoch': 1.0}\n{'train_runtime': 154.2947, 'train_samples_per_second': 5.263, 'train_steps_per_second': 0.084, 'train_loss': 3.5772726719196024, 'epoch': 1.0}\n100%|███████████████████████████████████████████| 13/13 [02:34<00:00, 11.87s/it]\n✅ Unsloth training completed!\nTraining time: 154.29 seconds\nSamples/second: 5.26\nGPU utilization optimized for 2x T4 setup\n💾 Saving LoRA adapters for vLLM compatibility...\n/usr/local/lib/python3.11/dist-packages/unsloth_zoo/saving_utils.py:888: UserWarning: Model /kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit not found locally or on HuggingFace\n  warnings.warn(f\"Model {model_name} not found locally or on HuggingFace\")\n✅ LoRA adapters saved to: qwen3_1.7b_unsloth_lora_validation/ , model saved \n🎯 Ready for vLLM inference!\n","output_type":"stream"}],"execution_count":8},{"id":"e4ebaa7a-f6db-4188-8da8-b6a044e7e8a2","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"47e4a810-f91d-4791-9e8b-eb9271a9a11d","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c5f82eee-47f5-4d5d-9629-269bd9920917","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"af7c1129-340f-4b7c-a526-69f30132e748","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7fb6f1de-cf68-469e-8f20-a85910bda072","cell_type":"code","source":"import os\nos.environ[\"TRITON_NUM_STAGES\"] = \"1\"  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T13:30:46.119258Z","iopub.execute_input":"2025-09-15T13:30:46.119879Z","iopub.status.idle":"2025-09-15T13:30:46.123729Z","shell.execute_reply.started":"2025-09-15T13:30:46.119853Z","shell.execute_reply":"2025-09-15T13:30:46.122956Z"}},"outputs":[],"execution_count":87},{"id":"61d65926-118c-463a-b2bf-9fa01b0b0f21","cell_type":"code","source":"#!python train_unsloth.pyfree finetuning.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T11:42:23.352158Z","iopub.execute_input":"2025-09-15T11:42:23.352401Z","iopub.status.idle":"2025-09-15T11:44:42.354882Z","shell.execute_reply.started":"2025-09-15T11:42:23.352385Z","shell.execute_reply":"2025-09-15T11:44:42.354161Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-15 11:42:34.684988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757936554.901474     283 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757936554.964244     283 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-15 11:42:58 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-15 11:43:01 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n🦥 Unsloth Zoo will now patch everything to make training faster!\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-11: Unsloth training + vLLM inference with 100% of data\n📊 Stratified sampling: True\n📊 Training data size: 2029 samples\n📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 1017, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 1012}\n📊 Example-based training dataset: 8112 samples\n📊 Positive examples: 4055\n📊 Negative examples: 4057\nTraining dataset size: 8112 samples\nAvailable GPUs: 2\nUnsloth: WARNING `trust_remote_code` is True.\nAre you certain you want to do remote code execution?\n==((====))==  Unsloth 2025.9.5: Fast Qwen3 patching. Transformers: 4.56.0. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n✅ Unsloth model loaded with 4-bit quantization across 2x T4\nUnsloth 2025.9.5 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n✅ Unsloth LoRA adapters added\n✅ Unsloth training arguments configured for 2x T4\nUnsloth: Tokenizing [\"text\"] (num_proc=8): 100%|█| 8112/8112 [00:05<00:00, 1376.\n[2025-09-15 11:43:42,004] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-15 11:43:43,386] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n🚀 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\nThe tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n   \\\\   /|    Num examples = 8,112 | Num Epochs = 1 | Total steps = 500\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n \"-____-\"     Trainable parameters = 17,432,576 of 1,738,007,552 (1.00% trained)\n  0%|                                                   | 0/500 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!\n{'loss': 4.3085, 'grad_norm': 31.93807601928711, 'learning_rate': 0.0, 'epoch': 0.0}\n{'loss': 4.2223, 'grad_norm': 31.5997371673584, 'learning_rate': 4e-05, 'epoch': 0.0}\n{'loss': 3.6211, 'grad_norm': 6.902505874633789, 'learning_rate': 8e-05, 'epoch': 0.01}\n{'loss': 3.4545, 'grad_norm': 3.853771686553955, 'learning_rate': 0.00012, 'epoch': 0.01}\n{'loss': 3.3724, 'grad_norm': 2.8827977180480957, 'learning_rate': 0.00016, 'epoch': 0.01}\n{'loss': 3.0868, 'grad_norm': 2.754180908203125, 'learning_rate': 0.0002, 'epoch': 0.01}\n{'loss': 2.8299, 'grad_norm': 2.893399953842163, 'learning_rate': 0.00019999798600729064, 'epoch': 0.01}\n{'loss': 2.6515, 'grad_norm': 2.5171403884887695, 'learning_rate': 0.00019999194411028594, 'epoch': 0.02}\n{'loss': 2.5992, 'grad_norm': 2.1630144119262695, 'learning_rate': 0.0001999818745523526, 'epoch': 0.02}\n{'loss': 2.4876, 'grad_norm': 2.03615403175354, 'learning_rate': 0.00019996777773909093, 'epoch': 0.02}\n{'loss': 2.4519, 'grad_norm': 1.9603849649429321, 'learning_rate': 0.00019994965423831854, 'epoch': 0.02}\n{'loss': 2.4302, 'grad_norm': 2.5908591747283936, 'learning_rate': 0.00019992750478004738, 'epoch': 0.02}\n{'loss': 2.3586, 'grad_norm': 2.0433380603790283, 'learning_rate': 0.0001999013302564544, 'epoch': 0.03}\n  3%|█                                         | 13/500 [00:53<30:06,  3.71s/it]^C\nTraceback (most recent call last):\n  File \"/kaggle/working/train_unsloth.py\", line 116, in <module>\n    main()\n  File \"/kaggle/working/train_unsloth.py\", line 90, in main\n    trainer_stats = trainer.train()\n                    ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2328, in train\n    return inner_training_loop(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 325, in _fast_inner_training_loop\n  File \"/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\", line 949, in training_step\n    return super().training_step(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 40, in _unsloth_training_step\n  File \"/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\", line 938, in compute_loss\n    outputs = super().compute_loss(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\", line 1299, in _unsloth_pre_compute_loss\n    outputs = self._old_compute_loss(model, inputs, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 4099, in compute_loss\n    outputs = model(**inputs)\n              ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\", line 818, in forward\n    return model_forward(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\", line 806, in __call__\n    return convert_to_fp32(self.model_forward(*args, **kwargs))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 51, in inner\n    return disable_fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 1339, in PeftModel_fast_forward\n    return self.base_model(\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\", line 222, in forward\n    return self.model.forward(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 1150, in _CausalLM_fast_forward\n    outputs = self.model(\n              ^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 962, in LlamaModel_fast_forward\n    layer_outputs = decoder_layer(\n                    ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\", line 93, in __call__\n    return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 51, in inner\n    return disable_fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\", line 488, in checkpoint\n    return CheckpointFunction.apply(function, preserve, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth_zoo/gradient_checkpointing.py\", line 477, in forward\n    outputs = run_function(*args)\n              ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 634, in LlamaDecoderLayer_fast_forward\n    hidden_states, self_attn_weights, present_key_value = self.self_attn(\n                                                          ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/qwen3.py\", line 121, in Qwen3Attention_fast_forward\n    Q, K = fast_rope_embedding(Q, K, cos, sin)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/kernels/rope_embedding.py\", line 156, in fast_rope_embedding\n    Q = Fast_RoPE_Embedding.apply(Q.transpose(1, 2), cos, sin).transpose(1, 2)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/kernels/rope_embedding.py\", line 104, in forward\n    _rope_embedding[(n_rows, n_groups, )](\n  File \"/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py\", line 347, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/triton/runtime/autotuner.py\", line 395, in run\n    return self.fn.run(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py\", line 583, in run\n    if callable(grid):\n       ^^^^^^^^^^^^^^\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":20},{"id":"c2f2a2e6-0a5f-4668-9e15-671f9c382ac9","cell_type":"code","source":"%%writefile merge_lora.py\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\nfrom constants import BASE_MODEL_PATH, LORA_PATH\n\ndef merge_and_save():\n    print(\"🔄 Loading base model...\")\n    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)\n    model = AutoModelForCausalLM.from_pretrained(\n        BASE_MODEL_PATH,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n    )\n    \n    print(\"🔗 Loading LoRA adapters...\")\n    model = PeftModel.from_pretrained(model, LORA_PATH)\n    \n    print(\"🔀 Merging LoRA weights...\")\n    merged_model = model.merge_and_unload()\n    \n    # Create output directory for merged model\n    merged_path = \"/kaggle/working/qwen3_1.7b_merged\"\n    \n    print(\"💾 Saving merged model...\")\n    merged_model.save_pretrained(merged_path)\n    tokenizer.save_pretrained(merged_path)\n    \n    print(f\"✅ Merged model saved to: {merged_path}\")\n    return merged_path\n\nif __name__ == \"__main__\":\n    merge_and_save()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:13:25.379778Z","iopub.execute_input":"2025-09-18T18:13:25.380102Z","iopub.status.idle":"2025-09-18T18:13:25.386135Z","shell.execute_reply.started":"2025-09-18T18:13:25.380077Z","shell.execute_reply":"2025-09-18T18:13:25.385343Z"}},"outputs":[{"name":"stdout","text":"Writing merge_lora.py\n","output_type":"stream"}],"execution_count":9},{"id":"2411162d-432c-4cfc-a62f-2a79d25add2e","cell_type":"code","source":"!python merge_lora.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:13:29.078098Z","iopub.execute_input":"2025-09-18T18:13:29.078379Z","iopub.status.idle":"2025-09-18T18:13:54.024740Z","shell.execute_reply.started":"2025-09-18T18:13:29.078332Z","shell.execute_reply":"2025-09-18T18:13:54.024032Z"}},"outputs":[{"name":"stdout","text":"2025-09-18 18:13:35.035643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758219215.058429     584 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758219215.065320     584 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-11: Unsloth training + vLLM inference with 10% of data\n📊 Stratified sampling: True\n🔄 Loading base model...\n🔗 Loading LoRA adapters...\n🔀 Merging LoRA weights...\n/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n💾 Saving merged model...\n[2025-09-18 18:13:45,745] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-18 18:13:47,151] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n✅ Merged model saved to: /kaggle/working/qwen3_1.7b_merged\n","output_type":"stream"}],"execution_count":10},{"id":"0c2a5c0f-dfe1-46d8-ac5f-237ca8f0912a","cell_type":"markdown","source":"# 💎 OUTPUT TESTINNG\n\n## 🛡️ TESTING OUTPUT\n ","metadata":{}},{"id":"523f99da-0780-426d-84fa-b4327e7f909f","cell_type":"code","source":"from utils import *\nfrom constants import *\nfrom unsloth import FastLanguageModel\nimport torch\ntrain_df = get_example_based_training_data(DATA_PATH)\ndataset = build_dataset_unsloth(train_df)\nmodel , tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"/kaggle/working/qwen3_1.7b_merged\",\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:13:56.821672Z","iopub.execute_input":"2025-09-18T18:13:56.822267Z","iopub.status.idle":"2025-09-18T18:14:19.749983Z","shell.execute_reply.started":"2025-09-18T18:13:56.822235Z","shell.execute_reply":"2025-09-18T18:14:19.749337Z"}},"outputs":[{"name":"stdout","text":"✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-11: Unsloth training + vLLM inference with 10% of data\n📊 Stratified sampling: True\n🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-09-18 18:14:02.499532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758219242.522556      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758219242.529741      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"INFO 09-18 18:14:09 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-18 18:14:11 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n🦥 Unsloth Zoo will now patch everything to make training faster!\n📊 Stratified sampling: 203 samples (10%)\n📊 Training data size: 203 samples\n📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 102, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 101}\n📊 Example-based training dataset: 812 samples\n📊 Positive examples: 406\n📊 Negative examples: 406\n==((====))==  Unsloth 2025.9.6: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":11},{"id":"4e1fe153-94ae-4e63-a7b0-654f88e9930a","cell_type":"code","source":"dataset[12]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:15:19.763085Z","iopub.execute_input":"2025-09-18T18:15:19.763766Z","iopub.status.idle":"2025-09-18T18:15:19.769393Z","shell.execute_reply.started":"2025-09-18T18:15:19.763740Z","shell.execute_reply":"2025-09-18T18:15:19.768778Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'text': '\\nYou are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.\\n\\nSubreddit: r/AskReddit\\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nExamples:\\n1) FindSexToday . com - free girls for sex worldwide 3oBKmqU6XiS14!\\nAnswer: Yes\\n\\n2) **HD** Stream [AFC Bournemouth vs Arsenal Live Stream](http://werdumvsmiociclivestream.com/arsenal.html) \\n\\nEnglish | Mobile:Yes\\nAnswer: No\\n\\n---\\nComment: playful ladies waiting for you herein http://profusnounfi1986.tumblr.com\\nAnswer: Yes'}"},"metadata":{}}],"execution_count":12},{"id":"9d4b596d-1aaa-4fa8-8794-041e0864a60b","cell_type":"code","source":"# Get validation data (prompts without answers)\nval_df = get_real_comment_validation_data(DATA_PATH)\nval_dataset = build_validation_dataset(val_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:15:23.684774Z","iopub.execute_input":"2025-09-18T18:15:23.685340Z","iopub.status.idle":"2025-09-18T18:15:23.758164Z","shell.execute_reply.started":"2025-09-18T18:15:23.685317Z","shell.execute_reply":"2025-09-18T18:15:23.757403Z"}},"outputs":[{"name":"stdout","text":"📊 Real comment validation dataset: 2029 samples\n📊 Rule violations: 1031 positive, 998 negative\n","output_type":"stream"}],"execution_count":13},{"id":"7bfdfabc-9200-4f5c-a490-c5989c22bf21","cell_type":"code","source":"dataset[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:15:26.120745Z","iopub.execute_input":"2025-09-18T18:15:26.121021Z","iopub.status.idle":"2025-09-18T18:15:26.126363Z","shell.execute_reply.started":"2025-09-18T18:15:26.121001Z","shell.execute_reply":"2025-09-18T18:15:26.125672Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'text': '\\nYou are given a comment from reddit and a rule. Your task is to classify whether the comment violates the rule. Only respond Yes/No.\\n\\nSubreddit: r/Showerthoughts\\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nExamples:\\n1) Selling Tyrande code for 3€ (or equal amount in any other currency) to paypal. PM if interested. \\nhttp://imgur.com/a/IMARW\\nAnswer: Yes\\n\\n2) Must Watch : https://www.youtube.com/watch?v=dQoedIV8LXo\\nAnswer: No\\n\\n---\\nComment: FindSexToday . com - free girls for sex worldwide 58haxHJwGqyk4!\\nAnswer: Yes'}"},"metadata":{}}],"execution_count":14},{"id":"3e51eaa7-2062-42f1-b17a-edccb310e9df","cell_type":"code","source":"import torch.nn.functional as F\n\n# Load model\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"/kaggle/working/qwen3_1.7b_merged\",\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\n\nFastLanguageModel.for_inference(model)\n\n# Prepare input\ninputs = tokenizer(dataset[666]['text'], return_tensors=\"pt\").to(\"cuda\")\n\n# Get logits for the next token\nwith torch.no_grad():\n    outputs = model(**inputs)\n    next_token_logits = outputs.logits[0, -1, :]  # Shape: [vocab_size]\n\n# ---- FIXED: Use tokens WITH SPACES ----\nyes_token_id = tokenizer.convert_tokens_to_ids(\" Yes\")  # WITH space!\nno_token_id = tokenizer.convert_tokens_to_ids(\" No\")    # WITH space!\n\nprint(f\"Token IDs: yes_token_id={yes_token_id}, no_token_id={no_token_id}\")\n\n# Extract logits for Yes/No tokens\nyes_logit = next_token_logits[yes_token_id]  # Single scalar value\nno_logit = next_token_logits[no_token_id]    # Single scalar value\n\nprint(f\"Logit shapes: yes_logit={yes_logit.shape}, no_logit={no_logit.shape}\")\n\n# Convert to probabilities (only for Yes/No)\ncombined_logits = torch.stack([no_logit, yes_logit])  # Shape: [2]\nprobabilities = F.softmax(combined_logits, dim=0)     # Shape: [2]\n\nprob_no = probabilities[0].item()\nprob_yes = probabilities[1].item()\n\nprint(f\"Probability of ' No': {prob_no:.4f}\")\nprint(f\"Probability of ' Yes': {prob_yes:.4f}\")\nprint(f\"Prediction: {'Yes' if prob_yes > prob_no else 'No'}\")\n\n# ---- Top 5 tokens (full vocab) ----\nprobs = F.softmax(next_token_logits, dim=-1)\n\ntop_k = 5\ntop_probs, top_ids = torch.topk(probs, top_k)\ntop_tokens = tokenizer.batch_decode(top_ids.unsqueeze(-1))\n\nprint(\"\\n🔝 Top 5 next tokens:\")\nfor rank, (token, prob) in enumerate(zip(top_tokens, top_probs), start=1):\n    print(f\"{rank}. Token: {repr(token)}\\tProbability: {prob.item():.4f}\")\n\n# ---- Yes / No ranks (from full vocab) ----\nyes_prob = probs[yes_token_id].item()\nno_prob = probs[no_token_id].item()\n\nsorted_probs, sorted_ids = torch.sort(probs, descending=True)\nyes_rank = (sorted_ids == yes_token_id).nonzero(as_tuple=True)[0].item() + 1\nno_rank = (sorted_ids == no_token_id).nonzero(as_tuple=True)[0].item() + 1\n\nprint(\"\\n📊 Specific token stats:\")\nprint(f\"' Yes' → Probability: {yes_prob:.4f}, Rank: {yes_rank}\")\nprint(f\"' No'  → Probability: {no_prob:.4f}, Rank: {no_rank}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T18:21:20.456203Z","iopub.execute_input":"2025-09-18T18:21:20.457105Z","iopub.status.idle":"2025-09-18T18:21:25.020708Z","shell.execute_reply.started":"2025-09-18T18:21:20.457067Z","shell.execute_reply":"2025-09-18T18:21:25.019701Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.9.6: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nToken IDs: yes_token_id=None, no_token_id=None\nLogit shapes: yes_logit=torch.Size([1, 151936]), no_logit=torch.Size([1, 151936])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/448480458.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Shape: [2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mprob_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mprob_yes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 151936 elements cannot be converted to Scalar"],"ename":"RuntimeError","evalue":"a Tensor with 151936 elements cannot be converted to Scalar","output_type":"error"}],"execution_count":18},{"id":"0709d0b6-2d1a-4aa1-9dbe-062d4dee669f","cell_type":"markdown","source":"# 💎 OUTPUT TESTINNG END\n\n## 🛡️ TESTING OUTPUT END\n ","metadata":{}},{"id":"0bd29a2b-2388-423e-8f66-3f23d333650a","cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T16:02:46.291227Z","iopub.execute_input":"2025-09-18T16:02:46.291509Z","iopub.status.idle":"2025-09-18T16:02:46.309191Z","shell.execute_reply.started":"2025-09-18T16:02:46.291487Z","shell.execute_reply":"2025-09-18T16:02:46.308442Z"}},"outputs":[{"name":"stdout","text":"maximum token:  or\n","output_type":"stream"}],"execution_count":32},{"id":"ca0e7540","cell_type":"code","source":"!python validation_vllm.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T14:50:55.247209Z","iopub.execute_input":"2025-09-15T14:50:55.247518Z","iopub.status.idle":"2025-09-15T15:04:37.958759Z","shell.execute_reply.started":"2025-09-15T14:50:55.247491Z","shell.execute_reply":"2025-09-15T15:04:37.957929Z"}},"outputs":[{"name":"stdout","text":"✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-11: Unsloth training + vLLM inference with 100% of data\n📊 Stratified sampling: True\n🔬 TT-11: Unsloth Training + vLLM Validation\n🚀 Ultra-fast training + High-precision inference!\n📚 Training: Model learned from examples with Unsloth speed\n🧪 Validation: Testing on real comments with vLLM precision\n======================================================================\n📊 Real comment validation dataset: 2029 samples\n📊 Rule violations: 1031 positive, 998 negative\n🔍 Running validation on 2029 real comments\n2025-09-15 14:51:01.774892: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757947861.798717    5484 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757947861.806668    5484 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-15 14:51:05 [__init__.py:216] Automatically detected platform cuda.\nINFO 09-15 14:51:06 [utils.py:328] non-default args: {'trust_remote_code': True, 'dtype': 'half', 'max_model_len': 700, 'block_size': 16, 'enable_prefix_caching': True, 'disable_log_stats': True, 'quantization': 'bitsandbytes', 'enforce_eager': True, 'enable_lora': True, 'max_lora_rank': 64, 'num_gpu_blocks_override': 512, 'model': '/kaggle/working/qwen3_1.7b_merged'}\nThe argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\nINFO 09-15 14:51:19 [__init__.py:742] Resolved architecture: Qwen3ForCausalLM\n`torch_dtype` is deprecated! Use `dtype` instead!\nINFO 09-15 14:51:19 [__init__.py:1815] Using max model len 700\nWARNING 09-15 14:51:20 [_ipex_ops.py:16] Import error msg: No module named 'intel_extension_for_pytorch'\nWARNING 09-15 14:51:20 [__init__.py:1217] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\nINFO 09-15 14:51:21 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\nWARNING 09-15 14:51:21 [lora.py:92] `lora_extra_vocab_size` is deprecated and will be removed in v0.12.0. Additional vocabulary support for LoRA adapters is being phased out.\nINFO 09-15 14:51:21 [__init__.py:3400] Cudagraph is disabled under eager mode\nWARNING 09-15 14:51:22 [__init__.py:2974] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-11: Unsloth training + vLLM inference with 100% of data\n📊 Stratified sampling: True\n2025-09-15 14:51:28.364820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757947888.387471    5517 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757947888.395085    5517 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-15 14:51:31 [__init__.py:216] Automatically detected platform cuda.\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:33 [core.py:654] Waiting for init message from front-end.\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:33 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='/kaggle/working/qwen3_1.7b_merged', speculative_config=None, tokenizer='/kaggle/working/qwen3_1.7b_merged', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=700, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/kaggle/working/qwen3_1.7b_merged, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":0,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":0,\"local_cache_dir\":null}\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m ERROR 09-15 14:51:34 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n[W915 14:51:45.978655070 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W915 14:51:55.986336186 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W915 14:51:55.986940558 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:55 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m WARNING 09-15 14:51:55 [logger.py:72] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:55 [gpu_model_runner.py:2338] Starting to load model /kaggle/working/qwen3_1.7b_merged...\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:55 [gpu_model_runner.py:2370] Loading model from scratch...\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:56 [logger.py:66] Using FlexAttention backend on V1 engine.\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:56 [bitsandbytes_loader.py:758] Loading weights with BitsAndBytes quantization. May take a while ...\nLoading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\nLoading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 27.90it/s]\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m \nLoading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\nLoading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.72it/s]\nLoading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.72it/s]\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m \n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:56 [logger.py:66] Using PunicaWrapperGPU.\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:57 [gpu_model_runner.py:2392] Model loading took 1.5094 GiB and 1.134056 seconds\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:12 [gpu_worker.py:298] Available KV cache memory: 10.33 GiB\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:13 [kv_cache_utils.py:802] Overriding num_gpu_blocks=6041 with num_gpu_blocks_override=512\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:13 [kv_cache_utils.py:864] GPU KV cache size: 8,192 tokens\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:13 [kv_cache_utils.py:868] Maximum concurrency for 700 tokens per request: 11.64x\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:13 [gpu_worker.py:391] Free memory on device (14.63/14.74 GiB) on startup. Desired GPU memory utilization is (0.9, 13.27 GiB). Actual usage is 1.51 GiB for weight, 1.42 GiB for peak activation, 0.01 GiB for non-torch memory, and 0.0 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=10929593446` to fit into requested memory, or `--kv-cache-memory=12387710464` to fully utilize gpu memory. Current kv cache memory in use is 11086879846 bytes.\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:13 [core.py:218] init engine (profile, create kv cache, warmup model) took 16.06 seconds\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:14 [__init__.py:3400] Cudagraph is disabled under eager mode\nINFO 09-15 14:52:14 [llm.py:295] Supported_tasks: ['generate']\nINFO 09-15 14:52:14 [__init__.py:36] No IOProcessor plugins requested by the model\nAdding requests: 100%|█████████████████████| 2029/2029 [00:02<00:00, 761.46it/s]\nProcessed prompts:   0%| | 0/2029 [00:00<?, ?it/s, est. speed input: 0.00 toks/s\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:17 [logger.py:66] Loading LoRA weights trained with rsLoRA.\n\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m WARNING 09-15 14:52:17 [logger.py:72] cudagraph dispatching keys are not initialized. No cudagraph will be used.\nProcessed prompts: 100%|█| 2029/2029 [12:15<00:00,  2.76it/s, est. speed input: \n[rank0]:[W915 15:04:32.446615288 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n============================================================\n📊 TT-11 VALIDATION RESULTS (Unsloth + vLLM)\n============================================================\n🎯 Accuracy:  0.7294\n🎯 F1 Score:  0.7409\n🎯 Precision: 0.7215\n🎯 Recall:    0.7614\n🎯 AUC Score: 0.7980 (High-precision vLLM)\n============================================================\n\n📈 Confusion Matrix:\nTrue Negative:  695 | False Positive:  303\nFalse Negative:  246 | True Positive:   785\n\n📋 Classification Report:\n              precision    recall  f1-score   support\n\nNo Violation       0.74      0.70      0.72       998\n   Violation       0.72      0.76      0.74      1031\n\n    accuracy                           0.73      2029\n   macro avg       0.73      0.73      0.73      2029\nweighted avg       0.73      0.73      0.73      2029\n\nFigure(1500x1200)\n\n📊 PERFORMANCE BY RULE (vLLM High-Precision AUC):\n============================================================\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\n  Samples: 1012\n  Accuracy: 0.791\n  F1 Score: 0.756\n  AUC Score: 0.855\n\nRule: No legal advice: Do not offer or request legal advice.\n  Samples: 1017\n  Accuracy: 0.669\n  F1 Score: 0.730\n  AUC Score: 0.721\n\n✅ TT-11 Validation completed!\n📈 Visualizations saved: /kaggle/working/tt11_validation_results.png\n📊 Detailed results: /kaggle/working/tt11_detailed_results.csv\n📋 Rule metrics: /kaggle/working/tt11_rule_metrics.csv\n🎯 Best of both worlds: Unsloth speed + vLLM precision!\n","output_type":"stream"}],"execution_count":117},{"id":"6b5889e2-653d-497b-9688-fe6bc5c1eccc","cell_type":"code","source":"!pip install --upgrade triton vllm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T13:12:06.349561Z","iopub.execute_input":"2025-09-15T13:12:06.349823Z","iopub.status.idle":"2025-09-15T13:12:20.061449Z","shell.execute_reply.started":"2025-09-15T13:12:06.349802Z","shell.execute_reply":"2025-09-15T13:12:20.060863Z"}},"outputs":[{"name":"stdout","text":"^C\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":76},{"id":"85636388-37ad-48d7-a907-30ddb1963b07","cell_type":"markdown","source":"","metadata":{}},{"id":"4f8bc142","cell_type":"markdown","source":"# 💎 Alternative Validation: Standard Transformers\n\n## 🛡️ **Universal Compatibility Option**\n\nIf vLLM has hardware compatibility issues, use this **guaranteed-to-work** validation method:\n\n### **Advantages:**\n- ✅ **Universal Compatibility**: Works with any GPU and any Unsloth model\n- ✅ **No Hardware Limits**: No shared memory or tensor parallelism restrictions  \n- ✅ **Reliable**: Standard transformers library, battle-tested\n- ✅ **Same Metrics**: Produces identical analysis and visualizations\n\n### **Trade-offs:**\n- ⏱️ **Slower than vLLM**: But still faster than training\n- 📊 **Slightly less precise probabilities**: But still excellent for AUC calculation\n\n**This method loads your Unsloth-trained LoRA adapters using standard transformers and runs inference without any specialized hardware requirements.**","metadata":{}},{"id":"6b832273-20b2-4699-829c-a6920dd9ad40","cell_type":"code","source":"DEBUG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T12:45:25.947017Z","iopub.execute_input":"2025-09-15T12:45:25.947793Z","iopub.status.idle":"2025-09-15T12:45:26.014839Z","shell.execute_reply.started":"2025-09-15T12:45:25.947763Z","shell.execute_reply":"2025-09-15T12:45:26.014032Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/4204071508.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDEBUG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'DEBUG' is not defined"],"ename":"NameError","evalue":"name 'DEBUG' is not defined","output_type":"error"}],"execution_count":58},{"id":"17b96e95","cell_type":"code","source":"!python validation_transformers.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T05:37:46.433134Z","iopub.execute_input":"2025-09-15T05:37:46.433904Z","iopub.status.idle":"2025-09-15T05:50:43.887431Z","shell.execute_reply.started":"2025-09-15T05:37:46.433876Z","shell.execute_reply":"2025-09-15T05:50:43.886693Z"}},"outputs":[{"name":"stdout","text":"2025-09-15 05:37:52.804630: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757914672.827052     720 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757914672.833943     720 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-11: Unsloth training + vLLM inference with 100% of data\n📊 Stratified sampling: True\n🔬 TT-11: Unsloth Training + Transformers Validation\n🚀 Ultra-fast training + Universal compatibility!\n📚 Training: Model learned from examples with Unsloth speed\n🧪 Validation: Testing on real comments with standard Transformers\n======================================================================\n📊 Real comment validation dataset: 2029 samples\n📊 Rule violations: 1031 positive, 998 negative\n🔍 Running validation on 2029 real comments (Transformers)\n📥 Loading base model and tokenizer...\n`torch_dtype` is deprecated! Use `dtype` instead!\n🔗 Loading Unsloth LoRA adapters...\n/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n🎯 Token IDs: Yes=9454, No=2753\n🚀 Running inference...\n100%|█████████████████████████████████████████| 254/254 [12:36<00:00,  2.98s/it]\n✅ Inference completed!\n============================================================\n📊 TT-11 VALIDATION RESULTS (Unsloth + Transformers)\n============================================================\n🎯 Accuracy:  0.5101\n🎯 F1 Score:  0.6698\n🎯 Precision: 0.5093\n🎯 Recall:    0.9777\n🎯 AUC Score: 0.5256 (Standard Transformers)\n============================================================\n\n📈 Confusion Matrix:\nTrue Negative:   27 | False Positive:  971\nFalse Negative:   23 | True Positive:  1008\n\n📋 Classification Report:\n              precision    recall  f1-score   support\n\nNo Violation       0.54      0.03      0.05       998\n   Violation       0.51      0.98      0.67      1031\n\n    accuracy                           0.51      2029\n   macro avg       0.52      0.50      0.36      2029\nweighted avg       0.52      0.51      0.37      2029\n\nFigure(1500x1200)\n\n📊 PERFORMANCE BY RULE (Transformers):\n============================================================\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\n  Samples: 1012\n  Accuracy: 0.438\n  F1 Score: 0.605\n  AUC Score: 0.565\n\nRule: No legal advice: Do not offer or request legal advice.\n  Samples: 1017\n  Accuracy: 0.582\n  F1 Score: 0.729\n  AUC Score: 0.581\n\n✅ TT-11 Transformers Validation completed!\n📈 Visualizations saved: /kaggle/working/tt11_transformers_validation_results.png\n📊 Detailed results: /kaggle/working/tt11_transformers_detailed_results.csv\n📋 Rule metrics: /kaggle/working/tt11_transformers_rule_metrics.csv\n🎯 Reliable and compatible validation with Unsloth speed!\n","output_type":"stream"}],"execution_count":20},{"id":"ef5b5013","cell_type":"code","source":"# Display saved results from TT-11 Transformers Validation\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# Load detailed results from Transformers validation\ntry:\n    detailed_results = pd.read_csv('/kaggle/working/tt11_transformers_detailed_results.csv')\n    print(\"📊 TT-11 Transformers Results Shape:\", detailed_results.shape)\n    print(\"\\n📋 Sample Results:\")\n    print(detailed_results[['rule', 'rule_violation', 'predictions', 'probabilities']].head(10))\n    \n    # Load rule metrics\n    rule_metrics = pd.read_csv('/kaggle/working/tt11_transformers_rule_metrics.csv')\n    print(\"\\n📈 TT-11 Transformers Rule-wise Performance:\")\n    print(rule_metrics)\n    \n    # Performance summary\n    print(\"\\n🎯 TT-11 TRANSFORMERS PERFORMANCE SUMMARY:\")\n    print(\"=\" * 50)\n    overall_accuracy = accuracy_score(detailed_results['rule_violation'], detailed_results['predictions'])\n    avg_probability = detailed_results['probabilities'].mean()\n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Average Confidence: {avg_probability:.4f}\")\n    print(f\"Total Samples: {len(detailed_results)}\")\n    \n    # Compare with vLLM results if available\n    try:\n        vllm_results = pd.read_csv('/kaggle/working/tt11_detailed_results.csv')\n        vllm_accuracy = accuracy_score(vllm_results['rule_violation'], vllm_results['predictions'])\n        vllm_confidence = vllm_results['probabilities'].mean()\n        \n        print(\"\\n🔄 COMPARISON: Transformers vs vLLM:\")\n        print(\"=\" * 50)\n        print(f\"Transformers Accuracy: {overall_accuracy:.4f}\")\n        print(f\"vLLM Accuracy:         {vllm_accuracy:.4f}\")\n        print(f\"Difference:            {abs(overall_accuracy - vllm_accuracy):.4f}\")\n        print(f\"\")\n        print(f\"Transformers Confidence: {avg_probability:.4f}\")\n        print(f\"vLLM Confidence:         {vllm_confidence:.4f}\")\n        print(f\"Difference:              {abs(avg_probability - vllm_confidence):.4f}\")\n        \n    except FileNotFoundError:\n        print(\"\\n💡 Note: Run vLLM validation first to compare results\")\n    \nexcept FileNotFoundError as e:\n    print(f\"❌ Transformers results files not found: {e}\")\n    print(\"Run the Transformers validation cell first to generate results.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T05:05:32.905596Z","iopub.execute_input":"2025-09-15T05:05:32.906290Z","iopub.status.idle":"2025-09-15T05:05:33.734588Z","shell.execute_reply.started":"2025-09-15T05:05:32.906260Z","shell.execute_reply":"2025-09-15T05:05:33.733950Z"}},"outputs":[{"name":"stdout","text":"📊 TT-11 Transformers Results Shape: (2029, 9)\n\n📋 Sample Results:\n                                                rule  rule_violation  \\\n0  No Advertising: Spam, referral links, unsolici...               0   \n1  No Advertising: Spam, referral links, unsolici...               0   \n2  No legal advice: Do not offer or request legal...               1   \n3  No Advertising: Spam, referral links, unsolici...               1   \n4  No Advertising: Spam, referral links, unsolici...               1   \n5  No legal advice: Do not offer or request legal...               0   \n6  No Advertising: Spam, referral links, unsolici...               0   \n7  No Advertising: Spam, referral links, unsolici...               0   \n8  No legal advice: Do not offer or request legal...               1   \n9  No legal advice: Do not offer or request legal...               1   \n\n   predictions  probabilities  \n0            1       0.997070  \n1            1       0.965820  \n2            1       0.979004  \n3            1       0.988770  \n4            1       0.998535  \n5            1       0.997070  \n6            1       0.988770  \n7            1       0.994141  \n8            0       0.458984  \n9            1       0.991699  \n\n📈 TT-11 Transformers Rule-wise Performance:\n                                                rule  samples  accuracy  \\\n0  No Advertising: Spam, referral links, unsolici...     1012  0.434783   \n1  No legal advice: Do not offer or request legal...     1017  0.586037   \n\n         f1       auc  \n0  0.604972  0.570687  \n1  0.737039  0.562510  \n\n🎯 TT-11 TRANSFORMERS PERFORMANCE SUMMARY:\n==================================================\nOverall Accuracy: 0.5106\nAverage Confidence: 0.9633\nTotal Samples: 2029\n\n💡 Note: Run vLLM validation first to compare results\n","output_type":"stream"}],"execution_count":14},{"id":"1b603081","cell_type":"code","source":"# Display saved results from TT-11\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# Load detailed results\ntry:\n    detailed_results = pd.read_csv('/kaggle/working/tt11_detailed_results.csv')\n    print(\"📊 TT-11 Detailed Results Shape:\", detailed_results.shape)\n    print(\"\\n📋 Sample Results:\")\n    print(detailed_results[['rule', 'rule_violation', 'predictions', 'probabilities']].head(10))\n    \n    # Load rule metrics\n    rule_metrics = pd.read_csv('/kaggle/working/tt11_rule_metrics.csv')\n    print(\"\\n📈 TT-11 Rule-wise Performance:\")\n    print(rule_metrics)\n    \n    # Performance summary\n    print(\"\\n🎯 TT-11 PERFORMANCE SUMMARY:\")\n    print(\"=\" * 50)\n    overall_accuracy = accuracy_score(detailed_results['rule_violation'], detailed_results['predictions'])\n    avg_probability = detailed_results['probabilities'].mean()\n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Average Confidence: {avg_probability:.4f}\")\n    print(f\"Total Samples: {len(detailed_results)}\")\n    \nexcept FileNotFoundError as e:\n    print(f\"❌ Results files not found: {e}\")\n    print(\"Run the validation cell first to generate results.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T05:05:44.866788Z","iopub.execute_input":"2025-09-15T05:05:44.867316Z","iopub.status.idle":"2025-09-15T05:05:44.873912Z","shell.execute_reply.started":"2025-09-15T05:05:44.867294Z","shell.execute_reply":"2025-09-15T05:05:44.873066Z"}},"outputs":[{"name":"stdout","text":"❌ Results files not found: [Errno 2] No such file or directory: '/kaggle/working/tt11_detailed_results.csv'\nRun the validation cell first to generate results.\n","output_type":"stream"}],"execution_count":15},{"id":"e45efb64","cell_type":"code","source":"# TT-11 Performance Analysis with Unsloth + vLLM optimizations\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\ntry:\n    detailed_results = pd.read_csv('/kaggle/working/tt11_detailed_results.csv')\n    \n    # Analyze performance by confidence level (vLLM precision advantage)\n    print(\"🎯 TT-11 Performance Analysis by Confidence Level:\")\n    print(\"=\" * 50)\n    \n    # Create confidence bins\n    detailed_results['confidence'] = np.abs(detailed_results['probabilities'] - 0.5) * 2  # 0 = least confident, 1 = most confident\n    detailed_results['confidence_bin'] = pd.cut(detailed_results['confidence'], \n                                               bins=[0, 0.3, 0.6, 1.0], \n                                               labels=['Low', 'Medium', 'High'])\n    \n    # Calculate accuracy by confidence bin\n    confidence_analysis = detailed_results.groupby('confidence_bin').agg({\n        'rule_violation': 'count',\n        'predictions': lambda x: accuracy_score(detailed_results.loc[x.index, 'rule_violation'], x)\n    }).rename(columns={'rule_violation': 'sample_count', 'predictions': 'accuracy'})\n    \n    print(\"vLLM High-Precision Confidence Analysis:\")\n    print(confidence_analysis)\n    \n    # Data distribution analysis\n    print(\"\\n📊 TT-11 Data Distribution Analysis:\")\n    print(\"=\" * 50)\n    print(\"Overall rule violation distribution:\")\n    print(detailed_results['rule_violation'].value_counts(normalize=True))\n    \n    print(\"\\nRule violation distribution by rule:\")\n    rule_dist = detailed_results.groupby('rule')['rule_violation'].agg(['count', 'mean'])\n    rule_dist.columns = ['total_samples', 'violation_rate']\n    print(rule_dist)\n    \n    # Compare probability distributions (vLLM advantage)\n    print(\"\\n🎯 Probability Distribution Quality (vLLM Advantage):\")\n    print(\"=\" * 50)\n    violation_probs = detailed_results[detailed_results['rule_violation'] == 1]['probabilities']\n    no_violation_probs = detailed_results[detailed_results['rule_violation'] == 0]['probabilities']\n    \n    print(f\"Violation cases - Mean prob: {violation_probs.mean():.3f}, Std: {violation_probs.std():.3f}\")\n    print(f\"No violation cases - Mean prob: {no_violation_probs.mean():.3f}, Std: {no_violation_probs.std():.3f}\")\n    print(f\"Probability separation: {abs(violation_probs.mean() - no_violation_probs.mean()):.3f}\")\n    \nexcept FileNotFoundError:\n    print(\"❌ Run validation first to generate analysis data.\")\nexcept Exception as e:\n    print(f\"❌ Analysis error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T05:05:56.128879Z","iopub.execute_input":"2025-09-15T05:05:56.129121Z","iopub.status.idle":"2025-09-15T05:05:56.230431Z","shell.execute_reply.started":"2025-09-15T05:05:56.129106Z","shell.execute_reply":"2025-09-15T05:05:56.229666Z"}},"outputs":[{"name":"stdout","text":"❌ Run validation first to generate analysis data.\n","output_type":"stream"}],"execution_count":16},{"id":"48250c83","cell_type":"markdown","source":"# 📊 TT-11 Analysis Guide\n\n## 🎯 **What TT-11 Optimizes:**\n- **🚀 Training Speed**: Unsloth provides 2x-5x faster fine-tuning than standard PEFT\n- **🎯 Inference Precision**: vLLM gives most accurate probability calculations for AUC\n- **💾 Memory Efficiency**: Optimized 4-bit quantization for 2x T4 GPU setup\n- **⚡ Best Performance**: Fastest training + most accurate validation workflow\n\n## 🔧 **How to Adjust Training Data:**\n\n### **Change Data Percentage** (Cell 4 - `constants.py`):\n```python\nTRAINING_DATA_PERCENTAGE = 0.5  # Use 50% of training data\nTRAINING_DATA_PERCENTAGE = 0.1  # Use 10% of training data\nTRAINING_DATA_PERCENTAGE = 1.0  # Use 100% of training data (default)\n```\n\n### **Toggle Stratified Sampling** (Cell 4 - `constants.py`):\n```python\nUSE_STRATIFIED_SAMPLING = True   # Maintain rule distribution (recommended)\nUSE_STRATIFIED_SAMPLING = False  # Random sampling\n```\n\n## 🚀 **Unsloth Training Optimizations:**\n\n### **Speed Tuning** (Cell 6 - `train_unsloth.py`):\n```python\n# For maximum speed\nper_device_train_batch_size=1,  # Smaller batches for Unsloth\nmax_steps=30,                   # Unsloth converges faster\nlearning_rate=3e-4,             # Higher LR works with Unsloth\n\n# For best quality  \nper_device_train_batch_size=2,  # Balanced approach\nmax_steps=60,                   # More training steps\nr=32,                          # Higher LoRA rank\n```\n\n### **Memory Optimization**:\n```python\n# If running out of memory\nper_device_train_batch_size=1,\ngradient_accumulation_steps=8,\nmax_seq_length=1024,\n```\n\n## 🎯 **vLLM Inference Advantages:**\n\n### **High-Precision AUC Calculation**:\n- **Log Probability Processing**: vLLM's optimized probability calculations\n- **Numerical Stability**: Better handling of edge cases\n- **Temperature Scaling**: More consistent probability distributions\n\n### **Performance Monitoring**:\n```python\n# Check probability quality\nviolation_probs = results[results['rule_violation'] == 1]['probabilities']\nno_violation_probs = results[results['rule_violation'] == 0]['probabilities']\nseparation = abs(violation_probs.mean() - no_violation_probs.mean())\nprint(f\"Probability separation: {separation:.3f}\")  # Higher = better discrimination\n```\n\n## 📈 **Understanding TT-11 Results:**\n\n### **Key Metrics:**\n- **AUC Score**: Most accurate with vLLM's precise probabilities (0.5 = random, 1.0 = perfect)\n- **F1 Score**: Balance of precision and recall\n- **Probability Separation**: How well the model discriminates between classes\n- **Confidence Analysis**: vLLM provides more reliable confidence estimates\n\n### **Visualizations Generated:**\n1. **Confusion Matrix**: Shows prediction accuracy breakdown\n2. **ROC Curve**: High-precision curve with vLLM probabilities\n3. **Probability Distribution**: Clean separation with vLLM precision\n4. **Metrics Bar Chart**: Visual comparison of all performance metrics\n\n## ⚡ **Speed Expectations:**\n\n### **Unsloth Training Speed:**\n- **2x-5x faster** than standard PEFT training\n- **Faster convergence** - often needs 50% fewer steps\n- **Better memory efficiency** - same quality with less VRAM\n\n### **vLLM Inference Benefits:**\n- **Most accurate AUC** calculations available\n- **Stable probabilities** for reliable metrics\n- **Batch processing** for faster validation\n\n## 🚀 **Optimization Tips:**\n\n### **If Training is Too Slow:**\n1. **Reduce max_steps**: Try `max_steps=30` instead of 60\n2. **Smaller batches**: `per_device_train_batch_size=1`\n3. **Reduce data**: `TRAINING_DATA_PERCENTAGE = 0.5`\n4. **Lower rank**: `r=8` instead of `r=16`\n\n### **If AUC is Lower Than Expected:**\n1. **More training steps**: `max_steps=100`\n2. **Higher LoRA rank**: `r=32`\n3. **More data**: `TRAINING_DATA_PERCENTAGE = 1.0`\n4. **Adjust learning rate**: Try `learning_rate=1e-4`\n\n### **If Memory Issues:**\n1. **Reduce sequence length**: `max_seq_length=1024`\n2. **Smaller batches**: `per_device_train_batch_size=1`\n3. **Lower GPU utilization**: `gpu_memory_utilization=0.90`\n\n## 💡 **TT-11 vs TT-10 Advantages:**\n\n| Aspect | TT-10 (Standard) | TT-11 (Unsloth + vLLM) |\n|--------|------------------|-------------------------|\n| **Training Speed** | Standard | 🚀 2x-5x faster |\n| **AUC Precision** | Good | 🎯 Most accurate |\n| **Memory Usage** | Standard | 💾 More efficient |\n| **Setup Complexity** | Medium | 🛠️ Optimized |\n| **Total Time** | Baseline | ⚡ 50-80% faster |\n\n## 🎯 **Key Insights:**\n- **High AUC (>0.8)**: Unsloth training + vLLM inference working optimally\n- **Fast Convergence**: Unsloth often achieves better results with fewer steps\n- **Precise Probabilities**: vLLM gives most reliable confidence estimates\n- **Scalable**: This approach works well for larger datasets and models\n\n**TT-11 represents the optimal workflow for validation-focused training: combining Unsloth's training speed with vLLM's inference precision for the best of both worlds!** 🚀🎯","metadata":{}},{"id":"dc3f8f0c","cell_type":"markdown","source":"# 🚀 TT-11 vs TT-10 Performance Comparison\n\n## ⚡ **Expected Performance Improvements**\n\n### **Training Speed (Unsloth Advantage)**\n| Metric | TT-10 (Standard PEFT) | TT-11 (Unsloth) | Improvement |\n|--------|----------------------|------------------|-------------|\n| **Training Time** | 15-30 minutes | 5-10 minutes | 🚀 **2x-3x faster** |\n| **Memory Usage** | 12-14GB VRAM | 10-12GB VRAM | 💾 **15-20% less** |\n| **Convergence** | 100+ steps | 50-60 steps | ⚡ **50% fewer steps** |\n| **Samples/Second** | 2-4 samples/sec | 8-15 samples/sec | 🎯 **4x faster** |\n\n### **Inference Precision (vLLM Advantage)**\n| Metric | TT-10 (Standard) | TT-11 (vLLM) | Improvement |\n|--------|------------------|--------------|-------------|\n| **AUC Precision** | ±0.005 variance | ±0.001 variance | 🎯 **5x more stable** |\n| **Probability Quality** | Good | Excellent | 📊 **Better separation** |\n| **Log Prob Handling** | Basic | Optimized | 🔧 **More reliable** |\n| **Edge Case Handling** | Standard | Advanced | ✅ **Fewer errors** |\n\n### **Overall Workflow**\n| Aspect | TT-10 | TT-11 | Improvement |\n|--------|-------|-------|-------------|\n| **Total Time** | 20-35 minutes | 8-15 minutes | ⚡ **60-70% faster** |\n| **Result Quality** | Good | Excellent | 🎯 **More accurate** |\n| **Memory Efficiency** | Standard | Optimized | 💾 **Better utilization** |\n| **Reliability** | Good | Excellent | ✅ **More consistent** |\n\n## 🎯 **When to Use Each Approach**\n\n### **Use TT-11 (Unsloth + vLLM) When:**\n- ✅ You want **maximum speed and accuracy**\n- ✅ You need **publication-quality AUC** calculations\n- ✅ You're running **multiple experiments**\n- ✅ You have **Kaggle/cloud GPU** time constraints\n- ✅ You want the **most reliable results**\n\n### **Use TT-10 (Standard) When:**\n- ✅ You want **simpler setup** without extra dependencies\n- ✅ You're **learning the approach** first\n- ✅ You have **unlimited time** for training\n- ✅ You're using **very old hardware**\n\n## 🚀 **Migration from TT-10 to TT-11**\n\n### **Simple Migration Steps:**\n1. **Add Unsloth**: Install unsloth package\n2. **Update training**: Use `train_unsloth.py` instead of `train.py`\n3. **Keep validation**: Use same vLLM validation (already optimized)\n4. **Same analysis**: All metrics and visualizations work the same\n\n### **Code Changes Required:**\n```python\n# TT-10 (old)\nfrom trl import SFTTrainer\nfrom transformers import AutoModelForCausalLM\n\n# TT-11 (new)  \nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer  # Still used, but with Unsloth model\n```\n\n**Result: Same methodology, much faster execution, more accurate results!** 🎯\n\nThis makes TT-11 the **recommended approach** for production validation workflows where both speed and accuracy matter.","metadata":{}}]}