{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":13121456,"isSourceIdPinned":false,"sourceId":94635,"sourceType":"competition"},{"datasetId":8044304,"sourceId":12726948,"sourceType":"datasetVersion"},{"datasetId":8067935,"sourceId":12762469,"sourceType":"datasetVersion"},{"sourceId":252850661,"sourceType":"kernelVersion"},{"sourceId":252853424,"sourceType":"kernelVersion"},{"sourceId":259545323,"sourceType":"kernelVersion"},{"isSourceIdPinned":false,"modelId":164048,"modelInstanceId":145960,"sourceId":171496,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":false,"modelId":164048,"modelInstanceId":146086,"sourceId":171638,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":false,"modelId":368803,"modelInstanceId":347541,"sourceId":426330,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":false,"modelId":429004,"modelInstanceId":411182,"sourceId":523492,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":false,"modelId":449553,"modelInstanceId":432662,"sourceId":579809,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b1f53c33","cell_type":"markdown","source":"# Alternative Validation Options\n\n## 🔧 **Choose Your Validation Method:**\n\nThis notebook now provides **two validation approaches**:\n\n### **Option 1: vLLM Validation (Original)**\n- **Pros**: Fastest inference, most precise probability calculations\n- **Cons**: Hardware compatibility issues with certain GPU/model combinations\n- **Use when**: You have compatible hardware and need maximum speed\n\n### **Option 2: Standard Transformers Validation (New)**\n- **Pros**: Universal compatibility, works with any Unsloth model, reliable\n- **Cons**: Slower than vLLM, but still faster than training\n- **Use when**: vLLM has compatibility issues or you want guaranteed reliability\n\n**Both methods produce identical metrics and visualizations** - the choice is purely based on your hardware compatibility and speed requirements.","metadata":{}},{"id":"4ef0213e","cell_type":"markdown","source":"# TT-11: Validation-Focused Training with Unsloth + vLLM\n\nThis notebook implements the same validation-focused approach as TT-10, but optimized for **maximum speed and accuracy**:\n\n**Key Improvements over TT-10:**\n- **🚀 Unsloth Training**: 2x-5x faster fine-tuning than standard PEFT\n- **🎯 vLLM Inference**: Most accurate AUC calculations with precise log probabilities\n- **💾 Memory Efficient**: Optimized for 2x T4 GPU setup\n- **⚡ Best Performance**: Fastest training + most accurate validation\n\n**Methodology:**\n- **Training**: Model learns from positive/negative examples using Unsloth (like test-time training)\n- **Validation**: Model predicts on real `body` comments with vLLM for precise probabilities\n- **Analysis**: Comprehensive metrics to understand generalization from examples to real data\n\n**Features:**\n- **Stratified Sampling**: Controllable % of training data while maintaining rule distribution\n- **Example-Based Training**: Similar to test-time training approach with Unsloth speed\n- **Real Comment Validation**: Test on actual comments with vLLM precision\n- **Comprehensive Metrics**: AUC, F1, Recall, Precision, Confusion Matrix\n- **Visualizations**: Performance plots and analysis\n- **4-bit + LoRA**: Memory-efficient training, vLLM-compatible inference\n\n**Benefits:**\n- **Fastest Training**: Unsloth provides 2x-5x speed improvement\n- **Most Accurate AUC**: vLLM gives precise probability calculations\n- **Best of Both Worlds**: Speed + Accuracy optimized workflow","metadata":{}},{"id":"4c705040","cell_type":"code","source":"# Install dependencies - Unsloth + vLLM + Analysis setup\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'trl==0.21.0' 'optimum==1.27.0' 'bitsandbytes==0.46.1' 'deepspeed==0.17.4' 'logits-processor-zoo==0.2.1' 'vllm==0.10.0'\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'triton==3.2.0'\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'clean-text'\n# Install PEFT for LoRA support\n!uv pip install --system --no-index -U --no-deps --find-links='/kaggle/input/jigsaw-packages2/whls/' 'peft' 'accelerate' 'datasets'\n# Install Unsloth for ultra-fast training\n#!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'unsloth'\n# Install analysis libraries\n#!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'scikit-learn' 'matplotlib' 'seaborn'\n\nprint(\"✅ TT-11 Dependencies installed:\")\nprint(\"🚀 Unsloth: Ultra-fast training\")\nprint(\"🎯 vLLM: Precise inference\") \nprint(\"📊 Analysis libraries: scikit-learn, matplotlib, seaborn\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T15:39:53.378492Z","iopub.execute_input":"2025-09-19T15:39:53.378805Z","iopub.status.idle":"2025-09-19T15:40:52.313805Z","shell.execute_reply.started":"2025-09-19T15:39:53.378766Z","shell.execute_reply":"2025-09-19T15:40:52.313025Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m164 packages\u001b[0m \u001b[2min 704ms\u001b[0m\u001b[0m                                       \u001b[0m\n\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                          \n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m63 packages\u001b[0m \u001b[2min 45.07s\u001b[0m\u001b[0m                                           \n\u001b[2mUninstalled \u001b[1m26 packages\u001b[0m \u001b[2min 2.21s\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m63 packages\u001b[0m \u001b[2min 431ms\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mastor\u001b[0m\u001b[2m==0.8.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.46.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mblake3\u001b[0m\u001b[2m==1.0.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcbor2\u001b[0m\u001b[2m==5.7.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcompressed-tensors\u001b[0m\u001b[2m==0.10.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdeepspeed\u001b[0m\u001b[2m==0.17.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdepyf\u001b[0m\u001b[2m==0.19.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cli\u001b[0m\u001b[2m==0.0.10\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cloud-cli\u001b[0m\u001b[2m==0.1.5\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.5.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgguf\u001b[0m\u001b[2m==0.17.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhjson\u001b[0m\u001b[2m==3.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.6.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.33.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.34.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1minteregular\u001b[0m\u001b[2m==0.3.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.2.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllguidance\u001b[0m\u001b[2m==0.7.30\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.43.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.44.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlm-format-enforcer\u001b[0m\u001b[2m==0.10.12\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlogits-processor-zoo\u001b[0m\u001b[2m==0.2.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmistral-common\u001b[0m\u001b[2m==1.8.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.19.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.60.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.61.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.11.1.6\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.6.85\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.91.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.90.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moptimum\u001b[0m\u001b[2m==1.27.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moutlines-core\u001b[0m\u001b[2m==0.2.10\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpartial-json-parser\u001b[0m\u001b[2m==0.2.1.1.post6\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mprometheus-fastapi-instrumentator\u001b[0m\u001b[2m==7.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpycountry\u001b[0m\u001b[2m==24.6.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpydantic-extra-types\u001b[0m\u001b[2m==2.10.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==24.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrich-toolkit\u001b[0m\u001b[2m==0.15.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrignore\u001b[0m\u001b[2m==0.6.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124 (from https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.22.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.52.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.56.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mvllm\u001b[0m\u001b[2m==0.10.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.31\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxgrammar\u001b[0m\u001b[2m==0.1.21\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 14ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 4.33s\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 14ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m4 packages\u001b[0m \u001b[2min 3.75s\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                               \n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 696ms\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mclean-text\u001b[0m\u001b[2m==0.6.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==2.14.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==1.7.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m3 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 43ms\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m3 packages\u001b[0m \u001b[2min 68ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m                                \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.8.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.10.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==3.6.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.0.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.15.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.17.1\u001b[0m\n✅ TT-11 Dependencies installed:\n🚀 Unsloth: Ultra-fast training\n🎯 vLLM: Precise inference\n📊 Analysis libraries: scikit-learn, matplotlib, seaborn\n","output_type":"stream"}],"execution_count":1},{"id":"dfd03d10-6426-41a4-8620-213cfd3402c3","cell_type":"code","source":"!pip install unsloth \n!pip install vllm","metadata":{"execution":{"iopub.status.busy":"2025-09-19T15:40:52.315969Z","iopub.execute_input":"2025-09-19T15:40:52.316712Z","iopub.status.idle":"2025-09-19T15:41:21.137957Z","shell.execute_reply.started":"2025-09-19T15:40:52.316681Z","shell.execute_reply":"2025-09-19T15:41:21.137237Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.9.7-py3-none-any.whl.metadata (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.9.9 (from unsloth)\n  Downloading unsloth_zoo-2025.9.9-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.7.1)\nRequirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.0.31)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.46.1)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.32-py3-none-any.whl.metadata (11 kB)\nCollecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3 (from unsloth)\n  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting datasets<4.0.0,>=3.4.1 (from unsloth)\n  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.10.1)\nRequirement already satisfied: trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.17.1)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.4)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.22.1)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2025.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth) (2024.11.6)\nCollecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth)\n  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: torchao in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.9->unsloth) (0.10.0)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.9.9->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.9->unsloth) (11.2.1)\nRequirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.9->unsloth) (0.19.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (14.0.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.13)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.6.15)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.9.7-py3-none-any.whl (314 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.6/314.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.9.9-py3-none-any.whl (233 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.9.32-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nInstalling collected packages: triton, shtab, tyro, tokenizers, cut_cross_entropy, transformers, datasets, unsloth_zoo, unsloth\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.22.0\n    Uninstalling tokenizers-0.22.0:\n      Successfully uninstalled tokenizers-0.22.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.56.0\n    Uninstalling transformers-4.56.0:\n      Successfully uninstalled transformers-4.56.0\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.0.0\n    Uninstalling datasets-4.0.0:\n      Successfully uninstalled datasets-4.0.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cut_cross_entropy-25.1.1 datasets-3.6.0 shtab-1.7.2 tokenizers-0.21.4 transformers-4.55.4 triton-3.3.1 tyro-0.9.32 unsloth-2025.9.7 unsloth_zoo-2025.9.9\nRequirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.10.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from vllm) (2024.11.6)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.4)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\nRequirement already satisfied: blake3 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.0.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\nRequirement already satisfied: transformers>=4.53.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.55.4)\nRequirement already satisfied: huggingface-hub>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.33.0->vllm) (0.34.4)\nRequirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.4)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (3.20.3)\nRequirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.13)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.12.13)\nRequirement already satisfied: openai<=1.90.0,>=1.87.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.90.0)\nRequirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.7)\nRequirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.22.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\nRequirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (7.1.0)\nRequirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\nRequirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.12)\nRequirement already satisfied: llguidance<0.8.0,>=0.7.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.7.30)\nRequirement already satisfied: outlines_core==0.2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.10)\nRequirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.11/dist-packages (from vllm) (5.6.3)\nRequirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.2.2)\nRequirement already satisfied: xgrammar==0.1.21 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.1.21)\nRequirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.14.0)\nRequirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\nRequirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.1.1.post6)\nRequirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (27.0.2)\nRequirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\nRequirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.17.1)\nRequirement already satisfied: mistral_common>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from mistral_common[audio,image]>=1.8.2->vllm) (1.8.4)\nRequirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\nRequirement already satisfied: compressed-tensors==0.10.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.2)\nRequirement already satisfied: depyf==0.19.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\nRequirement already satisfied: watchfiles in /usr/local/lib/python3.11/dist-packages (from vllm) (1.1.0)\nRequirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.3)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from vllm) (1.11.1.4)\nRequirement already satisfied: pybase64 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.4.2)\nRequirement already satisfied: cbor2 in /usr/local/lib/python3.11/dist-packages (from vllm) (5.7.0)\nRequirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.61.2)\nRequirement already satisfied: ray!=2.44.*,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (2.47.1)\nRequirement already satisfied: torch==2.7.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.7.1)\nRequirement already satisfied: torchaudio==2.7.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.7.1)\nRequirement already satisfied: torchvision==0.22.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.22.1)\nRequirement already satisfied: xformers==0.0.31 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.0.31)\nRequirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.8.1)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.3.8)\nRequirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba==0.61.2->vllm) (0.44.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (1.11.1.6)\nRequirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.3.1)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch==2.7.1->vllm) (75.2.0)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\nRequirement already satisfied: fastapi-cli>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.10)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\nRequirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\nRequirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.3)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (25.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (1.1.5)\nRequirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer<0.11,>=0.10.11->vllm) (0.3.3)\nRequirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.24.0)\nRequirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.10.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2.4.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (0.10.0)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (1.3.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.4.1)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.2.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.1)\nRequirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.6.15)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->vllm) (0.5.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.1)\nRequirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\nRequirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.16.0)\nRequirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.0)\nRequirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.1->vllm) (3.0.2)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.25.1)\nRequirement already satisfied: pycountry>=23 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (24.6.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.1->vllm) (1.3.0)\nRequirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\nRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\nRequirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\nRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.13.1)\nRequirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.5.0.post1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->vllm) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->vllm) (2024.2.0)\nRequirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\nRequirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.31.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->vllm) (2024.2.0)\nRequirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.0.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.17.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.22)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n","output_type":"stream"}],"execution_count":2},{"id":"c1b94d35-0643-4157-961a-3259c7ed7272","cell_type":"code","source":"import unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T15:41:21.138941Z","iopub.execute_input":"2025-09-19T15:41:21.139177Z","iopub.status.idle":"2025-09-19T15:42:06.213967Z","shell.execute_reply.started":"2025-09-19T15:41:21.139150Z","shell.execute_reply":"2025-09-19T15:42:06.213129Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-09-19 15:41:32.393120: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758296492.647485      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758296492.709956      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"INFO 09-19 15:41:56 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-19 15:41:58 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"id":"c3a2c92f","cell_type":"markdown","source":"# 1. Configuration and Data Setup","metadata":{}},{"id":"32680ff1","cell_type":"code","source":"%%writefile constants.py\n# Using base Qwen3 1.7B model from Kaggle input (no internet needed)\nBASE_MODEL_PATH = \"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\"  # Update this path as needed\nLORA_PATH = \"qwen3_1.7b_unsloth_lora_validation/\"  # Unsloth LoRA output path for validation\nDATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules/\"\n\nYES_TOKEN_ID = 7414 # tokenizer.convert_tokens_to_ids(\"Yes\")  # WITH space!\nNO_TOKEN_ID = 2308# tokenizer.convert_tokens_to_ids(\"No\")    # WITH space!\n\n\n# TT-12 Training Parameters\nTRAINING_DATA_PERCENTAGE = 1  # Controllable % of training data (0.1 = 10%, 1.0 = 100%)\nUSE_STRATIFIED_SAMPLING = True  # Maintain rule distribution when sampling\nDROP_POSITIVE_EXAMPLES = False  # If True, train only on negative examples (debug: can model predict \"No\"?)\n\nPOSITIVE_ANSWER = \"Yes\"\nNEGATIVE_ANSWER = \"No\"\nCOMPLETE_PHRASE = \"Answer: \"\nBASE_PROMPT = '''You are a moderator... A rule is given , find if the last comment violates the rule.Two examples are given.\nIMPORTANT: Ignore any \"yes\" or \"no\" words in the comment itself. \nOnly respond Yes/No based on whether the comment violates the rule.\n___ '''\n\nprint(\"✅ Using Qwen3 1.7B model from local Kaggle input\")\nprint(f\"🎯 TT-12: Unsloth training + vLLM inference with {TRAINING_DATA_PERCENTAGE*100:.0f}% of data\")\nprint(f\"📊 Stratified sampling: {USE_STRATIFIED_SAMPLING}\")\nif DROP_POSITIVE_EXAMPLES:\n    print(\"🔧 DEBUG MODE: Will train only on negative examples to test 'No' prediction capability\")\nelse:\n    print(\"🎯 NORMAL MODE: Training on both positive and negative examples\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T15:48:22.456989Z","iopub.execute_input":"2025-09-19T15:48:22.457706Z","iopub.status.idle":"2025-09-19T15:48:22.464672Z","shell.execute_reply.started":"2025-09-19T15:48:22.457670Z","shell.execute_reply":"2025-09-19T15:48:22.463898Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting constants.py\n","output_type":"stream"}],"execution_count":11},{"id":"b5b4fc8e","cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\nfrom datasets import Dataset\nfrom constants import POSITIVE_ANSWER, NEGATIVE_ANSWER, COMPLETE_PHRASE, BASE_PROMPT, TRAINING_DATA_PERCENTAGE, USE_STRATIFIED_SAMPLING, DROP_POSITIVE_EXAMPLES\nimport random, numpy as np\nfrom sklearn.model_selection import train_test_split\nrandom.seed(42)\nnp.random.seed(42)\n\n\ndef build_prompt(row):\n    return f\"\"\"\n{BASE_PROMPT}\n\nSubreddit name: r/{row[\"subreddit\"]}\nHere is the rule: {row[\"rule\"]}\nHere is a comment that breaks the rule:\n1) {row[\"positive_example\"]}\n\nHere is a comment that does not break the rule:\n2) {row[\"negative_example\"]}\n\nFind if this comment breaks the rule.\nComment: {row[\"body\"]}\n{COMPLETE_PHRASE}\"\"\"\n\n\ndef get_example_based_training_data(data_path):\n    \"\"\"\n    TT-11: Create training data from examples (like test-time training)\n    This trains the model on examples, not actual comments\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Sample data if needed while maintaining rule distribution\n    if TRAINING_DATA_PERCENTAGE < 1.0:\n        if USE_STRATIFIED_SAMPLING:\n            # Stratified sampling to maintain rule distribution\n            train_dataset = train_dataset.groupby('rule', group_keys=False).apply(\n                lambda x: x.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42)\n            ).reset_index(drop=True)\n            print(f\"📊 Stratified sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n        else:\n            # Simple random sampling\n            train_dataset = train_dataset.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42).reset_index(drop=True)\n            print(f\"📊 Random sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n    \n    print(f\"📊 Training data size: {len(train_dataset)} samples\")\n    print(f\"📊 Rule distribution: {train_dataset['rule'].value_counts().to_dict()}\")\n    \n    flatten = []\n    \n    # Create training data from examples (similar to test-time training)\n    violation_types = [\"positive\", \"negative\"]\n    \n    # Debug mode: Train only on negative examples if DROP_POSITIVE_EXAMPLES is True\n    if DROP_POSITIVE_EXAMPLES:\n        violation_types = [\"negative\"]\n        print(\"🔧 DEBUG MODE: Training only on negative examples (DROP_POSITIVE_EXAMPLES=True)\")\n    \n    for violation_type in violation_types:\n        for i in range(1, 3):\n            sub_dataset = train_dataset[[\"rule\",\"subreddit\",\n                                        \"positive_example_1\",\"positive_example_2\",\n                                        \"negative_example_1\",\"negative_example_2\"]].copy()\n\n            if violation_type == \"positive\":\n                # Use positive example as the \"body\" to classify\n                body_col = f\"positive_example_{i}\"\n                other_positive_col = f\"positive_example_{3-i}\"  # other positive\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"positive_example\"] = sub_dataset[other_positive_col]\n                # negative_example randomly selected\n                sub_dataset[\"negative_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"negative_example_1\"],\n                    sub_dataset[\"negative_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 1  # Positive examples violate rules\n\n            else:  # violation_type == \"negative\"\n                # Use negative example as the \"body\" to classify\n                body_col = f\"negative_example_{i}\"\n                other_negative_col = f\"negative_example_{3-i}\"\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"negative_example\"] = sub_dataset[other_negative_col]\n                sub_dataset[\"positive_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"positive_example_1\"],\n                    sub_dataset[\"positive_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 0  # Negative examples don't violate rules\n\n            # Drop original candidate columns\n            sub_dataset.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                                      \"negative_example_1\",\"negative_example_2\"], inplace=True)\n\n            flatten.append(sub_dataset)\n\n    # Merge all DataFrames\n    example_training_df = pd.concat(flatten, axis=0)\n    example_training_df = example_training_df.drop_duplicates(ignore_index=True)\n    \n    print(f\"📊 Example-based training dataset: {len(example_training_df)} samples\")\n    print(f\"📊 Positive examples: {sum(example_training_df['rule_violation'] == 1)}\")\n    print(f\"📊 Negative examples: {sum(example_training_df['rule_violation'] == 0)}\")\n    \n    return example_training_df\n\n\ndef get_real_comment_validation_data(data_path):\n    \"\"\"\n    TT-11: Get real comments with labels for validation\n    This is what we actually want to predict\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Use actual comments and their labels for validation\n    validation_df = train_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\",\n                                  \"positive_example_1\",\"positive_example_2\",\n                                  \"negative_example_1\",\"negative_example_2\"]].copy()\n\n    # Randomly select positive_example and negative_example for prompts\n    validation_df[\"positive_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"positive_example_1\"],\n        validation_df[\"positive_example_2\"]\n    )\n    validation_df[\"negative_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"negative_example_1\"],\n        validation_df[\"negative_example_2\"]\n    )\n\n    # Drop original candidate columns\n    validation_df.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                               \"negative_example_1\",\"negative_example_2\"], inplace=True)\n    \n    print(f\"📊 Real comment validation dataset: {len(validation_df)} samples\")\n    print(f\"📊 Rule violations: {sum(validation_df['rule_violation'] == 1)} positive, {sum(validation_df['rule_violation'] == 0)} negative\")\n    \n    return validation_df\n\n\ndef build_dataset_unsloth(dataframe):\n    \"\"\"Build dataset for Unsloth training with proper text formatting\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    \n    # Create completion column\n    dataframe[\"completion\"] = dataframe.apply(\n        lambda row: (POSITIVE_ANSWER if row[\"rule_violation\"] == 1 else NEGATIVE_ANSWER),\n        axis=1\n    )\n    \n    # Create full text (prompt + completion) for training\n    dataframe[\"text\"] = dataframe[\"prompt\"] + dataframe[\"completion\"]\n    \n    # Keep only necessary columns\n    dataframe = dataframe[[\"text\", \"completion\"]]\n    dataset = Dataset.from_pandas(dataframe.reset_index(drop=True))\n    return dataset\n\n\n\ndef build_validation_dataset(dataframe):\n    \"\"\"Build dataset for validation (keep labels for evaluation)\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    dataframe = dataframe[[\"prompt\", \"rule_violation\"]]  # Keep true labels for evaluation\n    dataset = Dataset.from_pandas(dataframe)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2025-09-19T15:48:30.046071Z","iopub.execute_input":"2025-09-19T15:48:30.046431Z","iopub.status.idle":"2025-09-19T15:48:30.055359Z","shell.execute_reply.started":"2025-09-19T15:48:30.046400Z","shell.execute_reply":"2025-09-19T15:48:30.054462Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting utils.py\n","output_type":"stream"}],"execution_count":12},{"id":"1e389c0f-ea4a-4b08-88d0-5a35c0c264ea","cell_type":"code","source":"import importlib\nimport utils  # regular import (only needed once)\nimport constants\nimportlib.reload(constants)\n\nimportlib.reload(utils)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T03:59:53.671001Z","iopub.execute_input":"2025-09-19T03:59:53.671561Z","iopub.status.idle":"2025-09-19T03:59:53.681092Z","shell.execute_reply.started":"2025-09-19T03:59:53.671537Z","shell.execute_reply":"2025-09-19T03:59:53.680349Z"},"trusted":true},"outputs":[{"name":"stdout","text":"✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 90% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"<module 'utils' from '/kaggle/working/utils.py'>"},"metadata":{}}],"execution_count":39},{"id":"2abcb14c-a7aa-4fea-a497-be8799e849d8","cell_type":"code","source":"%%writefile train_unsloth.py\nimport pandas as pd\nimport torch\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom utils import build_dataset_unsloth, get_example_based_training_data\nfrom constants import DATA_PATH, BASE_MODEL_PATH, LORA_PATH\n\n\ndef main():\n    # TT-11: Get example-based training data (train on examples, not real comments)\n    train_df = get_example_based_training_data(DATA_PATH)\n    train_dataset = build_dataset_unsloth(train_df)\n    \n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n    \n    # 🚀 UNSLOTH: Load model with 4-bit quantization (2x T4 optimized)\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,  # Adjust based on your max sequence length\n        dtype=None,  # Auto-detect (will use float16)\n        load_in_4bit=True,  # Enable 4-bit quantization\n        trust_remote_code=True,\n        local_files_only=True,\n        device_map=\"balanced\" ,\n       # full_finetuning= False\n    )\n    print(\"✅ Unsloth model loaded with 4-bit quantization across 2x T4\")\n    \n    # 🚀 UNSLOTH: Add LoRA adapters (automatic and optimized)\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r=16,  # LoRA rank (can try 8, 16, 32, 64, 128)\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n        lora_alpha=32,  # LoRA alpha (typically equal to r for Unsloth)\n        lora_dropout=0,  # 0 for faster training with Unsloth\n        bias=\"none\",\n        #use_gradient_checkpointing=False,  # Enable for memory efficiency\n        random_state=3407,  # For reproducibility\n        use_rslora=True,  # Can try True for better stability\n        loftq_config=None,  # LoftQ for even better quality\n        use_gradient_checkpointing = \"unsloth\"\n    )\n    print(\"✅ Unsloth LoRA adapters added\")\n    \n    # 🚀 UNSLOTH: Optimized training arguments for 2x T4 GPUs (28GB total)\n    training_args = TrainingArguments(\n        per_device_train_batch_size=8,  # Larger batches with 2x T4 (28GB total)\n        gradient_accumulation_steps=8,  # Effective batch size = 4*2*2 = 16\n        warmup_steps=5,  # Quick warmup with Unsloth\n        #max_steps=50,  # Unsloth converges much faster (adjust based on data size)\n        num_train_epochs=1 , \n        learning_rate=2e-4,  # Higher LR works better with Unsloth\n        fp16=not torch.cuda.is_bf16_supported(),\n        bf16=torch.cuda.is_bf16_supported(),\n        logging_steps=1,  # Frequent logging for monitoring\n        optim=\"adamw_8bit\",  # 8-bit optimizer for memory efficiency\n        weight_decay=0.01,\n        lr_scheduler_type=\"cosine\",  # Simple linear decay\n        seed=70,\n        output_dir=LORA_PATH,\n        report_to=\"none\",\n       \n        #save_strategy=\"steps\",\n        #save_steps=20,  # Save frequently for monitoring\n        #save_total_limit=2,  # Keep only recent checkpoints\n        #dataloader_pin_memory=False,  # Unsloth handles this\n        # Multi-GPU optimizations for 2x T4\n        dataloader_num_workers=4,  # Parallel data loading\n        #remove_unused_columns=False,  # Keep all data\n        #ddp_find_unused_parameters=False,  # DDP optimization\n        #ddp_broadcast_buffers=False,  # Reduce communication overhead\n    )\n    print(\"✅ Unsloth training arguments configured for 2x T4\")\n    \n    # 🚀 UNSLOTH: Use SFTTrainer with Unsloth model\n    trainer = SFTTrainer(\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=train_dataset,\n        max_seq_length=2048,\n        dataset_num_proc=4,  # More parallel processing for 2x T4\n        packing=False,  # Can try True for even faster training\n        args=training_args,\n        dataset_text_field=\"text\",\n        dataset_completion_field=\"completion\",\n        completion_only_loss=True ,\n\n    )\n    \n    print(\"🚀 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\")\n    \n    # 🚀 UNSLOTH: Train with optimized loop\n    trainer_stats = trainer.train()\n    \n    print(\"✅ Unsloth training completed!\")\n    print(f\"Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\n    print(f\"Samples/second: {trainer_stats.metrics['train_samples_per_second']:.2f}\")\n    print(f\"GPU utilization optimized for 2x T4 setup\")\n    \n    # 🚀 UNSLOTH: Save LoRA adapters in vLLM-compatible format\n    print(\"💾 Saving LoRA adapters for vLLM compatibility...\")\n    \n    # Save tokenizer\n    tokenizer.save_pretrained(LORA_PATH)\n    \n    # Save model in PEFT format (vLLM compatible)\n    model.save_pretrained(LORA_PATH)\n    #model.save_pretrained(...)  \n    #tokenizer.save_pretrained(...)\n    folder=\"16 bit\"\n    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"forced_merged_4bit\",)\n    \n\n    \n    print(f\"✅ LoRA adapters saved to: {LORA_PATH} , model saved \")\n    print(\"🎯 Ready for vLLM inference!\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-09-19T15:48:41.429549Z","iopub.execute_input":"2025-09-19T15:48:41.430195Z","iopub.status.idle":"2025-09-19T15:48:41.436978Z","shell.execute_reply.started":"2025-09-19T15:48:41.430171Z","shell.execute_reply":"2025-09-19T15:48:41.436118Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting train_unsloth.py\n","output_type":"stream"}],"execution_count":13},{"id":"772886cb","cell_type":"code","source":"%%writefile weight_train_unsloth.py\nimport pandas as pd\nimport torch\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom utils import build_dataset_unsloth, get_example_based_training_data\nfrom constants import DATA_PATH, BASE_MODEL_PATH, LORA_PATH, YES_TOKEN_ID, NO_TOKEN_ID\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef get_class_weights():\n    \"\"\"\n    Manual class weights to heavily penalize false positives\n\n    CLASS MAPPING:\n    - Index 0 = \"No\" (negative class, rule_violation = 0)\n    - Index 1 = \"Yes\" (positive class, rule_violation = 1)\n\n    WEIGHTS:\n    - Weight for \"No\" (index 0): 0.8 (higher penalty for getting \"No\" wrong)\n    - Weight for \"Yes\" (index 1): 0.2 (lower penalty for getting \"Yes\" wrong)\n    - Result: 4x more penalty for false positives (predicting \"Yes\" when should be \"No\")\n    \"\"\"\n    # Manual weights: [weight_for_no, weight_for_yes]\n    weights = torch.tensor([0.8, 0.2], dtype=torch.float)\n\n    # Print weight distribution for verification\n    print(f\"📊 Class Weights Mapping:\")\n    print(f\"   Index 0 ('No'/negative): {weights[0].item():.1f}\")\n    print(f\"   Index 1 ('Yes'/positive): {weights[1].item():.1f}\")\n    print(f\"📊 False Positive Penalty: {weights[0].item()/weights[1].item():.1f}x\")\n    print(f\"📊 Token IDs: No={NO_TOKEN_ID}, Yes={YES_TOKEN_ID}\")\n\n    return weights\n\n\nclass WeightedSFTTrainer(SFTTrainer):\n    \"\"\"Custom SFT Trainer with weighted loss - compatible with Unsloth\"\"\"\n\n    def __init__(self, class_weights, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.class_weights = class_weights\n        self.debug_counter = 0\n\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        \"\"\"\n        Custom loss computation with class weights\n        Compatible with Unsloth's additional parameters using **kwargs\n        \"\"\"\n        self.debug_counter += 1\n        \n        # Debug: Print detailed information\n        print(f\"\\n🔍 DEBUG Step {self.debug_counter}:\")\n        print(f\"   Model type: {type(model)}\")\n        print(f\"   Model device: {next(model.parameters()).device if model.parameters() else 'Unknown'}\")\n        print(f\"   Inputs keys: {list(inputs.keys()) if inputs else 'None'}\")\n        print(f\"   Inputs types: {[(k, type(v)) for k, v in inputs.items()] if inputs else 'None'}\")\n        \n        # Check inputs validity\n        if inputs is None:\n            print(\"❌ ERROR: inputs is None\")\n            return torch.tensor(0.0, requires_grad=True, device=self.model.device)\n        \n        labels = inputs.get(\"labels\")\n        print(f\"   Labels shape: {labels.shape if labels is not None else 'None'}\")\n        print(f\"   Labels device: {labels.device if labels is not None else 'None'}\")\n        \n        # Try model forward pass with error handling\n        try:\n            print(\"   Attempting model forward pass...\")\n            outputs = model(**inputs)\n            print(f\"   ✅ Forward pass successful\")\n            print(f\"   Outputs type: {type(outputs)}\")\n            \n            # Debug outputs structure\n            if outputs is None:\n                print(\"❌ ERROR: model outputs is None\")\n                return torch.tensor(0.0, requires_grad=True, device=self.model.device)\n            \n            print(f\"   Outputs attributes: {dir(outputs) if hasattr(outputs, '__dict__') else 'Not object'}\")\n            \n            if hasattr(outputs, '__dict__'):\n                print(f\"   Outputs dict: {outputs.__dict__.keys()}\")\n            \n        except Exception as e:\n            print(f\"❌ ERROR in model forward pass: {e}\")\n            return torch.tensor(0.0, requires_grad=True, device=self.model.device)\n\n        # Try different ways to access logits\n        logits = None\n        \n        if hasattr(outputs, 'logits'):\n            logits = outputs.logits\n            print(f\"   ✅ Found logits via outputs.logits: {logits.shape if logits is not None else 'None'}\")\n        elif isinstance(outputs, dict) and 'logits' in outputs:\n            logits = outputs['logits']\n            print(f\"   ✅ Found logits via outputs['logits']: {logits.shape if logits is not None else 'None'}\")\n        elif isinstance(outputs, tuple) and len(outputs) > 0:\n            logits = outputs[0]\n            print(f\"   ✅ Found logits via outputs[0]: {logits.shape if logits is not None else 'None'}\")\n        else:\n            print(f\"❌ ERROR: Could not find logits in outputs\")\n            print(f\"   Trying all attributes...\")\n            for attr in dir(outputs):\n                if not attr.startswith('_'):\n                    val = getattr(outputs, attr)\n                    print(f\"     {attr}: {type(val)} - {val.shape if hasattr(val, 'shape') else val}\")\n\n        if logits is None:\n            print(\"❌ CRITICAL: logits is None - using fallback loss\")\n            # Fall back to standard loss if available\n            if hasattr(outputs, 'loss') and outputs.loss is not None:\n                print(f\"   Using fallback loss: {outputs.loss}\")\n                return (outputs.loss, outputs) if return_outputs else outputs.loss\n            else:\n                print(\"   No fallback loss available - returning zero loss\")\n                return torch.tensor(0.0, requires_grad=True, device=self.model.device)\n\n        # If we get here, logits is not None\n        print(f\"   ✅ Logits found: {logits.shape}, device: {logits.device}\")\n\n        if labels is not None:\n            # For language modeling, we predict next token\n            if logits.dim() >= 3:  # Standard case: [batch, seq_len, vocab_size]\n                shift_logits = logits[..., :-1, :].contiguous()\n                shift_labels = labels[..., 1:].contiguous()\n                print(f\"   Shifted logits: {shift_logits.shape}\")\n                print(f\"   Shifted labels: {shift_labels.shape}\")\n            else:\n                # Handle edge case where logits might be 2D\n                shift_logits = logits\n                shift_labels = labels\n                print(f\"   Using original logits (2D): {shift_logits.shape}\")\n\n            # Flatten the tokens\n            shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n            shift_labels = shift_labels.view(-1)\n            print(f\"   Flattened logits: {shift_logits.shape}\")\n            print(f\"   Flattened labels: {shift_labels.shape}\")\n\n            # Move weights to correct device\n            weights = self.class_weights.to(shift_logits.device)\n\n            # Find positions where we're predicting Yes/No tokens\n            yes_no_mask = (shift_labels == YES_TOKEN_ID) | (shift_labels == NO_TOKEN_ID)\n            yes_no_count = yes_no_mask.sum().item()\n            print(f\"   Yes/No token positions found: {yes_no_count}\")\n\n            if yes_no_mask.any():\n                # Apply weighted loss only to Yes/No predictions\n                yes_no_logits = shift_logits[yes_no_mask]\n                yes_no_labels = shift_labels[yes_no_mask]\n\n                # Map token IDs to class indices\n                class_labels = torch.where(yes_no_labels == YES_TOKEN_ID, 1, 0)\n\n                # Apply weighted cross entropy to Yes/No predictions\n                weighted_loss = F.cross_entropy(\n                    yes_no_logits,\n                    yes_no_labels,\n                    reduction='none'\n                )\n\n                # Apply class weights\n                class_weights_expanded = weights[class_labels]\n                weighted_loss = (weighted_loss * class_weights_expanded).mean()\n\n                # Standard loss for other tokens\n                other_mask = ~yes_no_mask\n                if other_mask.any():\n                    other_loss = F.cross_entropy(\n                        shift_logits[other_mask],\n                        shift_labels[other_mask],\n                        ignore_index=-100\n                    )\n                    # Combine losses (give more weight to Yes/No predictions)\n                    loss = 0.7 * weighted_loss + 0.3 * other_loss\n                    print(f\"   Combined loss: weighted={weighted_loss:.4f}, other={other_loss:.4f}, final={loss:.4f}\")\n                else:\n                    loss = weighted_loss\n                    print(f\"   Weighted loss only: {loss:.4f}\")\n            else:\n                # No Yes/No tokens found, use standard loss\n                loss = F.cross_entropy(\n                    shift_logits,\n                    shift_labels,\n                    ignore_index=-100\n                )\n                print(f\"   Standard loss (no Yes/No tokens): {loss:.4f}\")\n        else:\n            # No labels provided, use model's built-in loss if available\n            if hasattr(outputs, 'loss') and outputs.loss is not None:\n                loss = outputs.loss\n                print(f\"   Using model's built-in loss: {loss:.4f}\")\n            else:\n                loss = torch.tensor(0.0, requires_grad=True, device=logits.device)\n                print(f\"   Zero loss (no labels, no built-in loss)\")\n\n        print(f\"   Final loss: {loss:.4f}\")\n        return (loss, outputs) if return_outputs else loss\n\n\ndef main():\n    # TT-12: Get example-based training data (train on examples, not real comments)\n    train_df = get_example_based_training_data(DATA_PATH)\n    train_dataset = build_dataset_unsloth(train_df)\n\n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n\n    # 🚀 UNSLOTH: Load model with 4-bit quantization (2x T4 optimized)\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,  # Adjust based on your max sequence length\n        dtype=None,  # Auto-detect (will use float16)\n        load_in_4bit=True,  # Enable 4-bit quantization\n        trust_remote_code=True,\n        local_files_only=True,\n        device_map=\"balanced\"\n    )\n    print(\"✅ Unsloth model loaded with 4-bit quantization across 2x T4\")\n\n    # 🚀 UNSLOTH: Add LoRA adapters (automatic and optimized)\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r=16,  # LoRA rank (can try 8, 16, 32, 64, 128)\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n        lora_alpha=32,  # LoRA alpha (typically equal to r for Unsloth)\n        lora_dropout=0,  # 0 for faster training with Unsloth\n        bias=\"none\",\n        random_state=3407,  # For reproducibility\n        use_rslora=False,  # Can try True for better stability\n        loftq_config=None,  # LoftQ for even better quality\n        use_gradient_checkpointing=\"unsloth\"\n    )\n    print(\"✅ Unsloth LoRA adapters added\")\n\n    # 🚀 UNSLOTH: Optimized training arguments for 2x T4 GPUs (28GB total)\n    training_args = TrainingArguments(\n        per_device_train_batch_size=2,  # Adjusted for memory\n        gradient_accumulation_steps=8,  # Effective batch size = 2*2*8 = 32\n        warmup_steps=5,  # Quick warmup with Unsloth\n        num_train_epochs=1,\n        learning_rate=1e-4,  # Conservative learning rate\n        fp16=not torch.cuda.is_bf16_supported(),\n        bf16=torch.cuda.is_bf16_supported(),\n        logging_steps=1,  # Frequent logging for monitoring\n        optim=\"adamw_8bit\",  # 8-bit optimizer for memory efficiency\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",  # Simple linear decay\n        seed=666,\n        output_dir=LORA_PATH,\n        report_to=\"none\",\n        save_strategy=\"steps\",\n        save_steps=20,  # Save frequently for monitoring\n        save_total_limit=2,  # Keep only recent checkpoints\n        dataloader_pin_memory=False,  # Unsloth handles this\n        # Multi-GPU optimizations for 2x T4\n        dataloader_num_workers=4,  # Parallel data loading\n        remove_unused_columns=False,  # Keep all data\n        ddp_find_unused_parameters=False,  # DDP optimization\n        ddp_broadcast_buffers=False,  # Reduce communication overhead\n    )\n    print(\"✅ Unsloth training arguments configured for 2x T4\")\n\n    # Get class weights for balanced training\n    class_weights = get_class_weights()\n\n    # 🚀 UNSLOTH: Use WeightedSFTTrainer with class weights\n    trainer = WeightedSFTTrainer(\n        class_weights=class_weights,\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=train_dataset,\n        dataset_text_field=\"text\",  # Unsloth expects \"text\" field\n        max_seq_length=2048,\n        dataset_num_proc=4,  # More parallel processing for 2x T4\n        packing=False,  # Can try True for even faster training\n        args=training_args,\n    )\n\n    print(\"🚀 Starting Unsloth training with weighted loss on 2x T4...\")\n    print(\"🎯 Heavily penalizing false positives (predicting 'Yes' when should be 'No')\")\n\n    # 🚀 UNSLOTH: Train with optimized loop\n    trainer_stats = trainer.train()\n\n    print(\"✅ Unsloth training completed!\")\n    print(f\"Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\n    print(f\"Samples/second: {trainer_stats.metrics['train_samples_per_second']:.2f}\")\n    print(f\"GPU utilization optimized for 2x T4 setup\")\n\n    # 🚀 UNSLOTH: Save LoRA adapters in vLLM-compatible format\n    print(\"💾 Saving LoRA adapters for vLLM compatibility...\")\n\n    # Save tokenizer\n    tokenizer.save_pretrained(LORA_PATH)\n\n    # Save model in PEFT format (vLLM compatible)\n    model.save_pretrained(LORA_PATH)\n\n    # Save merged 4-bit model\n    folder = \"merged_4bit_model\"\n    model.save_pretrained_merged(folder, tokenizer, save_method=\"merged_4bit\")\n\n    print(f\"✅ LoRA adapters saved to: {LORA_PATH}\")\n    print(f\"✅ Merged 4-bit model saved to: {folder}\")\n    print(\"🎯 Ready for vLLM inference with weighted training!\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-09-19T03:33:21.868583Z","iopub.execute_input":"2025-09-19T03:33:21.868864Z","iopub.status.idle":"2025-09-19T03:33:21.880147Z","shell.execute_reply.started":"2025-09-19T03:33:21.868841Z","shell.execute_reply":"2025-09-19T03:33:21.879602Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Writing weight_train_unsloth.py\n","output_type":"stream"}],"execution_count":6},{"id":"5195dc58","cell_type":"markdown","source":"# 🎯 2x T4 GPU Optimization Guide\n\n## ⚡ **Multi-GPU Configuration for TT-11**\n\n### **Your Setup: 2x T4 (28GB Total VRAM)**\n- **GPU 0**: ~14GB VRAM\n- **GPU 1**: ~14GB VRAM\n- **Total**: 28GB available for training\n\n### **Optimizations Applied:**\n\n#### **1. Model Distribution**\n```python\ndevice_map=\"auto\"  # Automatic distribution across GPUs\nmax_memory={0: \"13GB\", 1: \"13GB\"}  # Reserve 1GB per GPU for operations\n```\n\n#### **2. Batch Size Scaling**\n```python\nper_device_train_batch_size=4,  # 4 samples per GPU (8 total)\ngradient_accumulation_steps=2,  # Effective batch = 4*2*2 = 16\n```\n\n#### **3. Memory Optimizations**\n```python\nload_in_4bit=True,              # 4-bit quantization saves ~75% memory\nuse_gradient_checkpointing=True, # Trade compute for memory\ndataloader_pin_memory=False,     # Let Unsloth handle memory\n```\n\n#### **4. Multi-GPU Training**\n```python\ndataloader_num_workers=4,        # Parallel data loading\nddp_find_unused_parameters=False, # DDP optimization\nddp_broadcast_buffers=False,     # Reduce communication\n```\n\n### **Expected Performance:**\n- **Training Speed**: 3x-6x faster than single GPU\n- **Memory Usage**: ~12-13GB per GPU\n- **Effective Batch**: 16 samples (vs 4 on single GPU)\n- **Total Time**: 5-8 minutes for full training\n\n### **Troubleshooting 2x T4:**\n\n#### **If you get OOM (Out of Memory):**\n```python\n# Reduce batch size\nper_device_train_batch_size=2,   # 2 per GPU instead of 4\ngradient_accumulation_steps=4,   # Keep effective batch size\n\n# Or reduce sequence length\nmax_seq_length=1024,             # Shorter sequences\n```\n\n#### **If training is slower than expected:**\n```python\n# Check GPU utilization\nnvidia-smi  # Should show ~90%+ on both GPUs\n\n# Increase batch size if memory allows\nper_device_train_batch_size=6,   # Try larger batches\n```\n\n#### **Memory Distribution Check:**\n```python\nprint(f\"Available GPUs: {torch.cuda.device_count()}\")\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_properties(i).total_memory // 1024**3}GB\")\n```","metadata":{}},{"id":"9c272316-1b10-4ccd-bc25-ea7e46e2fdd1","cell_type":"code","source":"!export VLLM_LOGGING_LEVEL=DEBUG\n","metadata":{"execution":{"iopub.execute_input":"2025-09-18T15:30:55.180228Z","iopub.status.busy":"2025-09-18T15:30:55.179978Z","iopub.status.idle":"2025-09-18T15:30:55.295403Z","shell.execute_reply":"2025-09-18T15:30:55.294688Z","shell.execute_reply.started":"2025-09-18T15:30:55.180206Z"},"trusted":true},"outputs":[],"execution_count":6},{"id":"94fc07a4","cell_type":"code","source":"%%writefile validation_vllm.py\nimport os\nos.environ[\"TRITON_NUM_STAGES\"] = \"3\"  # Reduce stages\nos.environ[\"VLLM_USE_V1\"] = \"1\"\nimport vllm\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\nfrom vllm.lora.request import LoRARequest\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_vllm():\n    \"\"\"Run validation using Unsloth-trained model with vLLM for precise AUC\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"🔍 Running validation on {len(val_dataset)} real comments\")\n    model=\"/kaggle/working/qwen3_1.7b_merged\"\n    # 🎯 VLLM: Initialize with Unsloth LoRA support for precise probabilities\n    llm = vllm.LLM(\n        model= model,\n        tensor_parallel_size=1,\n        gpu_memory_utilization=0.90, # Reduced to prevent OOM\n        trust_remote_code=True,\n        dtype=\"half\" ,\n        quantization=\"bitsandbytes\",\n        #load_format=\"bitsandbytes\" ,\n        enforce_eager=True,\n        max_model_len=700,  # Reduced from 2048 to fix Triton shared memory error on T4\n        disable_log_stats=True,\n        enable_prefix_caching=True,\n        enable_lora=True,\n        max_lora_rank=64,  # Support Unsloth's LoRA rank\n        block_size=16,\n        num_gpu_blocks_override=512\n        \n\n        \n    )\n\n    # In validation_vllm.py, modify the LLM initialization:\n    # llm = vllm.LLM(\n    #     BASE_MODEL_PATH,\n    #     tensor_parallel_size=1,\n    #     gpu_memory_utilization=0.90,\n    #     trust_remote_code=True,\n    #     dtype=\"half\",  # Use half precision instead of quantization\n    #     enforce_eager=True,\n    #     max_model_len=512,\n    #     disable_log_stats=True,\n    #     enable_prefix_caching=True,\n    #     enable_lora=True,\n    #     max_lora_rank=64,\n    # )\n\n    tokenizer = llm.get_tokenizer()\n\n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n\n    # 🎯 VLLM: Generate with Unsloth LoRA for most accurate probabilities\n    # We remove the logits_processor and decrease logprobs to get token probabilities\n    outputs = llm.generate(\n        texts,\n        vllm.SamplingParams(\n            skip_special_tokens=True,\n            max_tokens=1,\n            logprobs=20,  # Request top 20 logprobs to find \"Yes\" and \"No\"\n        ),\n        use_tqdm=True,\n        lora_request=LoRARequest(\"unsloth_lora\", 1, LORA_PATH)  # Load Unsloth LoRA\n    )\n\n    # Extract predictions and probabilities with vLLM precision\n    predictions = []\n    probabilities = []  # High-precision probabilities for AUC\n    \n    # Get token IDs for \"Yes\" and \"No\"\n    yes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\n    no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n    \n    for out in outputs:\n        # Safely get log probabilities for \"Yes\" and \"No\"\n        log_probs = out.outputs[0].logprobs[0]\n        \n        log_prob_yes = log_probs.get(yes_token_id)\n        log_prob_no = log_probs.get(no_token_id)\n        \n        # Handle cases where tokens might not be in the top logprobs\n        if log_prob_yes is not None and log_prob_no is not None:\n            if log_prob_yes.logprob > log_prob_no.logprob:\n                predictions.append(1)\n            else:\n                predictions.append(0)\n            \n            # Calculate precise probability for AUC\n            exp_pos = np.exp(log_prob_yes.logprob)\n            exp_neg = np.exp(log_prob_no.logprob)\n            prob_positive = exp_pos / (exp_pos + exp_neg)\n            probabilities.append(prob_positive)\n        else:\n            # Fallback if one of the tokens is not in the top 20 logprobs\n            # This is unlikely but a safe fallback\n            predictions.append(0)\n            probabilities.append(0.5)\n\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    # Basic metrics\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"📊 TT-11 VALIDATION RESULTS (Unsloth + vLLM)\")\n    print(\"=\" * 60)\n    print(f\"🎯 Accuracy:  {accuracy:.4f}\")\n    print(f\"🎯 F1 Score:  {f1:.4f}\")\n    print(f\"🎯 Precision: {precision:.4f}\")\n    print(f\"🎯 Recall:    {recall:.4f}\")\n    print(f\"🎯 AUC Score: {auc:.4f} (High-precision vLLM)\")\n    print(\"=\" * 60)\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n📈 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    # Classification report\n    print(\"\\n📋 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'auc': auc,\n        'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-11: Unsloth Training + vLLM Validation Results', fontsize=16, fontweight='bold')\n    \n    # 1. Confusion Matrix Heatmap\n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    # 2. ROC Curve\n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (vLLM High-Precision)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # 3. Probability Distribution\n    pos_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 1]\n    neg_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (vLLM Precision)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    # 4. Metrics Bar Chart\n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics['accuracy'], metrics['f1'], metrics['precision'], metrics['recall'], metrics['auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (Unsloth + vLLM)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt11_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    # Add predictions to dataframe\n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n📊 PERFORMANCE BY RULE (vLLM High-Precision AUC):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        if len(np.unique(rule_true)) > 1:  # Check if both classes exist\n            rule_auc = roc_auc_score(rule_true, rule_prob)\n        else:\n            rule_auc = np.nan\n            \n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\")\n        print(f\"  Samples: {len(rule_data)}\")\n        print(f\"  Accuracy: {rule_acc:.3f}\")\n        print(f\"  F1 Score: {rule_f1:.3f}\" if not np.isnan(rule_f1) else \"  F1 Score: N/A\")\n        print(f\"  AUC Score: {rule_auc:.3f}\" if not np.isnan(rule_auc) else \"  AUC Score: N/A\")\n        print()\n        \n        rule_metrics.append({\n            'rule': rule,\n            'samples': len(rule_data),\n            'accuracy': rule_acc,\n            'f1': rule_f1,\n            'auc': rule_auc\n        })\n    \n    # Save detailed results\n    analysis_df.to_csv('/kaggle/working/tt11_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt11_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"🔬 TT-11: Unsloth Training + vLLM Validation\")\n    print(\"🚀 Ultra-fast training + High-precision inference!\")\n    print(\"📚 Training: Model learned from examples with Unsloth speed\")\n    print(\"🧪 Validation: Testing on real comments with vLLM precision\")\n    print(\"=\" * 70)\n    \n    # Run validation\n    true_labels, predictions, probabilities, val_df = run_validation_vllm()\n    \n    # Calculate metrics\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    \n    # Create visualizations\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    \n    # Analyze by rule\n    rule_metrics = analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"✅ TT-11 Validation completed!\")\n    print(\"📈 Visualizations saved: /kaggle/working/tt11_validation_results.png\")\n    print(\"📊 Detailed results: /kaggle/working/tt11_detailed_results.csv\")\n    print(\"📋 Rule metrics: /kaggle/working/tt11_rule_metrics.csv\")\n    print(\"🎯 Best of both worlds: Unsloth speed + vLLM precision!\")\n    \n    return metrics, rule_metrics\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T03:33:30.211264Z","iopub.execute_input":"2025-09-19T03:33:30.211543Z","iopub.status.idle":"2025-09-19T03:33:30.220823Z","shell.execute_reply.started":"2025-09-19T03:33:30.211522Z","shell.execute_reply":"2025-09-19T03:33:30.220255Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Writing validation_vllm.py\n","output_type":"stream"}],"execution_count":7},{"id":"07ec1ce0","cell_type":"code","source":"%%writefile validation_transformers.py\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom unsloth import FastLanguageModel  # Add this import\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\nfrom constants import *\nfrom tqdm import tqdm\n\ndef run_validation_transformers():\n    \"\"\"Run validation using Unsloth fast inference with merged LoRA - Maximum speed!\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"🔍 Running validation on {len(val_dataset)} real comments (Unsloth Fast Inference)\")\n    \n    # 🚀 UNSLOTH: Load merged model with fast inference support\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=\"/kaggle/working/qwen3_1.7b_merged\",  # Use merged model path\n        max_seq_length=2048,\n        load_in_4bit=True,  # Keep 4-bit for speed\n        dtype=None,\n    )\n    \n    # 🚀 UNSLOTH: Enable fast inference mode\n    FastLanguageModel.for_inference(model)\n    \n    # Get token IDs for \"Yes\" and \"No\"\n    yes_token_id = YES_TOKEN_ID  \n    no_token_id = NO_TOKEN_ID \n    \n    print(f\"🎯 Token IDs: Yes={yes_token_id}, No={no_token_id}\")\n    \n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n    \n    # 🚀 UNSLOTH: Fast batch inference\n    predictions = []\n    probabilities = []\n    batch_size = 16  # Larger batches with Unsloth optimization\n    \n    print(\"🚀 Running fast inference with Unsloth...\")\n    \n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch_texts = texts[i:i+batch_size]\n        \n        # 🚀 UNSLOTH: Optimized tokenization and inference\n        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            # 🚀 UNSLOTH: Fast forward pass\n            outputs = model(**inputs)\n            next_token_logits = outputs.logits[:, -1, :]  # Get last token logits\n            \n            # Get probabilities for \"Yes\" and \"No\" tokens\n            yes_logits = next_token_logits[:, yes_token_id]\n            no_logits = next_token_logits[:, no_token_id]\n            \n            # Convert to probabilities using softmax over Yes/No only\n            combined_logits = torch.stack([no_logits, yes_logits], dim=1)  # [batch, 2]\n            probs = torch.softmax(combined_logits, dim=1)  # [batch, 2]\n            \n            # Extract predictions and probabilities\n            batch_predictions = torch.argmax(probs, dim=1).cpu().numpy()\n            batch_probabilities = probs[:, 1].cpu().numpy()  # Probability of \"Yes\" (violation)\n            \n            predictions.extend(batch_predictions.tolist())\n            probabilities.extend(batch_probabilities.tolist())\n    \n    print(\"✅ Fast inference completed!\")\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    # Basic metrics\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"📊 TT-11 VALIDATION RESULTS (Unsloth + Transformers)\")\n    print(\"=\" * 60)\n    print(f\"🎯 Accuracy:  {accuracy:.4f}\")\n    print(f\"🎯 F1 Score:  {f1:.4f}\")\n    print(f\"🎯 Precision: {precision:.4f}\")\n    print(f\"🎯 Recall:    {recall:.4f}\")\n    print(f\"🎯 AUC Score: {auc:.4f} (Standard Transformers)\")\n    print(\"=\" * 60)\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n📈 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    # Classification report\n    print(\"\\n📋 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'auc': auc,\n        'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-11: Unsloth Training + Transformers Validation Results', fontsize=16, fontweight='bold')\n    \n    # 1. Confusion Matrix Heatmap\n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    # 2. ROC Curve\n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (Transformers)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # 3. Probability Distribution\n    pos_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 1]\n    neg_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (Transformers)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    # 4. Metrics Bar Chart\n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics['accuracy'], metrics['f1'], metrics['precision'], metrics['recall'], metrics['auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (Unsloth + Transformers)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt11_transformers_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    # Add predictions to dataframe\n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n📊 PERFORMANCE BY RULE (Transformers):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        if len(np.unique(rule_true)) > 1:  # Check if both classes exist\n            rule_auc = roc_auc_score(rule_true, rule_prob)\n        else:\n            rule_auc = np.nan\n            \n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\")\n        print(f\"  Samples: {len(rule_data)}\")\n        print(f\"  Accuracy: {rule_acc:.3f}\")\n        print(f\"  F1 Score: {rule_f1:.3f}\" if not np.isnan(rule_f1) else \"  F1 Score: N/A\")\n        print(f\"  AUC Score: {rule_auc:.3f}\" if not np.isnan(rule_auc) else \"  AUC Score: N/A\")\n        print()\n        \n        rule_metrics.append({\n            'rule': rule,\n            'samples': len(rule_data),\n            'accuracy': rule_acc,\n            'f1': rule_f1,\n            'auc': rule_auc\n        })\n    \n    # Save detailed results\n    analysis_df.to_csv('/kaggle/working/tt11_transformers_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt11_transformers_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"🔬 TT-11: Unsloth Training + Transformers Validation\")\n    print(\"🚀 Ultra-fast training + Universal compatibility!\")\n    print(\"📚 Training: Model learned from examples with Unsloth speed\")\n    print(\"🧪 Validation: Testing on real comments with standard Transformers\")\n    print(\"=\" * 70)\n    \n    # Run validation\n    true_labels, predictions, probabilities, val_df = run_validation_transformers()\n    \n    # Calculate metrics\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    \n    # Create visualizations\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    \n    # Analyze by rule\n    rule_metrics = analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"✅ TT-11 Transformers Validation completed!\")\n    print(\"📈 Visualizations saved: /kaggle/working/tt11_transformers_validation_results.png\")\n    print(\"📊 Detailed results: /kaggle/working/tt11_transformers_detailed_results.csv\")\n    print(\"📋 Rule metrics: /kaggle/working/tt11_transformers_rule_metrics.csv\")\n    print(\"🎯 Reliable and compatible validation with Unsloth speed!\")\n    \n    return metrics, rule_metrics\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-09-19T15:48:49.551939Z","iopub.execute_input":"2025-09-19T15:48:49.552682Z","iopub.status.idle":"2025-09-19T15:48:49.562868Z","shell.execute_reply.started":"2025-09-19T15:48:49.552657Z","shell.execute_reply":"2025-09-19T15:48:49.562130Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting validation_transformers.py\n","output_type":"stream"}],"execution_count":14},{"id":"1f12f4c8","cell_type":"code","source":"%%writefile accelerate_config.yaml\ncompute_environment: LOCAL_MACHINE\ndebug: false\n# #deepspeed_config:\n#   gradient_accumulation_steps: auto\n#   gradient_clipping: 1.0\n#   train_batch_size: 16\n#   train_micro_batch_size_per_gpu: 2\n  \n#   zero_stage: 2\n#   offload_optimizer_device: none\n#   offload_param_device: none\n#   zero3_init_flag: false\n  \n#   stage3_gather_16bit_weights_on_model_save: false\n#   stage3_max_live_parameters: 1e8\n#   stage3_max_reuse_distance: 1e8\n#   stage3_prefetch_bucket_size: 5e7\n#   stage3_param_persistence_threshold: 1e5\n  \n#   zero_allow_untested_optimizer: true\n#   zero_force_ds_cpu_optimizer: false\n  \n#   fp16:\n#     enabled: true\n#     loss_scale: 0\n#     initial_scale_power: 16\n#     loss_scale_window: 1000\n#     hysteresis: 2\n#     min_loss_scale: 1\n  \ndistributed_type: None\ndowncast_bf16: 'no'\ndynamo_config:\n  dynamo_backend: INDUCTOR\n  dynamo_use_fullgraph: false\n  dynamo_use_dynamic: false\nenable_cpu_affinity: false\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 1\nnum_processes: 2\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false","metadata":{"execution":{"iopub.execute_input":"2025-09-15T11:40:14.900532Z","iopub.status.busy":"2025-09-15T11:40:14.900015Z","iopub.status.idle":"2025-09-15T11:40:14.912715Z","shell.execute_reply":"2025-09-15T11:40:14.912134Z","shell.execute_reply.started":"2025-09-15T11:40:14.900507Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting accelerate_config.yaml\n"]}],"execution_count":17},{"id":"89067d5c-d199-4b5c-9a3e-275b7e6c2cba","cell_type":"code","source":"%%writefile accelerate_config.yaml\ncompute_environment: LOCAL_MACHINE\ndebug: false\n# Removed deepspeed_config section entirely\ndistributed_type:  NO   # Changed from DEEPSPEED to MULTI_GPU\ndowncast_bf16: 'no'\ndynamo_config:\n  dynamo_backend: INDUCTOR\n  dynamo_use_fullgraph: false\n  dynamo_use_dynamic: false\nenable_cpu_affinity: false\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 1\nnum_processes: 2  # Keep this for 2 GPUs\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false","metadata":{"execution":{"iopub.status.busy":"2025-09-19T15:46:31.070208Z","iopub.execute_input":"2025-09-19T15:46:31.070951Z","iopub.status.idle":"2025-09-19T15:46:31.075820Z","shell.execute_reply.started":"2025-09-19T15:46:31.070927Z","shell.execute_reply":"2025-09-19T15:46:31.075024Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Writing accelerate_config.yaml\n","output_type":"stream"}],"execution_count":9},{"id":"98dd1f21","cell_type":"code","source":"!accelerate launch --config_file accelerate_config.yaml train_unsloth.py\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T15:49:06.764351Z","iopub.execute_input":"2025-09-19T15:49:06.764657Z","iopub.status.idle":"2025-09-19T16:21:24.145912Z","shell.execute_reply.started":"2025-09-19T15:49:06.764635Z","shell.execute_reply":"2025-09-19T16:21:24.145036Z"},"trusted":true},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-19 15:49:18.445046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758296958.470545     313 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758296958.478146     313 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-19 15:49:26 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-19 15:49:27 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n🦥 Unsloth Zoo will now patch everything to make training faster!\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 100% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n📊 Training data size: 2029 samples\n📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 1017, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 1012}\n📊 Example-based training dataset: 8112 samples\n📊 Positive examples: 4055\n📊 Negative examples: 4057\nTraining dataset size: 8112 samples\nAvailable GPUs: 2\nUnsloth: WARNING `trust_remote_code` is True.\nAre you certain you want to do remote code execution?\n==((====))==  Unsloth 2025.9.7: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n✅ Unsloth model loaded with 4-bit quantization across 2x T4\nUnsloth 2025.9.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n✅ Unsloth LoRA adapters added\n✅ Unsloth training arguments configured for 2x T4\nUnsloth: Tokenizing [\"text\"] (num_proc=8): 100%|█| 8112/8112 [00:06<00:00, 1282.\n[2025-09-19 15:50:05,199] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-19 15:50:06,805] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n🚀 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\nUnsloth: Enabled auto compiling\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n   \\\\   /|    Num examples = 8,112 | Num Epochs = 1 | Total steps = 127\nO^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n \"-____-\"     Trainable parameters = 17,432,576 of 1,738,007,552 (1.00% trained)\n  0%|                                                   | 0/127 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!\n{'loss': 3.9606, 'grad_norm': 27.963727951049805, 'learning_rate': 0.0, 'epoch': 0.01}\n{'loss': 4.0961, 'grad_norm': 29.619474411010742, 'learning_rate': 4e-05, 'epoch': 0.02}\n{'loss': 3.6016, 'grad_norm': 5.906733512878418, 'learning_rate': 8e-05, 'epoch': 0.02}\n{'loss': 3.3732, 'grad_norm': 4.095688343048096, 'learning_rate': 0.00012, 'epoch': 0.03}\n{'loss': 3.0917, 'grad_norm': 3.0609142780303955, 'learning_rate': 0.00016, 'epoch': 0.04}\n{'loss': 2.8503, 'grad_norm': 2.758763551712036, 'learning_rate': 0.0002, 'epoch': 0.05}\n{'loss': 2.5993, 'grad_norm': 2.792922258377075, 'learning_rate': 0.0001999668467514313, 'epoch': 0.06}\n{'loss': 2.4487, 'grad_norm': 2.3459484577178955, 'learning_rate': 0.00019986740898848306, 'epoch': 0.06}\n{'loss': 2.1854, 'grad_norm': 1.9238590002059937, 'learning_rate': 0.00019970175264485266, 'epoch': 0.07}\n{'loss': 2.0221, 'grad_norm': 1.5313948392868042, 'learning_rate': 0.0001994699875614589, 'epoch': 0.08}\n{'loss': 2.0648, 'grad_norm': 1.5329726934432983, 'learning_rate': 0.00019917226741361015, 'epoch': 0.09}\n{'loss': 2.026, 'grad_norm': 1.3553873300552368, 'learning_rate': 0.00019880878960910772, 'epoch': 0.09}\n{'loss': 1.8914, 'grad_norm': 0.8347269296646118, 'learning_rate': 0.00019837979515735166, 'epoch': 0.1}\n{'loss': 1.9087, 'grad_norm': 0.7963870763778687, 'learning_rate': 0.0001978855685095358, 'epoch': 0.11}\n{'loss': 1.8852, 'grad_norm': 1.0383124351501465, 'learning_rate': 0.00019732643737003827, 'epoch': 0.12}\n{'loss': 1.9028, 'grad_norm': 0.8030833005905151, 'learning_rate': 0.00019670277247913205, 'epoch': 0.13}\n{'loss': 1.8257, 'grad_norm': 0.7289297580718994, 'learning_rate': 0.00019601498736716017, 'epoch': 0.13}\n{'loss': 1.7676, 'grad_norm': 0.7107284665107727, 'learning_rate': 0.00019526353808033825, 'epoch': 0.14}\n{'loss': 1.7255, 'grad_norm': 0.6533088088035583, 'learning_rate': 0.00019444892287836613, 'epoch': 0.15}\n{'loss': 1.7094, 'grad_norm': 0.6973357796669006, 'learning_rate': 0.00019357168190404936, 'epoch': 0.16}\n{'loss': 1.6611, 'grad_norm': 0.6936821937561035, 'learning_rate': 0.00019263239682514952, 'epoch': 0.17}\n{'loss': 1.7297, 'grad_norm': 0.6596165299415588, 'learning_rate': 0.0001916316904487005, 'epoch': 0.17}\n{'loss': 1.673, 'grad_norm': 0.6916879415512085, 'learning_rate': 0.00019057022630804716, 'epoch': 0.18}\n{'loss': 1.6636, 'grad_norm': 0.716342568397522, 'learning_rate': 0.00018944870822287956, 'epoch': 0.19}\n{'loss': 1.5817, 'grad_norm': 0.7004151940345764, 'learning_rate': 0.00018826787983255473, 'epoch': 0.2}\n{'loss': 1.541, 'grad_norm': 0.722049355506897, 'learning_rate': 0.00018702852410301554, 'epoch': 0.21}\n{'loss': 1.551, 'grad_norm': 0.7894964814186096, 'learning_rate': 0.00018573146280763324, 'epoch': 0.21}\n{'loss': 1.4702, 'grad_norm': 0.8608500957489014, 'learning_rate': 0.00018437755598231856, 'epoch': 0.22}\n{'loss': 1.4807, 'grad_norm': 0.8872397541999817, 'learning_rate': 0.0001829677013552619, 'epoch': 0.23}\n{'loss': 1.4991, 'grad_norm': 0.8692041039466858, 'learning_rate': 0.00018150283375168114, 'epoch': 0.24}\n{'loss': 1.4282, 'grad_norm': 0.8752294182777405, 'learning_rate': 0.00017998392447397197, 'epoch': 0.24}\n{'loss': 1.3304, 'grad_norm': 0.9530588388442993, 'learning_rate': 0.00017841198065767107, 'epoch': 0.25}\n{'loss': 1.3641, 'grad_norm': 1.0077812671661377, 'learning_rate': 0.00017678804460366, 'epoch': 0.26}\n{'loss': 1.2729, 'grad_norm': 1.0493733882904053, 'learning_rate': 0.00017511319308705198, 'epoch': 0.27}\n{'loss': 1.2799, 'grad_norm': 1.0854042768478394, 'learning_rate': 0.00017338853664321992, 'epoch': 0.28}\n{'loss': 1.2804, 'grad_norm': 1.112818956375122, 'learning_rate': 0.00017161521883143934, 'epoch': 0.28}\n{'loss': 1.2557, 'grad_norm': 1.2198867797851562, 'learning_rate': 0.00016979441547663435, 'epoch': 0.29}\n{'loss': 1.1835, 'grad_norm': 1.2053773403167725, 'learning_rate': 0.00016792733388972932, 'epoch': 0.3}\n{'loss': 1.1598, 'grad_norm': 1.4565247297286987, 'learning_rate': 0.00016601521206712318, 'epoch': 0.31}\n{'loss': 1.1008, 'grad_norm': 1.2909075021743774, 'learning_rate': 0.00016405931786981755, 'epoch': 0.32}\n{'loss': 1.137, 'grad_norm': 1.2395527362823486, 'learning_rate': 0.00016206094818274229, 'epoch': 0.32}\n{'loss': 1.0975, 'grad_norm': 1.381268858909607, 'learning_rate': 0.00016002142805483685, 'epoch': 0.33}\n{'loss': 1.0682, 'grad_norm': 1.469387412071228, 'learning_rate': 0.00015794210982045636, 'epoch': 0.34}\n{'loss': 1.0013, 'grad_norm': 1.3797062635421753, 'learning_rate': 0.00015582437220268647, 'epoch': 0.35}\n{'loss': 1.0189, 'grad_norm': 1.563994288444519, 'learning_rate': 0.00015366961939916008, 'epoch': 0.36}\n{'loss': 0.9806, 'grad_norm': 1.5723360776901245, 'learning_rate': 0.0001514792801509831, 'epoch': 0.36}\n{'loss': 0.9736, 'grad_norm': 1.3931622505187988, 'learning_rate': 0.00014925480679538647, 'epoch': 0.37}\n{'loss': 0.9245, 'grad_norm': 1.4371016025543213, 'learning_rate': 0.000146997674302732, 'epoch': 0.38}\n{'loss': 0.8904, 'grad_norm': 1.649793267250061, 'learning_rate': 0.0001447093792985114, 'epoch': 0.39}\n{'loss': 0.7929, 'grad_norm': 1.5633816719055176, 'learning_rate': 0.0001423914390709861, 'epoch': 0.39}\n{'loss': 0.8904, 'grad_norm': 1.5980695486068726, 'learning_rate': 0.00014004539056512667, 'epoch': 0.4}\n{'loss': 0.8183, 'grad_norm': 1.5381282567977905, 'learning_rate': 0.00013767278936351854, 'epoch': 0.41}\n{'loss': 0.6814, 'grad_norm': 1.780490756034851, 'learning_rate': 0.0001352752086549095, 'epoch': 0.42}\n{'loss': 0.8284, 'grad_norm': 1.6084561347961426, 'learning_rate': 0.0001328542381910835, 'epoch': 0.43}\n{'loss': 0.7582, 'grad_norm': 1.631435513496399, 'learning_rate': 0.0001304114832327518, 'epoch': 0.43}\n{'loss': 0.7761, 'grad_norm': 1.5321612358093262, 'learning_rate': 0.00012794856348516095, 'epoch': 0.44}\n{'loss': 0.7172, 'grad_norm': 1.5104917287826538, 'learning_rate': 0.00012546711202412287, 'epoch': 0.45}\n{'loss': 0.6648, 'grad_norm': 1.555009365081787, 'learning_rate': 0.0001229687742131796, 'epoch': 0.46}\n{'loss': 0.6583, 'grad_norm': 2.308988571166992, 'learning_rate': 0.0001204552066126201, 'epoch': 0.47}\n{'loss': 0.6456, 'grad_norm': 1.8110445737838745, 'learning_rate': 0.00011792807588107357, 'epoch': 0.47}\n{'loss': 0.6934, 'grad_norm': 1.5467755794525146, 'learning_rate': 0.0001153890576704062, 'epoch': 0.48}\n{'loss': 0.6427, 'grad_norm': 1.6585923433303833, 'learning_rate': 0.00011283983551465511, 'epoch': 0.49}\n{'loss': 0.7172, 'grad_norm': 1.5157184600830078, 'learning_rate': 0.00011028209971373605, 'epoch': 0.5}\n{'loss': 0.5675, 'grad_norm': 1.7015628814697266, 'learning_rate': 0.00010771754621266466, 'epoch': 0.5}\n{'loss': 0.5606, 'grad_norm': 1.6466330289840698, 'learning_rate': 0.00010514787547703466, 'epoch': 0.51}\n{'loss': 0.5361, 'grad_norm': 1.516118049621582, 'learning_rate': 0.00010257479136549889, 'epoch': 0.52}\n{'loss': 0.5771, 'grad_norm': 1.4309555292129517, 'learning_rate': 0.0001, 'epoch': 0.53}\n{'loss': 0.5161, 'grad_norm': 1.5421220064163208, 'learning_rate': 9.742520863450115e-05, 'epoch': 0.54}\n{'loss': 0.5307, 'grad_norm': 1.5092118978500366, 'learning_rate': 9.485212452296535e-05, 'epoch': 0.54}\n{'loss': 0.5092, 'grad_norm': 1.4499168395996094, 'learning_rate': 9.228245378733537e-05, 'epoch': 0.55}\n{'loss': 0.5369, 'grad_norm': 1.8871662616729736, 'learning_rate': 8.971790028626395e-05, 'epoch': 0.56}\n{'loss': 0.5177, 'grad_norm': 1.5119303464889526, 'learning_rate': 8.71601644853449e-05, 'epoch': 0.57}\n{'loss': 0.4752, 'grad_norm': 1.6642205715179443, 'learning_rate': 8.461094232959381e-05, 'epoch': 0.58}\n{'loss': 0.4661, 'grad_norm': 1.5104140043258667, 'learning_rate': 8.207192411892646e-05, 'epoch': 0.58}\n{'loss': 0.4552, 'grad_norm': 1.5709317922592163, 'learning_rate': 7.954479338737995e-05, 'epoch': 0.59}\n{'loss': 0.462, 'grad_norm': 1.5294740200042725, 'learning_rate': 7.703122578682046e-05, 'epoch': 0.6}\n{'loss': 0.4889, 'grad_norm': 1.9224787950515747, 'learning_rate': 7.453288797587714e-05, 'epoch': 0.61}\n{'loss': 0.4505, 'grad_norm': 1.4147456884384155, 'learning_rate': 7.205143651483906e-05, 'epoch': 0.62}\n{'loss': 0.4736, 'grad_norm': 1.4440032243728638, 'learning_rate': 6.958851676724823e-05, 'epoch': 0.62}\n{'loss': 0.4431, 'grad_norm': 1.3452149629592896, 'learning_rate': 6.714576180891654e-05, 'epoch': 0.63}\n{'loss': 0.425, 'grad_norm': 1.6527376174926758, 'learning_rate': 6.472479134509052e-05, 'epoch': 0.64}\n{'loss': 0.3816, 'grad_norm': 1.8321983814239502, 'learning_rate': 6.232721063648148e-05, 'epoch': 0.65}\n{'loss': 0.4298, 'grad_norm': 1.4802950620651245, 'learning_rate': 5.9954609434873344e-05, 'epoch': 0.65}\n{'loss': 0.4054, 'grad_norm': 1.3866734504699707, 'learning_rate': 5.7608560929013946e-05, 'epoch': 0.66}\n{'loss': 0.3925, 'grad_norm': 1.3750758171081543, 'learning_rate': 5.5290620701488594e-05, 'epoch': 0.67}\n{'loss': 0.4446, 'grad_norm': 1.4374603033065796, 'learning_rate': 5.300232569726804e-05, 'epoch': 0.68}\n{'loss': 0.3896, 'grad_norm': 1.3109086751937866, 'learning_rate': 5.074519320461357e-05, 'epoch': 0.69}\n{'loss': 0.3723, 'grad_norm': 1.3989046812057495, 'learning_rate': 4.852071984901696e-05, 'epoch': 0.69}\n{'loss': 0.2894, 'grad_norm': 1.383747935295105, 'learning_rate': 4.633038060083996e-05, 'epoch': 0.7}\n{'loss': 0.3479, 'grad_norm': 1.6017863750457764, 'learning_rate': 4.417562779731355e-05, 'epoch': 0.71}\n{'loss': 0.3261, 'grad_norm': 1.2914007902145386, 'learning_rate': 4.205789017954364e-05, 'epoch': 0.72}\n{'loss': 0.325, 'grad_norm': 1.303375005722046, 'learning_rate': 3.997857194516319e-05, 'epoch': 0.73}\n{'loss': 0.3388, 'grad_norm': 1.3934305906295776, 'learning_rate': 3.793905181725772e-05, 'epoch': 0.73}\n{'loss': 0.3313, 'grad_norm': 1.2261521816253662, 'learning_rate': 3.594068213018249e-05, 'epoch': 0.74}\n{'loss': 0.3704, 'grad_norm': 1.5967504978179932, 'learning_rate': 3.3984787932876814e-05, 'epoch': 0.75}\n{'loss': 0.3371, 'grad_norm': 1.215039849281311, 'learning_rate': 3.207266611027069e-05, 'epoch': 0.76}\n{'loss': 0.2838, 'grad_norm': 1.24811851978302, 'learning_rate': 3.0205584523365626e-05, 'epoch': 0.77}\n{'loss': 0.3554, 'grad_norm': 1.3708409070968628, 'learning_rate': 2.8384781168560693e-05, 'epoch': 0.77}\n{'loss': 0.2767, 'grad_norm': 1.1347594261169434, 'learning_rate': 2.6611463356780096e-05, 'epoch': 0.78}\n{'loss': 0.3043, 'grad_norm': 1.252915859222412, 'learning_rate': 2.4886806912948035e-05, 'epoch': 0.79}\n{'loss': 0.2821, 'grad_norm': 1.1575368642807007, 'learning_rate': 2.3211955396340002e-05, 'epoch': 0.8}\n{'loss': 0.2933, 'grad_norm': 1.1459600925445557, 'learning_rate': 2.1588019342328968e-05, 'epoch': 0.8}\n{'loss': 0.3072, 'grad_norm': 1.225542664527893, 'learning_rate': 2.0016075526028065e-05, 'epoch': 0.81}\n{'loss': 0.3315, 'grad_norm': 1.2049133777618408, 'learning_rate': 1.8497166248318876e-05, 'epoch': 0.82}\n{'loss': 0.2812, 'grad_norm': 1.2672250270843506, 'learning_rate': 1.703229864473811e-05, 'epoch': 0.83}\n{'loss': 0.2565, 'grad_norm': 1.1058695316314697, 'learning_rate': 1.562244401768144e-05, 'epoch': 0.84}\n{'loss': 0.2864, 'grad_norm': 1.1526880264282227, 'learning_rate': 1.426853719236676e-05, 'epoch': 0.84}\n{'loss': 0.2785, 'grad_norm': 1.1278890371322632, 'learning_rate': 1.2971475896984475e-05, 'epoch': 0.85}\n{'loss': 0.2508, 'grad_norm': 1.0775948762893677, 'learning_rate': 1.1732120167445248e-05, 'epoch': 0.86}\n{'loss': 0.2557, 'grad_norm': 1.0933572053909302, 'learning_rate': 1.0551291777120464e-05, 'epoch': 0.87}\n{'loss': 0.3167, 'grad_norm': 1.2470110654830933, 'learning_rate': 9.429773691952858e-06, 'epoch': 0.88}\n{'loss': 0.3033, 'grad_norm': 1.1144095659255981, 'learning_rate': 8.368309551299536e-06, 'epoch': 0.88}\n{'loss': 0.3287, 'grad_norm': 1.0990164279937744, 'learning_rate': 7.367603174850502e-06, 'epoch': 0.89}\n{'loss': 0.2597, 'grad_norm': 1.0472402572631836, 'learning_rate': 6.428318095950647e-06, 'epoch': 0.9}\n{'loss': 0.2682, 'grad_norm': 1.2445391416549683, 'learning_rate': 5.551077121633874e-06, 'epoch': 0.91}\n{'loss': 0.2921, 'grad_norm': 1.0744245052337646, 'learning_rate': 4.7364619196617495e-06, 'epoch': 0.92}\n{'loss': 0.2585, 'grad_norm': 0.9569548964500427, 'learning_rate': 3.985012632839824e-06, 'epoch': 0.92}\n{'loss': 0.2711, 'grad_norm': 1.155077576637268, 'learning_rate': 3.2972275208679625e-06, 'epoch': 0.93}\n{'loss': 0.279, 'grad_norm': 1.16922128200531, 'learning_rate': 2.6735626299617457e-06, 'epoch': 0.94}\n{'loss': 0.2737, 'grad_norm': 1.1087409257888794, 'learning_rate': 2.1144314904642195e-06, 'epoch': 0.95}\n{'loss': 0.2696, 'grad_norm': 1.0905632972717285, 'learning_rate': 1.6202048426483651e-06, 'epoch': 0.95}\n{'loss': 0.2624, 'grad_norm': 1.0595403909683228, 'learning_rate': 1.1912103908922945e-06, 'epoch': 0.96}\n{'loss': 0.2524, 'grad_norm': 1.0417275428771973, 'learning_rate': 8.277325863898511e-07, 'epoch': 0.97}\n{'loss': 0.3117, 'grad_norm': 1.1934953927993774, 'learning_rate': 5.300124385410943e-07, 'epoch': 0.98}\n{'loss': 0.3088, 'grad_norm': 1.0869134664535522, 'learning_rate': 2.9824735514732974e-07, 'epoch': 0.99}\n{'loss': 0.2377, 'grad_norm': 1.032553791999817, 'learning_rate': 1.3259101151694708e-07, 'epoch': 0.99}\n{'loss': 0.2837, 'grad_norm': 1.2714428901672363, 'learning_rate': 3.3153248568695835e-08, 'epoch': 1.0}\n{'train_runtime': 1867.2284, 'train_samples_per_second': 4.344, 'train_steps_per_second': 0.068, 'train_loss': 0.9457822453787946, 'epoch': 1.0}\n100%|█████████████████████████████████████████| 127/127 [31:07<00:00, 14.70s/it]\n✅ Unsloth training completed!\nTraining time: 1867.23 seconds\nSamples/second: 4.34\nGPU utilization optimized for 2x T4 setup\n💾 Saving LoRA adapters for vLLM compatibility...\n/usr/local/lib/python3.11/dist-packages/unsloth_zoo/saving_utils.py:899: UserWarning: Model /kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit not found locally or on HuggingFace\n  warnings.warn(f\"Model {model_name} not found locally or on HuggingFace\")\n✅ LoRA adapters saved to: qwen3_1.7b_unsloth_lora_validation/ , model saved \n🎯 Ready for vLLM inference!\n","output_type":"stream"}],"execution_count":15},{"id":"e4ebaa7a-f6db-4188-8da8-b6a044e7e8a2","cell_type":"code","source":"!python merge_lora.py\n!python validation_transformers.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T16:21:54.814448Z","iopub.execute_input":"2025-09-19T16:21:54.815215Z","iopub.status.idle":"2025-09-19T16:25:36.685261Z","shell.execute_reply.started":"2025-09-19T16:21:54.815190Z","shell.execute_reply":"2025-09-19T16:25:36.684350Z"}},"outputs":[{"name":"stdout","text":"2025-09-19 16:22:01.497672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758298921.523488     600 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758298921.531347     600 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 100% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n🔄 Loading base model...\n🔗 Loading LoRA adapters...\n🔀 Merging LoRA weights...\n/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n💾 Saving merged model...\n[2025-09-19 16:22:14,585] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-19 16:22:15,999] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n✅ Merged model saved to: /kaggle/working/qwen3_1.7b_merged\n🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-19 16:22:29.705914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758298949.731547     659 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758298949.739763     659 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-19 16:22:37 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-19 16:22:38 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n🦥 Unsloth Zoo will now patch everything to make training faster!\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 100% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n🔬 TT-11: Unsloth Training + Transformers Validation\n🚀 Ultra-fast training + Universal compatibility!\n📚 Training: Model learned from examples with Unsloth speed\n🧪 Validation: Testing on real comments with standard Transformers\n======================================================================\n📊 Real comment validation dataset: 2029 samples\n📊 Rule violations: 1031 positive, 998 negative\n🔍 Running validation on 2029 real comments (Unsloth Fast Inference)\n==((====))==  Unsloth 2025.9.7: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n🎯 Token IDs: Yes=7414, No=2308\n🚀 Running fast inference with Unsloth...\n100%|█████████████████████████████████████████| 127/127 [02:42<00:00,  1.28s/it]\n✅ Fast inference completed!\n============================================================\n📊 TT-11 VALIDATION RESULTS (Unsloth + Transformers)\n============================================================\n🎯 Accuracy:  0.5244\n🎯 F1 Score:  0.6657\n🎯 Precision: 0.5178\n🎯 Recall:    0.9321\n🎯 AUC Score: 0.5489 (Standard Transformers)\n============================================================\n\n📈 Confusion Matrix:\nTrue Negative:  103 | False Positive:  895\nFalse Negative:   70 | True Positive:   961\n\n📋 Classification Report:\n              precision    recall  f1-score   support\n\nNo Violation       0.60      0.10      0.18       998\n   Violation       0.52      0.93      0.67      1031\n\n    accuracy                           0.52      2029\n   macro avg       0.56      0.52      0.42      2029\nweighted avg       0.56      0.52      0.42      2029\n\nFigure(1500x1200)\n\n📊 PERFORMANCE BY RULE (Transformers):\n============================================================\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\n  Samples: 1012\n  Accuracy: 0.478\n  F1 Score: 0.620\n  AUC Score: 0.646\n\nRule: No legal advice: Do not offer or request legal advice.\n  Samples: 1017\n  Accuracy: 0.570\n  F1 Score: 0.708\n  AUC Score: 0.541\n\n✅ TT-11 Transformers Validation completed!\n📈 Visualizations saved: /kaggle/working/tt11_transformers_validation_results.png\n📊 Detailed results: /kaggle/working/tt11_transformers_detailed_results.csv\n📋 Rule metrics: /kaggle/working/tt11_transformers_rule_metrics.csv\n🎯 Reliable and compatible validation with Unsloth speed!\n","output_type":"stream"}],"execution_count":17},{"id":"47e4a810-f91d-4791-9e8b-eb9271a9a11d","cell_type":"code","source":"print(\"he\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T03:45:17.566249Z","iopub.execute_input":"2025-09-19T03:45:17.566564Z","iopub.status.idle":"2025-09-19T03:45:17.571213Z","shell.execute_reply.started":"2025-09-19T03:45:17.566536Z","shell.execute_reply":"2025-09-19T03:45:17.570519Z"}},"outputs":[{"name":"stdout","text":"he\n","output_type":"stream"}],"execution_count":19},{"id":"c5f82eee-47f5-4d5d-9629-269bd9920917","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"af7c1129-340f-4b7c-a526-69f30132e748","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7fb6f1de-cf68-469e-8f20-a85910bda072","cell_type":"code","source":"import os\nos.environ[\"TRITON_NUM_STAGES\"] = \"1\"  ","metadata":{"execution":{"iopub.execute_input":"2025-09-15T13:30:46.119879Z","iopub.status.busy":"2025-09-15T13:30:46.119258Z","iopub.status.idle":"2025-09-15T13:30:46.123729Z","shell.execute_reply":"2025-09-15T13:30:46.122956Z","shell.execute_reply.started":"2025-09-15T13:30:46.119853Z"},"trusted":true},"outputs":[],"execution_count":87},{"id":"61d65926-118c-463a-b2bf-9fa01b0b0f21","cell_type":"code","source":"#!python train_unsloth.pyfree finetuning.\n","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-09-15T11:42:23.352401Z","iopub.status.busy":"2025-09-15T11:42:23.352158Z","iopub.status.idle":"2025-09-15T11:44:42.354882Z","shell.execute_reply":"2025-09-15T11:44:42.354161Z","shell.execute_reply.started":"2025-09-15T11:42:23.352385Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","2025-09-15 11:42:34.684988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757936554.901474     283 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757936554.964244     283 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","INFO 09-15 11:42:58 [__init__.py:235] Automatically detected platform cuda.\n","ERROR 09-15 11:43:01 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","✅ Using Qwen3 1.7B model from local Kaggle input\n","🎯 TT-11: Unsloth training + vLLM inference with 100% of data\n","📊 Stratified sampling: True\n","📊 Training data size: 2029 samples\n","📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 1017, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 1012}\n","📊 Example-based training dataset: 8112 samples\n","📊 Positive examples: 4055\n","📊 Negative examples: 4057\n","Training dataset size: 8112 samples\n","Available GPUs: 2\n","Unsloth: WARNING `trust_remote_code` is True.\n","Are you certain you want to do remote code execution?\n","==((====))==  Unsloth 2025.9.5: Fast Qwen3 patching. Transformers: 4.56.0. vLLM: 0.10.0.\n","   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","✅ Unsloth model loaded with 4-bit quantization across 2x T4\n","Unsloth 2025.9.5 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","✅ Unsloth LoRA adapters added\n","✅ Unsloth training arguments configured for 2x T4\n","Unsloth: Tokenizing [\"text\"] (num_proc=8): 100%|█| 8112/8112 [00:05<00:00, 1376.\n","[2025-09-15 11:43:42,004] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2025-09-15 11:43:43,386] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n","🚀 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\n","The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n","==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n","   \\\\   /|    Num examples = 8,112 | Num Epochs = 1 | Total steps = 500\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n","\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n"," \"-____-\"     Trainable parameters = 17,432,576 of 1,738,007,552 (1.00% trained)\n","  0%|                                                   | 0/500 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!\n","{'loss': 4.3085, 'grad_norm': 31.93807601928711, 'learning_rate': 0.0, 'epoch': 0.0}\n","{'loss': 4.2223, 'grad_norm': 31.5997371673584, 'learning_rate': 4e-05, 'epoch': 0.0}\n","{'loss': 3.6211, 'grad_norm': 6.902505874633789, 'learning_rate': 8e-05, 'epoch': 0.01}\n","{'loss': 3.4545, 'grad_norm': 3.853771686553955, 'learning_rate': 0.00012, 'epoch': 0.01}\n","{'loss': 3.3724, 'grad_norm': 2.8827977180480957, 'learning_rate': 0.00016, 'epoch': 0.01}\n","{'loss': 3.0868, 'grad_norm': 2.754180908203125, 'learning_rate': 0.0002, 'epoch': 0.01}\n","{'loss': 2.8299, 'grad_norm': 2.893399953842163, 'learning_rate': 0.00019999798600729064, 'epoch': 0.01}\n","{'loss': 2.6515, 'grad_norm': 2.5171403884887695, 'learning_rate': 0.00019999194411028594, 'epoch': 0.02}\n","{'loss': 2.5992, 'grad_norm': 2.1630144119262695, 'learning_rate': 0.0001999818745523526, 'epoch': 0.02}\n","{'loss': 2.4876, 'grad_norm': 2.03615403175354, 'learning_rate': 0.00019996777773909093, 'epoch': 0.02}\n","{'loss': 2.4519, 'grad_norm': 1.9603849649429321, 'learning_rate': 0.00019994965423831854, 'epoch': 0.02}\n","{'loss': 2.4302, 'grad_norm': 2.5908591747283936, 'learning_rate': 0.00019992750478004738, 'epoch': 0.02}\n","{'loss': 2.3586, 'grad_norm': 2.0433380603790283, 'learning_rate': 0.0001999013302564544, 'epoch': 0.03}\n","  3%|█                                         | 13/500 [00:53<30:06,  3.71s/it]^C\n","Traceback (most recent call last):\n","  File \"/kaggle/working/train_unsloth.py\", line 116, in <module>\n","    main()\n","  File \"/kaggle/working/train_unsloth.py\", line 90, in main\n","    trainer_stats = trainer.train()\n","                    ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2328, in train\n","    return inner_training_loop(\n","           ^^^^^^^^^^^^^^^^^^^^\n","  File \"<string>\", line 325, in _fast_inner_training_loop\n","  File \"/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\", line 949, in training_step\n","    return super().training_step(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<string>\", line 40, in _unsloth_training_step\n","  File \"/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\", line 938, in compute_loss\n","    outputs = super().compute_loss(\n","              ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\", line 1299, in _unsloth_pre_compute_loss\n","    outputs = self._old_compute_loss(model, inputs, *args, **kwargs)\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 4099, in compute_loss\n","    outputs = model(**inputs)\n","              ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\", line 818, in forward\n","    return model_forward(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\", line 806, in __call__\n","    return convert_to_fp32(self.model_forward(*args, **kwargs))\n","                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 51, in inner\n","    return disable_fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n","    return fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 1339, in PeftModel_fast_forward\n","    return self.base_model(\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\", line 222, in forward\n","    return self.model.forward(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n","    output = module._old_forward(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 1150, in _CausalLM_fast_forward\n","    outputs = self.model(\n","              ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 962, in LlamaModel_fast_forward\n","    layer_outputs = decoder_layer(\n","                    ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\", line 93, in __call__\n","    return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 51, in inner\n","    return disable_fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n","    return fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\", line 488, in checkpoint\n","    return CheckpointFunction.apply(function, preserve, *args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n","    return super().apply(*args, **kwargs)  # type: ignore[misc]\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth_zoo/gradient_checkpointing.py\", line 477, in forward\n","    outputs = run_function(*args)\n","              ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n","    output = module._old_forward(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 634, in LlamaDecoderLayer_fast_forward\n","    hidden_states, self_attn_weights, present_key_value = self.self_attn(\n","                                                          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n","    output = module._old_forward(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/qwen3.py\", line 121, in Qwen3Attention_fast_forward\n","    Q, K = fast_rope_embedding(Q, K, cos, sin)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n","    return fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/kernels/rope_embedding.py\", line 156, in fast_rope_embedding\n","    Q = Fast_RoPE_Embedding.apply(Q.transpose(1, 2), cos, sin).transpose(1, 2)\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n","    return super().apply(*args, **kwargs)  # type: ignore[misc]\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/kernels/rope_embedding.py\", line 104, in forward\n","    _rope_embedding[(n_rows, n_groups, )](\n","  File \"/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py\", line 347, in <lambda>\n","    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n","                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/triton/runtime/autotuner.py\", line 395, in run\n","    return self.fn.run(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py\", line 583, in run\n","    if callable(grid):\n","       ^^^^^^^^^^^^^^\n","KeyboardInterrupt\n"]}],"execution_count":20},{"id":"c2f2a2e6-0a5f-4668-9e15-671f9c382ac9","cell_type":"code","source":"%%writefile merge_lora.py\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\nfrom constants import BASE_MODEL_PATH, LORA_PATH\n\ndef merge_and_save():\n    print(\"🔄 Loading base model...\")\n    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)\n    model = AutoModelForCausalLM.from_pretrained(\n        BASE_MODEL_PATH,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n    )\n    \n    print(\"🔗 Loading LoRA adapters...\")\n    model = PeftModel.from_pretrained(model, LORA_PATH)\n    \n    print(\"🔀 Merging LoRA weights...\")\n    merged_model = model.merge_and_unload()\n    \n    # Create output directory for merged model\n    merged_path = \"/kaggle/working/qwen3_1.7b_merged\"\n    \n    print(\"💾 Saving merged model...\")\n    merged_model.save_pretrained(merged_path)\n    tokenizer.save_pretrained(merged_path)\n    \n    print(f\"✅ Merged model saved to: {merged_path}\")\n    return merged_path\n\nif __name__ == \"__main__\":\n    merge_and_save()","metadata":{"execution":{"iopub.status.busy":"2025-09-19T16:21:24.147543Z","iopub.execute_input":"2025-09-19T16:21:24.147841Z","iopub.status.idle":"2025-09-19T16:21:24.154426Z","shell.execute_reply.started":"2025-09-19T16:21:24.147814Z","shell.execute_reply":"2025-09-19T16:21:24.153612Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Writing merge_lora.py\n","output_type":"stream"}],"execution_count":16},{"id":"2411162d-432c-4cfc-a62f-2a79d25add2e","cell_type":"code","source":"!python merge_lora.py\n!python validation_transformers.py","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:39:32.695871Z","iopub.execute_input":"2025-09-19T13:39:32.696397Z","iopub.status.idle":"2025-09-19T13:39:58.586828Z","shell.execute_reply.started":"2025-09-19T13:39:32.696374Z","shell.execute_reply":"2025-09-19T13:39:58.585865Z"},"trusted":true},"outputs":[{"name":"stdout","text":"2025-09-19 13:39:38.603112: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758289178.625280     567 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758289178.631843     567 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 50% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n🔄 Loading base model...\n🔗 Loading LoRA adapters...\n🔀 Merging LoRA weights...\n/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n💾 Saving merged model...\n[2025-09-19 13:39:50,880] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-19 13:39:52,185] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n✅ Merged model saved to: /kaggle/working/qwen3_1.7b_merged\n","output_type":"stream"}],"execution_count":10},{"id":"0c2a5c0f-dfe1-46d8-ac5f-237ca8f0912a","cell_type":"markdown","source":"# 💎 OUTPUT TESTINNG\n\n## 🛡️ TESTING OUTPUT\n ","metadata":{}},{"id":"523f99da-0780-426d-84fa-b4327e7f909f","cell_type":"code","source":"from utils import *\nfrom constants import *\nfrom unsloth import FastLanguageModel\nimport torch\ntrain_df = get_example_based_training_data(DATA_PATH)\ndataset = build_dataset_unsloth(train_df)\nmodel , tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"/kaggle/working/qwen3_1.7b_merged\",\n    #model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\" ,\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:42:41.331108Z","iopub.execute_input":"2025-09-19T13:42:41.331998Z","iopub.status.idle":"2025-09-19T13:42:46.345419Z","shell.execute_reply.started":"2025-09-19T13:42:41.331963Z","shell.execute_reply":"2025-09-19T13:42:46.344585Z"},"trusted":true},"outputs":[{"name":"stdout","text":"✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 50% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n📊 Stratified sampling: 1014 samples (50%)\n📊 Training data size: 1014 samples\n📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 508, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 506}\n📊 Example-based training dataset: 4056 samples\n📊 Positive examples: 2028\n📊 Negative examples: 2028\n==((====))==  Unsloth 2025.9.7: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":11},{"id":"4e1fe153-94ae-4e63-a7b0-654f88e9930a","cell_type":"code","source":"dataset[12]","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:42:50.233955Z","iopub.execute_input":"2025-09-19T13:42:50.234583Z","iopub.status.idle":"2025-09-19T13:42:50.240225Z","shell.execute_reply.started":"2025-09-19T13:42:50.234558Z","shell.execute_reply":"2025-09-19T13:42:50.239505Z"},"trusted":true},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'text': '\\nYou are a moderator of a subreddit , your task is to classify if a comment breaks a specific rule.\\nAt first ,the subreddit name and the rule is given.\\nexample (1) is a  example comment that breaks the rule .\\nexample (2) is a example comment that does not break the rule.\\nFinally the comment you are tasked to moderate is given .\\nYour task is think carefully about to classify whether this comment violates the rule.\\nRespond Yes if u think it violates the Rule, Respond No if u think it does not violate the rule .\\nOnly respond Yes or No.\\n\\nSubreddit name: r/AskReddit\\nHere is the rule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nHere is a comment that breaks the rule:\\n1) FindSexToday . com - free girls for sex worldwide 3oBKmqU6XiS14!\\n\\nHere is a comment that does not break the rule:\\n2) **HD** Stream [AFC Bournemouth vs Arsenal Live Stream](http://werdumvsmiociclivestream.com/arsenal.html) \\n\\nEnglish | Mobile:Yes\\n\\nFind if this comment breaks the rule.Answer only Yes or No.\\nComment: playful ladies waiting for you herein http://profusnounfi1986.tumblr.com\\nAnswer: Yes',\n 'completion': 'Yes'}"},"metadata":{}}],"execution_count":12},{"id":"9d4b596d-1aaa-4fa8-8794-041e0864a60b","cell_type":"code","source":"# Get validation data (prompts without answers)\nval_df = get_real_comment_validation_data(DATA_PATH)\nval_dataset = build_validation_dataset(val_df)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:42:54.694523Z","iopub.execute_input":"2025-09-19T13:42:54.695027Z","iopub.status.idle":"2025-09-19T13:42:54.775036Z","shell.execute_reply.started":"2025-09-19T13:42:54.695002Z","shell.execute_reply":"2025-09-19T13:42:54.774431Z"},"trusted":true},"outputs":[{"name":"stdout","text":"📊 Real comment validation dataset: 2029 samples\n📊 Rule violations: 1031 positive, 998 negative\n","output_type":"stream"}],"execution_count":13},{"id":"7bfdfabc-9200-4f5c-a490-c5989c22bf21","cell_type":"code","source":"dataset[1]['text']","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:42:58.450573Z","iopub.execute_input":"2025-09-19T13:42:58.451298Z","iopub.status.idle":"2025-09-19T13:42:58.456078Z","shell.execute_reply.started":"2025-09-19T13:42:58.451259Z","shell.execute_reply":"2025-09-19T13:42:58.455549Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'\\nYou are a moderator of a subreddit , your task is to classify if a comment breaks a specific rule.\\nAt first ,the subreddit name and the rule is given.\\nexample (1) is a  example comment that breaks the rule .\\nexample (2) is a example comment that does not break the rule.\\nFinally the comment you are tasked to moderate is given .\\nYour task is think carefully about to classify whether this comment violates the rule.\\nRespond Yes if u think it violates the Rule, Respond No if u think it does not violate the rule .\\nOnly respond Yes or No.\\n\\nSubreddit name: r/Showerthoughts\\nHere is the rule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nHere is a comment that breaks the rule:\\n1) Selling Tyrande code for 3€ (or equal amount in any other currency) to paypal. PM if interested. \\nhttp://imgur.com/a/IMARW\\n\\nHere is a comment that does not break the rule:\\n2) Must Watch : https://www.youtube.com/watch?v=dQoedIV8LXo\\n\\nFind if this comment breaks the rule.Answer only Yes or No.\\nComment: FindSexToday . com - free girls for sex worldwide 58haxHJwGqyk4!\\nAnswer: Yes'"},"metadata":{}}],"execution_count":14},{"id":"100d443d-55ef-4690-8045-2230008f1305","cell_type":"code","source":"yes_token_id = tokenizer.convert_tokens_to_ids(\" \")\nprint(f\"Token ID for ' Yes': {yes_token_id}\")  # Should be 7414","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:14:38.988806Z","iopub.status.busy":"2025-09-18T20:14:38.988484Z","iopub.status.idle":"2025-09-18T20:14:38.993498Z","shell.execute_reply":"2025-09-18T20:14:38.992754Z","shell.execute_reply.started":"2025-09-18T20:14:38.988782Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Token ID for ' Yes': None\n"]}],"execution_count":83},{"id":"fa611c10-f6e6-4d95-af9a-9159275a9ce5","cell_type":"code","source":"val_dataset[17]","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:44:34.201317Z","iopub.execute_input":"2025-09-19T13:44:34.201590Z","iopub.status.idle":"2025-09-19T13:44:34.206909Z","shell.execute_reply.started":"2025-09-19T13:44:34.201569Z","shell.execute_reply":"2025-09-19T13:44:34.206330Z"},"trusted":true},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'prompt': '\\nYou are a moderator of a subreddit , your task is to classify if a comment breaks a specific rule.\\nAt first ,the subreddit name and the rule is given.\\nexample (1) is a  example comment that breaks the rule .\\nexample (2) is a example comment that does not break the rule.\\nFinally the comment you are tasked to moderate is given .\\nYour task is think carefully about to classify whether this comment violates the rule.\\nRespond Yes if u think it violates the Rule, Respond No if u think it does not violate the rule .\\nOnly respond Yes or No.\\n\\nSubreddit name: r/news\\nHere is the rule: No legal advice: Do not offer or request legal advice.\\nHere is a comment that breaks the rule:\\n1) If they do it, its a war crime.\\nIf we do it, its not.\\n\\n&nbsp;\\n\\nJust consider all the Japanese we executed because they waterboarded US soldiers. Now we just call it enhanced interrogation and its no longer a crime! The magic of legal wordplay!\\n\\nHere is a comment that does not break the rule:\\n2) Depends how much you want to keep your liquor license.  \\n\\nFind if this comment breaks the rule.Answer only Yes or No.\\nComment: It had already come out that she hadn\\'t said no. In the jurisdiction you need either a \"no\" or force to be used for it to be rape. He was leading her to admit that force was used so he could charge the guy.\\nAnswer: ',\n 'rule_violation': 0}"},"metadata":{}}],"execution_count":19},{"id":"3e51eaa7-2062-42f1-b17a-edccb310e9df","cell_type":"code","source":"import torch.nn.functional as F\n\nFastLanguageModel.for_inference(model)\n\n# Prepare input\ninputs = tokenizer(val_dataset[17]['prompt'], return_tensors=\"pt\").to(\"cuda\")\n\n# Get logits for the next token\nwith torch.no_grad():\n    outputs = model(**inputs)\n    next_token_logits = outputs.logits[0, -1, :]  # Shape: [vocab_size]\n\n# ---- FIXED: Use tokens WITH SPACES ----\nyes_token_id = 7414 # tokenizer.convert_tokens_to_ids(\"Yes\")  # WITH space!\nno_token_id = 2308# tokenizer.convert_tokens_to_ids(\"No\")    # WITH space!\n#no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n\nprint(f\"Token IDs: yes_token_id={yes_token_id}, no_token_id={no_token_id}\")\n\n# Extract logits for Yes/No tokens\nyes_logit =  next_token_logits[yes_token_id]  # Single scalar value\nno_logit = next_token_logits[no_token_id]    # Single scalar value\n\nprint(f\"Logit shapes: yes_logit={yes_logit.shape}, no_logit={no_logit.shape}\")\n\n# Convert to probabilities (only for Yes/No)\ncombined_logits = torch.stack([no_logit, yes_logit])  # Shape: [2]\nprobabilities = F.softmax(combined_logits, dim=0)     # Shape: [2]\n\nprob_no = probabilities[0].item()\nprob_yes = probabilities[1].item()\n\nprint(f\"Probability of ' No': {prob_no:.4f}\")\nprint(f\"Probability of ' Yes': {prob_yes:.4f}\")\nprint(f\"Prediction: {'Yes' if prob_yes > prob_no else 'No'}\")\n\n# ---- Top 5 tokens (full vocab) ----\nprobs = F.softmax(next_token_logits, dim=-1)\n\ntop_k = 5\ntop_probs, top_ids = torch.topk(probs, top_k)\ntop_tokens = tokenizer.batch_decode(top_ids.unsqueeze(-1))\n\nprint(\"\\n🔝 Top 5 next tokens:\")\nfor rank, (token, prob) in enumerate(zip(top_tokens, top_probs), start=1):\n    print(f\"{rank}. Token: {repr(token)}\\tProbability: {prob.item():.4f}\")\n\n# ---- Yes / No ranks (from full vocab) ----\nyes_prob = probs[yes_token_id].item()\nno_prob = probs[no_token_id].item()\n\nsorted_probs, sorted_ids = torch.sort(probs, descending=True)\nyes_rank = (sorted_ids == yes_token_id).nonzero(as_tuple=True)[0].item() + 1\nno_rank = (sorted_ids == no_token_id).nonzero(as_tuple=True)[0].item() + 1\n\nprint(\"\\n📊 Specific token stats:\")\nprint(f\"'Yes' → Probability: {yes_prob:.4f}, Rank: {yes_rank}\")\nprint(f\"'No'  → Probability: {no_prob:.4f}, Rank: {no_rank}\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:44:22.294071Z","iopub.execute_input":"2025-09-19T13:44:22.294648Z","iopub.status.idle":"2025-09-19T13:44:22.473078Z","shell.execute_reply.started":"2025-09-19T13:44:22.294624Z","shell.execute_reply":"2025-09-19T13:44:22.472318Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Token IDs: yes_token_id=7414, no_token_id=2308\nLogit shapes: yes_logit=torch.Size([]), no_logit=torch.Size([])\nProbability of ' No': 0.8335\nProbability of ' Yes': 0.1666\nPrediction: No\n\n🔝 Top 5 next tokens:\n1. Token: ' No'\tProbability: 0.7070\n2. Token: ' Yes'\tProbability: 0.1414\n3. Token: '1'\tProbability: 0.0496\n4. Token: ' I'\tProbability: 0.0220\n5. Token: ' Please'\tProbability: 0.0159\n\n📊 Specific token stats:\n'Yes' → Probability: 0.1414, Rank: 2\n'No'  → Probability: 0.7070, Rank: 1\n","output_type":"stream"}],"execution_count":18},{"id":"5e6b5c84-7916-43f1-b7b1-be85021c01a5","cell_type":"code","source":"yes_logits = next_token_logits[:, yes_token_id]\nno_logits = next_token_logits[:, no_token_id]\ncombined_logits = torch.stack([no_logits, yes_logits], dim=1)\nprobs = torch.softmax(combined_logits, dim=1)\npredictions = torch.argmax(probs, dim=1).cpu().numpy()\n\n# Debug: Check actual logit values\nprint(f\"Yes logit: {yes_logits.item():.4f}\")\nprint(f\"No logit: {no_logits.item():.4f}\")\nprint(f\"Prediction: {predictions[0]} (0=No, 1=Yes)\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T03:50:10.173151Z","iopub.execute_input":"2025-09-19T03:50:10.173856Z","iopub.status.idle":"2025-09-19T03:50:10.237222Z","shell.execute_reply.started":"2025-09-19T03:50:10.173832Z","shell.execute_reply":"2025-09-19T03:50:10.236224Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2686309554.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myes_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myes_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mno_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcombined_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mno_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myes_logits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"],"ename":"IndexError","evalue":"too many indices for tensor of dimension 1","output_type":"error"}],"execution_count":32},{"id":"86adeb2f-1f90-4f5d-9a01-a45b8d257746","cell_type":"code","source":"# Test both positions\ninputs = tokenizer(\"Answer:\", return_tensors=\"pt\").to(\"cuda\")\nwith torch.no_grad():\n    outputs = model(**inputs)\n    \n# Check what tokens are at different positions\nfor pos in [-3, -2, -1]:\n    token_id = outputs.logits[0, pos].argmax().item()\n    token = tokenizer.decode([token_id])\n    print(f\"Position {pos}: Token '{token}' (ID: {token_id})\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T03:50:16.453732Z","iopub.execute_input":"2025-09-19T03:50:16.454450Z","iopub.status.idle":"2025-09-19T03:50:16.613136Z","shell.execute_reply.started":"2025-09-19T03:50:16.454425Z","shell.execute_reply":"2025-09-19T03:50:16.612187Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3629330751.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Check what tokens are at different positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtoken_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Position {pos}: Token '{token}' (ID: {token_id})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index -3 is out of bounds for dimension 1 with size 2"],"ename":"IndexError","evalue":"index -3 is out of bounds for dimension 1 with size 2","output_type":"error"}],"execution_count":33},{"id":"cef236ed-a716-4e5a-bb7e-77818e8ba070","cell_type":"code","source":"print(tokenizer.convert_tokens_to_ids(\"No\"))","metadata":{"execution":{"iopub.execute_input":"2025-09-18T18:35:26.144935Z","iopub.status.busy":"2025-09-18T18:35:26.144197Z","iopub.status.idle":"2025-09-18T18:35:26.149498Z","shell.execute_reply":"2025-09-18T18:35:26.148690Z","shell.execute_reply.started":"2025-09-18T18:35:26.144902Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2753\n"]}],"execution_count":43},{"id":"c9c5dee8-abd0-4fd9-a3af-83e8a38fc530","cell_type":"code","source":"negative_indices = val_df[val_df['rule_violation'] == 0].index.tolist()\n\nprint(f\"📊 Total training samples: {len(train_df)}\")\n\nprint(f\"📊 Negative answer samples: {len(negative_indices)}\")\nprint(f\"📊 Positive answer samples: {len(train_df) - len(negative_indices)}\")\nprint(f\"📊 Negative answer indices: {negative_indices}\")\n\n# Show first 10 negative samples for verification\nprint(\"\\n🔍 First 10 negative answer samples:\")\nnegative_samples = train_df[train_df['rule_violation'] == 0].head(10)\nfor idx, row in negative_samples.iterrows():\n    print(f\"Index {idx}: Rule='{row['rule']}', Violation={row['rule_violation']}\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T03:50:21.495203Z","iopub.execute_input":"2025-09-19T03:50:21.495781Z","iopub.status.idle":"2025-09-19T03:50:21.505477Z","shell.execute_reply.started":"2025-09-19T03:50:21.495760Z","shell.execute_reply":"2025-09-19T03:50:21.504789Z"},"trusted":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"📊 Total training samples: 812\n📊 Negative answer samples: 998\n📊 Positive answer samples: -186\n📊 Negative answer indices: [0, 1, 5, 6, 7, 11, 13, 14, 16, 17, 19, 20, 21, 23, 24, 25, 26, 30, 34, 35, 40, 42, 43, 47, 51, 52, 57, 58, 60, 62, 65, 66, 73, 74, 75, 76, 81, 82, 85, 86, 87, 89, 91, 96, 97, 102, 103, 104, 105, 108, 110, 111, 113, 114, 115, 116, 119, 120, 121, 122, 126, 127, 128, 129, 130, 131, 132, 138, 139, 141, 144, 145, 147, 151, 154, 155, 158, 161, 162, 164, 167, 169, 170, 172, 175, 181, 182, 184, 185, 186, 188, 190, 192, 194, 195, 202, 205, 209, 210, 211, 213, 215, 218, 223, 224, 225, 226, 229, 230, 231, 232, 233, 234, 235, 237, 241, 242, 243, 244, 246, 247, 250, 251, 253, 256, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 280, 281, 282, 284, 287, 290, 291, 292, 294, 295, 296, 300, 301, 302, 303, 304, 305, 306, 312, 314, 315, 316, 317, 318, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 342, 347, 348, 349, 353, 356, 360, 361, 363, 364, 365, 366, 367, 370, 373, 376, 381, 382, 383, 386, 388, 390, 392, 394, 395, 399, 400, 402, 403, 404, 405, 406, 408, 410, 411, 415, 419, 420, 423, 428, 430, 433, 435, 436, 437, 438, 440, 442, 443, 445, 448, 449, 450, 451, 452, 454, 455, 456, 458, 459, 460, 464, 466, 467, 469, 472, 475, 476, 477, 479, 480, 481, 483, 489, 493, 495, 501, 503, 504, 506, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 523, 526, 527, 528, 538, 539, 540, 546, 549, 550, 551, 552, 553, 555, 556, 560, 561, 562, 565, 566, 568, 569, 571, 578, 580, 581, 583, 586, 587, 588, 591, 593, 595, 597, 598, 600, 601, 603, 609, 610, 611, 612, 613, 614, 616, 620, 621, 625, 626, 629, 632, 636, 638, 640, 644, 645, 647, 652, 656, 657, 660, 661, 662, 664, 665, 668, 671, 673, 677, 678, 679, 680, 687, 688, 689, 690, 692, 695, 696, 697, 700, 701, 702, 703, 707, 708, 709, 710, 711, 712, 717, 718, 719, 720, 724, 725, 726, 728, 730, 731, 733, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 756, 759, 760, 762, 766, 769, 770, 774, 775, 778, 779, 781, 783, 784, 786, 787, 788, 789, 797, 800, 801, 802, 803, 804, 808, 809, 811, 814, 819, 821, 822, 824, 830, 831, 832, 833, 834, 835, 839, 840, 843, 845, 847, 852, 853, 855, 856, 858, 859, 860, 861, 862, 864, 866, 869, 874, 875, 883, 884, 885, 886, 887, 889, 890, 891, 893, 894, 895, 896, 897, 898, 899, 900, 901, 906, 908, 911, 917, 919, 926, 932, 933, 935, 939, 941, 943, 944, 945, 946, 947, 948, 951, 952, 953, 955, 957, 960, 962, 963, 967, 968, 969, 970, 971, 973, 979, 980, 982, 984, 987, 989, 991, 997, 998, 999, 1000, 1001, 1003, 1006, 1011, 1012, 1014, 1015, 1017, 1018, 1019, 1020, 1023, 1025, 1026, 1027, 1028, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1043, 1046, 1047, 1049, 1056, 1059, 1061, 1062, 1063, 1068, 1069, 1070, 1074, 1075, 1076, 1077, 1079, 1082, 1085, 1087, 1088, 1090, 1092, 1093, 1098, 1099, 1101, 1102, 1104, 1106, 1112, 1114, 1115, 1116, 1118, 1119, 1121, 1122, 1123, 1126, 1127, 1129, 1130, 1132, 1133, 1134, 1136, 1139, 1140, 1143, 1144, 1145, 1148, 1152, 1153, 1156, 1158, 1159, 1160, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1174, 1176, 1177, 1178, 1180, 1181, 1182, 1183, 1185, 1188, 1191, 1194, 1195, 1196, 1197, 1199, 1202, 1205, 1207, 1208, 1209, 1218, 1219, 1220, 1225, 1226, 1227, 1229, 1230, 1232, 1233, 1235, 1236, 1238, 1239, 1241, 1243, 1244, 1245, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1263, 1264, 1265, 1271, 1274, 1276, 1278, 1284, 1287, 1288, 1289, 1290, 1291, 1293, 1295, 1296, 1299, 1304, 1306, 1307, 1309, 1310, 1318, 1321, 1324, 1326, 1327, 1330, 1341, 1343, 1347, 1350, 1351, 1353, 1355, 1357, 1358, 1360, 1361, 1364, 1366, 1367, 1372, 1374, 1377, 1379, 1380, 1384, 1386, 1389, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1406, 1407, 1408, 1409, 1410, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1435, 1436, 1437, 1438, 1439, 1440, 1444, 1445, 1446, 1451, 1452, 1457, 1460, 1461, 1462, 1463, 1467, 1469, 1471, 1476, 1477, 1479, 1481, 1488, 1493, 1494, 1496, 1498, 1500, 1506, 1507, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1520, 1521, 1523, 1527, 1528, 1530, 1532, 1533, 1534, 1535, 1540, 1541, 1543, 1544, 1545, 1547, 1549, 1553, 1556, 1557, 1558, 1562, 1563, 1564, 1566, 1569, 1572, 1574, 1575, 1577, 1581, 1582, 1583, 1584, 1586, 1588, 1590, 1591, 1592, 1593, 1594, 1597, 1601, 1602, 1603, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1626, 1627, 1628, 1629, 1630, 1631, 1633, 1636, 1640, 1646, 1648, 1649, 1650, 1652, 1659, 1663, 1666, 1669, 1671, 1672, 1676, 1677, 1680, 1681, 1683, 1685, 1686, 1687, 1688, 1690, 1691, 1694, 1696, 1697, 1699, 1703, 1705, 1709, 1711, 1715, 1716, 1717, 1720, 1721, 1725, 1727, 1732, 1736, 1737, 1739, 1741, 1744, 1745, 1749, 1750, 1755, 1756, 1762, 1763, 1764, 1767, 1768, 1769, 1770, 1771, 1774, 1775, 1776, 1777, 1778, 1780, 1783, 1789, 1792, 1796, 1797, 1799, 1800, 1801, 1803, 1804, 1805, 1807, 1808, 1812, 1815, 1822, 1830, 1832, 1835, 1836, 1837, 1840, 1844, 1848, 1849, 1850, 1852, 1859, 1861, 1865, 1866, 1870, 1872, 1874, 1875, 1876, 1878, 1880, 1882, 1884, 1885, 1886, 1888, 1889, 1893, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1903, 1904, 1905, 1907, 1908, 1911, 1914, 1916, 1917, 1920, 1923, 1928, 1929, 1930, 1931, 1933, 1936, 1937, 1940, 1941, 1944, 1947, 1948, 1949, 1950, 1952, 1953, 1956, 1958, 1961, 1962, 1963, 1966, 1967, 1969, 1972, 1975, 1979, 1980, 1982, 1984, 1986, 1987, 1989, 1990, 1991, 1992, 1995, 1996, 1997, 2003, 2004, 2006, 2009, 2011, 2013, 2014, 2016, 2020, 2025]\n\n🔍 First 10 negative answer samples:\nIndex 406: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\nIndex 407: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\nIndex 408: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\nIndex 409: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\nIndex 410: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\nIndex 411: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\nIndex 412: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\nIndex 413: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\nIndex 414: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\nIndex 415: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","output_type":"stream"}],"execution_count":34},{"id":"0709d0b6-2d1a-4aa1-9dbe-062d4dee669f","cell_type":"markdown","source":"# 💎 OUTPUT TESTINNG END\n\n## 🛡️ TESTING OUTPUT END\n ","metadata":{}},{"id":"0bd29a2b-2388-423e-8f66-3f23d333650a","cell_type":"code","source":"","metadata":{"execution":{"iopub.execute_input":"2025-09-18T16:02:46.291509Z","iopub.status.busy":"2025-09-18T16:02:46.291227Z","iopub.status.idle":"2025-09-18T16:02:46.309191Z","shell.execute_reply":"2025-09-18T16:02:46.308442Z","shell.execute_reply.started":"2025-09-18T16:02:46.291487Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["maximum token:  or\n"]}],"execution_count":32},{"id":"ca0e7540","cell_type":"code","source":"!python validation_vllm.py","metadata":{"execution":{"iopub.status.busy":"2025-09-19T04:36:00.971263Z","iopub.execute_input":"2025-09-19T04:36:00.972040Z","iopub.status.idle":"2025-09-19T04:36:28.038985Z","shell.execute_reply.started":"2025-09-19T04:36:00.972010Z","shell.execute_reply":"2025-09-19T04:36:28.038006Z"},"trusted":true},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 90% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n🔬 TT-11: Unsloth Training + vLLM Validation\n🚀 Ultra-fast training + High-precision inference!\n📚 Training: Model learned from examples with Unsloth speed\n🧪 Validation: Testing on real comments with vLLM precision\n======================================================================\n📊 Real comment validation dataset: 2029 samples\n📊 Rule violations: 1031 positive, 998 negative\n🔍 Running validation on 2029 real comments\n2025-09-19 04:36:07.671931: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758256567.694792     965 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758256567.701466     965 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-19 04:36:11 [__init__.py:235] Automatically detected platform cuda.\nINFO 09-19 04:36:24 [config.py:1604] Using max model len 700\nWARNING 09-19 04:36:25 [config.py:1084] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\nTraceback (most recent call last):\n  File \"/kaggle/working/validation_vllm.py\", line 293, in <module>\n    main()\n  File \"/kaggle/working/validation_vllm.py\", line 272, in main\n    true_labels, predictions, probabilities, val_df = run_validation_vllm()\n                                                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/validation_vllm.py\", line 28, in run_validation_vllm\n    llm = vllm.LLM(\n          ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/llm.py\", line 273, in __init__\n    self.llm_engine = LLMEngine.from_engine_args(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/vllm/v1/engine/llm_engine.py\", line 144, in from_engine_args\n    vllm_config = engine_args.create_engine_config(usage_context)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\", line 1013, in create_engine_config\n    if try_v1 and self._is_v1_supported_oracle(model_config):\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\", line 1350, in _is_v1_supported_oracle\n    _raise_or_fallback(feature_name=\"Compute Capability < 8.0\",\n  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\", line 1683, in _raise_or_fallback\n    raise NotImplementedError(\nNotImplementedError: VLLM_USE_V1=1 is not supported with Compute Capability < 8.0.\n","output_type":"stream"}],"execution_count":44},{"id":"6b5889e2-653d-497b-9688-fe6bc5c1eccc","cell_type":"code","source":"!pip install --upgrade triton vllm","metadata":{"execution":{"iopub.execute_input":"2025-09-15T13:12:06.349823Z","iopub.status.busy":"2025-09-15T13:12:06.349561Z","iopub.status.idle":"2025-09-15T13:12:20.061449Z","shell.execute_reply":"2025-09-15T13:12:20.060863Z","shell.execute_reply.started":"2025-09-15T13:12:06.349802Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n"]},{"data":{"text/plain":["[]"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"execution_count":76},{"id":"85636388-37ad-48d7-a907-30ddb1963b07","cell_type":"markdown","source":"","metadata":{}},{"id":"4f8bc142","cell_type":"markdown","source":"# 💎 Alternative Validation: Standard Transformers\n\n## 🛡️ **Universal Compatibility Option**\n\nIf vLLM has hardware compatibility issues, use this **guaranteed-to-work** validation method:\n\n### **Advantages:**\n- ✅ **Universal Compatibility**: Works with any GPU and any Unsloth model\n- ✅ **No Hardware Limits**: No shared memory or tensor parallelism restrictions  \n- ✅ **Reliable**: Standard transformers library, battle-tested\n- ✅ **Same Metrics**: Produces identical analysis and visualizations\n\n### **Trade-offs:**\n- ⏱️ **Slower than vLLM**: But still faster than training\n- 📊 **Slightly less precise probabilities**: But still excellent for AUC calculation\n\n**This method loads your Unsloth-trained LoRA adapters using standard transformers and runs inference without any specialized hardware requirements.**","metadata":{}},{"id":"17b96e95","cell_type":"code","source":"%time\n!python validation_transformers.py","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:45:30.914525Z","iopub.execute_input":"2025-09-19T13:45:30.915192Z","iopub.status.idle":"2025-09-19T13:49:28.332170Z","shell.execute_reply.started":"2025-09-19T13:45:30.915168Z","shell.execute_reply":"2025-09-19T13:49:28.331434Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CPU times: user 3 µs, sys: 1 µs, total: 4 µs\nWall time: 11.7 µs\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-19 13:45:37.150321: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758289537.175203     640 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758289537.183116     640 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-19 13:45:44 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-19 13:45:45 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n🦥 Unsloth Zoo will now patch everything to make training faster!\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 50% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n🔬 TT-11: Unsloth Training + Transformers Validation\n🚀 Ultra-fast training + Universal compatibility!\n📚 Training: Model learned from examples with Unsloth speed\n🧪 Validation: Testing on real comments with standard Transformers\n======================================================================\n📊 Real comment validation dataset: 2029 samples\n📊 Rule violations: 1031 positive, 998 negative\n🔍 Running validation on 2029 real comments (Unsloth Fast Inference)\n==((====))==  Unsloth 2025.9.7: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n🎯 Token IDs: Yes=7414, No=2308\n🚀 Running fast inference with Unsloth...\n100%|█████████████████████████████████████████| 127/127 [03:27<00:00,  1.64s/it]\n✅ Fast inference completed!\n============================================================\n📊 TT-11 VALIDATION RESULTS (Unsloth + Transformers)\n============================================================\n🎯 Accuracy:  0.5692\n🎯 F1 Score:  0.6081\n🎯 Precision: 0.5655\n🎯 Recall:    0.6576\n🎯 AUC Score: 0.5892 (Standard Transformers)\n============================================================\n\n📈 Confusion Matrix:\nTrue Negative:  477 | False Positive:  521\nFalse Negative:  353 | True Positive:   678\n\n📋 Classification Report:\n              precision    recall  f1-score   support\n\nNo Violation       0.57      0.48      0.52       998\n   Violation       0.57      0.66      0.61      1031\n\n    accuracy                           0.57      2029\n   macro avg       0.57      0.57      0.56      2029\nweighted avg       0.57      0.57      0.57      2029\n\nFigure(1500x1200)\n\n📊 PERFORMANCE BY RULE (Transformers):\n============================================================\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\n  Samples: 1012\n  Accuracy: 0.612\n  F1 Score: 0.632\n  AUC Score: 0.673\n\nRule: No legal advice: Do not offer or request legal advice.\n  Samples: 1017\n  Accuracy: 0.527\n  F1 Score: 0.586\n  AUC Score: 0.516\n\n✅ TT-11 Transformers Validation completed!\n📈 Visualizations saved: /kaggle/working/tt11_transformers_validation_results.png\n📊 Detailed results: /kaggle/working/tt11_transformers_detailed_results.csv\n📋 Rule metrics: /kaggle/working/tt11_transformers_rule_metrics.csv\n🎯 Reliable and compatible validation with Unsloth speed!\n","output_type":"stream"}],"execution_count":22},{"id":"ef5b5013","cell_type":"code","source":"# Display saved results from TT-11 Transformers Validation\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# Load detailed results from Transformers validation\ntry:\n    detailed_results = pd.read_csv('/kaggle/working/tt11_transformers_detailed_results.csv')\n    print(\"📊 TT-11 Transformers Results Shape:\", detailed_results.shape)\n    print(\"\\n📋 Sample Results:\")\n    print(detailed_results[['rule', 'rule_violation', 'predictions', 'probabilities']].head(10))\n    \n    # Load rule metrics\n    rule_metrics = pd.read_csv('/kaggle/working/tt11_transformers_rule_metrics.csv')\n    print(\"\\n📈 TT-11 Transformers Rule-wise Performance:\")\n    print(rule_metrics)\n    \n    # Performance summary\n    print(\"\\n🎯 TT-11 TRANSFORMERS PERFORMANCE SUMMARY:\")\n    print(\"=\" * 50)\n    overall_accuracy = accuracy_score(detailed_results['rule_violation'], detailed_results['predictions'])\n    avg_probability = detailed_results['probabilities'].mean()\n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Average Confidence: {avg_probability:.4f}\")\n    print(f\"Total Samples: {len(detailed_results)}\")\n    \n    # Compare with vLLM results if available\n    try:\n        vllm_results = pd.read_csv('/kaggle/working/tt11_detailed_results.csv')\n        vllm_accuracy = accuracy_score(vllm_results['rule_violation'], vllm_results['predictions'])\n        vllm_confidence = vllm_results['probabilities'].mean()\n        \n        print(\"\\n🔄 COMPARISON: Transformers vs vLLM:\")\n        print(\"=\" * 50)\n        print(f\"Transformers Accuracy: {overall_accuracy:.4f}\")\n        print(f\"vLLM Accuracy:         {vllm_accuracy:.4f}\")\n        print(f\"Difference:            {abs(overall_accuracy - vllm_accuracy):.4f}\")\n        print(f\"\")\n        print(f\"Transformers Confidence: {avg_probability:.4f}\")\n        print(f\"vLLM Confidence:         {vllm_confidence:.4f}\")\n        print(f\"Difference:              {abs(avg_probability - vllm_confidence):.4f}\")\n        \n    except FileNotFoundError:\n        print(\"\\n💡 Note: Run vLLM validation first to compare results\")\n    \nexcept FileNotFoundError as e:\n    print(f\"❌ Transformers results files not found: {e}\")\n    print(\"Run the Transformers validation cell first to generate results.\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T13:56:07.965604Z","iopub.execute_input":"2025-09-19T13:56:07.965884Z","iopub.status.idle":"2025-09-19T13:56:08.049801Z","shell.execute_reply.started":"2025-09-19T13:56:07.965862Z","shell.execute_reply":"2025-09-19T13:56:08.049120Z"},"trusted":true},"outputs":[{"name":"stdout","text":"📊 TT-11 Transformers Results Shape: (2029, 9)\n\n📋 Sample Results:\n                                                rule  rule_violation  \\\n0  No Advertising: Spam, referral links, unsolici...               0   \n1  No Advertising: Spam, referral links, unsolici...               0   \n2  No legal advice: Do not offer or request legal...               1   \n3  No Advertising: Spam, referral links, unsolici...               1   \n4  No Advertising: Spam, referral links, unsolici...               1   \n5  No legal advice: Do not offer or request legal...               0   \n6  No Advertising: Spam, referral links, unsolici...               0   \n7  No Advertising: Spam, referral links, unsolici...               0   \n8  No legal advice: Do not offer or request legal...               1   \n9  No legal advice: Do not offer or request legal...               1   \n\n   predictions  probabilities  \n0            1       0.905762  \n1            0       0.177856  \n2            0       0.449463  \n3            1       0.924316  \n4            0       0.338135  \n5            1       0.872559  \n6            0       0.294189  \n7            0       0.187134  \n8            0       0.453369  \n9            1       0.725098  \n\n📈 TT-11 Transformers Rule-wise Performance:\n                                                rule  samples  accuracy  \\\n0  No Advertising: Spam, referral links, unsolici...     1012   0.61166   \n1  No legal advice: Do not offer or request legal...     1017   0.52704   \n\n         f1       auc  \n0  0.631678  0.673234  \n1  0.586414  0.515784  \n\n🎯 TT-11 TRANSFORMERS PERFORMANCE SUMMARY:\n==================================================\nOverall Accuracy: 0.5692\nAverage Confidence: 0.5619\nTotal Samples: 2029\n\n💡 Note: Run vLLM validation first to compare results\n","output_type":"stream"}],"execution_count":25},{"id":"b1a79e24-3014-49fe-8038-8936dcf13234","cell_type":"code","source":"\n!accelerate launch --config_file accelerate_config.yaml weight_train_unsloth.py\n    \n!python merge_lora.py\n!python validation_transformers.py","metadata":{"execution":{"iopub.execute_input":"2025-09-18T21:07:37.506096Z","iopub.status.busy":"2025-09-18T21:07:37.505535Z","iopub.status.idle":"2025-09-18T21:09:04.741775Z","shell.execute_reply":"2025-09-18T21:09:04.740420Z","shell.execute_reply.started":"2025-09-18T21:07:37.506069Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","2025-09-18 21:07:48.496285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1758229668.522265    1724 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1758229668.529928    1724 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","INFO 09-18 21:07:56 [__init__.py:235] Automatically detected platform cuda.\n","ERROR 09-18 21:07:58 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","✅ Using Qwen3 1.7B model from local Kaggle input\n","🎯 TT-12: Unsloth training + vLLM inference with 100% of data\n","📊 Stratified sampling: True\n","🎯 NORMAL MODE: Training on both positive and negative examples\n","📊 Training data size: 2029 samples\n","📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 1017, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 1012}\n","📊 Example-based training dataset: 8112 samples\n","📊 Positive examples: 4055\n","📊 Negative examples: 4057\n","Training dataset size: 8112 samples\n","Available GPUs: 2\n","Unsloth: WARNING `trust_remote_code` is True.\n","Are you certain you want to do remote code execution?\n","==((====))==  Unsloth 2025.9.6: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n","   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","✅ Unsloth model loaded with 4-bit quantization across 2x T4\n","Unsloth 2025.9.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","✅ Unsloth LoRA adapters added\n","✅ Unsloth training arguments configured for 2x T4\n","📊 Class Weights: No=0.8, Yes=0.2\n","📊 Penalty Ratio: 4.0x more for false positives\n","Unsloth: Tokenizing [\"text\"] (num_proc=8): 100%|█| 8112/8112 [00:06<00:00, 1200.\n","[2025-09-18 21:08:22,320] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2025-09-18 21:08:22,825] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n","🚀 Starting Unsloth training with weighted loss on 2x T4...\n","🎯 Penalizing false positives 4x more than false negatives\n","Unsloth: Enabled auto compiling\n","==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n","   \\\\   /|    Num examples = 8,112 | Num Epochs = 1 | Total steps = 507\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n","\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n"," \"-____-\"     Trainable parameters = 17,432,576 of 1,738,007,552 (1.00% trained)\n","  0%|                                                   | 0/507 [00:00<?, ?it/s]Traceback (most recent call last):\n","  File \"/kaggle/working/weight_train_unsloth.py\", line 175, in <module>\n","    main()\n","  File \"/kaggle/working/weight_train_unsloth.py\", line 149, in main\n","    trainer_stats = trainer.train()\n","                    ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2238, in train\n","    return inner_training_loop(\n","           ^^^^^^^^^^^^^^^^^^^^\n","  File \"<string>\", line 325, in _fast_inner_training_loop\n","  File \"/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\", line 1003, in training_step\n","    return super().training_step(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<string>\", line 34, in _unsloth_training_step\n","TypeError: WeightedSFTTrainer.compute_loss() got an unexpected keyword argument 'num_items_in_batch'\n","  0%|                                                   | 0/507 [00:01<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/accelerate\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n","    args.func(args)\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1235, in launch_command\n","    simple_launcher(args)\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 823, in simple_launcher\n","    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n","subprocess.CalledProcessError: Command '['/usr/bin/python3', 'weight_train_unsloth.py']' returned non-zero exit status 1.\n"]},{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["2025-09-18 21:08:36.662950: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1758229716.686302    1843 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1758229716.693037    1843 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","✅ Using Qwen3 1.7B model from local Kaggle input\n","🎯 TT-12: Unsloth training + vLLM inference with 100% of data\n","📊 Stratified sampling: True\n","🎯 NORMAL MODE: Training on both positive and negative examples\n","🔄 Loading base model...\n","🔗 Loading LoRA adapters...\n","🔀 Merging LoRA weights...\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n","  warnings.warn(\n","^C\n","Traceback (most recent call last):\n","  File \"/kaggle/working/merge_lora.py\", line 33, in <module>\n","    merge_and_save()\n","  File \"/kaggle/working/merge_lora.py\", line 20, in merge_and_save\n","    merged_model = model.merge_and_unload()\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py\", line 938, in merge_and_unload\n","    return self._unload_and_optionally_merge(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py\", line 555, in _unload_and_optionally_merge\n","    target.merge(safe_merge=safe_merge, adapter_names=adapter_names)\n","  File \"/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py\", line 373, in merge\n","    self.get_base_layer().weight = bnb.nn.Params4bit(w_data.to(\"cpu\"), **kwargs).to(weight.device)\n","                                                     ^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n"]},{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","2025-09-18 21:08:50.451109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1758229730.475658    1862 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1758229730.483300    1862 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","INFO 09-18 21:08:57 [__init__.py:235] Automatically detected platform cuda.\n","ERROR 09-18 21:08:59 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","✅ Using Qwen3 1.7B model from local Kaggle input\n","🎯 TT-12: Unsloth training + vLLM inference with 100% of data\n","📊 Stratified sampling: True\n","🎯 NORMAL MODE: Training on both positive and negative examples\n","🔬 TT-11: Unsloth Training + Transformers Validation\n","🚀 Ultra-fast training + Universal compatibility!\n","📚 Training: Model learned from examples with Unsloth speed\n","🧪 Validation: Testing on real comments with standard Transformers\n","======================================================================\n","📊 Real comment validation dataset: 2029 samples\n","📊 Rule violations: 1031 positive, 998 negative\n","🔍 Running validation on 2029 real comments (Unsloth Fast Inference)\n","==((====))==  Unsloth 2025.9.6: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n","   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","^C\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;31m# know whether we've finished (if we matched EOF) or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mres_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;31m# Still have time left, so read more data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mread_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# (possibly timeout=None), we call select() with a timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mselect_ignore_interrupts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild_fd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/utils.py\u001b[0m in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miwtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/4180278938.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accelerate launch --config_file accelerate_config.yaml weight_train_unsloth.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python merge_lora.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python validation_transformers.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_exit_code\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_exit_code\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;31m# Ensure new system_piped implementation is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;31m# Ensure the subprocess really is terminated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;31m# add isalive check, to ensure exitstatus is set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGCONT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterterminate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":null},{"id":"1b603081","cell_type":"code","source":"# Display saved results from TT-11\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# Load detailed results\ntry:\n    detailed_results = pd.read_csv('/kaggle/working/tt11_detailed_results.csv')\n    print(\"📊 TT-11 Detailed Results Shape:\", detailed_results.shape)\n    print(\"\\n📋 Sample Results:\")\n    print(detailed_results[['rule', 'rule_violation', 'predictions', 'probabilities']].head(10))\n    \n    # Load rule metrics\n    rule_metrics = pd.read_csv('/kaggle/working/tt11_rule_metrics.csv')\n    print(\"\\n📈 TT-11 Rule-wise Performance:\")\n    print(rule_metrics)\n    \n    # Performance summary\n    print(\"\\n🎯 TT-11 PERFORMANCE SUMMARY:\")\n    print(\"=\" * 50)\n    overall_accuracy = accuracy_score(detailed_results['rule_violation'], detailed_results['predictions'])\n    avg_probability = detailed_results['probabilities'].mean()\n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Average Confidence: {avg_probability:.4f}\")\n    print(f\"Total Samples: {len(detailed_results)}\")\n    \nexcept FileNotFoundError as e:\n    print(f\"❌ Results files not found: {e}\")\n    print(\"Run the validation cell first to generate results.\")","metadata":{"execution":{"iopub.status.busy":"2025-09-18T21:09:04.742655Z","iopub.status.idle":"2025-09-18T21:09:04.743672Z","shell.execute_reply":"2025-09-18T21:09:04.743432Z","shell.execute_reply.started":"2025-09-18T21:09:04.743388Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"48250c83","cell_type":"markdown","source":"# 📊 TT-11 Analysis Guide\n\n## 🎯 **What TT-11 Optimizes:**\n- **🚀 Training Speed**: Unsloth provides 2x-5x faster fine-tuning than standard PEFT\n- **🎯 Inference Precision**: vLLM gives most accurate probability calculations for AUC\n- **💾 Memory Efficiency**: Optimized 4-bit quantization for 2x T4 GPU setup\n- **⚡ Best Performance**: Fastest training + most accurate validation workflow\n\n## 🔧 **How to Adjust Training Data:**\n\n### **Change Data Percentage** (Cell 4 - `constants.py`):\n```python\nTRAINING_DATA_PERCENTAGE = 0.5  # Use 50% of training data\nTRAINING_DATA_PERCENTAGE = 0.1  # Use 10% of training data\nTRAINING_DATA_PERCENTAGE = 1.0  # Use 100% of training data (default)\n```\n\n### **Toggle Stratified Sampling** (Cell 4 - `constants.py`):\n```python\nUSE_STRATIFIED_SAMPLING = True   # Maintain rule distribution (recommended)\nUSE_STRATIFIED_SAMPLING = False  # Random sampling\n```\n\n## 🚀 **Unsloth Training Optimizations:**\n\n### **Speed Tuning** (Cell 6 - `train_unsloth.py`):\n```python\n# For maximum speed\nper_device_train_batch_size=1,  # Smaller batches for Unsloth\nmax_steps=30,                   # Unsloth converges faster\nlearning_rate=3e-4,             # Higher LR works with Unsloth\n\n# For best quality  \nper_device_train_batch_size=2,  # Balanced approach\nmax_steps=60,                   # More training steps\nr=32,                          # Higher LoRA rank\n```\n\n### **Memory Optimization**:\n```python\n# If running out of memory\nper_device_train_batch_size=1,\ngradient_accumulation_steps=8,\nmax_seq_length=1024,\n```\n\n## 🎯 **vLLM Inference Advantages:**\n\n### **High-Precision AUC Calculation**:\n- **Log Probability Processing**: vLLM's optimized probability calculations\n- **Numerical Stability**: Better handling of edge cases\n- **Temperature Scaling**: More consistent probability distributions\n\n### **Performance Monitoring**:\n```python\n# Check probability quality\nviolation_probs = results[results['rule_violation'] == 1]['probabilities']\nno_violation_probs = results[results['rule_violation'] == 0]['probabilities']\nseparation = abs(violation_probs.mean() - no_violation_probs.mean())\nprint(f\"Probability separation: {separation:.3f}\")  # Higher = better discrimination\n```\n\n## 📈 **Understanding TT-11 Results:**\n\n### **Key Metrics:**\n- **AUC Score**: Most accurate with vLLM's precise probabilities (0.5 = random, 1.0 = perfect)\n- **F1 Score**: Balance of precision and recall\n- **Probability Separation**: How well the model discriminates between classes\n- **Confidence Analysis**: vLLM provides more reliable confidence estimates\n\n### **Visualizations Generated:**\n1. **Confusion Matrix**: Shows prediction accuracy breakdown\n2. **ROC Curve**: High-precision curve with vLLM probabilities\n3. **Probability Distribution**: Clean separation with vLLM precision\n4. **Metrics Bar Chart**: Visual comparison of all performance metrics\n\n## ⚡ **Speed Expectations:**\n\n### **Unsloth Training Speed:**\n- **2x-5x faster** than standard PEFT training\n- **Faster convergence** - often needs 50% fewer steps\n- **Better memory efficiency** - same quality with less VRAM\n\n### **vLLM Inference Benefits:**\n- **Most accurate AUC** calculations available\n- **Stable probabilities** for reliable metrics\n- **Batch processing** for faster validation\n\n## 🚀 **Optimization Tips:**\n\n### **If Training is Too Slow:**\n1. **Reduce max_steps**: Try `max_steps=30` instead of 60\n2. **Smaller batches**: `per_device_train_batch_size=1`\n3. **Reduce data**: `TRAINING_DATA_PERCENTAGE = 0.5`\n4. **Lower rank**: `r=8` instead of `r=16`\n\n### **If AUC is Lower Than Expected:**\n1. **More training steps**: `max_steps=100`\n2. **Higher LoRA rank**: `r=32`\n3. **More data**: `TRAINING_DATA_PERCENTAGE = 1.0`\n4. **Adjust learning rate**: Try `learning_rate=1e-4`\n\n### **If Memory Issues:**\n1. **Reduce sequence length**: `max_seq_length=1024`\n2. **Smaller batches**: `per_device_train_batch_size=1`\n3. **Lower GPU utilization**: `gpu_memory_utilization=0.90`\n\n## 💡 **TT-11 vs TT-10 Advantages:**\n\n| Aspect | TT-10 (Standard) | TT-11 (Unsloth + vLLM) |\n|--------|------------------|-------------------------|\n| **Training Speed** | Standard | 🚀 2x-5x faster |\n| **AUC Precision** | Good | 🎯 Most accurate |\n| **Memory Usage** | Standard | 💾 More efficient |\n| **Setup Complexity** | Medium | 🛠️ Optimized |\n| **Total Time** | Baseline | ⚡ 50-80% faster |\n\n## 🎯 **Key Insights:**\n- **High AUC (>0.8)**: Unsloth training + vLLM inference working optimally\n- **Fast Convergence**: Unsloth often achieves better results with fewer steps\n- **Precise Probabilities**: vLLM gives most reliable confidence estimates\n- **Scalable**: This approach works well for larger datasets and models\n\n**TT-11 represents the optimal workflow for validation-focused training: combining Unsloth's training speed with vLLM's inference precision for the best of both worlds!** 🚀🎯","metadata":{}},{"id":"dc3f8f0c","cell_type":"markdown","source":"# 🚀 TT-11 vs TT-10 Performance Comparison\n\n## ⚡ **Expected Performance Improvements**\n\n### **Training Speed (Unsloth Advantage)**\n| Metric | TT-10 (Standard PEFT) | TT-11 (Unsloth) | Improvement |\n|--------|----------------------|------------------|-------------|\n| **Training Time** | 15-30 minutes | 5-10 minutes | 🚀 **2x-3x faster** |\n| **Memory Usage** | 12-14GB VRAM | 10-12GB VRAM | 💾 **15-20% less** |\n| **Convergence** | 100+ steps | 50-60 steps | ⚡ **50% fewer steps** |\n| **Samples/Second** | 2-4 samples/sec | 8-15 samples/sec | 🎯 **4x faster** |\n\n### **Inference Precision (vLLM Advantage)**\n| Metric | TT-10 (Standard) | TT-11 (vLLM) | Improvement |\n|--------|------------------|--------------|-------------|\n| **AUC Precision** | ±0.005 variance | ±0.001 variance | 🎯 **5x more stable** |\n| **Probability Quality** | Good | Excellent | 📊 **Better separation** |\n| **Log Prob Handling** | Basic | Optimized | 🔧 **More reliable** |\n| **Edge Case Handling** | Standard | Advanced | ✅ **Fewer errors** |\n\n### **Overall Workflow**\n| Aspect | TT-10 | TT-11 | Improvement |\n|--------|-------|-------|-------------|\n| **Total Time** | 20-35 minutes | 8-15 minutes | ⚡ **60-70% faster** |\n| **Result Quality** | Good | Excellent | 🎯 **More accurate** |\n| **Memory Efficiency** | Standard | Optimized | 💾 **Better utilization** |\n| **Reliability** | Good | Excellent | ✅ **More consistent** |\n\n## 🎯 **When to Use Each Approach**\n\n### **Use TT-11 (Unsloth + vLLM) When:**\n- ✅ You want **maximum speed and accuracy**\n- ✅ You need **publication-quality AUC** calculations\n- ✅ You're running **multiple experiments**\n- ✅ You have **Kaggle/cloud GPU** time constraints\n- ✅ You want the **most reliable results**\n\n### **Use TT-10 (Standard) When:**\n- ✅ You want **simpler setup** without extra dependencies\n- ✅ You're **learning the approach** first\n- ✅ You have **unlimited time** for training\n- ✅ You're using **very old hardware**\n\n## 🚀 **Migration from TT-10 to TT-11**\n\n### **Simple Migration Steps:**\n1. **Add Unsloth**: Install unsloth package\n2. **Update training**: Use `train_unsloth.py` instead of `train.py`\n3. **Keep validation**: Use same vLLM validation (already optimized)\n4. **Same analysis**: All metrics and visualizations work the same\n\n### **Code Changes Required:**\n```python\n# TT-10 (old)\nfrom trl import SFTTrainer\nfrom transformers import AutoModelForCausalLM\n\n# TT-11 (new)  \nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer  # Still used, but with Unsloth model\n```\n\n**Result: Same methodology, much faster execution, more accurate results!** 🎯\n\nThis makes TT-11 the **recommended approach** for production validation workflows where both speed and accuracy matter.","metadata":{}}]}