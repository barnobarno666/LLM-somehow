{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12726948,"sourceType":"datasetVersion","datasetId":8044304},{"sourceId":12762469,"sourceType":"datasetVersion","datasetId":8067935},{"sourceId":252850661,"sourceType":"kernelVersion"},{"sourceId":252853424,"sourceType":"kernelVersion"},{"sourceId":259545323,"sourceType":"kernelVersion"},{"sourceId":171496,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":145960,"modelId":164048},{"sourceId":171638,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":146086,"modelId":164048},{"sourceId":426330,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":347541,"modelId":368803},{"sourceId":523492,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":411182,"modelId":429004},{"sourceId":579809,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":432662,"modelId":449553},{"sourceId":583951,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":436166,"modelId":452934}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Alternative Validation Options\n\n## ðŸ”§ **Choose Your Validation Method:**\n\nThis notebook now provides **two validation approaches**:\n\n### **Option 1: vLLM Validation (Original)**\n- **Pros**: Fastest inference, most precise probability calculations\n- **Cons**: Hardware compatibility issues with certain GPU/model combinations\n- **Use when**: You have compatible hardware and need maximum speed\n\n### **Option 2: Standard Transformers Validation (New)**\n- **Pros**: Universal compatibility, works with any Unsloth model, reliable\n- **Cons**: Slower than vLLM, but still faster than training\n- **Use when**: vLLM has compatibility issues or you want guaranteed reliability\n\n**Both methods produce identical metrics and visualizations** - the choice is purely based on your hardware compatibility and speed requirements.","metadata":{}},{"cell_type":"code","source":"!pip install ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TT-11: Validation-Focused Training with Unsloth + vLLM\n\nThis notebook implements the same validation-focused approach as TT-10, but optimized for **maximum speed and accuracy**:\n\n**Key Improvements over TT-10:**\n- **ðŸš€ Unsloth Training**: 2x-5x faster fine-tuning than standard PEFT\n- **ðŸŽ¯ vLLM Inference**: Most accurate AUC calculations with precise log probabilities\n- **ðŸ’¾ Memory Efficient**: Optimized for 2x T4 GPU setup\n- **âš¡ Best Performance**: Fastest training + most accurate validation\n\n**Methodology:**\n- **Training**: Model learns from positive/negative examples using Unsloth (like test-time training)\n- **Validation**: Model predicts on real `body` comments with vLLM for precise probabilities\n- **Analysis**: Comprehensive metrics to understand generalization from examples to real data\n\n**Features:**\n- **Stratified Sampling**: Controllable % of training data while maintaining rule distribution\n- **Example-Based Training**: Similar to test-time training approach with Unsloth speed\n- **Real Comment Validation**: Test on actual comments with vLLM precision\n- **Comprehensive Metrics**: AUC, F1, Recall, Precision, Confusion Matrix\n- **Visualizations**: Performance plots and analysis\n- **4-bit + LoRA**: Memory-efficient training, vLLM-compatible inference\n\n**Benefits:**\n- **Fastest Training**: Unsloth provides 2x-5x speed improvement\n- **Most Accurate AUC**: vLLM gives precise probability calculations\n- **Best of Both Worlds**: Speed + Accuracy optimized workflow","metadata":{}},{"cell_type":"code","source":"# Install dependencies - Unsloth + vLLM + Analysis setup\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'trl==0.21.0' 'optimum==1.27.0' 'bitsandbytes==0.46.1' 'deepspeed==0.17.4' 'logits-processor-zoo==0.2.1' 'vllm==0.10.0'\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'triton==3.2.0'\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'clean-text'\n# Install PEFT for LoRA support\n!uv pip install --system --no-index -U --no-deps --find-links='/kaggle/input/jigsaw-packages2/whls/' 'peft' 'accelerate' 'datasets'\n# Install Unsloth for ultra-fast training\n#!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'unsloth'\n# Install analysis libraries\n#!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'scikit-learn' 'matplotlib' 'seaborn'\n\nprint(\"âœ… TT-11 Dependencies installed:\")\nprint(\"ðŸš€ Unsloth: Ultra-fast training\")\nprint(\"ðŸŽ¯ vLLM: Precise inference\") \nprint(\"ðŸ“Š Analysis libraries: scikit-learn, matplotlib, seaborn\")","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:09:32.451247Z","iopub.execute_input":"2025-09-20T16:09:32.452002Z","iopub.status.idle":"2025-09-20T16:10:25.585126Z","shell.execute_reply.started":"2025-09-20T16:09:32.451981Z","shell.execute_reply":"2025-09-20T16:10:25.584220Z"},"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m164 packages\u001b[0m \u001b[2min 936ms\u001b[0m\u001b[0m                                       \u001b[0m\n\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                          \n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m63 packages\u001b[0m \u001b[2min 35.78s\u001b[0m\u001b[0m                                           \n\u001b[2mUninstalled \u001b[1m26 packages\u001b[0m \u001b[2min 3.29s\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m63 packages\u001b[0m \u001b[2min 5.85s\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mastor\u001b[0m\u001b[2m==0.8.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.46.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mblake3\u001b[0m\u001b[2m==1.0.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcbor2\u001b[0m\u001b[2m==5.7.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcompressed-tensors\u001b[0m\u001b[2m==0.10.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdeepspeed\u001b[0m\u001b[2m==0.17.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdepyf\u001b[0m\u001b[2m==0.19.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cli\u001b[0m\u001b[2m==0.0.10\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfastapi-cloud-cli\u001b[0m\u001b[2m==0.1.5\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.5.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgguf\u001b[0m\u001b[2m==0.17.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhjson\u001b[0m\u001b[2m==3.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.6.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.33.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.34.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1minteregular\u001b[0m\u001b[2m==0.3.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.2.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllguidance\u001b[0m\u001b[2m==0.7.30\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.43.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.44.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlm-format-enforcer\u001b[0m\u001b[2m==0.10.12\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlogits-processor-zoo\u001b[0m\u001b[2m==0.2.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmistral-common\u001b[0m\u001b[2m==1.8.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.19.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.60.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.61.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.11.1.6\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.6.85\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.91.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.90.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moptimum\u001b[0m\u001b[2m==1.27.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1moutlines-core\u001b[0m\u001b[2m==0.2.10\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpartial-json-parser\u001b[0m\u001b[2m==0.2.1.1.post6\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mprometheus-fastapi-instrumentator\u001b[0m\u001b[2m==7.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpycountry\u001b[0m\u001b[2m==24.6.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpydantic-extra-types\u001b[0m\u001b[2m==2.10.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==24.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrich-toolkit\u001b[0m\u001b[2m==0.15.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrignore\u001b[0m\u001b[2m==0.6.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124 (from https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.22.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.52.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.56.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mvllm\u001b[0m\u001b[2m==0.10.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.31\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxgrammar\u001b[0m\u001b[2m==0.1.21\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 14ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 3.93s\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m4 packages\u001b[0m \u001b[2min 615ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                               \n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 715ms\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mclean-text\u001b[0m\u001b[2m==0.6.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==2.14.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==1.7.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m3 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 50ms\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m3 packages\u001b[0m \u001b[2min 149ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.8.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.10.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==3.6.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.0.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.15.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.17.1\u001b[0m\nâœ… TT-11 Dependencies installed:\nðŸš€ Unsloth: Ultra-fast training\nðŸŽ¯ vLLM: Precise inference\nðŸ“Š Analysis libraries: scikit-learn, matplotlib, seaborn\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install unsloth \n!pip install vllm","metadata":{"execution":{"iopub.status.busy":"2025-09-20T18:00:06.549947Z","iopub.execute_input":"2025-09-20T18:00:06.550200Z","iopub.status.idle":"2025-09-20T18:05:01.943607Z","shell.execute_reply.started":"2025-09-20T18:00:06.550180Z","shell.execute_reply":"2025-09-20T18:05:01.942585Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.9.7-py3-none-any.whl.metadata (54 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.9.9 (from unsloth)\n  Downloading unsloth_zoo-2025.9.9-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.32-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.52.4)\nRequirement already satisfied: datasets<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.6.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.8.1)\nCollecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.15.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\nCollecting huggingface_hub>=0.34.0 (from unsloth)\n  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth) (0.21.2)\nINFO: pip is looking at multiple versions of trl to determine which version is compatible with other requirements. This could take a while.\nCollecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n  Downloading trl-0.22.2-py3-none-any.whl.metadata (11 kB)\nCollecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3 (from unsloth)\n  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchao in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.9->unsloth) (0.10.0)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.9.9->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.9->unsloth) (11.2.1)\nCollecting msgspec (from unsloth_zoo>=2025.9.9->unsloth)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting nvidia-nccl-cu12==2.27.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (14.0.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.13)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.6.15)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.9.7-py3-none-any.whl (314 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m314.6/314.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.35.0-py3-none-any.whl (563 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m563.4/563.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.22.2-py3-none-any.whl (544 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.9.9-py3-none-any.whl (233 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m952.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.32-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface_hub, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.33.1\n    Uninstalling huggingface-hub-0.33.1:\n      Successfully uninstalled huggingface-hub-0.33.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 fsspec-2025.3.0 huggingface_hub-0.35.0 msgspec-0.19.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 shtab-1.7.2 sympy-1.14.0 torch-2.8.0 torchvision-0.23.0 transformers-4.55.4 triton-3.4.0 trl-0.22.2 tyro-0.9.32 unsloth-2025.9.7 unsloth_zoo-2025.9.9 xformers-0.0.32.post2\nCollecting vllm\n  Downloading vllm-0.10.2-cp38-abi3-manylinux1_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from vllm) (2024.11.6)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.4)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\nCollecting blake3 (from vllm)\n  Downloading blake3-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (217 bytes)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\nRequirement already satisfied: transformers>=4.55.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.55.4)\nRequirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (3.20.3)\nRequirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.13)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.12.13)\nCollecting openai>=1.99.1 (from vllm)\n  Downloading openai-1.108.1-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: pydantic>=2.11.7 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.7)\nRequirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.22.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\nCollecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\nCollecting lm-format-enforcer==0.11.3 (from vllm)\n  Downloading lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\nCollecting llguidance<0.8.0,>=0.7.11 (from vllm)\n  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nCollecting outlines_core==0.2.11 (from vllm)\n  Downloading outlines_core-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\nCollecting diskcache==5.6.3 (from vllm)\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nCollecting lark==1.2.2 (from vllm)\n  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\nCollecting xgrammar==0.1.23 (from vllm)\n  Downloading xgrammar-0.1.23-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.14.0)\nRequirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\nCollecting partial-json-parser (from vllm)\n  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\nCollecting pyzmq>=25.0.0 (from vllm)\n  Downloading pyzmq-27.1.0-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)\nRequirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\nCollecting gguf>=0.13.0 (from vllm)\n  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\nCollecting mistral_common>=1.8.2 (from mistral_common[audio,image]>=1.8.2->vllm)\n  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\nRequirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\nCollecting compressed-tensors==0.11.0 (from vllm)\n  Downloading compressed_tensors-0.11.0-py3-none-any.whl.metadata (7.0 kB)\nCollecting depyf==0.19.0 (from vllm)\n  Downloading depyf-0.19.0-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\nCollecting watchfiles (from vllm)\n  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.3)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from vllm) (1.11.1.4)\nCollecting pybase64 (from vllm)\n  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\nCollecting cbor2 (from vllm)\n  Downloading cbor2-5.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from vllm) (1.3.6)\nCollecting openai-harmony>=0.0.3 (from vllm)\n  Downloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\nCollecting numba==0.61.2 (from vllm)\n  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\nCollecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)\n  Downloading ray-2.49.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.8.0)\nCollecting torchaudio==2.8.0 (from vllm)\n  Downloading torchaudio-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\nRequirement already satisfied: torchvision==0.23.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.23.0)\nCollecting xformers==0.0.32.post1 (from vllm)\n  Downloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from compressed-tensors==0.11.0->vllm) (2.4.6)\nCollecting astor (from depyf==0.19.0->vllm)\n  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.3.8)\nCollecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)\n  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.11.3->vllm) (25.0)\nCollecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (1.13.1.3)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->vllm) (3.4.0)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch==2.8.0->vllm) (75.2.0)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\nCollecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading fastapi_cli-0.0.13-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\nRequirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\nRequirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.3)\nRequirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.24.0)\nCollecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2.4.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.99.1->vllm) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.99.1->vllm) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.99.1->vllm) (0.10.0)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.99.1->vllm) (1.3.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.7->vllm) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.7->vllm) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.7->vllm) (0.4.1)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (8.2.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (1.1.1)\nRequirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]>=2.48.0->vllm) (13.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.6.15)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.21.1->vllm) (0.35.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.2->vllm) (0.5.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.1)\nRequirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\nRequirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.16.0)\nCollecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\nCollecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading fastapi_cloud_cli-0.2.0-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.21.1->vllm) (1.1.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.8.0->vllm) (3.0.2)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.25.1)\nCollecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.8.0->vllm) (1.3.0)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\nRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm) (0.8.3)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.13.1)\nRequirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.5.0.post1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->vllm) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->vllm) (2024.2.0)\nCollecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n  Downloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nRequirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.31.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->vllm) (2024.2.0)\nRequirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.0.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.17.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.22)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\nDownloading vllm-0.10.2-cp38-abi3-manylinux1_x86_64.whl (436.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m436.4/436.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading compressed_tensors-0.11.0-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m133.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading depyf-0.19.0-py3-none-any.whl (39 kB)\nDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading outlines_core-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchaudio-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xgrammar-0.1.23-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gguf-0.17.1-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openai-1.108.1-py3-none-any.whl (948 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m948.4/948.4 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\nDownloading pyzmq-27.1.0-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (857 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m857.0/857.0 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ray-2.49.2-cp311-cp311-manylinux2014_x86_64.whl (70.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.1/70.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading blake3-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cbor2-5.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (254 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\nDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi_cli-0.0.13-py3-none-any.whl (11 kB)\nDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\nDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\nDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nDownloading fastapi_cloud_cli-0.2.0-py3-none-any.whl (19 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nDownloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\nDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (950 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m950.6/950.6 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: uvloop, rignore, pyzmq, python-dotenv, pycountry, pybase64, partial-json-parser, outlines_core, llvmlite, llguidance, lark, interegular, httptools, diskcache, cbor2, blake3, astor, watchfiles, depyf, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai-harmony, openai, lm-format-enforcer, torchaudio, ray, fastapi-cloud-cli, fastapi-cli, mistral_common, xgrammar, xformers, numba, gguf, compressed-tensors, vllm\n  Attempting uninstall: pyzmq\n    Found existing installation: pyzmq 24.0.1\n    Uninstalling pyzmq-24.0.1:\n      Successfully uninstalled pyzmq-24.0.1\n  Attempting uninstall: llvmlite\n    Found existing installation: llvmlite 0.43.0\n    Uninstalling llvmlite-0.43.0:\n      Successfully uninstalled llvmlite-0.43.0\n  Attempting uninstall: openai\n    Found existing installation: openai 1.91.0\n    Uninstalling openai-1.91.0:\n      Successfully uninstalled openai-1.91.0\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.6.0+cu124\n    Uninstalling torchaudio-2.6.0+cu124:\n      Successfully uninstalled torchaudio-2.6.0+cu124\n  Attempting uninstall: ray\n    Found existing installation: ray 2.47.1\n    Uninstalling ray-2.47.1:\n      Successfully uninstalled ray-2.47.1\n  Attempting uninstall: xformers\n    Found existing installation: xformers 0.0.32.post2\n    Uninstalling xformers-0.0.32.post2:\n      Successfully uninstalled xformers-0.0.32.post2\n  Attempting uninstall: numba\n    Found existing installation: numba 0.60.0\n    Uninstalling numba-0.60.0:\n      Successfully uninstalled numba-0.60.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\ncuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\ncudf-cu12 25.2.2 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\ndistributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\nydata-profiling 4.16.1 requires numba<=0.61,>=0.56.0, but you have numba 0.61.2 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed astor-0.8.1 blake3-1.0.6 cbor2-5.7.0 compressed-tensors-0.11.0 depyf-0.19.0 diskcache-5.6.3 fastapi-cli-0.0.13 fastapi-cloud-cli-0.2.0 gguf-0.17.1 httptools-0.6.4 interegular-0.3.3 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.11.3 mistral_common-1.8.5 numba-0.61.2 openai-1.108.1 openai-harmony-0.0.4 outlines_core-0.2.11 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 pybase64-1.4.2 pycountry-24.6.1 pydantic-extra-types-2.10.5 python-dotenv-1.1.1 pyzmq-27.1.0 ray-2.49.2 rich-toolkit-0.15.1 rignore-0.6.4 torchaudio-2.8.0 uvloop-0.21.0 vllm-0.10.2 watchfiles-1.1.0 xformers-0.0.32.post1 xgrammar-0.1.23\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import unsloth","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:11:35.251500Z","iopub.execute_input":"2025-09-20T16:11:35.252408Z","iopub.status.idle":"2025-09-20T16:12:26.668057Z","shell.execute_reply.started":"2025-09-20T16:11:35.252371Z","shell.execute_reply":"2025-09-20T16:12:26.667489Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-09-20 16:11:47.432876: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758384707.812967      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758384707.925041      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"INFO 09-20 16:12:16 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-20 16:12:18 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 1. Configuration and Data Setup","metadata":{}},{"cell_type":"code","source":"%%writefile constants.py\n# Using base Qwen3 1.7B model from Kaggle input (no internet needed)\nBASE_MODEL_PATH = \"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\"  # Update this path as needed\nLORA_PATH = \"qwen3_1.7b_unsloth_lora_validation/\"  # Unsloth LoRA output path for validation\nDATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules/\"\n\nYES_TOKEN_ID = 7414 # tokenizer.convert_tokens_to_ids(\"Yes\")  # WITH space!\nNO_TOKEN_ID = 2308# tokenizer.convert_tokens_to_ids(\"No\")    # WITH space!\n\n# NEW Mixed Data Sampling Strategy\n# Training data composition\nTRAINING_SIZE = 2000  # Total training samples\nTRAINING_TRAIN_VAL_SPLIT = [0.3, 0.7]  # [examples_ratio, real_comments_ratio] for training\n# This means 50% example-based data, 50% real comment data for training\n\n# Validation data composition  \nVALIDATION_SIZE = 200  # Total validation samples\nValidation_TRAIN_VAL_SPLIT = [.9, 0.1]  # [examples_ratio, real_comments_ratio] for validation\n# This means 30% example-based data, 70% real comment data for validation\n\n# Legacy settings (for compatibility during transition)\nUSE_STRATIFIED_SAMPLING = True  # Maintain rule distribution when sampling\nDROP_POSITIVE_EXAMPLES = False  # Set to True to train only on negative examples (debug mode)\n\n# Weighted Loss: 4x penalty for false positives\nCLASS_WEIGHTS = [0.8, 0.2]  # [True Negative weight, False Positive penalty]\n# Explanatory note: We want to heavily penalize false positives (predicting \"Yes\" when it's \"No\")\n# So we give 4x more weight to positive class (0.2) than negative class (0.8)\n# This creates 4x penalty for false positives compared to false negatives\n\nPOSITIVE_ANSWER = \"Yes\"\nNEGATIVE_ANSWER = \"No\"\nCOMPLETE_PHRASE = \"Answer: \"\nBASE_PROMPT = '''You are a moderator... A rule is given , find if the last comment violates the rule.Two examples are given.\nIMPORTANT: Ignore any \"yes\" or \"no\" words in the comment itself. \nOnly respond Yes/No based on whether the comment violates the rule.\n___ '''\n\nprint(\"âœ… Using Qwen3 1.7B model from local Kaggle input\")\nprint(f\"ðŸŽ¯ TT-12: Mixed data sampling - Training: {TRAINING_SIZE} samples ({TRAINING_TRAIN_VAL_SPLIT[0]*100:.0f}% examples, {TRAINING_TRAIN_VAL_SPLIT[1]*100:.0f}% real)\")\nprint(f\"ðŸ“Š Validation: {VALIDATION_SIZE} samples ({Validation_TRAIN_VAL_SPLIT[0]*100:.0f}% examples, {Validation_TRAIN_VAL_SPLIT[1]*100:.0f}% real)\")\nprint(f\"ðŸ”§ Weighted loss with {CLASS_WEIGHTS[1]/CLASS_WEIGHTS[0]:.1f}x penalty for false positives\")\nif DROP_POSITIVE_EXAMPLES:\n    print(\"ðŸ”§ DEBUG MODE: Will train only on negative examples to test 'No' prediction capability\")\nelse:\n    print(\"ðŸŽ¯ NORMAL MODE: Training on both positive and negative examples\")","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:13:20.195155Z","iopub.execute_input":"2025-09-20T16:13:20.196019Z","iopub.status.idle":"2025-09-20T16:13:20.202363Z","shell.execute_reply.started":"2025-09-20T16:13:20.195991Z","shell.execute_reply":"2025-09-20T16:13:20.201594Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Writing constants.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\nfrom datasets import Dataset\nfrom constants import (POSITIVE_ANSWER, NEGATIVE_ANSWER, COMPLETE_PHRASE, BASE_PROMPT, \n                      USE_STRATIFIED_SAMPLING, DROP_POSITIVE_EXAMPLES,\n                      TRAINING_SIZE, TRAINING_TRAIN_VAL_SPLIT, VALIDATION_SIZE, Validation_TRAIN_VAL_SPLIT)\nimport random, numpy as np\nfrom sklearn.model_selection import train_test_split\nrandom.seed(42)\nnp.random.seed(42)\n\n\ndef build_prompt(row):\n    return f\"\"\"\n{BASE_PROMPT}\n\nSubreddit name: r/{row[\"subreddit\"]}\nHere is the rule: {row[\"rule\"]}\nHere is a comment that breaks the rule:\n1) {row[\"positive_example\"]}\n\nHere is a comment that does not break the rule:\n2) {row[\"negative_example\"]}\n\nFind if this comment breaks the rule.\nComment: {row[\"body\"]}\n{COMPLETE_PHRASE}\"\"\"\n\n\ndef split_dataset_for_training_validation(data_path, train_size_fraction=0.8, random_state=42):\n    \"\"\"\n    Split the full dataset into training and validation pools to prevent data leakage\n    Returns: train_pool, validation_pool (non-overlapping datasets)\n    \"\"\"\n    # Load full dataset\n    full_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Split into training and validation pools (no overlap)\n    if USE_STRATIFIED_SAMPLING:\n        # Stratified split to maintain rule distribution\n        train_pool, val_pool = train_test_split(\n            full_dataset, \n            test_size=1-train_size_fraction, \n            random_state=random_state,\n            stratify=full_dataset['rule'],  # Maintain rule distribution\n            shuffle=True\n        )\n    else:\n        # Simple random split\n        train_pool, val_pool = train_test_split(\n            full_dataset, \n            test_size=1-train_size_fraction, \n            random_state=random_state,\n            shuffle=True\n        )\n    \n    print(f\"ðŸ“Š Dataset split: {len(train_pool)} training pool, {len(val_pool)} validation pool\")\n    print(f\"ðŸ“Š Training rules distribution: {train_pool['rule'].value_counts().to_dict()}\")\n    print(f\"ðŸ“Š Validation rules distribution: {val_pool['rule'].value_counts().to_dict()}\")\n    \n    return train_pool.reset_index(drop=True), val_pool.reset_index(drop=True)\n\n\ndef get_example_based_data(dataset_pool, num_samples):\n    \"\"\"\n    Create example-based training data from examples (like test-time training)\n    This creates data where we train on examples, not actual comments\n    \"\"\"\n    # Sample data while maintaining rule distribution\n    if USE_STRATIFIED_SAMPLING and num_samples < len(dataset_pool):\n        # Calculate fraction needed to get num_samples\n        sample_frac = num_samples / len(dataset_pool)\n        sampled_dataset = dataset_pool.groupby('rule', group_keys=False).apply(\n            lambda x: x.sample(frac=sample_frac, random_state=42)\n        ).reset_index(drop=True)\n        print(f\"ðŸ“Š Stratified sampling for examples: {len(sampled_dataset)} samples\")\n    elif num_samples < len(dataset_pool):\n        # Simple random sampling\n        sampled_dataset = dataset_pool.sample(n=num_samples, random_state=42).reset_index(drop=True)\n        print(f\"ðŸ“Š Random sampling for examples: {len(sampled_dataset)} samples\")\n    else:\n        sampled_dataset = dataset_pool.copy()\n    \n    flatten = []\n    \n    # Create training data from examples (similar to test-time training)\n    violation_types = [\"positive\", \"negative\"]\n    \n    # Debug mode: Train only on negative examples if DROP_POSITIVE_EXAMPLES is True\n    if DROP_POSITIVE_EXAMPLES:\n        violation_types = [\"negative\"]\n        print(\"ðŸ”§ DEBUG MODE: Creating only negative examples (DROP_POSITIVE_EXAMPLES=True)\")\n    \n    for violation_type in violation_types:\n        for i in range(1, 3):\n            sub_dataset = sampled_dataset[[\"rule\",\"subreddit\",\n                                        \"positive_example_1\",\"positive_example_2\",\n                                        \"negative_example_1\",\"negative_example_2\"]].copy()\n\n            if violation_type == \"positive\":\n                # Use positive example as the \"body\" to classify\n                body_col = f\"positive_example_{i}\"\n                other_positive_col = f\"positive_example_{3-i}\"  # other positive\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"positive_example\"] = sub_dataset[other_positive_col]\n                # negative_example randomly selected\n                sub_dataset[\"negative_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"negative_example_1\"],\n                    sub_dataset[\"negative_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 1  # Positive examples violate rules\n\n            else:  # violation_type == \"negative\"\n                # Use negative example as the \"body\" to classify\n                body_col = f\"negative_example_{i}\"\n                other_negative_col = f\"negative_example_{3-i}\"\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"negative_example\"] = sub_dataset[other_negative_col]\n                sub_dataset[\"positive_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"positive_example_1\"],\n                    sub_dataset[\"positive_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 0  # Negative examples don't violate rules\n\n            # Drop original candidate columns\n            sub_dataset.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                                      \"negative_example_1\",\"negative_example_2\"], inplace=True)\n\n            flatten.append(sub_dataset)\n\n    # Merge all DataFrames\n    example_df = pd.concat(flatten, axis=0)\n    example_df = example_df.drop_duplicates(ignore_index=True)\n    \n    print(f\"ðŸ“Š Example-based dataset: {len(example_df)} samples\")\n    print(f\"ðŸ“Š Positive examples: {sum(example_df['rule_violation'] == 1)}\")\n    print(f\"ðŸ“Š Negative examples: {sum(example_df['rule_violation'] == 0)}\")\n    \n    return example_df\n\n\ndef get_real_comment_data(dataset_pool, num_samples):\n    \"\"\"\n    Get real comments with labels for training/validation\n    This is what we actually want to predict\n    \"\"\"\n    # Sample data while maintaining rule distribution\n    if USE_STRATIFIED_SAMPLING and num_samples < len(dataset_pool):\n        # Calculate fraction needed to get num_samples\n        sample_frac = num_samples / len(dataset_pool)\n        sampled_dataset = dataset_pool.groupby('rule_violation', group_keys=False).apply(\n            lambda x: x.sample(frac=sample_frac, random_state=42)\n        ).reset_index(drop=True)\n        print(f\"ðŸ“Š Stratified sampling for real comments: {len(sampled_dataset)} samples\")\n    elif num_samples < len(dataset_pool):\n        # Simple random sampling\n        sampled_dataset = dataset_pool.sample(n=num_samples, random_state=42).reset_index(drop=True)\n        print(f\"ðŸ“Š Random sampling for real comments: {len(sampled_dataset)} samples\")\n    else:\n        sampled_dataset = dataset_pool.copy()\n    \n    # Use actual comments and their labels\n    real_df = sampled_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\",\n                              \"positive_example_1\",\"positive_example_2\",\n                              \"negative_example_1\",\"negative_example_2\"]].copy()\n\n    # Randomly select positive_example and negative_example for prompts\n    real_df[\"positive_example\"] = np.where(\n        np.random.rand(len(real_df)) < 0.5,\n        real_df[\"positive_example_1\"],\n        real_df[\"positive_example_2\"]\n    )\n    real_df[\"negative_example\"] = np.where(\n        np.random.rand(len(real_df)) < 0.5,\n        real_df[\"negative_example_1\"],\n        real_df[\"negative_example_2\"]\n    )\n\n    # Drop original candidate columns\n    real_df.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                         \"negative_example_1\",\"negative_example_2\"], inplace=True)\n    \n    print(f\"ðŸ“Š Real comment dataset: {len(real_df)} samples\")\n    print(f\"ðŸ“Š Rule violations: {sum(real_df['rule_violation'] == 1)} positive, {sum(real_df['rule_violation'] == 0)} negative\")\n    \n    return real_df\n\n\ndef get_mixed_training_data(data_path):\n    \"\"\"\n    NEW: Create mixed training data combining examples and real comments\n    according to TRAINING_TRAIN_VAL_SPLIT ratios\n    FIXED: Uses only training pool to prevent data leakage\n    \"\"\"\n    print(f\"ðŸ”„ Creating mixed training data: {TRAINING_SIZE} samples total\")\n    print(f\"ðŸ“Š Split: {TRAINING_TRAIN_VAL_SPLIT[0]*100:.0f}% examples, {TRAINING_TRAIN_VAL_SPLIT[1]*100:.0f}% real comments\")\n    \n    # FIXED: Get separate training and validation pools to prevent leakage\n    train_pool, val_pool = split_dataset_for_training_validation(data_path, train_size_fraction=0.8)\n    \n    # Calculate how many samples for each type\n    num_example_samples = int(TRAINING_SIZE * TRAINING_TRAIN_VAL_SPLIT[0])\n    num_real_samples = int(TRAINING_SIZE * TRAINING_TRAIN_VAL_SPLIT[1])\n    \n    print(f\"ðŸŽ¯ Target: {num_example_samples} example-based + {num_real_samples} real comment samples\")\n    \n    # Get example-based data from training pool only\n    example_data = get_example_based_data(train_pool, num_example_samples // 4)  # Divide by 4 because we create 4x samples\n    \n    # Get real comment data from training pool only\n    real_data = get_real_comment_data(train_pool, num_real_samples)\n    \n    # Combine the datasets\n    mixed_training_df = pd.concat([example_data, real_data], axis=0)\n    mixed_training_df = mixed_training_df.sample(frac=1.0, random_state=42).reset_index(drop=True)  # Shuffle\n    \n    print(f\"\\nðŸ“‹ MIXED TRAINING DATASET SUMMARY:\")\n    print(f\"ðŸ“Š Total samples: {len(mixed_training_df)}\")\n    print(f\"ðŸ“Š Rule violations: {sum(mixed_training_df['rule_violation'] == 1)} positive, {sum(mixed_training_df['rule_violation'] == 0)} negative\")\n    print(f\"ðŸ“Š Balance: {sum(mixed_training_df['rule_violation'] == 1)/len(mixed_training_df)*100:.1f}% positive\")\n    \n    # Store validation pool for later use\n    mixed_training_df._validation_pool = val_pool\n    \n    return mixed_training_df\n\n\ndef get_mixed_validation_data(data_path, training_data=None):\n    \"\"\"\n    NEW: Create mixed validation data combining examples and real comments\n    according to Validation_TRAIN_VAL_SPLIT ratios\n    FIXED: Uses only validation pool to prevent data leakage\n    \"\"\"\n    print(f\"ðŸ”„ Creating mixed validation data: {VALIDATION_SIZE} samples total\")\n    print(f\"ðŸ“Š Split: {Validation_TRAIN_VAL_SPLIT[0]*100:.0f}% examples, {Validation_TRAIN_VAL_SPLIT[1]*100:.0f}% real comments\")\n    \n    # FIXED: Use validation pool from training data if available, otherwise split again\n    if training_data is not None and hasattr(training_data, '_validation_pool'):\n        val_pool = training_data._validation_pool\n        print(\"âœ… Using validation pool from training data split (no data leakage)\")\n    else:\n        # Fallback: split again (should use same seed for consistency)\n        train_pool, val_pool = split_dataset_for_training_validation(data_path, train_size_fraction=0.8)\n        print(\"âš ï¸  Splitting dataset again (ensure consistency with training split)\")\n    \n    # Calculate how many samples for each type\n    num_example_samples = int(VALIDATION_SIZE * Validation_TRAIN_VAL_SPLIT[0])\n    num_real_samples = int(VALIDATION_SIZE * Validation_TRAIN_VAL_SPLIT[1])\n    \n    print(f\"ðŸŽ¯ Target: {num_example_samples} example-based + {num_real_samples} real comment samples\")\n    \n    # Get example-based data from validation pool only\n    example_data = get_example_based_data(val_pool, num_example_samples // 4)  # Divide by 4 because we create 4x samples\n    \n    # Get real comment data from validation pool only\n    real_data = get_real_comment_data(val_pool, num_real_samples)\n    \n    # Combine the datasets\n    mixed_validation_df = pd.concat([example_data, real_data], axis=0)\n    mixed_validation_df = mixed_validation_df.sample(frac=1.0, random_state=43).reset_index(drop=True)  # Different seed for validation shuffle\n    \n    print(f\"\\nðŸ“‹ MIXED VALIDATION DATASET SUMMARY:\")\n    print(f\"ðŸ“Š Total samples: {len(mixed_validation_df)}\")\n    print(f\"ðŸ“Š Rule violations: {sum(mixed_validation_df['rule_violation'] == 1)} positive, {sum(mixed_validation_df['rule_violation'] == 0)} negative\")\n    print(f\"ðŸ“Š Balance: {sum(mixed_validation_df['rule_violation'] == 1)/len(mixed_validation_df)*100:.1f}% positive\")\n    \n    return mixed_validation_df\n\n\n# Legacy functions (for backward compatibility)\ndef get_example_based_training_data(data_path):\n    \"\"\"\n    Legacy function: Create training data from examples only (original TT-11 approach)\n    \"\"\"\n    # Use training pool only to prevent leakage\n    train_pool, _ = split_dataset_for_training_validation(data_path, train_size_fraction=0.8)\n    return get_example_based_data(train_pool, len(train_pool))\n\n\ndef get_real_comment_validation_data(data_path):\n    \"\"\"\n    Legacy function: Get real comments with labels for validation (original TT-11 approach)\n    \"\"\"\n    # Use validation pool only to prevent leakage\n    _, val_pool = split_dataset_for_training_validation(data_path, train_size_fraction=0.8)\n    return get_real_comment_data(val_pool, len(val_pool))\n\n\ndef build_dataset_unsloth(dataframe):\n    \"\"\"Build dataset for Unsloth training with proper text formatting\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    \n    # Create completion column\n    dataframe[\"completion\"] = dataframe.apply(\n        lambda row: (POSITIVE_ANSWER if row[\"rule_violation\"] == 1 else NEGATIVE_ANSWER),\n        axis=1\n    )\n    \n    # Create full text (prompt + completion) for training\n    dataframe[\"text\"] = dataframe[\"prompt\"]  + dataframe[\"completion\"]\n    \n    # Keep only necessary columns\n    dataframe = dataframe[[\"text\"]]\n    dataset = Dataset.from_pandas(dataframe.reset_index(drop=True))\n    return dataset\n\n\ndef build_validation_dataset(dataframe):\n    \"\"\"Build dataset for validation (keep labels for evaluation)\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    dataframe = dataframe[[\"prompt\", \"rule_violation\"]]  # Keep true labels for evaluation\n    dataset = Dataset.from_pandas(dataframe)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:25:11.047824Z","iopub.execute_input":"2025-09-20T16:25:11.048613Z","iopub.status.idle":"2025-09-20T16:25:11.061061Z","shell.execute_reply.started":"2025-09-20T16:25:11.048582Z","shell.execute_reply":"2025-09-20T16:25:11.060399Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting utils.py\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import importlib\nimport utils  # regular import (only needed once)\nimport constants\nimportlib.reload(constants)\n\nimportlib.reload(utils)\n","metadata":{"execution":{"iopub.execute_input":"2025-09-19T03:59:53.671561Z","iopub.status.busy":"2025-09-19T03:59:53.671001Z","iopub.status.idle":"2025-09-19T03:59:53.681092Z","shell.execute_reply":"2025-09-19T03:59:53.680349Z","shell.execute_reply.started":"2025-09-19T03:59:53.671537Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile train_unsloth.py\nimport pandas as pd\nimport torch\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom utils import build_dataset_unsloth, get_mixed_training_data\nfrom constants import DATA_PATH, BASE_MODEL_PATH, LORA_PATH\n\n\ndef main():\n    # TT-12: Get mixed training data (combination of examples and real comments)\n    train_df = get_mixed_training_data(DATA_PATH)\n    train_dataset = build_dataset_unsloth(train_df)\n    \n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n    \n    # ðŸš€ UNSLOTH: Load model with 4-bit quantization (2x T4 optimized)\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,  # Adjust based on your max sequence length\n        dtype=None,  # Auto-detect (will use float16)\n        load_in_4bit=True,  # Enable 4-bit quantization\n        trust_remote_code=True,\n        local_files_only=True,\n        device_map=\"balanced\" ,\n       # full_finetuning= False\n    )\n    print(\"âœ… Unsloth model loaded with 4-bit quantization across 2x T4\")\n    \n    # ðŸš€ UNSLOTH: Add LoRA adapters (automatic and optimized)\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r=16,  # LoRA rank (can try 8, 16, 32, 64, 128)\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n        lora_alpha=32,  # LoRA alpha (typically equal to r for Unsloth)\n        lora_dropout=0,  # 0 for faster training with Unsloth\n        bias=\"none\",\n        #use_gradient_checkpointing=False,  # Enable for memory efficiency\n        random_state=3407,  # For reproducibility\n        use_rslora=True,  # Can try True for better stability\n        loftq_config=None,  # LoftQ for even better quality\n        use_gradient_checkpointing = \"unsloth\"\n    )\n    print(\"âœ… Unsloth LoRA adapters added\")\n    \n    # ðŸš€ UNSLOTH: Optimized training arguments for 2x T4 GPUs (28GB total)\n    training_args = TrainingArguments(\n        per_device_train_batch_size=8,  # Larger batches with 2x T4 (28GB total)\n        gradient_accumulation_steps=8,  # Effective batch size = 4*2*2 = 16\n        warmup_steps=5,  # Quick warmup with Unsloth\n        #max_steps=50,  # Unsloth converges much faster (adjust based on data size)\n        num_train_epochs=1 , \n        learning_rate=2e-4,  # Unsloth supports higher learning rates\n        fp16=True,  # Enable mixed precision for T4\n        logging_steps=1,\n        optim=\"adamw_8bit\",  # Memory-efficient optimizer\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        output_dir=LORA_PATH,  # LoRA adapters will be saved here\n        save_steps=50,  # Save every 50 steps for checkpointing\n        save_total_limit=3,  # Keep only 3 checkpoints\n        dataloader_num_workers=2,  # Adjust based on CPU cores\n        remove_unused_columns=False,  # Keep all columns for compatibility\n        push_to_hub=False,  # Don't push to hub\n        report_to=\"none\",  # Disable wandb/tensorboard\n    )\n    print(\"âœ… Unsloth training arguments configured\")\n    \n    # ðŸš€ UNSLOTH: Fast SFT Trainer (optimized for Unsloth)\n    trainer = SFTTrainer(\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=train_dataset,\n        dataset_text_field=\"text\",  # The text column containing the full conversation\n        max_seq_length=2048,\n        dataset_num_proc=2,  # Parallel processing\n        packing=False,  # True can be faster but may affect quality\n        args=training_args,\n    )\n    print(\"âœ… Unsloth SFT Trainer created\")\n    \n    # ðŸš€ Training with Unsloth (2-20x faster than standard)\n    print(\"ðŸš€ Starting Unsloth training...\")\n    trainer.train()\n    print(\"âœ… Unsloth training completed!\")\n\n    folder = \"/kaggle/working/Merged_unsloth_model\"  # âœ… Fixed typo\n    model.save_pretrained_merged(folder, tokenizer, save_method=\"merged_4bit_forced\")  # âœ… Correct method\n    # ðŸš€ UNSLOTH: Save model and adapters (native Unsloth format)\n    model.save_pretrained(LORA_PATH)  # Save LoRA adapters\n    tokenizer.save_pretrained(LORA_PATH)  # Save tokenizer\n    print(f\"âœ… Model and LoRA adapters saved to {LORA_PATH}\")\n    print(f\"âœ… Merged model Saved To  {folder}\")\n\n    print(\"ðŸŽ¯ Ass training complete! Ready for vLLM validation.\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:23:29.322779Z","iopub.execute_input":"2025-09-20T16:23:29.323604Z","iopub.status.idle":"2025-09-20T16:23:29.330884Z","shell.execute_reply.started":"2025-09-20T16:23:29.323570Z","shell.execute_reply":"2025-09-20T16:23:29.330130Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting train_unsloth.py\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"%%writefile weight_train_unsloth.py\nimport pandas as pd\nimport torch\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom utils import build_dataset_unsloth, get_example_based_training_data\nfrom constants import DATA_PATH, BASE_MODEL_PATH, LORA_PATH, YES_TOKEN_ID, NO_TOKEN_ID\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef get_class_weights():\n    \"\"\"\n    Manual class weights to heavily penalize false positives\n\n    CLASS MAPPING:\n    - Index 0 = \"No\" (negative class, rule_violation = 0)\n    - Index 1 = \"Yes\" (positive class, rule_violation = 1)\n\n    WEIGHTS:\n    - Weight for \"No\" (index 0): 0.8 (higher penalty for getting \"No\" wrong)\n    - Weight for \"Yes\" (index 1): 0.2 (lower penalty for getting \"Yes\" wrong)\n    - Result: 4x more penalty for false positives (predicting \"Yes\" when should be \"No\")\n    \"\"\"\n    # Manual weights: [weight_for_no, weight_for_yes]\n    weights = torch.tensor([0.8, 0.2], dtype=torch.float)\n\n    # Print weight distribution for verification\n    print(f\"ðŸ“Š Class Weights Mapping:\")\n    print(f\"   Index 0 ('No'/negative): {weights[0].item():.1f}\")\n    print(f\"   Index 1 ('Yes'/positive): {weights[1].item():.1f}\")\n    print(f\"ðŸ“Š False Positive Penalty: {weights[0].item()/weights[1].item():.1f}x\")\n    print(f\"ðŸ“Š Token IDs: No={NO_TOKEN_ID}, Yes={YES_TOKEN_ID}\")\n\n    return weights\n\n\nclass WeightedSFTTrainer(SFTTrainer):\n    \"\"\"Custom SFT Trainer with weighted loss - compatible with Unsloth\"\"\"\n\n    def __init__(self, class_weights, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.class_weights = class_weights\n        self.debug_counter = 0\n\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        \"\"\"\n        Custom loss computation with class weights\n        Compatible with Unsloth's additional parameters using **kwargs\n        \"\"\"\n        self.debug_counter += 1\n        \n        # Debug: Print detailed information\n        print(f\"\\nðŸ” DEBUG Step {self.debug_counter}:\")\n        print(f\"   Model type: {type(model)}\")\n        print(f\"   Model device: {next(model.parameters()).device if model.parameters() else 'Unknown'}\")\n        print(f\"   Inputs keys: {list(inputs.keys()) if inputs else 'None'}\")\n        print(f\"   Inputs types: {[(k, type(v)) for k, v in inputs.items()] if inputs else 'None'}\")\n        \n        # Check inputs validity\n        if inputs is None:\n            print(\"âŒ ERROR: inputs is None\")\n            return torch.tensor(0.0, requires_grad=True, device=self.model.device)\n        \n        labels = inputs.get(\"labels\")\n        print(f\"   Labels shape: {labels.shape if labels is not None else 'None'}\")\n        print(f\"   Labels device: {labels.device if labels is not None else 'None'}\")\n        \n        # Try model forward pass with error handling\n        try:\n            print(\"   Attempting model forward pass...\")\n            outputs = model(**inputs)\n            print(f\"   âœ… Forward pass successful\")\n            print(f\"   Outputs type: {type(outputs)}\")\n            \n            # Debug outputs structure\n            if outputs is None:\n                print(\"âŒ ERROR: model outputs is None\")\n                return torch.tensor(0.0, requires_grad=True, device=self.model.device)\n            \n            print(f\"   Outputs attributes: {dir(outputs) if hasattr(outputs, '__dict__') else 'Not object'}\")\n            \n            if hasattr(outputs, '__dict__'):\n                print(f\"   Outputs dict: {outputs.__dict__.keys()}\")\n            \n        except Exception as e:\n            print(f\"âŒ ERROR in model forward pass: {e}\")\n            return torch.tensor(0.0, requires_grad=True, device=self.model.device)\n\n        # Try different ways to access logits\n        logits = None\n        \n        if hasattr(outputs, 'logits'):\n            logits = outputs.logits\n            print(f\"   âœ… Found logits via outputs.logits: {logits.shape if logits is not None else 'None'}\")\n        elif isinstance(outputs, dict) and 'logits' in outputs:\n            logits = outputs['logits']\n            print(f\"   âœ… Found logits via outputs['logits']: {logits.shape if logits is not None else 'None'}\")\n        elif isinstance(outputs, tuple) and len(outputs) > 0:\n            logits = outputs[0]\n            print(f\"   âœ… Found logits via outputs[0]: {logits.shape if logits is not None else 'None'}\")\n        else:\n            print(f\"âŒ ERROR: Could not find logits in outputs\")\n            print(f\"   Trying all attributes...\")\n            for attr in dir(outputs):\n                if not attr.startswith('_'):\n                    val = getattr(outputs, attr)\n                    print(f\"     {attr}: {type(val)} - {val.shape if hasattr(val, 'shape') else val}\")\n\n        if logits is None:\n            print(\"âŒ CRITICAL: logits is None - using fallback loss\")\n            # Fall back to standard loss if available\n            if hasattr(outputs, 'loss') and outputs.loss is not None:\n                print(f\"   Using fallback loss: {outputs.loss}\")\n                return (outputs.loss, outputs) if return_outputs else outputs.loss\n            else:\n                print(\"   No fallback loss available - returning zero loss\")\n                return torch.tensor(0.0, requires_grad=True, device=self.model.device)\n\n        # If we get here, logits is not None\n        print(f\"   âœ… Logits found: {logits.shape}, device: {logits.device}\")\n\n        if labels is not None:\n            # For language modeling, we predict next token\n            if logits.dim() >= 3:  # Standard case: [batch, seq_len, vocab_size]\n                shift_logits = logits[..., :-1, :].contiguous()\n                shift_labels = labels[..., 1:].contiguous()\n                print(f\"   Shifted logits: {shift_logits.shape}\")\n                print(f\"   Shifted labels: {shift_labels.shape}\")\n            else:\n                # Handle edge case where logits might be 2D\n                shift_logits = logits\n                shift_labels = labels\n                print(f\"   Using original logits (2D): {shift_logits.shape}\")\n\n            # Flatten the tokens\n            shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n            shift_labels = shift_labels.view(-1)\n            print(f\"   Flattened logits: {shift_logits.shape}\")\n            print(f\"   Flattened labels: {shift_labels.shape}\")\n\n            # Move weights to correct device\n            weights = self.class_weights.to(shift_logits.device)\n\n            # Find positions where we're predicting Yes/No tokens\n            yes_no_mask = (shift_labels == YES_TOKEN_ID) | (shift_labels == NO_TOKEN_ID)\n            yes_no_count = yes_no_mask.sum().item()\n            print(f\"   Yes/No token positions found: {yes_no_count}\")\n\n            if yes_no_mask.any():\n                # Apply weighted loss only to Yes/No predictions\n                yes_no_logits = shift_logits[yes_no_mask]\n                yes_no_labels = shift_labels[yes_no_mask]\n\n                # Map token IDs to class indices\n                class_labels = torch.where(yes_no_labels == YES_TOKEN_ID, 1, 0)\n\n                # Apply weighted cross entropy to Yes/No predictions\n                weighted_loss = F.cross_entropy(\n                    yes_no_logits,\n                    yes_no_labels,\n                    reduction='none'\n                )\n\n                # Apply class weights\n                class_weights_expanded = weights[class_labels]\n                weighted_loss = (weighted_loss * class_weights_expanded).mean()\n\n                # Standard loss for other tokens\n                other_mask = ~yes_no_mask\n                if other_mask.any():\n                    other_loss = F.cross_entropy(\n                        shift_logits[other_mask],\n                        shift_labels[other_mask],\n                        ignore_index=-100\n                    )\n                    # Combine losses (give more weight to Yes/No predictions)\n                    loss = 0.7 * weighted_loss + 0.3 * other_loss\n                    print(f\"   Combined loss: weighted={weighted_loss:.4f}, other={other_loss:.4f}, final={loss:.4f}\")\n                else:\n                    loss = weighted_loss\n                    print(f\"   Weighted loss only: {loss:.4f}\")\n            else:\n                # No Yes/No tokens found, use standard loss\n                loss = F.cross_entropy(\n                    shift_logits,\n                    shift_labels,\n                    ignore_index=-100\n                )\n                print(f\"   Standard loss (no Yes/No tokens): {loss:.4f}\")\n        else:\n            # No labels provided, use model's built-in loss if available\n            if hasattr(outputs, 'loss') and outputs.loss is not None:\n                loss = outputs.loss\n                print(f\"   Using model's built-in loss: {loss:.4f}\")\n            else:\n                loss = torch.tensor(0.0, requires_grad=True, device=logits.device)\n                print(f\"   Zero loss (no labels, no built-in loss)\")\n\n        print(f\"   Final loss: {loss:.4f}\")\n        return (loss, outputs) if return_outputs else loss\n\n\ndef main():\n    # TT-12: Get example-based training data (train on examples, not real comments)\n    train_df = get_example_based_training_data(DATA_PATH)\n    train_dataset = build_dataset_unsloth(train_df)\n\n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n\n    # ðŸš€ UNSLOTH: Load model with 4-bit quantization (2x T4 optimized)\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,  # Adjust based on your max sequence length\n        dtype=None,  # Auto-detect (will use float16)\n        load_in_4bit=True,  # Enable 4-bit quantization\n        trust_remote_code=True,\n        local_files_only=True,\n        device_map=\"balanced\"\n    )\n    print(\"âœ… Unsloth model loaded with 4-bit quantization across 2x T4\")\n\n    # ðŸš€ UNSLOTH: Add LoRA adapters (automatic and optimized)\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r=16,  # LoRA rank (can try 8, 16, 32, 64, 128)\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n        lora_alpha=32,  # LoRA alpha (typically equal to r for Unsloth)\n        lora_dropout=0,  # 0 for faster training with Unsloth\n        bias=\"none\",\n        random_state=3407,  # For reproducibility\n        use_rslora=False,  # Can try True for better stability\n        loftq_config=None,  # LoftQ for even better quality\n        use_gradient_checkpointing=\"unsloth\"\n    )\n    print(\"âœ… Unsloth LoRA adapters added\")\n\n    # ðŸš€ UNSLOTH: Optimized training arguments for 2x T4 GPUs (28GB total)\n    training_args = TrainingArguments(\n        per_device_train_batch_size=2,  # Adjusted for memory\n        gradient_accumulation_steps=8,  # Effective batch size = 2*2*8 = 32\n        warmup_steps=5,  # Quick warmup with Unsloth\n        num_train_epochs=1,\n        learning_rate=1e-4,  # Conservative learning rate\n        fp16=not torch.cuda.is_bf16_supported(),\n        bf16=torch.cuda.is_bf16_supported(),\n        logging_steps=1,  # Frequent logging for monitoring\n        optim=\"adamw_8bit\",  # 8-bit optimizer for memory efficiency\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",  # Simple linear decay\n        seed=666,\n        output_dir=LORA_PATH,\n        report_to=\"none\",\n        save_strategy=\"steps\",\n        save_steps=20,  # Save frequently for monitoring\n        save_total_limit=2,  # Keep only recent checkpoints\n        dataloader_pin_memory=False,  # Unsloth handles this\n        # Multi-GPU optimizations for 2x T4\n        dataloader_num_workers=4,  # Parallel data loading\n        remove_unused_columns=False,  # Keep all data\n        ddp_find_unused_parameters=False,  # DDP optimization\n        ddp_broadcast_buffers=False,  # Reduce communication overhead\n    )\n    print(\"âœ… Unsloth training arguments configured for 2x T4\")\n\n    # Get class weights for balanced training\n    class_weights = get_class_weights()\n\n    # ðŸš€ UNSLOTH: Use WeightedSFTTrainer with class weights\n    trainer = WeightedSFTTrainer(\n        class_weights=class_weights,\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=train_dataset,\n        dataset_text_field=\"text\",  # Unsloth expects \"text\" field\n        max_seq_length=2048,\n        dataset_num_proc=4,  # More parallel processing for 2x T4\n        packing=False,  # Can try True for even faster training\n        args=training_args,\n    )\n\n    print(\"ðŸš€ Starting Unsloth training with weighted loss on 2x T4...\")\n    print(\"ðŸŽ¯ Heavily penalizing false positives (predicting 'Yes' when should be 'No')\")\n\n    # ðŸš€ UNSLOTH: Train with optimized loop\n    trainer_stats = trainer.train()\n\n    print(\"âœ… Unsloth training completed!\")\n    print(f\"Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\n    print(f\"Samples/second: {trainer_stats.metrics['train_samples_per_second']:.2f}\")\n    print(f\"GPU utilization optimized for 2x T4 setup\")\n\n    # ðŸš€ UNSLOTH: Save LoRA adapters in vLLM-compatible format\n    print(\"ðŸ’¾ Saving LoRA adapters for vLLM compatibility...\")\n\n    # Save tokenizer\n    tokenizer.save_pretrained(LORA_PATH)\n\n    # Save model in PEFT format (vLLM compatible)\n    model.save_pretrained(LORA_PATH)\n\n    # Save merged 4-bit model\n    folder = \"merged_4bit_model\"\n    model.save_pretrained_merged(folder, tokenizer, save_method=\"merged_4bit\")\n\n    print(f\"âœ… LoRA adapters saved to: {LORA_PATH}\")\n    print(f\"âœ… Merged 4-bit model saved to: {folder}\")\n    print(\"ðŸŽ¯ Ready for vLLM inference with weighted training!\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.execute_input":"2025-09-19T03:33:21.868864Z","iopub.status.busy":"2025-09-19T03:33:21.868583Z","iopub.status.idle":"2025-09-19T03:33:21.880147Z","shell.execute_reply":"2025-09-19T03:33:21.879602Z","shell.execute_reply.started":"2025-09-19T03:33:21.868841Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ðŸŽ¯ 2x T4 GPU Optimization Guide\n\n## âš¡ **Multi-GPU Configuration for TT-11**\n\n### **Your Setup: 2x T4 (28GB Total VRAM)**\n- **GPU 0**: ~14GB VRAM\n- **GPU 1**: ~14GB VRAM\n- **Total**: 28GB available for training\n\n### **Optimizations Applied:**\n\n#### **1. Model Distribution**\n```python\ndevice_map=\"auto\"  # Automatic distribution across GPUs\nmax_memory={0: \"13GB\", 1: \"13GB\"}  # Reserve 1GB per GPU for operations\n```\n\n#### **2. Batch Size Scaling**\n```python\nper_device_train_batch_size=4,  # 4 samples per GPU (8 total)\ngradient_accumulation_steps=2,  # Effective batch = 4*2*2 = 16\n```\n\n#### **3. Memory Optimizations**\n```python\nload_in_4bit=True,              # 4-bit quantization saves ~75% memory\nuse_gradient_checkpointing=True, # Trade compute for memory\ndataloader_pin_memory=False,     # Let Unsloth handle memory\n```\n\n#### **4. Multi-GPU Training**\n```python\ndataloader_num_workers=4,        # Parallel data loading\nddp_find_unused_parameters=False, # DDP optimization\nddp_broadcast_buffers=False,     # Reduce communication\n```\n\n### **Expected Performance:**\n- **Training Speed**: 3x-6x faster than single GPU\n- **Memory Usage**: ~12-13GB per GPU\n- **Effective Batch**: 16 samples (vs 4 on single GPU)\n- **Total Time**: 5-8 minutes for full training\n\n### **Troubleshooting 2x T4:**\n\n#### **If you get OOM (Out of Memory):**\n```python\n# Reduce batch size\nper_device_train_batch_size=2,   # 2 per GPU instead of 4\ngradient_accumulation_steps=4,   # Keep effective batch size\n\n# Or reduce sequence length\nmax_seq_length=1024,             # Shorter sequences\n```\n\n#### **If training is slower than expected:**\n```python\n# Check GPU utilization\nnvidia-smi  # Should show ~90%+ on both GPUs\n\n# Increase batch size if memory allows\nper_device_train_batch_size=6,   # Try larger batches\n```\n\n#### **Memory Distribution Check:**\n```python\nprint(f\"Available GPUs: {torch.cuda.device_count()}\")\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_properties(i).total_memory // 1024**3}GB\")\n```","metadata":{}},{"cell_type":"code","source":"!export VLLM_LOGGING_LEVEL=DEBUG\n","metadata":{"execution":{"iopub.execute_input":"2025-09-18T15:30:55.180228Z","iopub.status.busy":"2025-09-18T15:30:55.179978Z","iopub.status.idle":"2025-09-18T15:30:55.295403Z","shell.execute_reply":"2025-09-18T15:30:55.294688Z","shell.execute_reply.started":"2025-09-18T15:30:55.180206Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile validation_vllm.py\nimport os\nos.environ[\"TRITON_NUM_STAGES\"] = \"3\"  # Reduce stages\nos.environ[\"VLLM_USE_V1\"] = \"1\"\nimport vllm\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\nfrom vllm.lora.request import LoRARequest\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_vllm():\n    \"\"\"Run validation using Unsloth-trained model with vLLM for precise AUC\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"ðŸ” Running validation on {len(val_dataset)} real comments\")\n    model=\"/kaggle/working/qwen3_1.7b_merged\"\n    # ðŸŽ¯ VLLM: Initialize with Unsloth LoRA support for precise probabilities\n    llm = vllm.LLM(\n        model= model,\n        tensor_parallel_size=1,\n        gpu_memory_utilization=0.90, # Reduced to prevent OOM\n        trust_remote_code=True,\n        dtype=\"half\" ,\n        quantization=\"bitsandbytes\",\n        #load_format=\"bitsandbytes\" ,\n        enforce_eager=True,\n        max_model_len=700,  # Reduced from 2048 to fix Triton shared memory error on T4\n        disable_log_stats=True,\n        enable_prefix_caching=True,\n        enable_lora=True,\n        max_lora_rank=64,  # Support Unsloth's LoRA rank\n        block_size=16,\n        num_gpu_blocks_override=512\n        \n\n        \n    )\n\n    # In validation_vllm.py, modify the LLM initialization:\n    # llm = vllm.LLM(\n    #     BASE_MODEL_PATH,\n    #     tensor_parallel_size=1,\n    #     gpu_memory_utilization=0.90,\n    #     trust_remote_code=True,\n    #     dtype=\"half\",  # Use half precision instead of quantization\n    #     enforce_eager=True,\n    #     max_model_len=512,\n    #     disable_log_stats=True,\n    #     enable_prefix_caching=True,\n    #     enable_lora=True,\n    #     max_lora_rank=64,\n    # )\n\n    tokenizer = llm.get_tokenizer()\n\n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n\n    # ðŸŽ¯ VLLM: Generate with Unsloth LoRA for most accurate probabilities\n    # We remove the logits_processor and decrease logprobs to get token probabilities\n    outputs = llm.generate(\n        texts,\n        vllm.SamplingParams(\n            skip_special_tokens=True,\n            max_tokens=1,\n            logprobs=20,  # Request top 20 logprobs to find \"Yes\" and \"No\"\n        ),\n        use_tqdm=True,\n        lora_request=LoRARequest(\"unsloth_lora\", 1, LORA_PATH)  # Load Unsloth LoRA\n    )\n\n    # Extract predictions and probabilities with vLLM precision\n    predictions = []\n    probabilities = []  # High-precision probabilities for AUC\n    \n    # Get token IDs for \"Yes\" and \"No\"\n    yes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\n    no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n    \n    for out in outputs:\n        # Safely get log probabilities for \"Yes\" and \"No\"\n        log_probs = out.outputs[0].logprobs[0]\n        \n        log_prob_yes = log_probs.get(yes_token_id)\n        log_prob_no = log_probs.get(no_token_id)\n        \n        # Handle cases where tokens might not be in the top logprobs\n        if log_prob_yes is not None and log_prob_no is not None:\n            if log_prob_yes.logprob > log_prob_no.logprob:\n                predictions.append(1)\n            else:\n                predictions.append(0)\n            \n            # Calculate precise probability for AUC\n            exp_pos = np.exp(log_prob_yes.logprob)\n            exp_neg = np.exp(log_prob_no.logprob)\n            prob_positive = exp_pos / (exp_pos + exp_neg)\n            probabilities.append(prob_positive)\n        else:\n            # Fallback if one of the tokens is not in the top 20 logprobs\n            # This is unlikely but a safe fallback\n            predictions.append(0)\n            probabilities.append(0.5)\n\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    # Basic metrics\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"ðŸ“Š TT-11 VALIDATION RESULTS (Unsloth + vLLM)\")\n    print(\"=\" * 60)\n    print(f\"ðŸŽ¯ Accuracy:  {accuracy:.4f}\")\n    print(f\"ðŸŽ¯ F1 Score:  {f1:.4f}\")\n    print(f\"ðŸŽ¯ Precision: {precision:.4f}\")\n    print(f\"ðŸŽ¯ Recall:    {recall:.4f}\")\n    print(f\"ðŸŽ¯ AUC Score: {auc:.4f} (High-precision vLLM)\")\n    print(\"=\" * 60)\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\nðŸ“ˆ Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    # Classification report\n    print(\"\\nðŸ“‹ Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'auc': auc,\n        'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-11: Unsloth Training + vLLM Validation Results', fontsize=16, fontweight='bold')\n    \n    # 1. Confusion Matrix Heatmap\n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    # 2. ROC Curve\n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (vLLM High-Precision)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # 3. Probability Distribution\n    pos_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 1]\n    neg_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (vLLM Precision)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    # 4. Metrics Bar Chart\n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics['accuracy'], metrics['f1'], metrics['precision'], metrics['recall'], metrics['auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (Unsloth + vLLM)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt11_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    # Add predictions to dataframe\n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\nðŸ“Š PERFORMANCE BY RULE (vLLM High-Precision AUC):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        if len(np.unique(rule_true)) > 1:  # Check if both classes exist\n            rule_auc = roc_auc_score(rule_true, rule_prob)\n        else:\n            rule_auc = np.nan\n            \n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\")\n        print(f\"  Samples: {len(rule_data)}\")\n        print(f\"  Accuracy: {rule_acc:.3f}\")\n        print(f\"  F1 Score: {rule_f1:.3f}\" if not np.isnan(rule_f1) else \"  F1 Score: N/A\")\n        print(f\"  AUC Score: {rule_auc:.3f}\" if not np.isnan(rule_auc) else \"  AUC Score: N/A\")\n        print()\n        \n        rule_metrics.append({\n            'rule': rule,\n            'samples': len(rule_data),\n            'accuracy': rule_acc,\n            'f1': rule_f1,\n            'auc': rule_auc\n        })\n    \n    # Save detailed results\n    analysis_df.to_csv('/kaggle/working/tt11_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt11_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"ðŸ”¬ TT-11: Unsloth Training + vLLM Validation\")\n    print(\"ðŸš€ Ultra-fast training + High-precision inference!\")\n    print(\"ðŸ“š Training: Model learned from examples with Unsloth speed\")\n    print(\"ðŸ§ª Validation: Testing on real comments with vLLM precision\")\n    print(\"=\" * 70)\n    \n    # Run validation\n    true_labels, predictions, probabilities, val_df = run_validation_vllm()\n    \n    # Calculate metrics\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    \n    # Create visualizations\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    \n    # Analyze by rule\n    rule_metrics = analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"âœ… TT-11 Validation completed!\")\n    print(\"ðŸ“ˆ Visualizations saved: /kaggle/working/tt11_validation_results.png\")\n    print(\"ðŸ“Š Detailed results: /kaggle/working/tt11_detailed_results.csv\")\n    print(\"ðŸ“‹ Rule metrics: /kaggle/working/tt11_rule_metrics.csv\")\n    print(\"ðŸŽ¯ Best of both worlds: Unsloth speed + vLLM precision!\")\n    \n    return metrics, rule_metrics\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"execution":{"iopub.execute_input":"2025-09-19T03:33:30.211543Z","iopub.status.busy":"2025-09-19T03:33:30.211264Z","iopub.status.idle":"2025-09-19T03:33:30.220823Z","shell.execute_reply":"2025-09-19T03:33:30.220255Z","shell.execute_reply.started":"2025-09-19T03:33:30.211522Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile validation_transformers.py\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom unsloth import FastLanguageModel  # Add this import\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\nfrom constants import *\nfrom tqdm import tqdm\n\ndef run_validation_transformers():\n    \"\"\"Run validation using Unsloth fast inference with merged LoRA - Maximum speed!\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"ðŸ” Running validation on {len(val_dataset)} real comments (Unsloth Fast Inference)\")\n    folder = \"/kaggle/working/Merged_unsloth_model\"  # âœ… Fixed typo\n\n    # ðŸš€ UNSLOTH: Load merged model with fast inference support\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=LORA_PATH,  # Use merged model path\n        max_seq_length=2048,\n        load_in_4bit=True,  # Keep 4-bit for speed\n        dtype=None,\n    )\n    \n    # ðŸš€ UNSLOTH: Enable fast inference mode\n    FastLanguageModel.for_inference(model)\n    \n    # Get token IDs for \"Yes\" and \"No\"\n    yes_token_id = YES_TOKEN_ID  \n    no_token_id = NO_TOKEN_ID \n    \n    print(f\"ðŸŽ¯ Token IDs: Yes={yes_token_id}, No={no_token_id}\")\n    \n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n    \n    # ðŸš€ UNSLOTH: Fast batch inference\n    predictions = []\n    probabilities = []\n    batch_size = 16  # Larger batches with Unsloth optimization\n    \n    print(\"ðŸš€ Running fast inference with Unsloth...\")\n    \n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch_texts = texts[i:i+batch_size]\n        \n        # ðŸš€ UNSLOTH: Optimized tokenization and inference\n        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            # ðŸš€ UNSLOTH: Fast forward pass\n            outputs = model(**inputs)\n            next_token_logits = outputs.logits[:, -1, :]  # Get last token logits\n            \n            # Get probabilities for \"Yes\" and \"No\" tokens\n            yes_logits = next_token_logits[:, yes_token_id]\n            no_logits = next_token_logits[:, no_token_id]\n            \n            # Convert to probabilities using softmax over Yes/No only\n            combined_logits = torch.stack([no_logits, yes_logits], dim=1)  # [batch, 2]\n            probs = torch.softmax(combined_logits, dim=1)  # [batch, 2]\n            \n            # Extract predictions and probabilities\n            batch_predictions = torch.argmax(probs, dim=1).cpu().numpy()\n            batch_probabilities = probs[:, 1].cpu().numpy()  # Probability of \"Yes\" (violation)\n            \n            predictions.extend(batch_predictions.tolist())\n            probabilities.extend(batch_probabilities.tolist())\n    \n    print(\"âœ… Fast inference completed!\")\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    # Basic metrics\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"ðŸ“Š TT-11 VALIDATION RESULTS (Unsloth + Transformers)\")\n    print(\"=\" * 60)\n    print(f\"ðŸŽ¯ Accuracy:  {accuracy:.4f}\")\n    print(f\"ðŸŽ¯ F1 Score:  {f1:.4f}\")\n    print(f\"ðŸŽ¯ Precision: {precision:.4f}\")\n    print(f\"ðŸŽ¯ Recall:    {recall:.4f}\")\n    print(f\"ðŸŽ¯ AUC Score: {auc:.4f} (Standard Transformers)\")\n    print(\"=\" * 60)\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\nðŸ“ˆ Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    # Classification report\n    print(\"\\nðŸ“‹ Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'auc': auc,\n        'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-11: Unsloth Training + Transformers Validation Results', fontsize=16, fontweight='bold')\n    \n    # 1. Confusion Matrix Heatmap\n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    # 2. ROC Curve\n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (Transformers)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # 3. Probability Distribution\n    pos_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 1]\n    neg_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (Transformers)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    # 4. Metrics Bar Chart\n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics['accuracy'], metrics['f1'], metrics['precision'], metrics['recall'], metrics['auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (Unsloth + Transformers)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt11_transformers_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    # Add predictions to dataframe\n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\nðŸ“Š PERFORMANCE BY RULE (Transformers):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        if len(np.unique(rule_true)) > 1:  # Check if both classes exist\n            rule_auc = roc_auc_score(rule_true, rule_prob)\n        else:\n            rule_auc = np.nan\n            \n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\")\n        print(f\"  Samples: {len(rule_data)}\")\n        print(f\"  Accuracy: {rule_acc:.3f}\")\n        print(f\"  F1 Score: {rule_f1:.3f}\" if not np.isnan(rule_f1) else \"  F1 Score: N/A\")\n        print(f\"  AUC Score: {rule_auc:.3f}\" if not np.isnan(rule_auc) else \"  AUC Score: N/A\")\n        print()\n        \n        rule_metrics.append({\n            'rule': rule,\n            'samples': len(rule_data),\n            'accuracy': rule_acc,\n            'f1': rule_f1,\n            'auc': rule_auc\n        })\n    \n    # Save detailed results\n    analysis_df.to_csv('/kaggle/working/tt11_transformers_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt11_transformers_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"ðŸ”¬ TT-11: Unsloth Training + Transformers Validation\")\n    print(\"ðŸš€ Ultra-fast training + Universal compatibility!\")\n    print(\"ðŸ“š Training: Model learned from examples with Unsloth speed\")\n    print(\"ðŸ§ª Validation: Testing on real comments with standard Transformers\")\n    print(\"=\" * 70)\n    \n    # Run validation\n    true_labels, predictions, probabilities, val_df = run_validation_transformers()\n    \n    # Calculate metrics\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    \n    # Create visualizations\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    \n    # Analyze by rule\n    rule_metrics = analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"âœ… TT-11 Transformers Validation completed!\")\n    print(\"ðŸ“ˆ Visualizations saved: /kaggle/working/tt11_transformers_validation_results.png\")\n    print(\"ðŸ“Š Detailed results: /kaggle/working/tt11_transformers_detailed_results.csv\")\n    print(\"ðŸ“‹ Rule metrics: /kaggle/working/tt11_transformers_rule_metrics.csv\")\n    print(\"ðŸŽ¯ Reliable and compatible validation with Unsloth speed!\")\n    \n    return metrics, rule_metrics\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:34:31.732024Z","iopub.execute_input":"2025-09-20T16:34:31.732860Z","iopub.status.idle":"2025-09-20T16:34:31.743525Z","shell.execute_reply.started":"2025-09-20T16:34:31.732824Z","shell.execute_reply":"2025-09-20T16:34:31.742824Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting validation_transformers.py\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"%%writefile accelerate_config.yaml\ncompute_environment: LOCAL_MACHINE\ndebug: false\n# #deepspeed_config:\n#   gradient_accumulation_steps: auto\n#   gradient_clipping: 1.0\n#   train_batch_size: 16\n#   train_micro_batch_size_per_gpu: 2\n  \n#   zero_stage: 2\n#   offload_optimizer_device: none\n#   offload_param_device: none\n#   zero3_init_flag: false\n  \n#   stage3_gather_16bit_weights_on_model_save: false\n#   stage3_max_live_parameters: 1e8\n#   stage3_max_reuse_distance: 1e8\n#   stage3_prefetch_bucket_size: 5e7\n#   stage3_param_persistence_threshold: 1e5\n  \n#   zero_allow_untested_optimizer: true\n#   zero_force_ds_cpu_optimizer: false\n  \n#   fp16:\n#     enabled: true\n#     loss_scale: 0\n#     initial_scale_power: 16\n#     loss_scale_window: 1000\n#     hysteresis: 2\n#     min_loss_scale: 1\n  \ndistributed_type: None\ndowncast_bf16: 'no'\ndynamo_config:\n  dynamo_backend: INDUCTOR\n  dynamo_use_fullgraph: false\n  dynamo_use_dynamic: false\nenable_cpu_affinity: false\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 1\nnum_processes: 2\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false","metadata":{"execution":{"iopub.execute_input":"2025-09-15T11:40:14.900532Z","iopub.status.busy":"2025-09-15T11:40:14.900015Z","iopub.status.idle":"2025-09-15T11:40:14.912715Z","shell.execute_reply":"2025-09-15T11:40:14.912134Z","shell.execute_reply.started":"2025-09-15T11:40:14.900507Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile accelerate_config.yaml\ncompute_environment: LOCAL_MACHINE\ndebug: false\n# Removed deepspeed_config section entirely\ndistributed_type:  NO   # Changed from DEEPSPEED to MULTI_GPU\ndowncast_bf16: 'no'\ndynamo_config:\n  dynamo_backend: INDUCTOR\n  dynamo_use_fullgraph: false\n  dynamo_use_dynamic: false\nenable_cpu_affinity: false\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 1\nnum_processes: 2  # Keep this for 2 GPUs\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:14:48.447114Z","iopub.execute_input":"2025-09-20T16:14:48.447446Z","iopub.status.idle":"2025-09-20T16:14:48.452136Z","shell.execute_reply.started":"2025-09-20T16:14:48.447424Z","shell.execute_reply":"2025-09-20T16:14:48.451435Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Writing accelerate_config.yaml\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!accelerate launch --config_file accelerate_config.yaml train_unsloth.py\n","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:25:23.191586Z","iopub.execute_input":"2025-09-20T16:25:23.191846Z","iopub.status.idle":"2025-09-20T16:33:57.543813Z","shell.execute_reply.started":"2025-09-20T16:25:23.191829Z","shell.execute_reply":"2025-09-20T16:33:57.542896Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-20 16:25:35.169244: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758385535.192879     518 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758385535.201122     518 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-20 16:25:42 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-20 16:25:44 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\nâœ… Using Qwen3 1.7B model from local Kaggle input\nðŸŽ¯ TT-12: Mixed data sampling - Training: 2000 samples (30% examples, 70% real)\nðŸ“Š Validation: 200 samples (90% examples, 10% real)\nðŸ”§ Weighted loss with 0.2x penalty for false positives\nðŸŽ¯ NORMAL MODE: Training on both positive and negative examples\nðŸ”„ Creating mixed training data: 2000 samples total\nðŸ“Š Split: 30% examples, 70% real comments\nðŸ“Š Dataset split: 1623 training pool, 406 validation pool\nðŸ“Š Training rules distribution: {'No legal advice: Do not offer or request legal advice.': 813, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 810}\nðŸ“Š Validation rules distribution: {'No legal advice: Do not offer or request legal advice.': 204, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 202}\nðŸŽ¯ Target: 600 example-based + 1400 real comment samples\nðŸ“Š Stratified sampling for examples: 150 samples\nðŸ“Š Example-based dataset: 600 samples\nðŸ“Š Positive examples: 300\nðŸ“Š Negative examples: 300\nðŸ“Š Stratified sampling for real comments: 1400 samples\nðŸ“Š Real comment dataset: 1400 samples\nðŸ“Š Rule violations: 710 positive, 690 negative\n\nðŸ“‹ MIXED TRAINING DATASET SUMMARY:\nðŸ“Š Total samples: 2000\nðŸ“Š Rule violations: 1010 positive, 990 negative\nðŸ“Š Balance: 50.5% positive\n/kaggle/working/utils.py:224: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  mixed_training_df._validation_pool = val_pool\nTraining dataset size: 2000 samples\nAvailable GPUs: 2\nUnsloth: WARNING `trust_remote_code` is True.\nAre you certain you want to do remote code execution?\n==((====))==  Unsloth 2025.9.7: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nâœ… Unsloth model loaded with 4-bit quantization across 2x T4\nUnsloth 2025.9.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\nâœ… Unsloth LoRA adapters added\nâœ… Unsloth training arguments configured\nUnsloth: Tokenizing [\"text\"] (num_proc=8): 100%|â–ˆ| 2000/2000 [00:03<00:00, 562.3\n[2025-09-20 16:26:05,216] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-20 16:26:05,732] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\nâœ… Unsloth SFT Trainer created\nðŸš€ Starting Unsloth training...\nUnsloth: Enabled auto compiling\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n   \\\\   /|    Num examples = 2,000 | Num Epochs = 1 | Total steps = 32\nO^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n \"-____-\"     Trainable parameters = 17,432,576 of 1,738,007,552 (1.00% trained)\n  0%|                                                    | 0/32 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!\n{'loss': 4.044, 'grad_norm': 28.871856689453125, 'learning_rate': 0.0, 'epoch': 0.03}\n{'loss': 3.9914, 'grad_norm': 28.442197799682617, 'learning_rate': 4e-05, 'epoch': 0.06}\n{'loss': 3.6712, 'grad_norm': 6.06510066986084, 'learning_rate': 8e-05, 'epoch': 0.1}\n{'loss': 3.3653, 'grad_norm': 3.9593708515167236, 'learning_rate': 0.00012, 'epoch': 0.13}\n{'loss': 3.1361, 'grad_norm': 3.107633590698242, 'learning_rate': 0.00016, 'epoch': 0.16}\n{'loss': 2.8686, 'grad_norm': 2.7897233963012695, 'learning_rate': 0.0002, 'epoch': 0.19}\n{'loss': 2.5418, 'grad_norm': 2.774216413497925, 'learning_rate': 0.0001925925925925926, 'epoch': 0.22}\n{'loss': 2.3708, 'grad_norm': 2.352654218673706, 'learning_rate': 0.0001851851851851852, 'epoch': 0.26}\n{'loss': 2.227, 'grad_norm': 1.901868224143982, 'learning_rate': 0.00017777777777777779, 'epoch': 0.29}\n{'loss': 2.0156, 'grad_norm': 1.4792505502700806, 'learning_rate': 0.00017037037037037037, 'epoch': 0.32}\n{'loss': 1.9637, 'grad_norm': 1.465834379196167, 'learning_rate': 0.00016296296296296295, 'epoch': 0.35}\n{'loss': 1.9877, 'grad_norm': 1.4212759733200073, 'learning_rate': 0.00015555555555555556, 'epoch': 0.38}\n{'loss': 1.9053, 'grad_norm': 1.128129482269287, 'learning_rate': 0.00014814814814814815, 'epoch': 0.42}\n{'loss': 1.9333, 'grad_norm': 0.7725051045417786, 'learning_rate': 0.00014074074074074076, 'epoch': 0.45}\n{'loss': 1.8886, 'grad_norm': 0.7811769247055054, 'learning_rate': 0.00013333333333333334, 'epoch': 0.48}\n{'loss': 1.8589, 'grad_norm': 0.6884003281593323, 'learning_rate': 0.00012592592592592592, 'epoch': 0.51}\n{'loss': 1.7762, 'grad_norm': 0.6402652263641357, 'learning_rate': 0.00011851851851851852, 'epoch': 0.54}\n{'loss': 1.7694, 'grad_norm': 0.7097988128662109, 'learning_rate': 0.00011111111111111112, 'epoch': 0.58}\n{'loss': 1.7966, 'grad_norm': 0.6708892583847046, 'learning_rate': 0.0001037037037037037, 'epoch': 0.61}\n{'loss': 1.7878, 'grad_norm': 0.6682239174842834, 'learning_rate': 9.62962962962963e-05, 'epoch': 0.64}\n{'loss': 1.8848, 'grad_norm': 0.6607533097267151, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.67}\n{'loss': 1.7782, 'grad_norm': 0.6892961263656616, 'learning_rate': 8.148148148148148e-05, 'epoch': 0.7}\n{'loss': 1.7941, 'grad_norm': 0.645623505115509, 'learning_rate': 7.407407407407407e-05, 'epoch': 0.74}\n{'loss': 1.7933, 'grad_norm': 0.5939496159553528, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.77}\n{'loss': 1.7935, 'grad_norm': 0.6420817375183105, 'learning_rate': 5.925925925925926e-05, 'epoch': 0.8}\n{'loss': 1.7205, 'grad_norm': 0.5846848487854004, 'learning_rate': 5.185185185185185e-05, 'epoch': 0.83}\n{'loss': 1.7884, 'grad_norm': 0.6246790289878845, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.86}\n{'loss': 1.7819, 'grad_norm': 0.6398747563362122, 'learning_rate': 3.7037037037037037e-05, 'epoch': 0.9}\n{'loss': 1.735, 'grad_norm': 0.6211516261100769, 'learning_rate': 2.962962962962963e-05, 'epoch': 0.93}\n{'loss': 1.6232, 'grad_norm': 0.6190028786659241, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.96}\n{'loss': 1.6811, 'grad_norm': 0.6195240020751953, 'learning_rate': 1.4814814814814815e-05, 'epoch': 0.99}\n{'loss': 1.4397, 'grad_norm': 1.0905760526657104, 'learning_rate': 7.4074074074074075e-06, 'epoch': 1.0}\n{'train_runtime': 461.2568, 'train_samples_per_second': 4.336, 'train_steps_per_second': 0.069, 'train_loss': 2.178528517484665, 'epoch': 1.0}\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [07:41<00:00, 14.41s/it]\nâœ… Unsloth training completed!\n/usr/local/lib/python3.11/dist-packages/unsloth_zoo/saving_utils.py:899: UserWarning: Model /kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit not found locally or on HuggingFace\n  warnings.warn(f\"Model {model_name} not found locally or on HuggingFace\")\nâœ… Model and LoRA adapters saved to qwen3_1.7b_unsloth_lora_validation/\nâœ… Merged model Saved To  /kaggle/working/Merged_unsloth_model\nðŸŽ¯ Ass training complete! Ready for vLLM validation.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"!python validation_transformers.py","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:34:39.469762Z","iopub.execute_input":"2025-09-20T16:34:39.470451Z","iopub.status.idle":"2025-09-20T16:35:53.405825Z","shell.execute_reply.started":"2025-09-20T16:34:39.470427Z","shell.execute_reply":"2025-09-20T16:35:53.405062Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-20 16:34:45.862739: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758386085.885740     797 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758386085.893199     797 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-20 16:34:52 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-20 16:34:54 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\nâœ… Using Qwen3 1.7B model from local Kaggle input\nðŸŽ¯ TT-12: Mixed data sampling - Training: 2000 samples (30% examples, 70% real)\nðŸ“Š Validation: 200 samples (90% examples, 10% real)\nðŸ”§ Weighted loss with 0.2x penalty for false positives\nðŸŽ¯ NORMAL MODE: Training on both positive and negative examples\nðŸ”¬ TT-11: Unsloth Training + Transformers Validation\nðŸš€ Ultra-fast training + Universal compatibility!\nðŸ“š Training: Model learned from examples with Unsloth speed\nðŸ§ª Validation: Testing on real comments with standard Transformers\n======================================================================\nðŸ“Š Dataset split: 1623 training pool, 406 validation pool\nðŸ“Š Training rules distribution: {'No legal advice: Do not offer or request legal advice.': 813, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 810}\nðŸ“Š Validation rules distribution: {'No legal advice: Do not offer or request legal advice.': 204, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 202}\nðŸ“Š Real comment dataset: 406 samples\nðŸ“Š Rule violations: 208 positive, 198 negative\nðŸ” Running validation on 406 real comments (Unsloth Fast Inference)\n==((====))==  Unsloth 2025.9.7: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nUnsloth 2025.9.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\nðŸŽ¯ Token IDs: Yes=7414, No=2308\nðŸš€ Running fast inference with Unsloth...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:42<00:00,  1.63s/it]\nâœ… Fast inference completed!\n============================================================\nðŸ“Š TT-11 VALIDATION RESULTS (Unsloth + Transformers)\n============================================================\nðŸŽ¯ Accuracy:  0.4901\nðŸŽ¯ F1 Score:  0.0096\nðŸŽ¯ Precision: 1.0000\nðŸŽ¯ Recall:    0.0048\nðŸŽ¯ AUC Score: 0.3788 (Standard Transformers)\n============================================================\n\nðŸ“ˆ Confusion Matrix:\nTrue Negative:  198 | False Positive:    0\nFalse Negative:  207 | True Positive:     1\n\nðŸ“‹ Classification Report:\n              precision    recall  f1-score   support\n\nNo Violation       0.49      1.00      0.66       198\n   Violation       1.00      0.00      0.01       208\n\n    accuracy                           0.49       406\n   macro avg       0.74      0.50      0.33       406\nweighted avg       0.75      0.49      0.33       406\n\nFigure(1500x1200)\n\nðŸ“Š PERFORMANCE BY RULE (Transformers):\n============================================================\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\n  Samples: 202\n  Accuracy: 0.604\n  F1 Score: 0.024\n  AUC Score: 0.406\n\nRule: No legal advice: Do not offer or request legal advice.\n  Samples: 204\n  Accuracy: 0.377\n  F1 Score: 0.000\n  AUC Score: 0.480\n\nâœ… TT-11 Transformers Validation completed!\nðŸ“ˆ Visualizations saved: /kaggle/working/tt11_transformers_validation_results.png\nðŸ“Š Detailed results: /kaggle/working/tt11_transformers_detailed_results.csv\nðŸ“‹ Rule metrics: /kaggle/working/tt11_transformers_rule_metrics.csv\nðŸŽ¯ Reliable and compatible validation with Unsloth speed!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(\"he\")","metadata":{"execution":{"iopub.execute_input":"2025-09-19T03:45:17.566564Z","iopub.status.busy":"2025-09-19T03:45:17.566249Z","iopub.status.idle":"2025-09-19T03:45:17.571213Z","shell.execute_reply":"2025-09-19T03:45:17.570519Z","shell.execute_reply.started":"2025-09-19T03:45:17.566536Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"TRITON_NUM_STAGES\"] = \"1\"  ","metadata":{"execution":{"iopub.execute_input":"2025-09-15T13:30:46.119879Z","iopub.status.busy":"2025-09-15T13:30:46.119258Z","iopub.status.idle":"2025-09-15T13:30:46.123729Z","shell.execute_reply":"2025-09-15T13:30:46.122956Z","shell.execute_reply.started":"2025-09-15T13:30:46.119853Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!python train_unsloth.pyfree finetuning.\n","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-09-15T11:42:23.352401Z","iopub.status.busy":"2025-09-15T11:42:23.352158Z","iopub.status.idle":"2025-09-15T11:44:42.354882Z","shell.execute_reply":"2025-09-15T11:44:42.354161Z","shell.execute_reply.started":"2025-09-15T11:42:23.352385Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile merge_lora.py\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\nfrom constants import BASE_MODEL_PATH, LORA_PATH\n\ndef merge_and_save():\n    print(\"ðŸ”„ Loading base model...\")\n    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)\n    model = AutoModelForCausalLM.from_pretrained(\n        BASE_MODEL_PATH,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n    )\n    \n    print(\"ðŸ”— Loading LoRA adapters...\")\n    model = PeftModel.from_pretrained(model, LORA_PATH)\n    \n    print(\"ðŸ”€ Merging LoRA weights...\")\n    merged_model = model.merge_and_unload()\n    \n    # Create output directory for merged model\n    merged_path = \"/kaggle/working/qwen3_1.7b_merged\"\n    \n    print(\"ðŸ’¾ Saving merged model...\")\n    merged_model.save_pretrained(merged_path)\n    tokenizer.save_pretrained(merged_path)\n    \n    print(f\"âœ… Merged model saved to: {merged_path}\")\n    return merged_path\n\nif __name__ == \"__main__\":\n    merge_and_save()","metadata":{"execution":{"iopub.execute_input":"2025-09-19T16:21:24.147841Z","iopub.status.busy":"2025-09-19T16:21:24.147543Z","iopub.status.idle":"2025-09-19T16:21:24.154426Z","shell.execute_reply":"2025-09-19T16:21:24.153612Z","shell.execute_reply.started":"2025-09-19T16:21:24.147814Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python merge_lora.py\n!python validation_transformers.py","metadata":{"execution":{"iopub.execute_input":"2025-09-19T13:39:32.696397Z","iopub.status.busy":"2025-09-19T13:39:32.695871Z","iopub.status.idle":"2025-09-19T13:39:58.586828Z","shell.execute_reply":"2025-09-19T13:39:58.585865Z","shell.execute_reply.started":"2025-09-19T13:39:32.696374Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nmodel , tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\",\n    #model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\" ,\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T18:06:35.248667Z","iopub.execute_input":"2025-09-20T18:06:35.248998Z","iopub.status.idle":"2025-09-20T18:06:51.742602Z","shell.execute_reply.started":"2025-09-20T18:06:35.248974Z","shell.execute_reply":"2025-09-20T18:06:51.741793Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.9.7: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.4.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post1. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from unsloth.chat_templates import get_chat_template\n\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"qwen3-thinking\",\n)\nprint(tokenizer.chat_template)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T18:07:21.172022Z","iopub.execute_input":"2025-09-20T18:07:21.172648Z","iopub.status.idle":"2025-09-20T18:07:21.178480Z","shell.execute_reply.started":"2025-09-20T18:07:21.172623Z","shell.execute_reply":"2025-09-20T18:07:21.177654Z"}},"outputs":[{"name":"stdout","text":"{%- if tools %}\n    {{- '<|im_start|>system\\n' }}\n    {%- if messages[0].role == 'system' %}\n        {{- messages[0].content + '\\n\\n' }}\n    {%- endif %}\n    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n{%- else %}\n    {%- if messages[0].role == 'system' %}\n        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n{%- for message in messages[::-1] %}\n    {%- set index = (messages|length - 1) - loop.index0 %}\n    {%- if ns.multi_step_tool and message.role == \"user\" and message.content is string and not(message.content.startswith('<tool_response>') and message.content.endswith('</tool_response>')) %}\n        {%- set ns.multi_step_tool = false %}\n        {%- set ns.last_query_index = index %}\n    {%- endif %}\n{%- endfor %}\n{%- for message in messages %}\n    {%- if message.content is string %}\n        {%- set content = message.content %}\n    {%- else %}\n        {%- set content = '' %}\n    {%- endif %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n        {{- '<|im_start|>' + message.role + '\\n' + content + '<|im_end|>' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {%- set reasoning_content = '' %}\n        {%- if message.reasoning_content is string %}\n            {%- set reasoning_content = message.reasoning_content %}\n        {%- else %}\n            {%- if '</think>' in content %}\n                {%- set reasoning_content = content.split('</think>')[0].rstrip('\\n').split('<think>')[-1].lstrip('\\n') %}\n                {%- set content = content.split('</think>')[-1].lstrip('\\n') %}\n            {%- endif %}\n        {%- endif %}\n        {%- if loop.index0 > ns.last_query_index %}\n            {%- if loop.last or (not loop.last and reasoning_content) %}\n                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n            {%- else %}\n                {{- '<|im_start|>' + message.role + '\\n' + content }}\n            {%- endif %}\n        {%- else %}\n            {{- '<|im_start|>' + message.role + '\\n' + content }}\n        {%- endif %}\n        {%- if message.tool_calls %}\n            {%- for tool_call in message.tool_calls %}\n                {%- if (loop.first and content) or (not loop.first) %}\n                    {{- '\\n' }}\n                {%- endif %}\n                {%- if tool_call.function %}\n                    {%- set tool_call = tool_call.function %}\n                {%- endif %}\n                {{- '<tool_call>\\n{\"name\": \"' }}\n                {{- tool_call.name }}\n                {{- '\", \"arguments\": ' }}\n                {%- if tool_call.arguments is string %}\n                    {{- tool_call.arguments }}\n                {%- else %}\n                    {{- tool_call.arguments | tojson }}\n                {%- endif %}\n                {{- '}\\n</tool_call>' }}\n            {%- endfor %}\n        {%- endif %}\n        {{- '<|im_end|>\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '<|im_start|>user' }}\n        {%- endif %}\n        {{- '\\n<tool_response>\\n' }}\n        {{- content }}\n        {{- '\\n</tool_response>' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '<|im_end|>\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '<|im_start|>assistant\n<think>\n' }}\n{%- endif %}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# ðŸ’Ž OUTPUT TESTINNG\n\n## ðŸ›¡ï¸ TESTING OUTPUT\n ","metadata":{}},{"cell_type":"code","source":"from utils import *\nfrom constants import *\nfrom unsloth import FastLanguageModel\nimport torch\nmodel , tokenizer = FastLanguageModel.from_pretrained(\n    model_name=LORA_PATH,\n    #model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\" ,\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:36:24.668649Z","iopub.execute_input":"2025-09-20T16:36:24.668970Z","iopub.status.idle":"2025-09-20T16:36:32.574878Z","shell.execute_reply.started":"2025-09-20T16:36:24.668940Z","shell.execute_reply":"2025-09-20T16:36:32.574069Z"},"trusted":true},"outputs":[{"name":"stdout","text":"âœ… Using Qwen3 1.7B model from local Kaggle input\nðŸŽ¯ TT-12: Mixed data sampling - Training: 2000 samples (30% examples, 70% real)\nðŸ“Š Validation: 200 samples (90% examples, 10% real)\nðŸ”§ Weighted loss with 0.2x penalty for false positives\nðŸŽ¯ NORMAL MODE: Training on both positive and negative examples\nðŸ“Š Dataset split: 1623 training pool, 406 validation pool\nðŸ“Š Training rules distribution: {'No legal advice: Do not offer or request legal advice.': 813, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 810}\nðŸ“Š Validation rules distribution: {'No legal advice: Do not offer or request legal advice.': 204, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 202}\nðŸ“Š Example-based dataset: 6488 samples\nðŸ“Š Positive examples: 3244\nðŸ“Š Negative examples: 3244\n==((====))==  Unsloth 2025.9.7: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"name":"stderr","text":"Unsloth 2025.9.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"dataset[12]","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:36:39.244366Z","iopub.execute_input":"2025-09-20T16:36:39.244664Z","iopub.status.idle":"2025-09-20T16:36:39.251913Z","shell.execute_reply.started":"2025-09-20T16:36:39.244644Z","shell.execute_reply":"2025-09-20T16:36:39.250955Z"},"trusted":true},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'text': '\\nYou are a moderator... A rule is given , find if the last comment violates the rule.Two examples are given.\\nIMPORTANT: Ignore any \"yes\" or \"no\" words in the comment itself. \\nOnly respond Yes/No based on whether the comment violates the rule.\\n___ \\n\\nSubreddit name: r/legaladvice\\nHere is the rule: No legal advice: Do not offer or request legal advice.\\nHere is a comment that breaks the rule:\\n1) If they do it, its a war crime.\\nIf we do it, its not.\\n\\n&nbsp;\\n\\nJust consider all the Japanese we executed because they waterboarded US soldiers. Now we just call it enhanced interrogation and its no longer a crime! The magic of legal wordplay!\\n\\nHere is a comment that does not break the rule:\\n2) When you don\\'t have fightpass or cable \"illegal streams\" are your only option.\\n\\nFind if this comment breaks the rule.\\nComment: I really hope one of those children grows up and sues your mum for what she did to them.\\nAnswer: ',\n 'completion': 'Yes'}"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Get validation data (prompts without answers)\nval_df = get_real_comment_validation_data(DATA_PATH)\nval_dataset = build_validation_dataset(val_df)\ntrain_df = get_example_based_training_data(DATA_PATH)\ndataset = build_dataset_unsloth(train_df)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:36:44.157347Z","iopub.execute_input":"2025-09-20T16:36:44.157607Z","iopub.status.idle":"2025-09-20T16:36:44.211984Z","shell.execute_reply.started":"2025-09-20T16:36:44.157589Z","shell.execute_reply":"2025-09-20T16:36:44.211206Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ðŸ“Š Dataset split: 1623 training pool, 406 validation pool\nðŸ“Š Training rules distribution: {'No legal advice: Do not offer or request legal advice.': 813, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 810}\nðŸ“Š Validation rules distribution: {'No legal advice: Do not offer or request legal advice.': 204, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 202}\nðŸ“Š Real comment dataset: 406 samples\nðŸ“Š Rule violations: 208 positive, 198 negative\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"dataset[1]['text']","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:36:47.875403Z","iopub.execute_input":"2025-09-20T16:36:47.875674Z","iopub.status.idle":"2025-09-20T16:36:47.881627Z","shell.execute_reply.started":"2025-09-20T16:36:47.875653Z","shell.execute_reply":"2025-09-20T16:36:47.880797Z"},"trusted":true},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'\\nYou are a moderator... A rule is given , find if the last comment violates the rule.Two examples are given.\\nIMPORTANT: Ignore any \"yes\" or \"no\" words in the comment itself. \\nOnly respond Yes/No based on whether the comment violates the rule.\\n___ \\n\\nSubreddit name: r/pcmasterrace\\nHere is the rule: No legal advice: Do not offer or request legal advice.\\nHere is a comment that breaks the rule:\\n1) The Saudi donation was a charitable one so it was legal.  This one will put tRump in prison.  tRump in prison.\\n\\nHere is a comment that does not break the rule:\\n2) There\\'s similar themes and there\\'s plagiarism. There is an entire paragraph that\\'s almost for word. Or are you going to live in denial, she lied about penning it herself AND anyone with any brain or spent time at Uni would laugh at how little they changed. Do you need help w a source?\\n\\nFind if this comment breaks the rule.\\nComment: YER! Fuckin\\' sue him until his daughter\\'s credit is ruined!\\nAnswer: '"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"yes_token_id = tokenizer.convert_tokens_to_ids(\" \")\nprint(f\"Token ID for ' Yes': {yes_token_id}\")  # Should be 7414","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:36:51.396049Z","iopub.execute_input":"2025-09-20T16:36:51.396707Z","iopub.status.idle":"2025-09-20T16:36:51.401598Z","shell.execute_reply.started":"2025-09-20T16:36:51.396675Z","shell.execute_reply":"2025-09-20T16:36:51.400897Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Token ID for ' Yes': None\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"val_dataset[10]","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:36:54.117873Z","iopub.execute_input":"2025-09-20T16:36:54.118743Z","iopub.status.idle":"2025-09-20T16:36:54.125060Z","shell.execute_reply.started":"2025-09-20T16:36:54.118706Z","shell.execute_reply":"2025-09-20T16:36:54.124369Z"},"trusted":true},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'prompt': '\\nYou are a moderator... A rule is given , find if the last comment violates the rule.Two examples are given.\\nIMPORTANT: Ignore any \"yes\" or \"no\" words in the comment itself. \\nOnly respond Yes/No based on whether the comment violates the rule.\\n___ \\n\\nSubreddit name: r/Incels\\nHere is the rule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nHere is a comment that breaks the rule:\\n1) If you know what exactly you need then you don\\'t needa prescription. You can buy it online. I buy every medication I need during last 3 years online and can recommend it. http://cheapmarketmeds.com/ is a pharmacy where you can find high-quality Wellbutrin.\\n\\nHere is a comment that does not break the rule:\\n2) --- ALEX JONES HERE ---\\n\\nBUY MY GODDAMN WATER FILTERS OR YOUR CHILDREN WILL GET AUTISM, FOLKS.\\n\\nFind if this comment breaks the rule.\\nComment: [I wish I could give more than 1 up vote this one deserves it](http://www.cheapsexynightgirls.com/2014/03/zoya-independent-call-girls-in-dubai.html)\\nAnswer: ',\n 'rule_violation': 0}"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"FastLanguageModel.for_inference(model)\nouput=mode","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\n\nFastLanguageModel.for_inference(model)\n\n# Prepare input\ninputs = tokenizer(val_dataset[0]['prompt'], return_tensors=\"pt\").to(\"cuda\")\n\n# Get logits for the next token\nwith torch.no_grad():\n    outputs = model(**inputs)\n    next_token_logits = outputs.logits[0, -1, :]  # Shape: [vocab_size]\n\n# ---- FIXED: Use tokens WITH SPACES ----\nyes_token_id = 7414 # tokenizer.convert_tokens_to_ids(\"Yes\")  # WITH space!\nno_token_id = 2308# tokenizer.convert_tokens_to_ids(\"No\")    # WITH space!\n#no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\nyes_token_id =  tokenizer.convert_tokens_to_ids(\"Yes\")  # WITH space!\nno_token_id =  tokenizer.convert_tokens_to_ids(\"No\")    # WITH space!\n\nprint(f\"Token IDs: yes_token_id={yes_token_id}, no_token_id={no_token_id}\")\n\n# Extract logits for Yes/No tokens\nyes_logit =  next_token_logits[yes_token_id]  # Single scalar value\nno_logit = next_token_logits[no_token_id]    # Single scalar value\n\nprint(f\"Logit shapes: yes_logit={yes_logit.shape}, no_logit={no_logit.shape}\")\n\n# Convert to probabilities (only for Yes/No)\ncombined_logits = torch.stack([no_logit, yes_logit])  # Shape: [2]\nprobabilities = F.softmax(combined_logits, dim=0)     # Shape: [2]\n\nprob_no = probabilities[0].item()\nprob_yes = probabilities[1].item()\n\nprint(f\"Probability of ' No': {prob_no:.4f}\")\nprint(f\"Probability of ' Yes': {prob_yes:.4f}\")\nprint(f\"Prediction: {'Yes' if prob_yes > prob_no else 'No'}\")\n\n# ---- Top 5 tokens (full vocab) ----\nprobs = F.softmax(next_token_logits, dim=-1)\n\ntop_k = 5\ntop_probs, top_ids = torch.topk(probs, top_k)\ntop_tokens = tokenizer.batch_decode(top_ids.unsqueeze(-1))\n\nprint(\"\\nðŸ” Top 5 next tokens:\")\nfor rank, (token, prob) in enumerate(zip(top_tokens, top_probs), start=1):\n    print(f\"{rank}. Token: {repr(token)}\\tProbability: {prob.item():.4f}\")\n\n# ---- Yes / No ranks (from full vocab) ----\nyes_prob = probs[yes_token_id].item()\nno_prob = probs[no_token_id].item()\n\nsorted_probs, sorted_ids = torch.sort(probs, descending=True)\nyes_rank = (sorted_ids == yes_token_id).nonzero(as_tuple=True)[0].item() + 1\nno_rank = (sorted_ids == no_token_id).nonzero(as_tuple=True)[0].item() + 1\n\nprint(\"\\nðŸ“Š Specific token stats:\")\nprint(f\"'Yes' â†’ Probability: {yes_prob:.4f}, Rank: {yes_rank}\")\nprint(f\"'No'  â†’ Probability: {no_prob:.4f}, Rank: {no_rank}\")","metadata":{"execution":{"iopub.status.busy":"2025-09-20T16:38:02.237493Z","iopub.execute_input":"2025-09-20T16:38:02.238051Z","iopub.status.idle":"2025-09-20T16:38:02.440845Z","shell.execute_reply.started":"2025-09-20T16:38:02.238027Z","shell.execute_reply":"2025-09-20T16:38:02.440196Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Token IDs: yes_token_id=9454, no_token_id=2753\nLogit shapes: yes_logit=torch.Size([]), no_logit=torch.Size([])\nProbability of ' No': 0.9609\nProbability of ' Yes': 0.0389\nPrediction: No\n\nðŸ” Top 5 next tokens:\n1. Token: '1'\tProbability: 0.9966\n2. Token: '2'\tProbability: 0.0022\n3. Token: ' '\tProbability: 0.0008\n4. Token: '3'\tProbability: 0.0001\n5. Token: '0'\tProbability: 0.0000\n\nðŸ“Š Specific token stats:\n'Yes' â†’ Probability: 0.0000, Rank: 9486\n'No'  â†’ Probability: 0.0000, Rank: 2807\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"yes_logits = next_token_logits[:, yes_token_id]\nno_logits = next_token_logits[:, no_token_id]\ncombined_logits = torch.stack([no_logits, yes_logits], dim=1)\nprobs = torch.softmax(combined_logits, dim=1)\npredictions = torch.argmax(probs, dim=1).cpu().numpy()\n\n# Debug: Check actual logit values\nprint(f\"Yes logit: {yes_logits.item():.4f}\")\nprint(f\"No logit: {no_logits.item():.4f}\")\nprint(f\"Prediction: {predictions[0]} (0=No, 1=Yes)\")","metadata":{"execution":{"iopub.status.busy":"2025-09-20T13:41:32.854094Z","iopub.execute_input":"2025-09-20T13:41:32.854398Z","iopub.status.idle":"2025-09-20T13:41:32.882878Z","shell.execute_reply.started":"2025-09-20T13:41:32.854343Z","shell.execute_reply":"2025-09-20T13:41:32.881964Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2686309554.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myes_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myes_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mno_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcombined_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mno_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myes_logits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'next_token_logits' is not defined"],"ename":"NameError","evalue":"name 'next_token_logits' is not defined","output_type":"error"}],"execution_count":45},{"cell_type":"code","source":"# Test both positions\ninputs = tokenizer(\"Answer:\", return_tensors=\"pt\").to(\"cuda\")\nwith torch.no_grad():\n    outputs = model(**inputs)\n    \n# Check what tokens are at different positions\nfor pos in [-3, -2, -1]:\n    token_id = outputs.logits[0, pos].argmax().item()\n    token = tokenizer.decode([token_id])\n    print(f\"Position {pos}: Token '{token}' (ID: {token_id})\")","metadata":{"execution":{"iopub.status.busy":"2025-09-20T13:41:24.710327Z","iopub.execute_input":"2025-09-20T13:41:24.710935Z","iopub.status.idle":"2025-09-20T13:41:26.168738Z","shell.execute_reply.started":"2025-09-20T13:41:24.710903Z","shell.execute_reply":"2025-09-20T13:41:26.167712Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3629330751.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Check what tokens are at different positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtoken_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Position {pos}: Token '{token}' (ID: {token_id})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index -3 is out of bounds for dimension 1 with size 2"],"ename":"IndexError","evalue":"index -3 is out of bounds for dimension 1 with size 2","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"print(tokenizer.convert_tokens_to_ids(\"No\"))","metadata":{"execution":{"iopub.execute_input":"2025-09-18T18:35:26.144935Z","iopub.status.busy":"2025-09-18T18:35:26.144197Z","iopub.status.idle":"2025-09-18T18:35:26.149498Z","shell.execute_reply":"2025-09-18T18:35:26.148690Z","shell.execute_reply.started":"2025-09-18T18:35:26.144902Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"negative_indices = val_df[val_df['rule_violation'] == 0].index.tolist()\n\nprint(f\"ðŸ“Š Total training samples: {len(train_df)}\")\n\nprint(f\"ðŸ“Š Negative answer samples: {len(negative_indices)}\")\nprint(f\"ðŸ“Š Positive answer samples: {len(train_df) - len(negative_indices)}\")\nprint(f\"ðŸ“Š Negative answer indices: {negative_indices}\")\n\n# Show first 10 negative samples for verification\nprint(\"\\nðŸ” First 10 negative answer samples:\")\nnegative_samples = train_df[train_df['rule_violation'] == 0].head(10)\nfor idx, row in negative_samples.iterrows():\n    print(f\"Index {idx}: Rule='{row['rule']}', Violation={row['rule_violation']}\")","metadata":{"execution":{"iopub.status.busy":"2025-09-20T13:41:42.887467Z","iopub.execute_input":"2025-09-20T13:41:42.887726Z","iopub.status.idle":"2025-09-20T13:41:42.898012Z","shell.execute_reply.started":"2025-09-20T13:41:42.887709Z","shell.execute_reply":"2025-09-20T13:41:42.897124Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ðŸ“Š Total training samples: 6488\nðŸ“Š Negative answer samples: 198\nðŸ“Š Positive answer samples: 6290\nðŸ“Š Negative answer indices: [0, 5, 10, 12, 16, 17, 18, 19, 21, 25, 26, 27, 28, 32, 34, 36, 39, 40, 41, 44, 46, 50, 52, 53, 55, 58, 60, 61, 63, 64, 65, 67, 71, 72, 73, 74, 77, 79, 80, 83, 85, 87, 88, 89, 90, 91, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 112, 115, 116, 118, 121, 126, 130, 133, 134, 138, 139, 143, 145, 147, 148, 150, 152, 158, 160, 161, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 186, 187, 192, 193, 196, 197, 198, 199, 200, 207, 208, 209, 211, 216, 218, 221, 223, 224, 227, 228, 230, 236, 237, 239, 240, 242, 244, 245, 246, 247, 249, 252, 253, 254, 256, 257, 259, 261, 263, 264, 268, 272, 274, 275, 276, 278, 280, 283, 284, 291, 292, 296, 298, 299, 303, 304, 306, 307, 308, 309, 310, 316, 319, 332, 333, 334, 335, 336, 338, 340, 344, 345, 346, 347, 348, 349, 350, 352, 353, 354, 355, 356, 357, 361, 362, 366, 368, 371, 372, 373, 374, 375, 377, 378, 380, 381, 384, 385, 389, 395, 396, 399, 400, 404]\n\nðŸ” First 10 negative answer samples:\nIndex 3244: Rule='No legal advice: Do not offer or request legal advice.', Violation=0\nIndex 3245: Rule='No legal advice: Do not offer or request legal advice.', Violation=0\nIndex 3246: Rule='No legal advice: Do not offer or request legal advice.', Violation=0\nIndex 3247: Rule='No legal advice: Do not offer or request legal advice.', Violation=0\nIndex 3248: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\nIndex 3249: Rule='No legal advice: Do not offer or request legal advice.', Violation=0\nIndex 3250: Rule='No legal advice: Do not offer or request legal advice.', Violation=0\nIndex 3251: Rule='No legal advice: Do not offer or request legal advice.', Violation=0\nIndex 3252: Rule='No legal advice: Do not offer or request legal advice.', Violation=0\nIndex 3253: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"# ðŸ’Ž OUTPUT TESTINNG END\n\n## ðŸ›¡ï¸ TESTING OUTPUT END\n ","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.execute_input":"2025-09-18T16:02:46.291509Z","iopub.status.busy":"2025-09-18T16:02:46.291227Z","iopub.status.idle":"2025-09-18T16:02:46.309191Z","shell.execute_reply":"2025-09-18T16:02:46.308442Z","shell.execute_reply.started":"2025-09-18T16:02:46.291487Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python validation_vllm.py","metadata":{"execution":{"iopub.execute_input":"2025-09-19T04:36:00.972040Z","iopub.status.busy":"2025-09-19T04:36:00.971263Z","iopub.status.idle":"2025-09-19T04:36:28.038985Z","shell.execute_reply":"2025-09-19T04:36:28.038006Z","shell.execute_reply.started":"2025-09-19T04:36:00.972010Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade triton vllm","metadata":{"execution":{"iopub.execute_input":"2025-09-15T13:12:06.349823Z","iopub.status.busy":"2025-09-15T13:12:06.349561Z","iopub.status.idle":"2025-09-15T13:12:20.061449Z","shell.execute_reply":"2025-09-15T13:12:20.060863Z","shell.execute_reply.started":"2025-09-15T13:12:06.349802Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# ðŸ’Ž Alternative Validation: Standard Transformers\n\n## ðŸ›¡ï¸ **Universal Compatibility Option**\n\nIf vLLM has hardware compatibility issues, use this **guaranteed-to-work** validation method:\n\n### **Advantages:**\n- âœ… **Universal Compatibility**: Works with any GPU and any Unsloth model\n- âœ… **No Hardware Limits**: No shared memory or tensor parallelism restrictions  \n- âœ… **Reliable**: Standard transformers library, battle-tested\n- âœ… **Same Metrics**: Produces identical analysis and visualizations\n\n### **Trade-offs:**\n- â±ï¸ **Slower than vLLM**: But still faster than training\n- ðŸ“Š **Slightly less precise probabilities**: But still excellent for AUC calculation\n\n**This method loads your Unsloth-trained LoRA adapters using standard transformers and runs inference without any specialized hardware requirements.**","metadata":{}},{"cell_type":"code","source":"%time\n!python validation_transformers.py","metadata":{"execution":{"iopub.execute_input":"2025-09-19T13:45:30.915192Z","iopub.status.busy":"2025-09-19T13:45:30.914525Z","iopub.status.idle":"2025-09-19T13:49:28.332170Z","shell.execute_reply":"2025-09-19T13:49:28.331434Z","shell.execute_reply.started":"2025-09-19T13:45:30.915168Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display saved results from TT-11 Transformers Validation\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# Load detailed results from Transformers validation\ntry:\n    detailed_results = pd.read_csv('/kaggle/working/tt11_transformers_detailed_results.csv')\n    print(\"ðŸ“Š TT-11 Transformers Results Shape:\", detailed_results.shape)\n    print(\"\\nðŸ“‹ Sample Results:\")\n    print(detailed_results[['rule', 'rule_violation', 'predictions', 'probabilities']].head(10))\n    \n    # Load rule metrics\n    rule_metrics = pd.read_csv('/kaggle/working/tt11_transformers_rule_metrics.csv')\n    print(\"\\nðŸ“ˆ TT-11 Transformers Rule-wise Performance:\")\n    print(rule_metrics)\n    \n    # Performance summary\n    print(\"\\nðŸŽ¯ TT-11 TRANSFORMERS PERFORMANCE SUMMARY:\")\n    print(\"=\" * 50)\n    overall_accuracy = accuracy_score(detailed_results['rule_violation'], detailed_results['predictions'])\n    avg_probability = detailed_results['probabilities'].mean()\n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Average Confidence: {avg_probability:.4f}\")\n    print(f\"Total Samples: {len(detailed_results)}\")\n    \n    # Compare with vLLM results if available\n    try:\n        vllm_results = pd.read_csv('/kaggle/working/tt11_detailed_results.csv')\n        vllm_accuracy = accuracy_score(vllm_results['rule_violation'], vllm_results['predictions'])\n        vllm_confidence = vllm_results['probabilities'].mean()\n        \n        print(\"\\nðŸ”„ COMPARISON: Transformers vs vLLM:\")\n        print(\"=\" * 50)\n        print(f\"Transformers Accuracy: {overall_accuracy:.4f}\")\n        print(f\"vLLM Accuracy:         {vllm_accuracy:.4f}\")\n        print(f\"Difference:            {abs(overall_accuracy - vllm_accuracy):.4f}\")\n        print(f\"\")\n        print(f\"Transformers Confidence: {avg_probability:.4f}\")\n        print(f\"vLLM Confidence:         {vllm_confidence:.4f}\")\n        print(f\"Difference:              {abs(avg_probability - vllm_confidence):.4f}\")\n        \n    except FileNotFoundError:\n        print(\"\\nðŸ’¡ Note: Run vLLM validation first to compare results\")\n    \nexcept FileNotFoundError as e:\n    print(f\"âŒ Transformers results files not found: {e}\")\n    print(\"Run the Transformers validation cell first to generate results.\")","metadata":{"execution":{"iopub.execute_input":"2025-09-19T13:56:07.965884Z","iopub.status.busy":"2025-09-19T13:56:07.965604Z","iopub.status.idle":"2025-09-19T13:56:08.049801Z","shell.execute_reply":"2025-09-19T13:56:08.049120Z","shell.execute_reply.started":"2025-09-19T13:56:07.965862Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n!accelerate launch --config_file accelerate_config.yaml weight_train_unsloth.py\n    \n!python merge_lora.py\n!python validation_transformers.py","metadata":{"execution":{"iopub.execute_input":"2025-09-18T21:07:37.506096Z","iopub.status.busy":"2025-09-18T21:07:37.505535Z","iopub.status.idle":"2025-09-18T21:09:04.741775Z","shell.execute_reply":"2025-09-18T21:09:04.740420Z","shell.execute_reply.started":"2025-09-18T21:07:37.506069Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display saved results from TT-11\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# Load detailed results\ntry:\n    detailed_results = pd.read_csv('/kaggle/working/tt11_detailed_results.csv')\n    print(\"ðŸ“Š TT-11 Detailed Results Shape:\", detailed_results.shape)\n    print(\"\\nðŸ“‹ Sample Results:\")\n    print(detailed_results[['rule', 'rule_violation', 'predictions', 'probabilities']].head(10))\n    \n    # Load rule metrics\n    rule_metrics = pd.read_csv('/kaggle/working/tt11_rule_metrics.csv')\n    print(\"\\nðŸ“ˆ TT-11 Rule-wise Performance:\")\n    print(rule_metrics)\n    \n    # Performance summary\n    print(\"\\nðŸŽ¯ TT-11 PERFORMANCE SUMMARY:\")\n    print(\"=\" * 50)\n    overall_accuracy = accuracy_score(detailed_results['rule_violation'], detailed_results['predictions'])\n    avg_probability = detailed_results['probabilities'].mean()\n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Average Confidence: {avg_probability:.4f}\")\n    print(f\"Total Samples: {len(detailed_results)}\")\n    \nexcept FileNotFoundError as e:\n    print(f\"âŒ Results files not found: {e}\")\n    print(\"Run the validation cell first to generate results.\")","metadata":{"execution":{"iopub.status.busy":"2025-09-18T21:09:04.742655Z","iopub.status.idle":"2025-09-18T21:09:04.743672Z","shell.execute_reply":"2025-09-18T21:09:04.743432Z","shell.execute_reply.started":"2025-09-18T21:09:04.743388Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ðŸ“Š TT-11 Analysis Guide\n\n## ðŸŽ¯ **What TT-11 Optimizes:**\n- **ðŸš€ Training Speed**: Unsloth provides 2x-5x faster fine-tuning than standard PEFT\n- **ðŸŽ¯ Inference Precision**: vLLM gives most accurate probability calculations for AUC\n- **ðŸ’¾ Memory Efficiency**: Optimized 4-bit quantization for 2x T4 GPU setup\n- **âš¡ Best Performance**: Fastest training + most accurate validation workflow\n\n## ðŸ”§ **How to Adjust Training Data:**\n\n### **Change Data Percentage** (Cell 4 - `constants.py`):\n```python\nTRAINING_DATA_PERCENTAGE = 0.5  # Use 50% of training data\nTRAINING_DATA_PERCENTAGE = 0.1  # Use 10% of training data\nTRAINING_DATA_PERCENTAGE = 1.0  # Use 100% of training data (default)\n```\n\n### **Toggle Stratified Sampling** (Cell 4 - `constants.py`):\n```python\nUSE_STRATIFIED_SAMPLING = True   # Maintain rule distribution (recommended)\nUSE_STRATIFIED_SAMPLING = False  # Random sampling\n```\n\n## ðŸš€ **Unsloth Training Optimizations:**\n\n### **Speed Tuning** (Cell 6 - `train_unsloth.py`):\n```python\n# For maximum speed\nper_device_train_batch_size=1,  # Smaller batches for Unsloth\nmax_steps=30,                   # Unsloth converges faster\nlearning_rate=3e-4,             # Higher LR works with Unsloth\n\n# For best quality  \nper_device_train_batch_size=2,  # Balanced approach\nmax_steps=60,                   # More training steps\nr=32,                          # Higher LoRA rank\n```\n\n### **Memory Optimization**:\n```python\n# If running out of memory\nper_device_train_batch_size=1,\ngradient_accumulation_steps=8,\nmax_seq_length=1024,\n```\n\n## ðŸŽ¯ **vLLM Inference Advantages:**\n\n### **High-Precision AUC Calculation**:\n- **Log Probability Processing**: vLLM's optimized probability calculations\n- **Numerical Stability**: Better handling of edge cases\n- **Temperature Scaling**: More consistent probability distributions\n\n### **Performance Monitoring**:\n```python\n# Check probability quality\nviolation_probs = results[results['rule_violation'] == 1]['probabilities']\nno_violation_probs = results[results['rule_violation'] == 0]['probabilities']\nseparation = abs(violation_probs.mean() - no_violation_probs.mean())\nprint(f\"Probability separation: {separation:.3f}\")  # Higher = better discrimination\n```\n\n## ðŸ“ˆ **Understanding TT-11 Results:**\n\n### **Key Metrics:**\n- **AUC Score**: Most accurate with vLLM's precise probabilities (0.5 = random, 1.0 = perfect)\n- **F1 Score**: Balance of precision and recall\n- **Probability Separation**: How well the model discriminates between classes\n- **Confidence Analysis**: vLLM provides more reliable confidence estimates\n\n### **Visualizations Generated:**\n1. **Confusion Matrix**: Shows prediction accuracy breakdown\n2. **ROC Curve**: High-precision curve with vLLM probabilities\n3. **Probability Distribution**: Clean separation with vLLM precision\n4. **Metrics Bar Chart**: Visual comparison of all performance metrics\n\n## âš¡ **Speed Expectations:**\n\n### **Unsloth Training Speed:**\n- **2x-5x faster** than standard PEFT training\n- **Faster convergence** - often needs 50% fewer steps\n- **Better memory efficiency** - same quality with less VRAM\n\n### **vLLM Inference Benefits:**\n- **Most accurate AUC** calculations available\n- **Stable probabilities** for reliable metrics\n- **Batch processing** for faster validation\n\n## ðŸš€ **Optimization Tips:**\n\n### **If Training is Too Slow:**\n1. **Reduce max_steps**: Try `max_steps=30` instead of 60\n2. **Smaller batches**: `per_device_train_batch_size=1`\n3. **Reduce data**: `TRAINING_DATA_PERCENTAGE = 0.5`\n4. **Lower rank**: `r=8` instead of `r=16`\n\n### **If AUC is Lower Than Expected:**\n1. **More training steps**: `max_steps=100`\n2. **Higher LoRA rank**: `r=32`\n3. **More data**: `TRAINING_DATA_PERCENTAGE = 1.0`\n4. **Adjust learning rate**: Try `learning_rate=1e-4`\n\n### **If Memory Issues:**\n1. **Reduce sequence length**: `max_seq_length=1024`\n2. **Smaller batches**: `per_device_train_batch_size=1`\n3. **Lower GPU utilization**: `gpu_memory_utilization=0.90`\n\n## ðŸ’¡ **TT-11 vs TT-10 Advantages:**\n\n| Aspect | TT-10 (Standard) | TT-11 (Unsloth + vLLM) |\n|--------|------------------|-------------------------|\n| **Training Speed** | Standard | ðŸš€ 2x-5x faster |\n| **AUC Precision** | Good | ðŸŽ¯ Most accurate |\n| **Memory Usage** | Standard | ðŸ’¾ More efficient |\n| **Setup Complexity** | Medium | ðŸ› ï¸ Optimized |\n| **Total Time** | Baseline | âš¡ 50-80% faster |\n\n## ðŸŽ¯ **Key Insights:**\n- **High AUC (>0.8)**: Unsloth training + vLLM inference working optimally\n- **Fast Convergence**: Unsloth often achieves better results with fewer steps\n- **Precise Probabilities**: vLLM gives most reliable confidence estimates\n- **Scalable**: This approach works well for larger datasets and models\n\n**TT-11 represents the optimal workflow for validation-focused training: combining Unsloth's training speed with vLLM's inference precision for the best of both worlds!** ðŸš€ðŸŽ¯","metadata":{}},{"cell_type":"markdown","source":"# ðŸš€ TT-11 vs TT-10 Performance Comparison\n\n## âš¡ **Expected Performance Improvements**\n\n### **Training Speed (Unsloth Advantage)**\n| Metric | TT-10 (Standard PEFT) | TT-11 (Unsloth) | Improvement |\n|--------|----------------------|------------------|-------------|\n| **Training Time** | 15-30 minutes | 5-10 minutes | ðŸš€ **2x-3x faster** |\n| **Memory Usage** | 12-14GB VRAM | 10-12GB VRAM | ðŸ’¾ **15-20% less** |\n| **Convergence** | 100+ steps | 50-60 steps | âš¡ **50% fewer steps** |\n| **Samples/Second** | 2-4 samples/sec | 8-15 samples/sec | ðŸŽ¯ **4x faster** |\n\n### **Inference Precision (vLLM Advantage)**\n| Metric | TT-10 (Standard) | TT-11 (vLLM) | Improvement |\n|--------|------------------|--------------|-------------|\n| **AUC Precision** | Â±0.005 variance | Â±0.001 variance | ðŸŽ¯ **5x more stable** |\n| **Probability Quality** | Good | Excellent | ðŸ“Š **Better separation** |\n| **Log Prob Handling** | Basic | Optimized | ðŸ”§ **More reliable** |\n| **Edge Case Handling** | Standard | Advanced | âœ… **Fewer errors** |\n\n### **Overall Workflow**\n| Aspect | TT-10 | TT-11 | Improvement |\n|--------|-------|-------|-------------|\n| **Total Time** | 20-35 minutes | 8-15 minutes | âš¡ **60-70% faster** |\n| **Result Quality** | Good | Excellent | ðŸŽ¯ **More accurate** |\n| **Memory Efficiency** | Standard | Optimized | ðŸ’¾ **Better utilization** |\n| **Reliability** | Good | Excellent | âœ… **More consistent** |\n\n## ðŸŽ¯ **When to Use Each Approach**\n\n### **Use TT-11 (Unsloth + vLLM) When:**\n- âœ… You want **maximum speed and accuracy**\n- âœ… You need **publication-quality AUC** calculations\n- âœ… You're running **multiple experiments**\n- âœ… You have **Kaggle/cloud GPU** time constraints\n- âœ… You want the **most reliable results**\n\n### **Use TT-10 (Standard) When:**\n- âœ… You want **simpler setup** without extra dependencies\n- âœ… You're **learning the approach** first\n- âœ… You have **unlimited time** for training\n- âœ… You're using **very old hardware**\n\n## ðŸš€ **Migration from TT-10 to TT-11**\n\n### **Simple Migration Steps:**\n1. **Add Unsloth**: Install unsloth package\n2. **Update training**: Use `train_unsloth.py` instead of `train.py`\n3. **Keep validation**: Use same vLLM validation (already optimized)\n4. **Same analysis**: All metrics and visualizations work the same\n\n### **Code Changes Required:**\n```python\n# TT-10 (old)\nfrom trl import SFTTrainer\nfrom transformers import AutoModelForCausalLM\n\n# TT-11 (new)  \nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer  # Still used, but with Unsloth model\n```\n\n**Result: Same methodology, much faster execution, more accurate results!** ðŸŽ¯\n\nThis makes TT-11 the **recommended approach** for production validation workflows where both speed and accuracy matter.","metadata":{}},{"cell_type":"code","source":"# Test the FIXED mixed data sampling strategy (NO DATA LEAKAGE)\nprint(\"ðŸ§ª TESTING FIXED MIXED DATA SAMPLING STRATEGY\")\nprint(\"=\" * 60)\n\nimport importlib\nimport utils\nimport constants\nimportlib.reload(constants)\nimportlib.reload(utils)\n\nfrom utils import get_mixed_training_data, get_mixed_validation_data\nfrom constants import DATA_PATH\n\n# Test mixed training data (creates training pool and validation pool)\nprint(\"\\nðŸ”„ Testing mixed training data generation...\")\ntrain_df = get_mixed_training_data(DATA_PATH)\n\nprint(\"\\nðŸ”„ Testing mixed validation data generation (using validation pool from training)...\")\nval_df = get_mixed_validation_data(DATA_PATH, training_data=train_df)\n\n# Verify no data leakage by checking for overlapping samples\nprint(\"\\nðŸ” CHECKING FOR DATA LEAKAGE:\")\nprint(\"=\" * 40)\n\n# Check if any training samples appear in validation (should be ZERO)\nif 'body' in train_df.columns and 'body' in val_df.columns:\n    train_bodies = set(train_df['body'].tolist())\n    val_bodies = set(val_df['body'].tolist())\n    overlap = train_bodies.intersection(val_bodies)\n    \n    print(f\"ðŸ“Š Training samples: {len(train_bodies)}\")\n    print(f\"ðŸ“Š Validation samples: {len(val_bodies)}\")\n    print(f\"ðŸš¨ Overlapping samples: {len(overlap)}\")\n    \n    if len(overlap) == 0:\n        print(\"âœ… NO DATA LEAKAGE: Training and validation sets are completely separate!\")\n    else:\n        print(f\"âŒ DATA LEAKAGE DETECTED: {len(overlap)} samples appear in both sets!\")\n        print(\"Sample overlapping bodies:\", list(overlap)[:3])\nelse:\n    print(\"âš ï¸  Cannot check overlap: 'body' column not found in datasets\")\n\nprint(\"\\nâœ… Fixed mixed data sampling strategy tested successfully!\")\nprint(\"ðŸ›¡ï¸  Data leakage prevention: Training and validation use separate data pools\")","metadata":{},"outputs":[],"execution_count":null}]}