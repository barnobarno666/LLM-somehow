{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12726948,"sourceType":"datasetVersion","datasetId":8044304},{"sourceId":12762469,"sourceType":"datasetVersion","datasetId":8067935},{"sourceId":252850661,"sourceType":"kernelVersion"},{"sourceId":252853424,"sourceType":"kernelVersion"},{"sourceId":259545323,"sourceType":"kernelVersion"},{"sourceId":171496,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":145960,"modelId":164048},{"sourceId":171638,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":146086,"modelId":164048},{"sourceId":426330,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":347541,"modelId":368803},{"sourceId":523492,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":411182,"modelId":429004},{"sourceId":579809,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":432662,"modelId":449553}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b1f53c33","cell_type":"markdown","source":"# Alternative Validation Options\n\n## 🔧 **Choose Your Validation Method:**\n\nThis notebook now provides **two validation approaches**:\n\n### **Option 1: vLLM Validation (Original)**\n- **Pros**: Fastest inference, most precise probability calculations\n- **Cons**: Hardware compatibility issues with certain GPU/model combinations\n- **Use when**: You have compatible hardware and need maximum speed\n\n### **Option 2: Standard Transformers Validation (New)**\n- **Pros**: Universal compatibility, works with any Unsloth model, reliable\n- **Cons**: Slower than vLLM, but still faster than training\n- **Use when**: vLLM has compatibility issues or you want guaranteed reliability\n\n**Both methods produce identical metrics and visualizations** - the choice is purely based on your hardware compatibility and speed requirements.","metadata":{}},{"id":"4ef0213e","cell_type":"markdown","source":"# TT-11: Validation-Focused Training with Unsloth + vLLM\n\nThis notebook implements the same validation-focused approach as TT-10, but optimized for **maximum speed and accuracy**:\n\n**Key Improvements over TT-10:**\n- **🚀 Unsloth Training**: 2x-5x faster fine-tuning than standard PEFT\n- **🎯 vLLM Inference**: Most accurate AUC calculations with precise log probabilities\n- **💾 Memory Efficient**: Optimized for 2x T4 GPU setup\n- **⚡ Best Performance**: Fastest training + most accurate validation\n\n**Methodology:**\n- **Training**: Model learns from positive/negative examples using Unsloth (like test-time training)\n- **Validation**: Model predicts on real `body` comments with vLLM for precise probabilities\n- **Analysis**: Comprehensive metrics to understand generalization from examples to real data\n\n**Features:**\n- **Stratified Sampling**: Controllable % of training data while maintaining rule distribution\n- **Example-Based Training**: Similar to test-time training approach with Unsloth speed\n- **Real Comment Validation**: Test on actual comments with vLLM precision\n- **Comprehensive Metrics**: AUC, F1, Recall, Precision, Confusion Matrix\n- **Visualizations**: Performance plots and analysis\n- **4-bit + LoRA**: Memory-efficient training, vLLM-compatible inference\n\n**Benefits:**\n- **Fastest Training**: Unsloth provides 2x-5x speed improvement\n- **Most Accurate AUC**: vLLM gives precise probability calculations\n- **Best of Both Worlds**: Speed + Accuracy optimized workflow","metadata":{}},{"id":"4c705040","cell_type":"code","source":"# Install dependencies - Unsloth + vLLM + Analysis setup\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'trl==0.21.0' 'optimum==1.27.0' 'bitsandbytes==0.46.1' 'deepspeed==0.17.4' 'logits-processor-zoo==0.2.1' 'vllm==0.10.0'\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'triton==3.2.0'\n!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'clean-text'\n# Install PEFT for LoRA support\n!uv pip install --system --no-index -U --no-deps --find-links='/kaggle/input/jigsaw-packages2/whls/' 'peft' 'accelerate' 'datasets'\n# Install Unsloth for ultra-fast training\n#!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'unsloth'\n# Install analysis libraries\n#!uv pip install --system --no-index --find-links='/kaggle/input/jigsaw-packages2/whls/' 'scikit-learn' 'matplotlib' 'seaborn'\n\nprint(\"✅ TT-11 Dependencies installed:\")\nprint(\"🚀 Unsloth: Ultra-fast training\")\nprint(\"🎯 vLLM: Precise inference\") \nprint(\"📊 Analysis libraries: scikit-learn, matplotlib, seaborn\")","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-09-18T18:44:29.910155Z","iopub.status.busy":"2025-09-18T18:44:29.909859Z","iopub.status.idle":"2025-09-18T18:45:19.773337Z","shell.execute_reply":"2025-09-18T18:45:19.772530Z","shell.execute_reply.started":"2025-09-18T18:44:29.910129Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m164 packages\u001b[0m \u001b[2min 885ms\u001b[0m\u001b[0m                                       \u001b[0m\n","\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                          \n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m deepspeed\u001b[2m==0.17.4\u001b[0m                                  \u001b[1A\n","\u001b[2K\u001b[2mPrepared \u001b[1m63 packages\u001b[0m \u001b[2min 32.58s\u001b[0m\u001b[0m                                           \n","\u001b[2mUninstalled \u001b[1m26 packages\u001b[0m \u001b[2min 3.47s\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m63 packages\u001b[0m \u001b[2min 556ms\u001b[0m\u001b[0m                              \u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mastor\u001b[0m\u001b[2m==0.8.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.46.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mblake3\u001b[0m\u001b[2m==1.0.5\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mcbor2\u001b[0m\u001b[2m==5.7.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mcompressed-tensors\u001b[0m\u001b[2m==0.10.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mdeepspeed\u001b[0m\u001b[2m==0.17.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mdepyf\u001b[0m\u001b[2m==0.19.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mfastapi-cli\u001b[0m\u001b[2m==0.0.10\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mfastapi-cloud-cli\u001b[0m\u001b[2m==0.1.5\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.5.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mgguf\u001b[0m\u001b[2m==0.17.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mhjson\u001b[0m\u001b[2m==3.1.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.6.4\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.33.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.34.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1minteregular\u001b[0m\u001b[2m==0.3.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.2.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mllguidance\u001b[0m\u001b[2m==0.7.30\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.43.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.44.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mlm-format-enforcer\u001b[0m\u001b[2m==0.10.12\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mlogits-processor-zoo\u001b[0m\u001b[2m==0.2.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mmistral-common\u001b[0m\u001b[2m==1.8.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.19.0\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.60.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.61.2\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.5.1.17\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.11.1.6\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.3\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.26.2\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.6.85\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.91.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.90.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1moptimum\u001b[0m\u001b[2m==1.27.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1moutlines-core\u001b[0m\u001b[2m==0.2.10\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpartial-json-parser\u001b[0m\u001b[2m==0.2.1.1.post6\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mprometheus-fastapi-instrumentator\u001b[0m\u001b[2m==7.1.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpybase64\u001b[0m\u001b[2m==1.4.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpycountry\u001b[0m\u001b[2m==24.6.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpydantic-extra-types\u001b[0m\u001b[2m==2.10.5\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.1\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==24.0.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mrich-toolkit\u001b[0m\u001b[2m==0.15.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mrignore\u001b[0m\u001b[2m==0.6.4\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.0\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.7.1\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtorchaudio\u001b[0m\u001b[2m==2.7.1\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124 (from https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.22.1\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.52.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.56.0\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.21.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.21.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mvllm\u001b[0m\u001b[2m==0.10.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.1.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.31\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mxgrammar\u001b[0m\u001b[2m==0.1.21\u001b[0m\n","\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m                                           \u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 4.12s\u001b[0m\u001b[0m                                              \n","\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m                                 \u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.3.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n","\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m4 packages\u001b[0m \u001b[2min 5.36s\u001b[0m\u001b[0m                                         \u001b[0m\n","\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                               \n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n","\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n","\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m emoji\u001b[2m==1.7.0\u001b[0m                                       \u001b[1A\n","\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 736ms\u001b[0m\u001b[0m                                             \n","\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m                                 \u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mclean-text\u001b[0m\u001b[2m==0.6.0\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==2.14.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==1.7.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n","\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m3 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m                                           \u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 51ms\u001b[0m\u001b[0m                                              \n","\u001b[2mUninstalled \u001b[1m3 packages\u001b[0m \u001b[2min 134ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m                                \u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.8.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.10.1\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==3.6.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.0.0\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.15.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.17.1\u001b[0m\n","✅ TT-11 Dependencies installed:\n","🚀 Unsloth: Ultra-fast training\n","🎯 vLLM: Precise inference\n","📊 Analysis libraries: scikit-learn, matplotlib, seaborn\n"]}],"execution_count":1},{"id":"dfd03d10-6426-41a4-8620-213cfd3402c3","cell_type":"code","source":"!pip install unsloth \n!pip install vllm","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-09-18T18:45:19.775155Z","iopub.status.busy":"2025-09-18T18:45:19.774877Z","iopub.status.idle":"2025-09-18T18:45:50.154894Z","shell.execute_reply":"2025-09-18T18:45:50.154007Z","shell.execute_reply.started":"2025-09-18T18:45:19.775130Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting unsloth\n","  Downloading unsloth-2025.9.6-py3-none-any.whl.metadata (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting unsloth_zoo>=2025.9.7 (from unsloth)\n","  Downloading unsloth_zoo-2025.9.8-py3-none-any.whl.metadata (31 kB)\n","Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.7.1)\n","Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.0.31)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.46.1)\n","Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\n","Collecting tyro (from unsloth)\n","  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\n","Collecting transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3 (from unsloth)\n","  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets<4.0.0,>=3.4.1 (from unsloth)\n","  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.10.1)\n","Requirement already satisfied: trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.17.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\n","Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.4)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\n","Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.22.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (19.0.1)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.2.3)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.1.5)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.2.0)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.2.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (9.5.1.17)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.3)\n","Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.26.2)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\n","Collecting triton>=3.0.0 (from unsloth)\n","  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth) (2024.11.6)\n","Collecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.55.4,>=4.51.3->unsloth)\n","  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: torchao in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.7->unsloth) (0.10.0)\n","Collecting cut_cross_entropy (from unsloth_zoo>=2025.9.7->unsloth)\n","  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.7->unsloth) (11.2.1)\n","Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.9.7->unsloth) (0.19.0)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (14.0.0)\n","Collecting shtab>=1.5.6 (from tyro->unsloth)\n","  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.13)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.6.15)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.2.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.4.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\n","Downloading unsloth-2025.9.6-py3-none-any.whl (312 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.6/312.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading unsloth_zoo-2025.9.8-py3-none-any.whl (230 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.2/230.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.9.31-py3-none-any.whl (131 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n","Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n","Installing collected packages: triton, shtab, tyro, tokenizers, cut_cross_entropy, transformers, datasets, unsloth_zoo, unsloth\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.22.0\n","    Uninstalling tokenizers-0.22.0:\n","      Successfully uninstalled tokenizers-0.22.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.56.0\n","    Uninstalling transformers-4.56.0:\n","      Successfully uninstalled transformers-4.56.0\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 4.0.0\n","    Uninstalling datasets-4.0.0:\n","      Successfully uninstalled datasets-4.0.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cut_cross_entropy-25.1.1 datasets-3.6.0 shtab-1.7.2 tokenizers-0.21.4 transformers-4.55.4 triton-3.3.1 tyro-0.9.31 unsloth-2025.9.6 unsloth_zoo-2025.9.8\n","Requirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.10.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from vllm) (2024.11.6)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.4)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n","Requirement already satisfied: blake3 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.0.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n","Requirement already satisfied: transformers>=4.53.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.55.4)\n","Requirement already satisfied: huggingface-hub>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.33.0->vllm) (0.34.4)\n","Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.4)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (3.20.3)\n","Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.13)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.12.13)\n","Requirement already satisfied: openai<=1.90.0,>=1.87.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.90.0)\n","Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.7)\n","Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.22.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\n","Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (7.1.0)\n","Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\n","Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.12)\n","Requirement already satisfied: llguidance<0.8.0,>=0.7.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.7.30)\n","Requirement already satisfied: outlines_core==0.2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.10)\n","Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.11/dist-packages (from vllm) (5.6.3)\n","Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.2.2)\n","Requirement already satisfied: xgrammar==0.1.21 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.1.21)\n","Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.14.0)\n","Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\n","Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.1.1.post6)\n","Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (27.0.2)\n","Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\n","Requirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.17.1)\n","Requirement already satisfied: mistral_common>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from mistral_common[audio,image]>=1.8.2->vllm) (1.8.4)\n","Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\n","Requirement already satisfied: compressed-tensors==0.10.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.2)\n","Requirement already satisfied: depyf==0.19.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n","Requirement already satisfied: watchfiles in /usr/local/lib/python3.11/dist-packages (from vllm) (1.1.0)\n","Requirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.3)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from vllm) (1.11.1.4)\n","Requirement already satisfied: pybase64 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.4.2)\n","Requirement already satisfied: cbor2 in /usr/local/lib/python3.11/dist-packages (from vllm) (5.7.0)\n","Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.61.2)\n","Requirement already satisfied: ray!=2.44.*,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (2.47.1)\n","Requirement already satisfied: torch==2.7.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.7.1)\n","Requirement already satisfied: torchaudio==2.7.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.7.1)\n","Requirement already satisfied: torchvision==0.22.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.22.1)\n","Requirement already satisfied: xformers==0.0.31 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.0.31)\n","Requirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.8.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.3.8)\n","Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba==0.61.2->vllm) (0.44.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (1.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (9.5.1.17)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (0.6.3)\n","Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (2.26.2)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (1.11.1.6)\n","Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.3.1)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch==2.7.1->vllm) (75.2.0)\n","Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\n","Requirement already satisfied: fastapi-cli>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.10)\n","Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n","Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\n","Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.3)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (25.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (1.1.5)\n","Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer<0.11,>=0.10.11->vllm) (0.3.3)\n","Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.24.0)\n","Requirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.10.5)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2025.2.0)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2022.2.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->vllm) (2.4.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (1.3.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.4.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.2.1)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.1)\n","Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.6.15)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->vllm) (0.5.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.1)\n","Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\n","Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n","Requirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.0)\n","Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.1->vllm) (3.0.2)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.25.1)\n","Requirement already satisfied: pycountry>=23 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (24.6.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.1->vllm) (1.3.0)\n","Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\n","Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.13.1)\n","Requirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.5.0.post1)\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vllm) (2022.2.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->vllm) (1.4.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->vllm) (2024.2.0)\n","Requirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\n","Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.31.0)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->vllm) (2024.2.0)\n","Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.0.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.17.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.22)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n"]}],"execution_count":2},{"id":"c3a2c92f","cell_type":"markdown","source":"# 1. Configuration and Data Setup","metadata":{}},{"id":"32680ff1","cell_type":"code","source":"%%writefile constants.py\n# Using base Qwen3 1.7B model from Kaggle input (no internet needed)\nBASE_MODEL_PATH = \"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\"  # Update this path as needed\nLORA_PATH = \"qwen3_1.7b_unsloth_lora_validation/\"  # Unsloth LoRA output path for validation\nDATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules/\"\n\nYES_TOKEN_ID = 7414 # tokenizer.convert_tokens_to_ids(\"Yes\")  # WITH space!\nNO_TOKEN_ID = 2308# tokenizer.convert_tokens_to_ids(\"No\")    # WITH space!\n\n\n# TT-12 Training Parameters\nTRAINING_DATA_PERCENTAGE = .5  # Controllable % of training data (0.1 = 10%, 1.0 = 100%)\nUSE_STRATIFIED_SAMPLING = True  # Maintain rule distribution when sampling\nDROP_POSITIVE_EXAMPLES = False  # If True, train only on negative examples (debug: can model predict \"No\"?)\n\nPOSITIVE_ANSWER = \"Yes\"\nNEGATIVE_ANSWER = \"No\"\nCOMPLETE_PHRASE = \"Answer:\"\nBASE_PROMPT = '''You are a moderator of a subreddit , your task isto classify if a comment breaks a rule.The subreddit name and the rule is first given.\nAt first , In positive example and it's answer a comment is given that breaks the rule.\nThen , In negative example and it's answer a comment is given that does not break the rule.\nFinally the comment you are tasked to moderate is given .\nYour task is think carefully about to classify whether this comment violates the rule.Respond Yes if u think it violates the Rule, Respond No if u think it does not violate the rule .\nOnly respond Yes/No.'''\n\nprint(\"✅ Using Qwen3 1.7B model from local Kaggle input\")\nprint(f\"🎯 TT-12: Unsloth training + vLLM inference with {TRAINING_DATA_PERCENTAGE*100:.0f}% of data\")\nprint(f\"📊 Stratified sampling: {USE_STRATIFIED_SAMPLING}\")\nif DROP_POSITIVE_EXAMPLES:\n    print(\"🔧 DEBUG MODE: Will train only on negative examples to test 'No' prediction capability\")\nelse:\n    print(\"🎯 NORMAL MODE: Training on both positive and negative examples\")","metadata":{"execution":{"iopub.status.busy":"2025-09-18T21:28:03.449160Z","iopub.execute_input":"2025-09-18T21:28:03.450009Z","iopub.status.idle":"2025-09-18T21:28:03.456275Z","shell.execute_reply.started":"2025-09-18T21:28:03.449962Z","shell.execute_reply":"2025-09-18T21:28:03.455558Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting constants.py\n","output_type":"stream"}],"execution_count":146},{"id":"b5b4fc8e","cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\nfrom datasets import Dataset\nfrom constants import POSITIVE_ANSWER, NEGATIVE_ANSWER, COMPLETE_PHRASE, BASE_PROMPT, TRAINING_DATA_PERCENTAGE, USE_STRATIFIED_SAMPLING, DROP_POSITIVE_EXAMPLES\nimport random, numpy as np\nfrom sklearn.model_selection import train_test_split\nrandom.seed(42)\nnp.random.seed(42)\n\n\ndef build_prompt(row):\n    return f\"\"\"\n{BASE_PROMPT}\n\nSubreddit: r/{row[\"subreddit\"]}\nRule: {row[\"rule\"]}\nExamples:\n1) {row[\"positive_example\"]}\n{COMPLETE_PHRASE} Yes\n\n2) {row[\"negative_example\"]}\n{COMPLETE_PHRASE} No\n\n---\nComment: {row[\"body\"]}\n{COMPLETE_PHRASE}\"\"\"\n\n\ndef get_example_based_training_data(data_path):\n    \"\"\"\n    TT-11: Create training data from examples (like test-time training)\n    This trains the model on examples, not actual comments\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Sample data if needed while maintaining rule distribution\n    if TRAINING_DATA_PERCENTAGE < 1.0:\n        if USE_STRATIFIED_SAMPLING:\n            # Stratified sampling to maintain rule distribution\n            train_dataset = train_dataset.groupby('rule', group_keys=False).apply(\n                lambda x: x.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42)\n            ).reset_index(drop=True)\n            print(f\"📊 Stratified sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n        else:\n            # Simple random sampling\n            train_dataset = train_dataset.sample(frac=TRAINING_DATA_PERCENTAGE, random_state=42).reset_index(drop=True)\n            print(f\"📊 Random sampling: {len(train_dataset)} samples ({TRAINING_DATA_PERCENTAGE*100:.0f}%)\")\n    \n    print(f\"📊 Training data size: {len(train_dataset)} samples\")\n    print(f\"📊 Rule distribution: {train_dataset['rule'].value_counts().to_dict()}\")\n    \n    flatten = []\n    \n    # Create training data from examples (similar to test-time training)\n    violation_types = [\"positive\", \"negative\"]\n    \n    # Debug mode: Train only on negative examples if DROP_POSITIVE_EXAMPLES is True\n    if DROP_POSITIVE_EXAMPLES:\n        violation_types = [\"negative\"]\n        print(\"🔧 DEBUG MODE: Training only on negative examples (DROP_POSITIVE_EXAMPLES=True)\")\n    \n    for violation_type in violation_types:\n        for i in range(1, 3):\n            sub_dataset = train_dataset[[\"rule\",\"subreddit\",\n                                        \"positive_example_1\",\"positive_example_2\",\n                                        \"negative_example_1\",\"negative_example_2\"]].copy()\n\n            if violation_type == \"positive\":\n                # Use positive example as the \"body\" to classify\n                body_col = f\"positive_example_{i}\"\n                other_positive_col = f\"positive_example_{3-i}\"  # other positive\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"positive_example\"] = sub_dataset[other_positive_col]\n                # negative_example randomly selected\n                sub_dataset[\"negative_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"negative_example_1\"],\n                    sub_dataset[\"negative_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 1  # Positive examples violate rules\n\n            else:  # violation_type == \"negative\"\n                # Use negative example as the \"body\" to classify\n                body_col = f\"negative_example_{i}\"\n                other_negative_col = f\"negative_example_{3-i}\"\n                sub_dataset[\"body\"] = sub_dataset[body_col]\n                sub_dataset[\"negative_example\"] = sub_dataset[other_negative_col]\n                sub_dataset[\"positive_example\"] = np.where(\n                    np.random.rand(len(sub_dataset)) < 0.5,\n                    sub_dataset[\"positive_example_1\"],\n                    sub_dataset[\"positive_example_2\"]\n                )\n                sub_dataset[\"rule_violation\"] = 0  # Negative examples don't violate rules\n\n            # Drop original candidate columns\n            sub_dataset.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                                      \"negative_example_1\",\"negative_example_2\"], inplace=True)\n\n            flatten.append(sub_dataset)\n\n    # Merge all DataFrames\n    example_training_df = pd.concat(flatten, axis=0)\n    example_training_df = example_training_df.drop_duplicates(ignore_index=True)\n    \n    print(f\"📊 Example-based training dataset: {len(example_training_df)} samples\")\n    print(f\"📊 Positive examples: {sum(example_training_df['rule_violation'] == 1)}\")\n    print(f\"📊 Negative examples: {sum(example_training_df['rule_violation'] == 0)}\")\n    \n    return example_training_df\n\n\ndef get_real_comment_validation_data(data_path):\n    \"\"\"\n    TT-11: Get real comments with labels for validation\n    This is what we actually want to predict\n    \"\"\"\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    \n    # Use actual comments and their labels for validation\n    validation_df = train_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\",\n                                  \"positive_example_1\",\"positive_example_2\",\n                                  \"negative_example_1\",\"negative_example_2\"]].copy()\n\n    # Randomly select positive_example and negative_example for prompts\n    validation_df[\"positive_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"positive_example_1\"],\n        validation_df[\"positive_example_2\"]\n    )\n    validation_df[\"negative_example\"] = np.where(\n        np.random.rand(len(validation_df)) < 0.5,\n        validation_df[\"negative_example_1\"],\n        validation_df[\"negative_example_2\"]\n    )\n\n    # Drop original candidate columns\n    validation_df.drop(columns=[\"positive_example_1\",\"positive_example_2\",\n                               \"negative_example_1\",\"negative_example_2\"], inplace=True)\n    \n    print(f\"📊 Real comment validation dataset: {len(validation_df)} samples\")\n    print(f\"📊 Rule violations: {sum(validation_df['rule_violation'] == 1)} positive, {sum(validation_df['rule_violation'] == 0)} negative\")\n    \n    return validation_df\n\n\ndef build_dataset_unsloth(dataframe):\n    \"\"\"Build dataset for Unsloth training with proper text formatting\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    \n    # Unsloth expects \"text\" field with full prompt + completion\n    dataframe[\"text\"] = dataframe.apply(lambda row: \n        row[\"prompt\"] +\" \" + (POSITIVE_ANSWER if row[\"rule_violation\"] == 1 else NEGATIVE_ANSWER), #i removed the space after the prompt\n        axis=1\n    )\n    \n    dataframe = dataframe[[\"text\"]]\n    dataset = Dataset.from_pandas(dataframe)\n    return dataset\n\n\ndef build_validation_dataset(dataframe):\n    \"\"\"Build dataset for validation (keep labels for evaluation)\"\"\"\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n    dataframe = dataframe[[\"prompt\", \"rule_violation\"]]  # Keep true labels for evaluation\n    dataset = Dataset.from_pandas(dataframe)\n    return dataset","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:09:25.663779Z","iopub.status.busy":"2025-09-18T20:09:25.663366Z","iopub.status.idle":"2025-09-18T20:09:25.672262Z","shell.execute_reply":"2025-09-18T20:09:25.671478Z","shell.execute_reply.started":"2025-09-18T20:09:25.663750Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting utils.py\n"]}],"execution_count":72},{"id":"1e389c0f-ea4a-4b08-88d0-5a35c0c264ea","cell_type":"code","source":"import importlib\nimport utils  # regular import (only needed once)\nimport constants\nimportlib.reload(constants)\n\nimportlib.reload(utils)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-18T21:28:06.927555Z","iopub.execute_input":"2025-09-18T21:28:06.927812Z","iopub.status.idle":"2025-09-18T21:28:06.936750Z","shell.execute_reply.started":"2025-09-18T21:28:06.927792Z","shell.execute_reply":"2025-09-18T21:28:06.936049Z"},"trusted":true},"outputs":[{"name":"stdout","text":"✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 50% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n","output_type":"stream"},{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"<module 'utils' from '/kaggle/working/utils.py'>"},"metadata":{}}],"execution_count":147},{"id":"2abcb14c-a7aa-4fea-a497-be8799e849d8","cell_type":"code","source":"%%writefile train_unsloth.py\nimport pandas as pd\nimport torch\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom utils import build_dataset_unsloth, get_example_based_training_data\nfrom constants import DATA_PATH, BASE_MODEL_PATH, LORA_PATH\n\n\ndef main():\n    # TT-11: Get example-based training data (train on examples, not real comments)\n    train_df = get_example_based_training_data(DATA_PATH)\n    train_dataset = build_dataset_unsloth(train_df)\n    \n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n    \n    # 🚀 UNSLOTH: Load model with 4-bit quantization (2x T4 optimized)\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,  # Adjust based on your max sequence length\n        dtype=None,  # Auto-detect (will use float16)\n        load_in_4bit=True,  # Enable 4-bit quantization\n        trust_remote_code=True,\n        local_files_only=True,\n        device_map=\"balanced\"\n    )\n    print(\"✅ Unsloth model loaded with 4-bit quantization across 2x T4\")\n    \n    # 🚀 UNSLOTH: Add LoRA adapters (automatic and optimized)\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r=16,  # LoRA rank (can try 8, 16, 32, 64, 128)\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n        lora_alpha=16,  # LoRA alpha (typically equal to r for Unsloth)\n        lora_dropout=0,  # 0 for faster training with Unsloth\n        bias=\"none\",\n        #use_gradient_checkpointing=False,  # Enable for memory efficiency\n        random_state=3407,  # For reproducibility\n        use_rslora=False,  # Can try True for better stability\n        loftq_config=None,  # LoftQ for even better quality\n        use_gradient_checkpointing = \"unsloth\"\n    )\n    print(\"✅ Unsloth LoRA adapters added\")\n    \n    # 🚀 UNSLOTH: Optimized training arguments for 2x T4 GPUs (28GB total)\n    training_args = TrainingArguments(\n        per_device_train_batch_size=8,  # Larger batches with 2x T4 (28GB total)\n        gradient_accumulation_steps=8,  # Effective batch size = 4*2*2 = 16\n        warmup_steps=5,  # Quick warmup with Unsloth\n        #max_steps=50,  # Unsloth converges much faster (adjust based on data size)\n        num_train_epochs=1 , \n        learning_rate=2e-4,  # Higher LR works better with Unsloth\n        fp16=not torch.cuda.is_bf16_supported(),\n        bf16=torch.cuda.is_bf16_supported(),\n        logging_steps=1,  # Frequent logging for monitoring\n        optim=\"adamw_8bit\",  # 8-bit optimizer for memory efficiency\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",  # Simple linear decay\n        seed=666,\n        output_dir=LORA_PATH,\n        report_to=\"none\",\n        save_strategy=\"steps\",\n        save_steps=20,  # Save frequently for monitoring\n        save_total_limit=2,  # Keep only recent checkpoints\n        dataloader_pin_memory=False,  # Unsloth handles this\n        # Multi-GPU optimizations for 2x T4\n        dataloader_num_workers=4,  # Parallel data loading\n        remove_unused_columns=False,  # Keep all data\n        ddp_find_unused_parameters=False,  # DDP optimization\n        ddp_broadcast_buffers=False,  # Reduce communication overhead\n    )\n    print(\"✅ Unsloth training arguments configured for 2x T4\")\n    \n    # 🚀 UNSLOTH: Use SFTTrainer with Unsloth model\n    trainer = SFTTrainer(\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=train_dataset,\n        dataset_text_field=\"text\",  # Unsloth expects \"text\" field\n        max_seq_length=2048,\n        dataset_num_proc=4,  # More parallel processing for 2x T4\n        packing=False,  # Can try True for even faster training\n        args=training_args,\n    )\n    \n    print(\"🚀 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\")\n    \n    # 🚀 UNSLOTH: Train with optimized loop\n    trainer_stats = trainer.train()\n    \n    print(\"✅ Unsloth training completed!\")\n    print(f\"Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\n    print(f\"Samples/second: {trainer_stats.metrics['train_samples_per_second']:.2f}\")\n    print(f\"GPU utilization optimized for 2x T4 setup\")\n    \n    # 🚀 UNSLOTH: Save LoRA adapters in vLLM-compatible format\n    print(\"💾 Saving LoRA adapters for vLLM compatibility...\")\n    \n    # Save tokenizer\n    tokenizer.save_pretrained(LORA_PATH)\n    \n    # Save model in PEFT format (vLLM compatible)\n    model.save_pretrained(LORA_PATH)\n    #model.save_pretrained(...)  \n    #tokenizer.save_pretrained(...)\n    folder=\"16 bit\"\n    model.save_pretrained_merged(\"model\", tokenizer, save_method = \"forced_merged_4bit\",)\n    \n\n    \n    print(f\"✅ LoRA adapters saved to: {LORA_PATH} , model saved \")\n    print(\"🎯 Ready for vLLM inference!\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.execute_input":"2025-09-18T21:00:42.172149Z","iopub.status.busy":"2025-09-18T21:00:42.171804Z","iopub.status.idle":"2025-09-18T21:00:42.179747Z","shell.execute_reply":"2025-09-18T21:00:42.179026Z","shell.execute_reply.started":"2025-09-18T21:00:42.172124Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting train_unsloth.py\n"]}],"execution_count":128},{"id":"772886cb","cell_type":"code","source":"%%writefile weight_train_unsloth.py\nimport pandas as pd\nimport torch\nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom utils import build_dataset_unsloth, get_example_based_training_data\nfrom constants import DATA_PATH, BASE_MODEL_PATH, LORA_PATH, YES_TOKEN_ID, NO_TOKEN_ID\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef get_class_weights():\n    \"\"\"\n    Manual class weights to heavily penalize false positives\n\n    CLASS MAPPING:\n    - Index 0 = \"No\" (negative class, rule_violation = 0)\n    - Index 1 = \"Yes\" (positive class, rule_violation = 1)\n\n    WEIGHTS:\n    - Weight for \"No\" (index 0): 0.8 (higher penalty for getting \"No\" wrong)\n    - Weight for \"Yes\" (index 1): 0.2 (lower penalty for getting \"Yes\" wrong)\n    - Result: 4x more penalty for false positives (predicting \"Yes\" when should be \"No\")\n    \"\"\"\n    # Manual weights: [weight_for_no, weight_for_yes]\n    weights = torch.tensor([0.8, 0.2], dtype=torch.float)\n\n    # Print weight distribution for verification\n    print(f\"📊 Class Weights Mapping:\")\n    print(f\"   Index 0 ('No'/negative): {weights[0].item():.1f}\")\n    print(f\"   Index 1 ('Yes'/positive): {weights[1].item():.1f}\")\n    print(f\"📊 False Positive Penalty: {weights[0].item()/weights[1].item():.1f}x\")\n    print(f\"📊 Token IDs: No={NO_TOKEN_ID}, Yes={YES_TOKEN_ID}\")\n\n    return weights\n\n\nclass WeightedSFTTrainer(SFTTrainer):\n    \"\"\"Custom SFT Trainer with weighted loss - compatible with Unsloth\"\"\"\n\n    def __init__(self, class_weights, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.class_weights = class_weights\n\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        \"\"\"\n        Custom loss computation with class weights\n        Compatible with Unsloth's additional parameters using **kwargs\n        \"\"\"\n        # Handle Unsloth's additional parameters\n        labels = inputs.get(\"labels\")\n        outputs = model(**inputs)\n\n        # Debug: Check outputs structure\n        if outputs is None:\n            print(\"❌ ERROR: model outputs is None\")\n            return torch.tensor(0.0, requires_grad=True, device=self.model.device)\n\n        # Try different ways to access logits (Unsloth might structure differently)\n        logits = None\n        if hasattr(outputs, 'logits'):\n            logits = outputs.logits\n        elif isinstance(outputs, dict) and 'logits' in outputs:\n            logits = outputs['logits']\n        elif isinstance(outputs, tuple) and len(outputs) > 0:\n            logits = outputs[0]  # Some models return tuple\n\n        if logits is None:\n            print(\"❌ ERROR: Could not find logits in model outputs\")\n            print(f\"   Outputs type: {type(outputs)}\")\n            print(f\"   Outputs attributes: {dir(outputs) if hasattr(outputs, '__dict__') else 'No __dict__'}\")\n            # Fall back to standard loss if available\n            if hasattr(outputs, 'loss') and outputs.loss is not None:\n                return (outputs.loss, outputs) if return_outputs else outputs.loss\n            else:\n                return torch.tensor(0.0, requires_grad=True, device=self.model.device)\n\n        if labels is not None:\n            # For language modeling, we predict next token\n            if logits.dim() >= 3:  # Standard case: [batch, seq_len, vocab_size]\n                shift_logits = logits[..., :-1, :].contiguous()\n                shift_labels = labels[..., 1:].contiguous()\n            else:\n                # Handle edge case where logits might be 2D\n                shift_logits = logits\n                shift_labels = labels\n\n            # Flatten the tokens\n            shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n            shift_labels = shift_labels.view(-1)\n\n            # Move weights to correct device\n            weights = self.class_weights.to(shift_logits.device)\n\n            # Find positions where we're predicting Yes/No tokens\n            yes_no_mask = (shift_labels == YES_TOKEN_ID) | (shift_labels == NO_TOKEN_ID)\n\n            if yes_no_mask.any():\n                # Apply weighted loss only to Yes/No predictions\n                yes_no_logits = shift_logits[yes_no_mask]\n                yes_no_labels = shift_labels[yes_no_mask]\n\n                # Map token IDs to class indices\n                class_labels = torch.where(yes_no_labels == YES_TOKEN_ID, 1, 0)\n\n                # Apply weighted cross entropy to Yes/No predictions\n                weighted_loss = F.cross_entropy(\n                    yes_no_logits,\n                    yes_no_labels,\n                    reduction='none'\n                )\n\n                # Apply class weights\n                class_weights_expanded = weights[class_labels]\n                weighted_loss = (weighted_loss * class_weights_expanded).mean()\n\n                # Standard loss for other tokens\n                other_mask = ~yes_no_mask\n                if other_mask.any():\n                    other_loss = F.cross_entropy(\n                        shift_logits[other_mask],\n                        shift_labels[other_mask],\n                        ignore_index=-100\n                    )\n                    # Combine losses (give more weight to Yes/No predictions)\n                    loss = 0.7 * weighted_loss + 0.3 * other_loss\n                else:\n                    loss = weighted_loss\n            else:\n                # No Yes/No tokens found, use standard loss\n                loss = F.cross_entropy(\n                    shift_logits,\n                    shift_labels,\n                    ignore_index=-100\n                )\n        else:\n            # No labels provided, use model's built-in loss if available\n            if hasattr(outputs, 'loss') and outputs.loss is not None:\n                loss = outputs.loss\n            else:\n                loss = torch.tensor(0.0, requires_grad=True, device=logits.device)\n\n        return (loss, outputs) if return_outputs else loss\n\n\ndef main():\n    # TT-12: Get example-based training data (train on examples, not real comments)\n    train_df = get_example_based_training_data(DATA_PATH)\n    train_dataset = build_dataset_unsloth(train_df)\n\n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n\n    # 🚀 UNSLOTH: Load model with 4-bit quantization (2x T4 optimized)\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=BASE_MODEL_PATH,\n        max_seq_length=2048,  # Adjust based on your max sequence length\n        dtype=None,  # Auto-detect (will use float16)\n        load_in_4bit=True,  # Enable 4-bit quantization\n        trust_remote_code=True,\n        local_files_only=True,\n        device_map=\"balanced\"\n    )\n    print(\"✅ Unsloth model loaded with 4-bit quantization across 2x T4\")\n\n    # 🚀 UNSLOTH: Add LoRA adapters (automatic and optimized)\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r=16,  # LoRA rank (can try 8, 16, 32, 64, 128)\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n        lora_alpha=32,  # LoRA alpha (typically equal to r for Unsloth)\n        lora_dropout=0,  # 0 for faster training with Unsloth\n        bias=\"none\",\n        random_state=3407,  # For reproducibility\n        use_rslora=False,  # Can try True for better stability\n        loftq_config=None,  # LoftQ for even better quality\n        use_gradient_checkpointing=\"unsloth\"\n    )\n    print(\"✅ Unsloth LoRA adapters added\")\n\n    # 🚀 UNSLOTH: Optimized training arguments for 2x T4 GPUs (28GB total)\n    training_args = TrainingArguments(\n        per_device_train_batch_size=2,  # Adjusted for memory\n        gradient_accumulation_steps=8,  # Effective batch size = 2*2*8 = 32\n        warmup_steps=5,  # Quick warmup with Unsloth\n        num_train_epochs=1,\n        learning_rate=1e-4,  # Conservative learning rate\n        fp16=not torch.cuda.is_bf16_supported(),\n        bf16=torch.cuda.is_bf16_supported(),\n        logging_steps=1,  # Frequent logging for monitoring\n        optim=\"adamw_8bit\",  # 8-bit optimizer for memory efficiency\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",  # Simple linear decay\n        seed=666,\n        output_dir=LORA_PATH,\n        report_to=\"none\",\n        save_strategy=\"steps\",\n        save_steps=20,  # Save frequently for monitoring\n        save_total_limit=2,  # Keep only recent checkpoints\n        dataloader_pin_memory=False,  # Unsloth handles this\n        # Multi-GPU optimizations for 2x T4\n        dataloader_num_workers=4,  # Parallel data loading\n        remove_unused_columns=False,  # Keep all data\n        ddp_find_unused_parameters=False,  # DDP optimization\n        ddp_broadcast_buffers=False,  # Reduce communication overhead\n    )\n    print(\"✅ Unsloth training arguments configured for 2x T4\")\n\n    # Get class weights for balanced training\n    class_weights = get_class_weights()\n\n    # 🚀 UNSLOTH: Use WeightedSFTTrainer with class weights\n    trainer = WeightedSFTTrainer(\n        class_weights=class_weights,\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=train_dataset,\n        dataset_text_field=\"text\",  # Unsloth expects \"text\" field\n        max_seq_length=2048,\n        dataset_num_proc=4,  # More parallel processing for 2x T4\n        packing=False,  # Can try True for even faster training\n        args=training_args,\n    )\n\n    print(\"🚀 Starting Unsloth training with weighted loss on 2x T4...\")\n    print(\"🎯 Heavily penalizing false positives (predicting 'Yes' when should be 'No')\")\n\n    # 🚀 UNSLOTH: Train with optimized loop\n    trainer_stats = trainer.train()\n\n    print(\"✅ Unsloth training completed!\")\n    print(f\"Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\n    print(f\"Samples/second: {trainer_stats.metrics['train_samples_per_second']:.2f}\")\n    print(f\"GPU utilization optimized for 2x T4 setup\")\n\n    # 🚀 UNSLOTH: Save LoRA adapters in vLLM-compatible format\n    print(\"💾 Saving LoRA adapters for vLLM compatibility...\")\n\n    # Save tokenizer\n    tokenizer.save_pretrained(LORA_PATH)\n\n    # Save model in PEFT format (vLLM compatible)\n    model.save_pretrained(LORA_PATH)\n\n    # Save merged 4-bit model\n\n    print(f\"✅ LoRA adapters saved to: {LORA_PATH}\")\n    print(f\"✅ Merged 4-bit model saved to: {folder}\")\n    print(\"🎯 Ready for vLLM inference with weighted training!\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-09-18T21:26:42.042000Z","iopub.execute_input":"2025-09-18T21:26:42.042268Z","iopub.status.idle":"2025-09-18T21:26:42.054408Z","shell.execute_reply.started":"2025-09-18T21:26:42.042249Z","shell.execute_reply":"2025-09-18T21:26:42.053551Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting weight_train_unsloth.py\n","output_type":"stream"}],"execution_count":145},{"id":"5195dc58","cell_type":"markdown","source":"# 🎯 2x T4 GPU Optimization Guide\n\n## ⚡ **Multi-GPU Configuration for TT-11**\n\n### **Your Setup: 2x T4 (28GB Total VRAM)**\n- **GPU 0**: ~14GB VRAM\n- **GPU 1**: ~14GB VRAM\n- **Total**: 28GB available for training\n\n### **Optimizations Applied:**\n\n#### **1. Model Distribution**\n```python\ndevice_map=\"auto\"  # Automatic distribution across GPUs\nmax_memory={0: \"13GB\", 1: \"13GB\"}  # Reserve 1GB per GPU for operations\n```\n\n#### **2. Batch Size Scaling**\n```python\nper_device_train_batch_size=4,  # 4 samples per GPU (8 total)\ngradient_accumulation_steps=2,  # Effective batch = 4*2*2 = 16\n```\n\n#### **3. Memory Optimizations**\n```python\nload_in_4bit=True,              # 4-bit quantization saves ~75% memory\nuse_gradient_checkpointing=True, # Trade compute for memory\ndataloader_pin_memory=False,     # Let Unsloth handle memory\n```\n\n#### **4. Multi-GPU Training**\n```python\ndataloader_num_workers=4,        # Parallel data loading\nddp_find_unused_parameters=False, # DDP optimization\nddp_broadcast_buffers=False,     # Reduce communication\n```\n\n### **Expected Performance:**\n- **Training Speed**: 3x-6x faster than single GPU\n- **Memory Usage**: ~12-13GB per GPU\n- **Effective Batch**: 16 samples (vs 4 on single GPU)\n- **Total Time**: 5-8 minutes for full training\n\n### **Troubleshooting 2x T4:**\n\n#### **If you get OOM (Out of Memory):**\n```python\n# Reduce batch size\nper_device_train_batch_size=2,   # 2 per GPU instead of 4\ngradient_accumulation_steps=4,   # Keep effective batch size\n\n# Or reduce sequence length\nmax_seq_length=1024,             # Shorter sequences\n```\n\n#### **If training is slower than expected:**\n```python\n# Check GPU utilization\nnvidia-smi  # Should show ~90%+ on both GPUs\n\n# Increase batch size if memory allows\nper_device_train_batch_size=6,   # Try larger batches\n```\n\n#### **Memory Distribution Check:**\n```python\nprint(f\"Available GPUs: {torch.cuda.device_count()}\")\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_properties(i).total_memory // 1024**3}GB\")\n```","metadata":{}},{"id":"9c272316-1b10-4ccd-bc25-ea7e46e2fdd1","cell_type":"code","source":"!export VLLM_LOGGING_LEVEL=DEBUG\n","metadata":{"execution":{"iopub.execute_input":"2025-09-18T15:30:55.180228Z","iopub.status.busy":"2025-09-18T15:30:55.179978Z","iopub.status.idle":"2025-09-18T15:30:55.295403Z","shell.execute_reply":"2025-09-18T15:30:55.294688Z","shell.execute_reply.started":"2025-09-18T15:30:55.180206Z"},"trusted":true},"outputs":[],"execution_count":6},{"id":"09a9ce47-01e2-499f-bac9-49a3fc60aa31","cell_type":"code","source":"","metadata":{"execution":{"iopub.execute_input":"2025-09-15T12:50:03.642051Z","iopub.status.busy":"2025-09-15T12:50:03.641772Z","iopub.status.idle":"2025-09-15T12:50:03.649916Z","shell.execute_reply":"2025-09-15T12:50:03.649026Z","shell.execute_reply.started":"2025-09-15T12:50:03.642031Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'LORA_PATH' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2768232158.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLORA_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'LORA_PATH' is not defined"]}],"execution_count":59},{"id":"94fc07a4","cell_type":"code","source":"%%writefile validation_vllm.py\nimport os\nos.environ[\"TRITON_NUM_STAGES\"] = \"3\"  # Reduce stages\nos.environ[\"VLLM_USE_V1\"] = \"1\"\nimport vllm\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\nfrom vllm.lora.request import LoRARequest\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\n\n\ndef run_validation_vllm():\n    \"\"\"Run validation using Unsloth-trained model with vLLM for precise AUC\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"🔍 Running validation on {len(val_dataset)} real comments\")\n    model=\"/kaggle/working/qwen3_1.7b_merged\"\n    # 🎯 VLLM: Initialize with Unsloth LoRA support for precise probabilities\n    llm = vllm.LLM(\n        model= model,\n        tensor_parallel_size=1,\n        gpu_memory_utilization=0.90, # Reduced to prevent OOM\n        trust_remote_code=True,\n        dtype=\"half\" ,\n        quantization=\"bitsandbytes\",\n        #load_format=\"bitsandbytes\" ,\n        enforce_eager=True,\n        max_model_len=700,  # Reduced from 2048 to fix Triton shared memory error on T4\n        disable_log_stats=True,\n        enable_prefix_caching=True,\n        enable_lora=True,\n        max_lora_rank=64,  # Support Unsloth's LoRA rank\n        block_size=16,\n        num_gpu_blocks_override=512\n        \n\n        \n    )\n\n    # In validation_vllm.py, modify the LLM initialization:\n    # llm = vllm.LLM(\n    #     BASE_MODEL_PATH,\n    #     tensor_parallel_size=1,\n    #     gpu_memory_utilization=0.90,\n    #     trust_remote_code=True,\n    #     dtype=\"half\",  # Use half precision instead of quantization\n    #     enforce_eager=True,\n    #     max_model_len=512,\n    #     disable_log_stats=True,\n    #     enable_prefix_caching=True,\n    #     enable_lora=True,\n    #     max_lora_rank=64,\n    # )\n\n    tokenizer = llm.get_tokenizer()\n\n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n\n    # 🎯 VLLM: Generate with Unsloth LoRA for most accurate probabilities\n    # We remove the logits_processor and decrease logprobs to get token probabilities\n    outputs = llm.generate(\n        texts,\n        vllm.SamplingParams(\n            skip_special_tokens=True,\n            max_tokens=1,\n            logprobs=20,  # Request top 20 logprobs to find \"Yes\" and \"No\"\n        ),\n        use_tqdm=True,\n        lora_request=LoRARequest(\"unsloth_lora\", 1, LORA_PATH)  # Load Unsloth LoRA\n    )\n\n    # Extract predictions and probabilities with vLLM precision\n    predictions = []\n    probabilities = []  # High-precision probabilities for AUC\n    \n    # Get token IDs for \"Yes\" and \"No\"\n    yes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\n    no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n    \n    for out in outputs:\n        # Safely get log probabilities for \"Yes\" and \"No\"\n        log_probs = out.outputs[0].logprobs[0]\n        \n        log_prob_yes = log_probs.get(yes_token_id)\n        log_prob_no = log_probs.get(no_token_id)\n        \n        # Handle cases where tokens might not be in the top logprobs\n        if log_prob_yes is not None and log_prob_no is not None:\n            if log_prob_yes.logprob > log_prob_no.logprob:\n                predictions.append(1)\n            else:\n                predictions.append(0)\n            \n            # Calculate precise probability for AUC\n            exp_pos = np.exp(log_prob_yes.logprob)\n            exp_neg = np.exp(log_prob_no.logprob)\n            prob_positive = exp_pos / (exp_pos + exp_neg)\n            probabilities.append(prob_positive)\n        else:\n            # Fallback if one of the tokens is not in the top 20 logprobs\n            # This is unlikely but a safe fallback\n            predictions.append(0)\n            probabilities.append(0.5)\n\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    # Basic metrics\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"📊 TT-11 VALIDATION RESULTS (Unsloth + vLLM)\")\n    print(\"=\" * 60)\n    print(f\"🎯 Accuracy:  {accuracy:.4f}\")\n    print(f\"🎯 F1 Score:  {f1:.4f}\")\n    print(f\"🎯 Precision: {precision:.4f}\")\n    print(f\"🎯 Recall:    {recall:.4f}\")\n    print(f\"🎯 AUC Score: {auc:.4f} (High-precision vLLM)\")\n    print(\"=\" * 60)\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n📈 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    # Classification report\n    print(\"\\n📋 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'auc': auc,\n        'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-11: Unsloth Training + vLLM Validation Results', fontsize=16, fontweight='bold')\n    \n    # 1. Confusion Matrix Heatmap\n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    # 2. ROC Curve\n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (vLLM High-Precision)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # 3. Probability Distribution\n    pos_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 1]\n    neg_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (vLLM Precision)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    # 4. Metrics Bar Chart\n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics['accuracy'], metrics['f1'], metrics['precision'], metrics['recall'], metrics['auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (Unsloth + vLLM)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt11_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    # Add predictions to dataframe\n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n📊 PERFORMANCE BY RULE (vLLM High-Precision AUC):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        if len(np.unique(rule_true)) > 1:  # Check if both classes exist\n            rule_auc = roc_auc_score(rule_true, rule_prob)\n        else:\n            rule_auc = np.nan\n            \n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\")\n        print(f\"  Samples: {len(rule_data)}\")\n        print(f\"  Accuracy: {rule_acc:.3f}\")\n        print(f\"  F1 Score: {rule_f1:.3f}\" if not np.isnan(rule_f1) else \"  F1 Score: N/A\")\n        print(f\"  AUC Score: {rule_auc:.3f}\" if not np.isnan(rule_auc) else \"  AUC Score: N/A\")\n        print()\n        \n        rule_metrics.append({\n            'rule': rule,\n            'samples': len(rule_data),\n            'accuracy': rule_acc,\n            'f1': rule_f1,\n            'auc': rule_auc\n        })\n    \n    # Save detailed results\n    analysis_df.to_csv('/kaggle/working/tt11_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt11_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"🔬 TT-11: Unsloth Training + vLLM Validation\")\n    print(\"🚀 Ultra-fast training + High-precision inference!\")\n    print(\"📚 Training: Model learned from examples with Unsloth speed\")\n    print(\"🧪 Validation: Testing on real comments with vLLM precision\")\n    print(\"=\" * 70)\n    \n    # Run validation\n    true_labels, predictions, probabilities, val_df = run_validation_vllm()\n    \n    # Calculate metrics\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    \n    # Create visualizations\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    \n    # Analyze by rule\n    rule_metrics = analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"✅ TT-11 Validation completed!\")\n    print(\"📈 Visualizations saved: /kaggle/working/tt11_validation_results.png\")\n    print(\"📊 Detailed results: /kaggle/working/tt11_detailed_results.csv\")\n    print(\"📋 Rule metrics: /kaggle/working/tt11_rule_metrics.csv\")\n    print(\"🎯 Best of both worlds: Unsloth speed + vLLM precision!\")\n    \n    return metrics, rule_metrics\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"execution":{"iopub.execute_input":"2025-09-18T18:46:26.155415Z","iopub.status.busy":"2025-09-18T18:46:26.155155Z","iopub.status.idle":"2025-09-18T18:46:26.165950Z","shell.execute_reply":"2025-09-18T18:46:26.165134Z","shell.execute_reply.started":"2025-09-18T18:46:26.155397Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing validation_vllm.py\n"]}],"execution_count":7},{"id":"07ec1ce0","cell_type":"code","source":"%%writefile validation_transformers.py\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, \n                           roc_auc_score, confusion_matrix, classification_report, roc_curve)\nfrom unsloth import FastLanguageModel  # Add this import\nfrom utils import build_validation_dataset, get_real_comment_validation_data\nfrom constants import BASE_MODEL_PATH, LORA_PATH, DATA_PATH, POSITIVE_ANSWER, NEGATIVE_ANSWER\nfrom constants import *\nfrom tqdm import tqdm\n\ndef run_validation_transformers():\n    \"\"\"Run validation using Unsloth fast inference with merged LoRA - Maximum speed!\"\"\"\n    \n    # Get real comment validation data\n    val_df = get_real_comment_validation_data(DATA_PATH)\n    val_dataset = build_validation_dataset(val_df)\n    \n    print(f\"🔍 Running validation on {len(val_dataset)} real comments (Unsloth Fast Inference)\")\n    \n    # 🚀 UNSLOTH: Load merged model with fast inference support\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name=\"/kaggle/working/qwen3_1.7b_merged\",  # Use merged model path\n        max_seq_length=2048,\n        load_in_4bit=True,  # Keep 4-bit for speed\n        dtype=None,\n    )\n    \n    # 🚀 UNSLOTH: Enable fast inference mode\n    FastLanguageModel.for_inference(model)\n    \n    # Get token IDs for \"Yes\" and \"No\"\n    yes_token_id = YES_TOKEN_ID  \n    no_token_id = NO_TOKEN_ID \n    \n    print(f\"🎯 Token IDs: Yes={yes_token_id}, No={no_token_id}\")\n    \n    texts = val_dataset[\"prompt\"]\n    true_labels = val_dataset[\"rule_violation\"]\n    \n    # 🚀 UNSLOTH: Fast batch inference\n    predictions = []\n    probabilities = []\n    batch_size = 16  # Larger batches with Unsloth optimization\n    \n    print(\"🚀 Running fast inference with Unsloth...\")\n    \n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch_texts = texts[i:i+batch_size]\n        \n        # 🚀 UNSLOTH: Optimized tokenization and inference\n        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            # 🚀 UNSLOTH: Fast forward pass\n            outputs = model(**inputs)\n            next_token_logits = outputs.logits[:, -1, :]  # Get last token logits\n            \n            # Get probabilities for \"Yes\" and \"No\" tokens\n            yes_logits = next_token_logits[:, yes_token_id]\n            no_logits = next_token_logits[:, no_token_id]\n            \n            # Convert to probabilities using softmax over Yes/No only\n            combined_logits = torch.stack([no_logits, yes_logits], dim=1)  # [batch, 2]\n            probs = torch.softmax(combined_logits, dim=1)  # [batch, 2]\n            \n            # Extract predictions and probabilities\n            batch_predictions = torch.argmax(probs, dim=1).cpu().numpy()\n            batch_probabilities = probs[:, 1].cpu().numpy()  # Probability of \"Yes\" (violation)\n            \n            predictions.extend(batch_predictions.tolist())\n            probabilities.extend(batch_probabilities.tolist())\n    \n    print(\"✅ Fast inference completed!\")\n    return true_labels, predictions, probabilities, val_df\n\n\ndef calculate_and_display_metrics(true_labels, predictions, probabilities):\n    \"\"\"Calculate comprehensive metrics and display results\"\"\"\n    \n    # Basic metrics\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions)\n    recall = recall_score(true_labels, predictions)\n    auc = roc_auc_score(true_labels, probabilities)\n    \n    print(\"=\" * 60)\n    print(\"📊 TT-11 VALIDATION RESULTS (Unsloth + Transformers)\")\n    print(\"=\" * 60)\n    print(f\"🎯 Accuracy:  {accuracy:.4f}\")\n    print(f\"🎯 F1 Score:  {f1:.4f}\")\n    print(f\"🎯 Precision: {precision:.4f}\")\n    print(f\"🎯 Recall:    {recall:.4f}\")\n    print(f\"🎯 AUC Score: {auc:.4f} (Standard Transformers)\")\n    print(\"=\" * 60)\n    \n    # Confusion matrix\n    cm = confusion_matrix(true_labels, predictions)\n    print(\"\\n📈 Confusion Matrix:\")\n    print(f\"True Negative: {cm[0,0]:4d} | False Positive: {cm[0,1]:4d}\")\n    print(f\"False Negative: {cm[1,0]:4d} | True Positive:  {cm[1,1]:4d}\")\n    \n    # Classification report\n    print(\"\\n📋 Classification Report:\")\n    print(classification_report(true_labels, predictions, target_names=['No Violation', 'Violation']))\n    \n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall,\n        'auc': auc,\n        'confusion_matrix': cm\n    }\n\n\ndef create_visualizations(true_labels, predictions, probabilities, metrics):\n    \"\"\"Create comprehensive visualizations\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n    fig.suptitle('TT-11: Unsloth Training + Transformers Validation Results', fontsize=16, fontweight='bold')\n    \n    # 1. Confusion Matrix Heatmap\n    cm = metrics['confusion_matrix']\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n                xticklabels=['No Violation', 'Violation'],\n                yticklabels=['No Violation', 'Violation'])\n    axes[0,0].set_title('Confusion Matrix')\n    axes[0,0].set_xlabel('Predicted')\n    axes[0,0].set_ylabel('Actual')\n    \n    # 2. ROC Curve\n    fpr, tpr, _ = roc_curve(true_labels, probabilities)\n    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {metrics[\"auc\"]:.3f})')\n    axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n    axes[0,1].set_xlabel('False Positive Rate')\n    axes[0,1].set_ylabel('True Positive Rate')\n    axes[0,1].set_title('ROC Curve (Transformers)')\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # 3. Probability Distribution\n    pos_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 1]\n    neg_probs = [probabilities[i] for i in range(len(probabilities)) if true_labels[i] == 0]\n    \n    axes[1,0].hist(neg_probs, bins=30, alpha=0.7, label='No Violation', color='blue', density=True)\n    axes[1,0].hist(pos_probs, bins=30, alpha=0.7, label='Violation', color='red', density=True)\n    axes[1,0].set_xlabel('Predicted Probability (Transformers)')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Probability Distribution by True Label')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    # 4. Metrics Bar Chart\n    metric_names = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC']\n    metric_values = [metrics['accuracy'], metrics['f1'], metrics['precision'], metrics['recall'], metrics['auc']]\n    \n    bars = axes[1,1].bar(metric_names, metric_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'gold'])\n    axes[1,1].set_ylabel('Score')\n    axes[1,1].set_title('Performance Metrics (Unsloth + Transformers)')\n    axes[1,1].set_ylim(0, 1)\n    axes[1,1].grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar, value in zip(bars, metric_values):\n        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                      f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/tt11_transformers_validation_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n\ndef analyze_by_rule(true_labels, predictions, probabilities, val_df):\n    \"\"\"Analyze performance by rule type\"\"\"\n    \n    # Add predictions to dataframe\n    analysis_df = val_df.copy()\n    analysis_df['predictions'] = predictions\n    analysis_df['probabilities'] = probabilities\n    \n    print(\"\\n📊 PERFORMANCE BY RULE (Transformers):\")\n    print(\"=\" * 60)\n    \n    rule_metrics = []\n    for rule in analysis_df['rule'].unique():\n        rule_data = analysis_df[analysis_df['rule'] == rule]\n        \n        rule_true = rule_data['rule_violation'].values\n        rule_pred = rule_data['predictions'].values\n        rule_prob = rule_data['probabilities'].values\n        \n        if len(np.unique(rule_true)) > 1:  # Check if both classes exist\n            rule_auc = roc_auc_score(rule_true, rule_prob)\n        else:\n            rule_auc = np.nan\n            \n        rule_acc = accuracy_score(rule_true, rule_pred)\n        rule_f1 = f1_score(rule_true, rule_pred) if len(np.unique(rule_true)) > 1 else np.nan\n        \n        print(f\"Rule: {rule}\")\n        print(f\"  Samples: {len(rule_data)}\")\n        print(f\"  Accuracy: {rule_acc:.3f}\")\n        print(f\"  F1 Score: {rule_f1:.3f}\" if not np.isnan(rule_f1) else \"  F1 Score: N/A\")\n        print(f\"  AUC Score: {rule_auc:.3f}\" if not np.isnan(rule_auc) else \"  AUC Score: N/A\")\n        print()\n        \n        rule_metrics.append({\n            'rule': rule,\n            'samples': len(rule_data),\n            'accuracy': rule_acc,\n            'f1': rule_f1,\n            'auc': rule_auc\n        })\n    \n    # Save detailed results\n    analysis_df.to_csv('/kaggle/working/tt11_transformers_detailed_results.csv', index=False)\n    pd.DataFrame(rule_metrics).to_csv('/kaggle/working/tt11_transformers_rule_metrics.csv', index=False)\n    \n    return rule_metrics\n\n\ndef main():\n    print(\"🔬 TT-11: Unsloth Training + Transformers Validation\")\n    print(\"🚀 Ultra-fast training + Universal compatibility!\")\n    print(\"📚 Training: Model learned from examples with Unsloth speed\")\n    print(\"🧪 Validation: Testing on real comments with standard Transformers\")\n    print(\"=\" * 70)\n    \n    # Run validation\n    true_labels, predictions, probabilities, val_df = run_validation_transformers()\n    \n    # Calculate metrics\n    metrics = calculate_and_display_metrics(true_labels, predictions, probabilities)\n    \n    # Create visualizations\n    create_visualizations(true_labels, predictions, probabilities, metrics)\n    \n    # Analyze by rule\n    rule_metrics = analyze_by_rule(true_labels, predictions, probabilities, val_df)\n    \n    print(\"✅ TT-11 Transformers Validation completed!\")\n    print(\"📈 Visualizations saved: /kaggle/working/tt11_transformers_validation_results.png\")\n    print(\"📊 Detailed results: /kaggle/working/tt11_transformers_detailed_results.csv\")\n    print(\"📋 Rule metrics: /kaggle/working/tt11_transformers_rule_metrics.csv\")\n    print(\"🎯 Reliable and compatible validation with Unsloth speed!\")\n    \n    return metrics, rule_metrics\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.execute_input":"2025-09-18T21:02:33.277333Z","iopub.status.busy":"2025-09-18T21:02:33.277025Z","iopub.status.idle":"2025-09-18T21:02:33.288516Z","shell.execute_reply":"2025-09-18T21:02:33.287898Z","shell.execute_reply.started":"2025-09-18T21:02:33.277308Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting validation_transformers.py\n"]}],"execution_count":130},{"id":"71830c7e-b562-4e8e-8b68-22521796501e","cell_type":"markdown","source":"","metadata":{}},{"id":"1f12f4c8","cell_type":"code","source":"%%writefile accelerate_config.yaml\ncompute_environment: LOCAL_MACHINE\ndebug: false\n# #deepspeed_config:\n#   gradient_accumulation_steps: auto\n#   gradient_clipping: 1.0\n#   train_batch_size: 16\n#   train_micro_batch_size_per_gpu: 2\n  \n#   zero_stage: 2\n#   offload_optimizer_device: none\n#   offload_param_device: none\n#   zero3_init_flag: false\n  \n#   stage3_gather_16bit_weights_on_model_save: false\n#   stage3_max_live_parameters: 1e8\n#   stage3_max_reuse_distance: 1e8\n#   stage3_prefetch_bucket_size: 5e7\n#   stage3_param_persistence_threshold: 1e5\n  \n#   zero_allow_untested_optimizer: true\n#   zero_force_ds_cpu_optimizer: false\n  \n#   fp16:\n#     enabled: true\n#     loss_scale: 0\n#     initial_scale_power: 16\n#     loss_scale_window: 1000\n#     hysteresis: 2\n#     min_loss_scale: 1\n  \ndistributed_type: None\ndowncast_bf16: 'no'\ndynamo_config:\n  dynamo_backend: INDUCTOR\n  dynamo_use_fullgraph: false\n  dynamo_use_dynamic: false\nenable_cpu_affinity: false\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 1\nnum_processes: 2\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false","metadata":{"execution":{"iopub.execute_input":"2025-09-15T11:40:14.900532Z","iopub.status.busy":"2025-09-15T11:40:14.900015Z","iopub.status.idle":"2025-09-15T11:40:14.912715Z","shell.execute_reply":"2025-09-15T11:40:14.912134Z","shell.execute_reply.started":"2025-09-15T11:40:14.900507Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting accelerate_config.yaml\n"]}],"execution_count":17},{"id":"89067d5c-d199-4b5c-9a3e-275b7e6c2cba","cell_type":"code","source":"%%writefile accelerate_config.yaml\ncompute_environment: LOCAL_MACHINE\ndebug: false\n# Removed deepspeed_config section entirely\ndistributed_type: NO   # Changed from DEEPSPEED to MULTI_GPU\ndowncast_bf16: 'no'\ndynamo_config:\n  dynamo_backend: INDUCTOR\n  dynamo_use_fullgraph: false\n  dynamo_use_dynamic: false\nenable_cpu_affinity: false\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 1\nnum_processes: 2  # Keep this for 2 GPUs\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false","metadata":{"execution":{"iopub.execute_input":"2025-09-18T21:02:41.058931Z","iopub.status.busy":"2025-09-18T21:02:41.058323Z","iopub.status.idle":"2025-09-18T21:02:41.063625Z","shell.execute_reply":"2025-09-18T21:02:41.063019Z","shell.execute_reply.started":"2025-09-18T21:02:41.058905Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting accelerate_config.yaml\n"]}],"execution_count":131},{"id":"98dd1f21","cell_type":"code","source":"!accelerate launch --config_file accelerate_config.yaml train_unsloth.py\n","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-09-18T20:40:03.125649Z","iopub.status.busy":"2025-09-18T20:40:03.125337Z","iopub.status.idle":"2025-09-18T20:49:19.894069Z","shell.execute_reply":"2025-09-18T20:49:19.893194Z","shell.execute_reply.started":"2025-09-18T20:40:03.125626Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","2025-09-18 20:40:14.316506: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1758228014.342409    1474 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1758228014.349894    1474 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","INFO 09-18 20:40:21 [__init__.py:235] Automatically detected platform cuda.\n","ERROR 09-18 20:40:23 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","✅ Using Qwen3 1.7B model from local Kaggle input\n","🎯 TT-12: Unsloth training + vLLM inference with 50% of data\n","📊 Stratified sampling: True\n","🔧 DEBUG MODE: Will train only on negative examples to test 'No' prediction capability\n","📊 Stratified sampling: 1014 samples (50%)\n","📊 Training data size: 1014 samples\n","📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 508, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 506}\n","🔧 DEBUG MODE: Training only on negative examples (DROP_POSITIVE_EXAMPLES=True)\n","📊 Example-based training dataset: 2028 samples\n","📊 Positive examples: 0\n","📊 Negative examples: 2028\n","Training dataset size: 2028 samples\n","Available GPUs: 2\n","Unsloth: WARNING `trust_remote_code` is True.\n","Are you certain you want to do remote code execution?\n","==((====))==  Unsloth 2025.9.6: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n","   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","✅ Unsloth model loaded with 4-bit quantization across 2x T4\n","Unsloth 2025.9.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","✅ Unsloth LoRA adapters added\n","✅ Unsloth training arguments configured for 2x T4\n","Unsloth: Tokenizing [\"text\"] (num_proc=8): 100%|█| 2028/2028 [00:03<00:00, 570.7\n","[2025-09-18 20:40:43,147] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2025-09-18 20:40:43,720] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n","🚀 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\n","Unsloth: Enabled auto compiling\n","==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n","   \\\\   /|    Num examples = 2,028 | Num Epochs = 1 | Total steps = 32\n","O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n","\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n"," \"-____-\"     Trainable parameters = 17,432,576 of 1,738,007,552 (1.00% trained)\n","  0%|                                                    | 0/32 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!\n","{'loss': 3.9033, 'grad_norm': 2.986849784851074, 'learning_rate': 0.0, 'epoch': 0.03}\n","{'loss': 3.8437, 'grad_norm': 2.909322500228882, 'learning_rate': 4e-05, 'epoch': 0.06}\n","{'loss': 3.8182, 'grad_norm': 2.318240165710449, 'learning_rate': 8e-05, 'epoch': 0.09}\n","{'loss': 3.6449, 'grad_norm': 1.3102130889892578, 'learning_rate': 0.00012, 'epoch': 0.13}\n","{'loss': 3.547, 'grad_norm': 0.9535450339317322, 'learning_rate': 0.00016, 'epoch': 0.16}\n","{'loss': 3.4466, 'grad_norm': 0.9663930535316467, 'learning_rate': 0.0002, 'epoch': 0.19}\n","{'loss': 3.3473, 'grad_norm': 0.8051015734672546, 'learning_rate': 0.0001925925925925926, 'epoch': 0.22}\n","{'loss': 3.1756, 'grad_norm': 0.7693246603012085, 'learning_rate': 0.0001851851851851852, 'epoch': 0.25}\n","{'loss': 3.0984, 'grad_norm': 0.7282397150993347, 'learning_rate': 0.00017777777777777779, 'epoch': 0.28}\n","{'loss': 3.0686, 'grad_norm': 0.7046773433685303, 'learning_rate': 0.00017037037037037037, 'epoch': 0.31}\n","{'loss': 2.9411, 'grad_norm': 0.6298860311508179, 'learning_rate': 0.00016296296296296295, 'epoch': 0.35}\n","{'loss': 2.8564, 'grad_norm': 0.6046486496925354, 'learning_rate': 0.00015555555555555556, 'epoch': 0.38}\n","{'loss': 2.7813, 'grad_norm': 0.5675356388092041, 'learning_rate': 0.00014814814814814815, 'epoch': 0.41}\n","{'loss': 2.6186, 'grad_norm': 0.5563918948173523, 'learning_rate': 0.00014074074074074076, 'epoch': 0.44}\n","{'loss': 2.6205, 'grad_norm': 0.5776029229164124, 'learning_rate': 0.00013333333333333334, 'epoch': 0.47}\n","{'loss': 2.4985, 'grad_norm': 0.6138342618942261, 'learning_rate': 0.00012592592592592592, 'epoch': 0.5}\n","{'loss': 2.4597, 'grad_norm': 0.6173025369644165, 'learning_rate': 0.00011851851851851852, 'epoch': 0.54}\n","{'loss': 2.4508, 'grad_norm': 0.6356896758079529, 'learning_rate': 0.00011111111111111112, 'epoch': 0.57}\n","{'loss': 2.2541, 'grad_norm': 0.6188490986824036, 'learning_rate': 0.0001037037037037037, 'epoch': 0.6}\n","{'loss': 2.3058, 'grad_norm': 0.6195845603942871, 'learning_rate': 9.62962962962963e-05, 'epoch': 0.63}\n","{'loss': 2.164, 'grad_norm': 0.6415518522262573, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.66}\n","{'loss': 2.1354, 'grad_norm': 0.6107873320579529, 'learning_rate': 8.148148148148148e-05, 'epoch': 0.69}\n","{'loss': 2.1154, 'grad_norm': 0.5738499164581299, 'learning_rate': 7.407407407407407e-05, 'epoch': 0.72}\n","{'loss': 2.0546, 'grad_norm': 0.5733180642127991, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.76}\n","{'loss': 2.0396, 'grad_norm': 0.646399974822998, 'learning_rate': 5.925925925925926e-05, 'epoch': 0.79}\n","{'loss': 1.9964, 'grad_norm': 0.6410204172134399, 'learning_rate': 5.185185185185185e-05, 'epoch': 0.82}\n","{'loss': 1.9455, 'grad_norm': 0.6641688346862793, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.85}\n","{'loss': 1.9728, 'grad_norm': 0.5643298029899597, 'learning_rate': 3.7037037037037037e-05, 'epoch': 0.88}\n","{'loss': 1.8933, 'grad_norm': 0.3503834307193756, 'learning_rate': 2.962962962962963e-05, 'epoch': 0.91}\n","{'loss': 1.9585, 'grad_norm': 0.3302839398384094, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.94}\n","{'loss': 1.9711, 'grad_norm': 0.34094613790512085, 'learning_rate': 1.4814814814814815e-05, 'epoch': 0.98}\n","{'loss': 1.9634, 'grad_norm': 0.3352689743041992, 'learning_rate': 7.4074074074074075e-06, 'epoch': 1.0}\n","{'train_runtime': 506.2752, 'train_samples_per_second': 4.006, 'train_steps_per_second': 0.063, 'train_loss': 2.652825765311718, 'epoch': 1.0}\n","100%|███████████████████████████████████████████| 32/32 [08:26<00:00, 15.82s/it]\n","✅ Unsloth training completed!\n","Training time: 506.28 seconds\n","Samples/second: 4.01\n","GPU utilization optimized for 2x T4 setup\n","💾 Saving LoRA adapters for vLLM compatibility...\n","/usr/local/lib/python3.11/dist-packages/unsloth_zoo/saving_utils.py:888: UserWarning: Model /kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit not found locally or on HuggingFace\n","  warnings.warn(f\"Model {model_name} not found locally or on HuggingFace\")\n","✅ LoRA adapters saved to: qwen3_1.7b_unsloth_lora_validation/ , model saved \n","🎯 Ready for vLLM inference!\n"]}],"execution_count":122},{"id":"e4ebaa7a-f6db-4188-8da8-b6a044e7e8a2","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"47e4a810-f91d-4791-9e8b-eb9271a9a11d","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c5f82eee-47f5-4d5d-9629-269bd9920917","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"af7c1129-340f-4b7c-a526-69f30132e748","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7fb6f1de-cf68-469e-8f20-a85910bda072","cell_type":"code","source":"import os\nos.environ[\"TRITON_NUM_STAGES\"] = \"1\"  ","metadata":{"execution":{"iopub.execute_input":"2025-09-15T13:30:46.119879Z","iopub.status.busy":"2025-09-15T13:30:46.119258Z","iopub.status.idle":"2025-09-15T13:30:46.123729Z","shell.execute_reply":"2025-09-15T13:30:46.122956Z","shell.execute_reply.started":"2025-09-15T13:30:46.119853Z"},"trusted":true},"outputs":[],"execution_count":87},{"id":"61d65926-118c-463a-b2bf-9fa01b0b0f21","cell_type":"code","source":"#!python train_unsloth.pyfree finetuning.\n","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-09-15T11:42:23.352401Z","iopub.status.busy":"2025-09-15T11:42:23.352158Z","iopub.status.idle":"2025-09-15T11:44:42.354882Z","shell.execute_reply":"2025-09-15T11:44:42.354161Z","shell.execute_reply.started":"2025-09-15T11:42:23.352385Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","2025-09-15 11:42:34.684988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757936554.901474     283 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757936554.964244     283 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","INFO 09-15 11:42:58 [__init__.py:235] Automatically detected platform cuda.\n","ERROR 09-15 11:43:01 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","✅ Using Qwen3 1.7B model from local Kaggle input\n","🎯 TT-11: Unsloth training + vLLM inference with 100% of data\n","📊 Stratified sampling: True\n","📊 Training data size: 2029 samples\n","📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 1017, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 1012}\n","📊 Example-based training dataset: 8112 samples\n","📊 Positive examples: 4055\n","📊 Negative examples: 4057\n","Training dataset size: 8112 samples\n","Available GPUs: 2\n","Unsloth: WARNING `trust_remote_code` is True.\n","Are you certain you want to do remote code execution?\n","==((====))==  Unsloth 2025.9.5: Fast Qwen3 patching. Transformers: 4.56.0. vLLM: 0.10.0.\n","   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","✅ Unsloth model loaded with 4-bit quantization across 2x T4\n","Unsloth 2025.9.5 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","✅ Unsloth LoRA adapters added\n","✅ Unsloth training arguments configured for 2x T4\n","Unsloth: Tokenizing [\"text\"] (num_proc=8): 100%|█| 8112/8112 [00:05<00:00, 1376.\n","[2025-09-15 11:43:42,004] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2025-09-15 11:43:43,386] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n","🚀 Starting Unsloth training on 2x T4 (2x-5x faster than standard fine-tuning)...\n","The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n","==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n","   \\\\   /|    Num examples = 8,112 | Num Epochs = 1 | Total steps = 500\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n","\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n"," \"-____-\"     Trainable parameters = 17,432,576 of 1,738,007,552 (1.00% trained)\n","  0%|                                                   | 0/500 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!\n","{'loss': 4.3085, 'grad_norm': 31.93807601928711, 'learning_rate': 0.0, 'epoch': 0.0}\n","{'loss': 4.2223, 'grad_norm': 31.5997371673584, 'learning_rate': 4e-05, 'epoch': 0.0}\n","{'loss': 3.6211, 'grad_norm': 6.902505874633789, 'learning_rate': 8e-05, 'epoch': 0.01}\n","{'loss': 3.4545, 'grad_norm': 3.853771686553955, 'learning_rate': 0.00012, 'epoch': 0.01}\n","{'loss': 3.3724, 'grad_norm': 2.8827977180480957, 'learning_rate': 0.00016, 'epoch': 0.01}\n","{'loss': 3.0868, 'grad_norm': 2.754180908203125, 'learning_rate': 0.0002, 'epoch': 0.01}\n","{'loss': 2.8299, 'grad_norm': 2.893399953842163, 'learning_rate': 0.00019999798600729064, 'epoch': 0.01}\n","{'loss': 2.6515, 'grad_norm': 2.5171403884887695, 'learning_rate': 0.00019999194411028594, 'epoch': 0.02}\n","{'loss': 2.5992, 'grad_norm': 2.1630144119262695, 'learning_rate': 0.0001999818745523526, 'epoch': 0.02}\n","{'loss': 2.4876, 'grad_norm': 2.03615403175354, 'learning_rate': 0.00019996777773909093, 'epoch': 0.02}\n","{'loss': 2.4519, 'grad_norm': 1.9603849649429321, 'learning_rate': 0.00019994965423831854, 'epoch': 0.02}\n","{'loss': 2.4302, 'grad_norm': 2.5908591747283936, 'learning_rate': 0.00019992750478004738, 'epoch': 0.02}\n","{'loss': 2.3586, 'grad_norm': 2.0433380603790283, 'learning_rate': 0.0001999013302564544, 'epoch': 0.03}\n","  3%|█                                         | 13/500 [00:53<30:06,  3.71s/it]^C\n","Traceback (most recent call last):\n","  File \"/kaggle/working/train_unsloth.py\", line 116, in <module>\n","    main()\n","  File \"/kaggle/working/train_unsloth.py\", line 90, in main\n","    trainer_stats = trainer.train()\n","                    ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2328, in train\n","    return inner_training_loop(\n","           ^^^^^^^^^^^^^^^^^^^^\n","  File \"<string>\", line 325, in _fast_inner_training_loop\n","  File \"/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\", line 949, in training_step\n","    return super().training_step(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<string>\", line 40, in _unsloth_training_step\n","  File \"/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\", line 938, in compute_loss\n","    outputs = super().compute_loss(\n","              ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\", line 1299, in _unsloth_pre_compute_loss\n","    outputs = self._old_compute_loss(model, inputs, *args, **kwargs)\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 4099, in compute_loss\n","    outputs = model(**inputs)\n","              ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\", line 818, in forward\n","    return model_forward(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\", line 806, in __call__\n","    return convert_to_fp32(self.model_forward(*args, **kwargs))\n","                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 51, in inner\n","    return disable_fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n","    return fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 1339, in PeftModel_fast_forward\n","    return self.base_model(\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\", line 222, in forward\n","    return self.model.forward(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n","    output = module._old_forward(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 1150, in _CausalLM_fast_forward\n","    outputs = self.model(\n","              ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 962, in LlamaModel_fast_forward\n","    layer_outputs = decoder_layer(\n","                    ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\", line 93, in __call__\n","    return self._gradient_checkpointing_func(partial(super().__call__, **kwargs), *args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 51, in inner\n","    return disable_fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n","    return fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\", line 488, in checkpoint\n","    return CheckpointFunction.apply(function, preserve, *args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n","    return super().apply(*args, **kwargs)  # type: ignore[misc]\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth_zoo/gradient_checkpointing.py\", line 477, in forward\n","    outputs = run_function(*args)\n","              ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n","    output = module._old_forward(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\", line 634, in LlamaDecoderLayer_fast_forward\n","    hidden_states, self_attn_weights, present_key_value = self.self_attn(\n","                                                          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 175, in new_forward\n","    output = module._old_forward(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/models/qwen3.py\", line 121, in Qwen3Attention_fast_forward\n","    Q, K = fast_rope_embedding(Q, K, cos, sin)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n","    return fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/kernels/rope_embedding.py\", line 156, in fast_rope_embedding\n","    Q = Fast_RoPE_Embedding.apply(Q.transpose(1, 2), cos, sin).transpose(1, 2)\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\", line 575, in apply\n","    return super().apply(*args, **kwargs)  # type: ignore[misc]\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/unsloth/kernels/rope_embedding.py\", line 104, in forward\n","    _rope_embedding[(n_rows, n_groups, )](\n","  File \"/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py\", line 347, in <lambda>\n","    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n","                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/triton/runtime/autotuner.py\", line 395, in run\n","    return self.fn.run(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py\", line 583, in run\n","    if callable(grid):\n","       ^^^^^^^^^^^^^^\n","KeyboardInterrupt\n"]}],"execution_count":20},{"id":"c2f2a2e6-0a5f-4668-9e15-671f9c382ac9","cell_type":"code","source":"%%writefile merge_lora.py\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\nfrom constants import BASE_MODEL_PATH, LORA_PATH\n\ndef merge_and_save():\n    print(\"🔄 Loading base model...\")\n    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)\n    model = AutoModelForCausalLM.from_pretrained(\n        BASE_MODEL_PATH,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n    )\n    \n    print(\"🔗 Loading LoRA adapters...\")\n    model = PeftModel.from_pretrained(model, LORA_PATH)\n    \n    print(\"🔀 Merging LoRA weights...\")\n    merged_model = model.merge_and_unload()\n    \n    # Create output directory for merged model\n    merged_path = \"/kaggle/working/qwen3_1.7b_merged\"\n    \n    print(\"💾 Saving merged model...\")\n    merged_model.save_pretrained(merged_path)\n    tokenizer.save_pretrained(merged_path)\n    \n    print(f\"✅ Merged model saved to: {merged_path}\")\n    return merged_path\n\nif __name__ == \"__main__\":\n    merge_and_save()","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:49:19.896132Z","iopub.status.busy":"2025-09-18T20:49:19.895877Z","iopub.status.idle":"2025-09-18T20:49:19.903081Z","shell.execute_reply":"2025-09-18T20:49:19.902326Z","shell.execute_reply.started":"2025-09-18T20:49:19.896107Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting merge_lora.py\n"]}],"execution_count":123},{"id":"2411162d-432c-4cfc-a62f-2a79d25add2e","cell_type":"code","source":"!python merge_lora.py","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-09-18T20:49:19.904244Z","iopub.status.busy":"2025-09-18T20:49:19.904034Z","iopub.status.idle":"2025-09-18T20:49:45.208531Z","shell.execute_reply":"2025-09-18T20:49:45.207546Z","shell.execute_reply.started":"2025-09-18T20:49:19.904227Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["2025-09-18 20:49:25.870608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1758228565.893302    1607 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1758228565.901578    1607 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","✅ Using Qwen3 1.7B model from local Kaggle input\n","🎯 TT-12: Unsloth training + vLLM inference with 50% of data\n","📊 Stratified sampling: True\n","🔧 DEBUG MODE: Will train only on negative examples to test 'No' prediction capability\n","🔄 Loading base model...\n","🔗 Loading LoRA adapters...\n","🔀 Merging LoRA weights...\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n","  warnings.warn(\n","💾 Saving merged model...\n","[2025-09-18 20:49:35,791] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2025-09-18 20:49:37,166] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n","✅ Merged model saved to: /kaggle/working/qwen3_1.7b_merged\n"]}],"execution_count":124},{"id":"0c2a5c0f-dfe1-46d8-ac5f-237ca8f0912a","cell_type":"markdown","source":"# 💎 OUTPUT TESTINNG\n\n## 🛡️ TESTING OUTPUT\n ","metadata":{}},{"id":"523f99da-0780-426d-84fa-b4327e7f909f","cell_type":"code","source":"from utils import *\nfrom constants import *\nfrom unsloth import FastLanguageModel\nimport torch\ntrain_df = get_example_based_training_data(DATA_PATH)\ndataset = build_dataset_unsloth(train_df)\nmodel , tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"/kaggle/working/qwen3_1.7b_merged\",\n    #model_name=\"/kaggle/input/qwen3-1.7b-unsloth-bnb-4bit/gguf/default/1/qwen3_4bit\" ,\n    max_seq_length=2048,\n    load_in_4bit=True,\n)\n","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:38:06.794547Z","iopub.status.busy":"2025-09-18T20:38:06.793820Z","iopub.status.idle":"2025-09-18T20:38:11.510006Z","shell.execute_reply":"2025-09-18T20:38:11.509193Z","shell.execute_reply.started":"2025-09-18T20:38:06.794483Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["📊 Stratified sampling: 203 samples (10%)\n","📊 Training data size: 203 samples\n","📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 102, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 101}\n","🔧 DEBUG MODE: Training only on negative examples (DROP_POSITIVE_EXAMPLES=True)\n","📊 Example-based training dataset: 406 samples\n","📊 Positive examples: 0\n","📊 Negative examples: 406\n","==((====))==  Unsloth 2025.9.6: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n","   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}],"execution_count":115},{"id":"4e1fe153-94ae-4e63-a7b0-654f88e9930a","cell_type":"code","source":"dataset[12]","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:38:21.437311Z","iopub.status.busy":"2025-09-18T20:38:21.437056Z","iopub.status.idle":"2025-09-18T20:38:21.443107Z","shell.execute_reply":"2025-09-18T20:38:21.442069Z","shell.execute_reply.started":"2025-09-18T20:38:21.437293Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'text': \"\\nYou are given a comment from reddit and a rule.\\nAt first , In positive example and it's answer a comment is given that breaks the rule.\\nThen , In negative example and it's answer a comment is given that does not break the rule.\\nFinally a comment is given .\\nYour task is to classify whether this comment violates the rule.Respond Yes if u think it violates the Rule, Respond No if u think it does not violate the rule .\\nOnly respond Yes/No.\\n\\nSubreddit: r/AskReddit\\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nExamples:\\n1) FindSexToday . com - free girls for sex worldwide 3oBKmqU6XiS14!\\nAnswer: Yes\\n\\n2) **HD** Stream [AFC Bournemouth vs Arsenal Live Stream](http://werdumvsmiociclivestream.com/arsenal.html) \\n\\nEnglish | Mobile:Yes\\nAnswer: No\\n\\n---\\nComment: \\n**HD** ENG [ 1080P HD Amazing] :- [USTREAM EURO CUP 2016 HD Live Stream](http://tnthdlive.blogspot.com/p/adsbygoogle-window_11.html) [Mobile Compatible]    \\nIf Stream gets banned just refresh will be back in 1 minute!    \\nPlease UPVOTE if you like the stream. Thanks!\\n\\nAnswer: No\"}"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"execution_count":116},{"id":"9d4b596d-1aaa-4fa8-8794-041e0864a60b","cell_type":"code","source":"# Get validation data (prompts without answers)\nval_df = get_real_comment_validation_data(DATA_PATH)\nval_dataset = build_validation_dataset(val_df)\n","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:38:58.215482Z","iopub.status.busy":"2025-09-18T20:38:58.215208Z","iopub.status.idle":"2025-09-18T20:38:58.297480Z","shell.execute_reply":"2025-09-18T20:38:58.296650Z","shell.execute_reply.started":"2025-09-18T20:38:58.215460Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["📊 Real comment validation dataset: 2029 samples\n","📊 Rule violations: 1031 positive, 998 negative\n"]}],"execution_count":117},{"id":"7bfdfabc-9200-4f5c-a490-c5989c22bf21","cell_type":"code","source":"dataset[1]['text']","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:39:00.575743Z","iopub.status.busy":"2025-09-18T20:39:00.574934Z","iopub.status.idle":"2025-09-18T20:39:00.580708Z","shell.execute_reply":"2025-09-18T20:39:00.579902Z","shell.execute_reply.started":"2025-09-18T20:39:00.575716Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"\\nYou are given a comment from reddit and a rule.\\nAt first , In positive example and it's answer a comment is given that breaks the rule.\\nThen , In negative example and it's answer a comment is given that does not break the rule.\\nFinally a comment is given .\\nYour task is to classify whether this comment violates the rule.Respond Yes if u think it violates the Rule, Respond No if u think it does not violate the rule .\\nOnly respond Yes/No.\\n\\nSubreddit: r/Showerthoughts\\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nExamples:\\n1) Selling Tyrande code for 3€ (or equal amount in any other currency) to paypal. PM if interested. \\nhttp://imgur.com/a/IMARW\\nAnswer: Yes\\n\\n2) Must Watch : https://www.youtube.com/watch?v=dQoedIV8LXo\\nAnswer: No\\n\\n---\\nComment: Try http://lfil.es/jb\\n\\nI know the guy (/u/jq-) who owns the site, it's a mirror of totoa/imokhles'.\\nAnswer: No\""]},"execution_count":118,"metadata":{},"output_type":"execute_result"}],"execution_count":118},{"id":"100d443d-55ef-4690-8045-2230008f1305","cell_type":"code","source":"yes_token_id = tokenizer.convert_tokens_to_ids(\" \")\nprint(f\"Token ID for ' Yes': {yes_token_id}\")  # Should be 7414","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:14:38.988806Z","iopub.status.busy":"2025-09-18T20:14:38.988484Z","iopub.status.idle":"2025-09-18T20:14:38.993498Z","shell.execute_reply":"2025-09-18T20:14:38.992754Z","shell.execute_reply.started":"2025-09-18T20:14:38.988782Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Token ID for ' Yes': None\n"]}],"execution_count":83},{"id":"fa611c10-f6e6-4d95-af9a-9159275a9ce5","cell_type":"code","source":"val_dataset[0]","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:39:10.486385Z","iopub.status.busy":"2025-09-18T20:39:10.486086Z","iopub.status.idle":"2025-09-18T20:39:10.492407Z","shell.execute_reply":"2025-09-18T20:39:10.491753Z","shell.execute_reply.started":"2025-09-18T20:39:10.486361Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'prompt': \"\\nYou are given a comment from reddit and a rule.\\nAt first , In positive example and it's answer a comment is given that breaks the rule.\\nThen , In negative example and it's answer a comment is given that does not break the rule.\\nFinally a comment is given .\\nYour task is to classify whether this comment violates the rule.Respond Yes if u think it violates the Rule, Respond No if u think it does not violate the rule .\\nOnly respond Yes/No.\\n\\nSubreddit: r/Futurology\\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\\nExamples:\\n1) If you could tell your younger self something different about sex, what would that be?\\n\\ni AM IN A CONTEST TO WIN FUNDING FOR MY SEX POSITIVE FILM: VOTE HERE:\\n\\nhttp://sheknows.offerpop.com/campaign/813112/entry/v144417\\nAnswer: Yes\\n\\n2) Watch Golden Globe Awards 2017 Live Online in HD Coverage without ADS (VIP STREAMS)\\n=\\n\\nHD STREAM QUALITY >>> [WATCH LINK1](http://forum.submitexpress.com/viewtopic.php?f=9&t=215858)\\n=\\n\\nHD BROADCASTING QUALITY >>> [WATCH LINK1](http://forum.submitexpress.com/viewtopic.php?f=9&t=215858)\\n=\\n\\nMobile Compatibility: YES\\n=\\n\\nNO ADS | NO ADS | ADS\\n=\\n\\nAnswer: No\\n\\n---\\nComment: Banks don't want you to know this! Click here to know more!\\nAnswer:\",\n"," 'rule_violation': 0}"]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"execution_count":119},{"id":"3e51eaa7-2062-42f1-b17a-edccb310e9df","cell_type":"code","source":"import torch.nn.functional as F\n\nFastLanguageModel.for_inference(model)\n\n# Prepare input\ninputs = tokenizer(val_dataset[0]['prompt'], return_tensors=\"pt\").to(\"cuda\")\n\n# Get logits for the next token\nwith torch.no_grad():\n    outputs = model(**inputs)\n    next_token_logits = outputs.logits[0, -1, :]  # Shape: [vocab_size]\n\n# ---- FIXED: Use tokens WITH SPACES ----\nyes_token_id = 7414 # tokenizer.convert_tokens_to_ids(\"Yes\")  # WITH space!\nno_token_id = 2308# tokenizer.convert_tokens_to_ids(\"No\")    # WITH space!\n#no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\nprint(f\"Token IDs: yes_token_id={yes_token_id}, no_token_id={no_token_id}\")\n\n# Extract logits for Yes/No tokens\nyes_logit =  next_token_logits[yes_token_id]  # Single scalar value\nno_logit = next_token_logits[no_token_id]    # Single scalar value\n\nprint(f\"Logit shapes: yes_logit={yes_logit.shape}, no_logit={no_logit.shape}\")\n\n# Convert to probabilities (only for Yes/No)\ncombined_logits = torch.stack([no_logit, yes_logit])  # Shape: [2]\nprobabilities = F.softmax(combined_logits, dim=0)     # Shape: [2]\n\nprob_no = probabilities[0].item()\nprob_yes = probabilities[1].item()\n\nprint(f\"Probability of ' No': {prob_no:.4f}\")\nprint(f\"Probability of ' Yes': {prob_yes:.4f}\")\nprint(f\"Prediction: {'Yes' if prob_yes > prob_no else 'No'}\")\n\n# ---- Top 5 tokens (full vocab) ----\nprobs = F.softmax(next_token_logits, dim=-1)\n\ntop_k = 5\ntop_probs, top_ids = torch.topk(probs, top_k)\ntop_tokens = tokenizer.batch_decode(top_ids.unsqueeze(-1))\n\nprint(\"\\n🔝 Top 5 next tokens:\")\nfor rank, (token, prob) in enumerate(zip(top_tokens, top_probs), start=1):\n    print(f\"{rank}. Token: {repr(token)}\\tProbability: {prob.item():.4f}\")\n\n# ---- Yes / No ranks (from full vocab) ----\nyes_prob = probs[yes_token_id].item()\nno_prob = probs[no_token_id].item()\n\nsorted_probs, sorted_ids = torch.sort(probs, descending=True)\nyes_rank = (sorted_ids == yes_token_id).nonzero(as_tuple=True)[0].item() + 1\nno_rank = (sorted_ids == no_token_id).nonzero(as_tuple=True)[0].item() + 1\n\nprint(\"\\n📊 Specific token stats:\")\nprint(f\"'Yes' → Probability: {yes_prob:.4f}, Rank: {yes_rank}\")\nprint(f\"'No'  → Probability: {no_prob:.4f}, Rank: {no_rank}\")","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:39:26.261005Z","iopub.status.busy":"2025-09-18T20:39:26.260748Z","iopub.status.idle":"2025-09-18T20:39:26.469753Z","shell.execute_reply":"2025-09-18T20:39:26.469043Z","shell.execute_reply.started":"2025-09-18T20:39:26.260987Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Token IDs: yes_token_id=7414, no_token_id=2308\n","Logit shapes: yes_logit=torch.Size([]), no_logit=torch.Size([])\n","Probability of ' No': 0.0087\n","Probability of ' Yes': 0.9912\n","Prediction: Yes\n","\n","🔝 Top 5 next tokens:\n","1. Token: ' Yes'\tProbability: 0.9766\n","2. Token: ' No'\tProbability: 0.0086\n","3. Token: ' ?\\n'\tProbability: 0.0068\n","4. Token: ' ?\\n\\n'\tProbability: 0.0048\n","5. Token: ' ?'\tProbability: 0.0011\n","\n","📊 Specific token stats:\n","'Yes' → Probability: 0.9766, Rank: 1\n","'No'  → Probability: 0.0086, Rank: 2\n"]}],"execution_count":120},{"id":"5e6b5c84-7916-43f1-b7b1-be85021c01a5","cell_type":"code","source":"yes_logits = next_token_logits[:, yes_token_id]\nno_logits = next_token_logits[:, no_token_id]\ncombined_logits = torch.stack([no_logits, yes_logits], dim=1)\nprobs = torch.softmax(combined_logits, dim=1)\npredictions = torch.argmax(probs, dim=1).cpu().numpy()\n\n# Debug: Check actual logit values\nprint(f\"Yes logit: {yes_logits.item():.4f}\")\nprint(f\"No logit: {no_logits.item():.4f}\")\nprint(f\"Prediction: {predictions[0]} (0=No, 1=Yes)\")","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:21:08.009483Z","iopub.status.busy":"2025-09-18T20:21:08.009154Z","iopub.status.idle":"2025-09-18T20:21:08.043616Z","shell.execute_reply":"2025-09-18T20:21:08.042549Z","shell.execute_reply.started":"2025-09-18T20:21:08.009446Z"},"trusted":true},"outputs":[{"ename":"IndexError","evalue":"too many indices for tensor of dimension 1","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2686309554.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myes_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myes_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mno_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcombined_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mno_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myes_logits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"]}],"execution_count":98},{"id":"86adeb2f-1f90-4f5d-9a01-a45b8d257746","cell_type":"code","source":"# Test both positions\ninputs = tokenizer(\"Answer:\", return_tensors=\"pt\").to(\"cuda\")\nwith torch.no_grad():\n    outputs = model(**inputs)\n    \n# Check what tokens are at different positions\nfor pos in [-3, -2, -1]:\n    token_id = outputs.logits[0, pos].argmax().item()\n    token = tokenizer.decode([token_id])\n    print(f\"Position {pos}: Token '{token}' (ID: {token_id})\")","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:19:36.484051Z","iopub.status.busy":"2025-09-18T20:19:36.483268Z","iopub.status.idle":"2025-09-18T20:19:36.650858Z","shell.execute_reply":"2025-09-18T20:19:36.649818Z","shell.execute_reply.started":"2025-09-18T20:19:36.484007Z"},"trusted":true},"outputs":[{"ename":"IndexError","evalue":"index -3 is out of bounds for dimension 1 with size 2","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3629330751.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Check what tokens are at different positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtoken_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Position {pos}: Token '{token}' (ID: {token_id})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index -3 is out of bounds for dimension 1 with size 2"]}],"execution_count":97},{"id":"cef236ed-a716-4e5a-bb7e-77818e8ba070","cell_type":"code","source":"print(tokenizer.convert_tokens_to_ids(\"No\"))","metadata":{"execution":{"iopub.execute_input":"2025-09-18T18:35:26.144935Z","iopub.status.busy":"2025-09-18T18:35:26.144197Z","iopub.status.idle":"2025-09-18T18:35:26.149498Z","shell.execute_reply":"2025-09-18T18:35:26.148690Z","shell.execute_reply.started":"2025-09-18T18:35:26.144902Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2753\n"]}],"execution_count":43},{"id":"c9c5dee8-abd0-4fd9-a3af-83e8a38fc530","cell_type":"code","source":"negative_indices = val_df[val_df['rule_violation'] == 0].index.tolist()\n\nprint(f\"📊 Total training samples: {len(train_df)}\")\n\nprint(f\"📊 Negative answer samples: {len(negative_indices)}\")\nprint(f\"📊 Positive answer samples: {len(train_df) - len(negative_indices)}\")\nprint(f\"📊 Negative answer indices: {negative_indices}\")\n\n# Show first 10 negative samples for verification\nprint(\"\\n🔍 First 10 negative answer samples:\")\nnegative_samples = train_df[train_df['rule_violation'] == 0].head(10)\nfor idx, row in negative_samples.iterrows():\n    print(f\"Index {idx}: Rule='{row['rule']}', Violation={row['rule_violation']}\")","metadata":{"execution":{"iopub.execute_input":"2025-09-18T19:18:14.237352Z","iopub.status.busy":"2025-09-18T19:18:14.236792Z","iopub.status.idle":"2025-09-18T19:18:14.248177Z","shell.execute_reply":"2025-09-18T19:18:14.247541Z","shell.execute_reply.started":"2025-09-18T19:18:14.237328Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["📊 Total training samples: 7301\n","📊 Negative answer samples: 998\n","📊 Positive answer samples: 6303\n","📊 Negative answer indices: [0, 1, 5, 6, 7, 11, 13, 14, 16, 17, 19, 20, 21, 23, 24, 25, 26, 30, 34, 35, 40, 42, 43, 47, 51, 52, 57, 58, 60, 62, 65, 66, 73, 74, 75, 76, 81, 82, 85, 86, 87, 89, 91, 96, 97, 102, 103, 104, 105, 108, 110, 111, 113, 114, 115, 116, 119, 120, 121, 122, 126, 127, 128, 129, 130, 131, 132, 138, 139, 141, 144, 145, 147, 151, 154, 155, 158, 161, 162, 164, 167, 169, 170, 172, 175, 181, 182, 184, 185, 186, 188, 190, 192, 194, 195, 202, 205, 209, 210, 211, 213, 215, 218, 223, 224, 225, 226, 229, 230, 231, 232, 233, 234, 235, 237, 241, 242, 243, 244, 246, 247, 250, 251, 253, 256, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 280, 281, 282, 284, 287, 290, 291, 292, 294, 295, 296, 300, 301, 302, 303, 304, 305, 306, 312, 314, 315, 316, 317, 318, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 342, 347, 348, 349, 353, 356, 360, 361, 363, 364, 365, 366, 367, 370, 373, 376, 381, 382, 383, 386, 388, 390, 392, 394, 395, 399, 400, 402, 403, 404, 405, 406, 408, 410, 411, 415, 419, 420, 423, 428, 430, 433, 435, 436, 437, 438, 440, 442, 443, 445, 448, 449, 450, 451, 452, 454, 455, 456, 458, 459, 460, 464, 466, 467, 469, 472, 475, 476, 477, 479, 480, 481, 483, 489, 493, 495, 501, 503, 504, 506, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 523, 526, 527, 528, 538, 539, 540, 546, 549, 550, 551, 552, 553, 555, 556, 560, 561, 562, 565, 566, 568, 569, 571, 578, 580, 581, 583, 586, 587, 588, 591, 593, 595, 597, 598, 600, 601, 603, 609, 610, 611, 612, 613, 614, 616, 620, 621, 625, 626, 629, 632, 636, 638, 640, 644, 645, 647, 652, 656, 657, 660, 661, 662, 664, 665, 668, 671, 673, 677, 678, 679, 680, 687, 688, 689, 690, 692, 695, 696, 697, 700, 701, 702, 703, 707, 708, 709, 710, 711, 712, 717, 718, 719, 720, 724, 725, 726, 728, 730, 731, 733, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 756, 759, 760, 762, 766, 769, 770, 774, 775, 778, 779, 781, 783, 784, 786, 787, 788, 789, 797, 800, 801, 802, 803, 804, 808, 809, 811, 814, 819, 821, 822, 824, 830, 831, 832, 833, 834, 835, 839, 840, 843, 845, 847, 852, 853, 855, 856, 858, 859, 860, 861, 862, 864, 866, 869, 874, 875, 883, 884, 885, 886, 887, 889, 890, 891, 893, 894, 895, 896, 897, 898, 899, 900, 901, 906, 908, 911, 917, 919, 926, 932, 933, 935, 939, 941, 943, 944, 945, 946, 947, 948, 951, 952, 953, 955, 957, 960, 962, 963, 967, 968, 969, 970, 971, 973, 979, 980, 982, 984, 987, 989, 991, 997, 998, 999, 1000, 1001, 1003, 1006, 1011, 1012, 1014, 1015, 1017, 1018, 1019, 1020, 1023, 1025, 1026, 1027, 1028, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1043, 1046, 1047, 1049, 1056, 1059, 1061, 1062, 1063, 1068, 1069, 1070, 1074, 1075, 1076, 1077, 1079, 1082, 1085, 1087, 1088, 1090, 1092, 1093, 1098, 1099, 1101, 1102, 1104, 1106, 1112, 1114, 1115, 1116, 1118, 1119, 1121, 1122, 1123, 1126, 1127, 1129, 1130, 1132, 1133, 1134, 1136, 1139, 1140, 1143, 1144, 1145, 1148, 1152, 1153, 1156, 1158, 1159, 1160, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1174, 1176, 1177, 1178, 1180, 1181, 1182, 1183, 1185, 1188, 1191, 1194, 1195, 1196, 1197, 1199, 1202, 1205, 1207, 1208, 1209, 1218, 1219, 1220, 1225, 1226, 1227, 1229, 1230, 1232, 1233, 1235, 1236, 1238, 1239, 1241, 1243, 1244, 1245, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1263, 1264, 1265, 1271, 1274, 1276, 1278, 1284, 1287, 1288, 1289, 1290, 1291, 1293, 1295, 1296, 1299, 1304, 1306, 1307, 1309, 1310, 1318, 1321, 1324, 1326, 1327, 1330, 1341, 1343, 1347, 1350, 1351, 1353, 1355, 1357, 1358, 1360, 1361, 1364, 1366, 1367, 1372, 1374, 1377, 1379, 1380, 1384, 1386, 1389, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1406, 1407, 1408, 1409, 1410, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1435, 1436, 1437, 1438, 1439, 1440, 1444, 1445, 1446, 1451, 1452, 1457, 1460, 1461, 1462, 1463, 1467, 1469, 1471, 1476, 1477, 1479, 1481, 1488, 1493, 1494, 1496, 1498, 1500, 1506, 1507, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1520, 1521, 1523, 1527, 1528, 1530, 1532, 1533, 1534, 1535, 1540, 1541, 1543, 1544, 1545, 1547, 1549, 1553, 1556, 1557, 1558, 1562, 1563, 1564, 1566, 1569, 1572, 1574, 1575, 1577, 1581, 1582, 1583, 1584, 1586, 1588, 1590, 1591, 1592, 1593, 1594, 1597, 1601, 1602, 1603, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1626, 1627, 1628, 1629, 1630, 1631, 1633, 1636, 1640, 1646, 1648, 1649, 1650, 1652, 1659, 1663, 1666, 1669, 1671, 1672, 1676, 1677, 1680, 1681, 1683, 1685, 1686, 1687, 1688, 1690, 1691, 1694, 1696, 1697, 1699, 1703, 1705, 1709, 1711, 1715, 1716, 1717, 1720, 1721, 1725, 1727, 1732, 1736, 1737, 1739, 1741, 1744, 1745, 1749, 1750, 1755, 1756, 1762, 1763, 1764, 1767, 1768, 1769, 1770, 1771, 1774, 1775, 1776, 1777, 1778, 1780, 1783, 1789, 1792, 1796, 1797, 1799, 1800, 1801, 1803, 1804, 1805, 1807, 1808, 1812, 1815, 1822, 1830, 1832, 1835, 1836, 1837, 1840, 1844, 1848, 1849, 1850, 1852, 1859, 1861, 1865, 1866, 1870, 1872, 1874, 1875, 1876, 1878, 1880, 1882, 1884, 1885, 1886, 1888, 1889, 1893, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1903, 1904, 1905, 1907, 1908, 1911, 1914, 1916, 1917, 1920, 1923, 1928, 1929, 1930, 1931, 1933, 1936, 1937, 1940, 1941, 1944, 1947, 1948, 1949, 1950, 1952, 1953, 1956, 1958, 1961, 1962, 1963, 1966, 1967, 1969, 1972, 1975, 1979, 1980, 1982, 1984, 1986, 1987, 1989, 1990, 1991, 1992, 1995, 1996, 1997, 2003, 2004, 2006, 2009, 2011, 2013, 2014, 2016, 2020, 2025]\n","\n","🔍 First 10 negative answer samples:\n","Index 3651: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","Index 3652: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","Index 3653: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","Index 3654: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","Index 3655: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","Index 3656: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","Index 3657: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","Index 3658: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","Index 3659: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n","Index 3660: Rule='No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.', Violation=0\n"]}],"execution_count":20},{"id":"0709d0b6-2d1a-4aa1-9dbe-062d4dee669f","cell_type":"markdown","source":"# 💎 OUTPUT TESTINNG END\n\n## 🛡️ TESTING OUTPUT END\n ","metadata":{}},{"id":"0bd29a2b-2388-423e-8f66-3f23d333650a","cell_type":"code","source":"","metadata":{"execution":{"iopub.execute_input":"2025-09-18T16:02:46.291509Z","iopub.status.busy":"2025-09-18T16:02:46.291227Z","iopub.status.idle":"2025-09-18T16:02:46.309191Z","shell.execute_reply":"2025-09-18T16:02:46.308442Z","shell.execute_reply.started":"2025-09-18T16:02:46.291487Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["maximum token:  or\n"]}],"execution_count":32},{"id":"ca0e7540","cell_type":"code","source":"!python validation_vllm.py","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2025-09-15T14:50:55.247518Z","iopub.status.busy":"2025-09-15T14:50:55.247209Z","iopub.status.idle":"2025-09-15T15:04:37.958759Z","shell.execute_reply":"2025-09-15T15:04:37.957929Z","shell.execute_reply.started":"2025-09-15T14:50:55.247491Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Using Qwen3 1.7B model from local Kaggle input\n","🎯 TT-11: Unsloth training + vLLM inference with 100% of data\n","📊 Stratified sampling: True\n","🔬 TT-11: Unsloth Training + vLLM Validation\n","🚀 Ultra-fast training + High-precision inference!\n","📚 Training: Model learned from examples with Unsloth speed\n","🧪 Validation: Testing on real comments with vLLM precision\n","======================================================================\n","📊 Real comment validation dataset: 2029 samples\n","📊 Rule violations: 1031 positive, 998 negative\n","🔍 Running validation on 2029 real comments\n","2025-09-15 14:51:01.774892: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757947861.798717    5484 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757947861.806668    5484 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","INFO 09-15 14:51:05 [__init__.py:216] Automatically detected platform cuda.\n","INFO 09-15 14:51:06 [utils.py:328] non-default args: {'trust_remote_code': True, 'dtype': 'half', 'max_model_len': 700, 'block_size': 16, 'enable_prefix_caching': True, 'disable_log_stats': True, 'quantization': 'bitsandbytes', 'enforce_eager': True, 'enable_lora': True, 'max_lora_rank': 64, 'num_gpu_blocks_override': 512, 'model': '/kaggle/working/qwen3_1.7b_merged'}\n","The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n","INFO 09-15 14:51:19 [__init__.py:742] Resolved architecture: Qwen3ForCausalLM\n","`torch_dtype` is deprecated! Use `dtype` instead!\n","INFO 09-15 14:51:19 [__init__.py:1815] Using max model len 700\n","WARNING 09-15 14:51:20 [_ipex_ops.py:16] Import error msg: No module named 'intel_extension_for_pytorch'\n","WARNING 09-15 14:51:20 [__init__.py:1217] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n","INFO 09-15 14:51:21 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\n","WARNING 09-15 14:51:21 [lora.py:92] `lora_extra_vocab_size` is deprecated and will be removed in v0.12.0. Additional vocabulary support for LoRA adapters is being phased out.\n","INFO 09-15 14:51:21 [__init__.py:3400] Cudagraph is disabled under eager mode\n","WARNING 09-15 14:51:22 [__init__.py:2974] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n","✅ Using Qwen3 1.7B model from local Kaggle input\n","🎯 TT-11: Unsloth training + vLLM inference with 100% of data\n","📊 Stratified sampling: True\n","2025-09-15 14:51:28.364820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757947888.387471    5517 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757947888.395085    5517 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","INFO 09-15 14:51:31 [__init__.py:216] Automatically detected platform cuda.\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:33 [core.py:654] Waiting for init message from front-end.\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:33 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='/kaggle/working/qwen3_1.7b_merged', speculative_config=None, tokenizer='/kaggle/working/qwen3_1.7b_merged', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=700, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/kaggle/working/qwen3_1.7b_merged, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":0,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":0,\"local_cache_dir\":null}\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m ERROR 09-15 14:51:34 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n","[W915 14:51:45.978655070 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n","[W915 14:51:55.986336186 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n","[W915 14:51:55.986940558 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n","[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n","[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n","[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n","[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n","[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n","[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:55 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m WARNING 09-15 14:51:55 [logger.py:72] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:55 [gpu_model_runner.py:2338] Starting to load model /kaggle/working/qwen3_1.7b_merged...\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:55 [gpu_model_runner.py:2370] Loading model from scratch...\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:56 [logger.py:66] Using FlexAttention backend on V1 engine.\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:56 [bitsandbytes_loader.py:758] Loading weights with BitsAndBytes quantization. May take a while ...\n","Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n","Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 27.90it/s]\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m \n","Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n","Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.72it/s]\n","Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.72it/s]\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m \n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:56 [logger.py:66] Using PunicaWrapperGPU.\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:51:57 [gpu_model_runner.py:2392] Model loading took 1.5094 GiB and 1.134056 seconds\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:12 [gpu_worker.py:298] Available KV cache memory: 10.33 GiB\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:13 [kv_cache_utils.py:802] Overriding num_gpu_blocks=6041 with num_gpu_blocks_override=512\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:13 [kv_cache_utils.py:864] GPU KV cache size: 8,192 tokens\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:13 [kv_cache_utils.py:868] Maximum concurrency for 700 tokens per request: 11.64x\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:13 [gpu_worker.py:391] Free memory on device (14.63/14.74 GiB) on startup. Desired GPU memory utilization is (0.9, 13.27 GiB). Actual usage is 1.51 GiB for weight, 1.42 GiB for peak activation, 0.01 GiB for non-torch memory, and 0.0 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=10929593446` to fit into requested memory, or `--kv-cache-memory=12387710464` to fully utilize gpu memory. Current kv cache memory in use is 11086879846 bytes.\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:13 [core.py:218] init engine (profile, create kv cache, warmup model) took 16.06 seconds\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:14 [__init__.py:3400] Cudagraph is disabled under eager mode\n","INFO 09-15 14:52:14 [llm.py:295] Supported_tasks: ['generate']\n","INFO 09-15 14:52:14 [__init__.py:36] No IOProcessor plugins requested by the model\n","Adding requests: 100%|█████████████████████| 2029/2029 [00:02<00:00, 761.46it/s]\n","Processed prompts:   0%| | 0/2029 [00:00<?, ?it/s, est. speed input: 0.00 toks/s\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m INFO 09-15 14:52:17 [logger.py:66] Loading LoRA weights trained with rsLoRA.\n","\u001b[1;36m(EngineCore_DP0 pid=5517)\u001b[0;0m WARNING 09-15 14:52:17 [logger.py:72] cudagraph dispatching keys are not initialized. No cudagraph will be used.\n","Processed prompts: 100%|█| 2029/2029 [12:15<00:00,  2.76it/s, est. speed input: \n","[rank0]:[W915 15:04:32.446615288 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n","============================================================\n","📊 TT-11 VALIDATION RESULTS (Unsloth + vLLM)\n","============================================================\n","🎯 Accuracy:  0.7294\n","🎯 F1 Score:  0.7409\n","🎯 Precision: 0.7215\n","🎯 Recall:    0.7614\n","🎯 AUC Score: 0.7980 (High-precision vLLM)\n","============================================================\n","\n","📈 Confusion Matrix:\n","True Negative:  695 | False Positive:  303\n","False Negative:  246 | True Positive:   785\n","\n","📋 Classification Report:\n","              precision    recall  f1-score   support\n","\n","No Violation       0.74      0.70      0.72       998\n","   Violation       0.72      0.76      0.74      1031\n","\n","    accuracy                           0.73      2029\n","   macro avg       0.73      0.73      0.73      2029\n","weighted avg       0.73      0.73      0.73      2029\n","\n","Figure(1500x1200)\n","\n","📊 PERFORMANCE BY RULE (vLLM High-Precision AUC):\n","============================================================\n","Rule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\n","  Samples: 1012\n","  Accuracy: 0.791\n","  F1 Score: 0.756\n","  AUC Score: 0.855\n","\n","Rule: No legal advice: Do not offer or request legal advice.\n","  Samples: 1017\n","  Accuracy: 0.669\n","  F1 Score: 0.730\n","  AUC Score: 0.721\n","\n","✅ TT-11 Validation completed!\n","📈 Visualizations saved: /kaggle/working/tt11_validation_results.png\n","📊 Detailed results: /kaggle/working/tt11_detailed_results.csv\n","📋 Rule metrics: /kaggle/working/tt11_rule_metrics.csv\n","🎯 Best of both worlds: Unsloth speed + vLLM precision!\n"]}],"execution_count":117},{"id":"6b5889e2-653d-497b-9688-fe6bc5c1eccc","cell_type":"code","source":"!pip install --upgrade triton vllm","metadata":{"execution":{"iopub.execute_input":"2025-09-15T13:12:06.349823Z","iopub.status.busy":"2025-09-15T13:12:06.349561Z","iopub.status.idle":"2025-09-15T13:12:20.061449Z","shell.execute_reply":"2025-09-15T13:12:20.060863Z","shell.execute_reply.started":"2025-09-15T13:12:06.349802Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n"]},{"data":{"text/plain":["[]"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"execution_count":76},{"id":"85636388-37ad-48d7-a907-30ddb1963b07","cell_type":"markdown","source":"","metadata":{}},{"id":"4f8bc142","cell_type":"markdown","source":"# 💎 Alternative Validation: Standard Transformers\n\n## 🛡️ **Universal Compatibility Option**\n\nIf vLLM has hardware compatibility issues, use this **guaranteed-to-work** validation method:\n\n### **Advantages:**\n- ✅ **Universal Compatibility**: Works with any GPU and any Unsloth model\n- ✅ **No Hardware Limits**: No shared memory or tensor parallelism restrictions  \n- ✅ **Reliable**: Standard transformers library, battle-tested\n- ✅ **Same Metrics**: Produces identical analysis and visualizations\n\n### **Trade-offs:**\n- ⏱️ **Slower than vLLM**: But still faster than training\n- 📊 **Slightly less precise probabilities**: But still excellent for AUC calculation\n\n**This method loads your Unsloth-trained LoRA adapters using standard transformers and runs inference without any specialized hardware requirements.**","metadata":{}},{"id":"6b832273-20b2-4699-829c-a6920dd9ad40","cell_type":"code","source":"DEBUG","metadata":{"execution":{"iopub.execute_input":"2025-09-15T12:45:25.947793Z","iopub.status.busy":"2025-09-15T12:45:25.947017Z","iopub.status.idle":"2025-09-15T12:45:26.014839Z","shell.execute_reply":"2025-09-15T12:45:26.014032Z","shell.execute_reply.started":"2025-09-15T12:45:25.947763Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'DEBUG' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/4204071508.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDEBUG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'DEBUG' is not defined"]}],"execution_count":58},{"id":"17b96e95","cell_type":"code","source":"%time\n!python validation_transformers.py","metadata":{"execution":{"iopub.execute_input":"2025-09-18T20:49:45.210995Z","iopub.status.busy":"2025-09-18T20:49:45.210734Z","iopub.status.idle":"2025-09-18T20:53:21.410901Z","shell.execute_reply":"2025-09-18T20:53:21.410090Z","shell.execute_reply.started":"2025-09-18T20:49:45.210969Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n","Wall time: 8.34 µs\n"]},{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","2025-09-18 20:49:51.500200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1758228591.522996    1666 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1758228591.530110    1666 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","INFO 09-18 20:49:58 [__init__.py:235] Automatically detected platform cuda.\n","ERROR 09-18 20:50:00 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","✅ Using Qwen3 1.7B model from local Kaggle input\n","🎯 TT-12: Unsloth training + vLLM inference with 50% of data\n","📊 Stratified sampling: True\n","🔧 DEBUG MODE: Will train only on negative examples to test 'No' prediction capability\n","🔬 TT-11: Unsloth Training + Transformers Validation\n","🚀 Ultra-fast training + Universal compatibility!\n","📚 Training: Model learned from examples with Unsloth speed\n","🧪 Validation: Testing on real comments with standard Transformers\n","======================================================================\n","📊 Real comment validation dataset: 2029 samples\n","📊 Rule violations: 1031 positive, 998 negative\n","🔍 Running validation on 2029 real comments (Unsloth Fast Inference)\n","==((====))==  Unsloth 2025.9.6: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n","   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","🎯 Token IDs: Yes=7414, No=2308\n","🚀 Running fast inference with Unsloth...\n","100%|█████████████████████████████████████████| 127/127 [03:06<00:00,  1.47s/it]\n","✅ Fast inference completed!\n","============================================================\n","📊 TT-11 VALIDATION RESULTS (Unsloth + Transformers)\n","============================================================\n","🎯 Accuracy:  0.5224\n","🎯 F1 Score:  0.6630\n","🎯 Precision: 0.5168\n","🎯 Recall:    0.9243\n","🎯 AUC Score: 0.5308 (Standard Transformers)\n","============================================================\n","\n","📈 Confusion Matrix:\n","True Negative:  107 | False Positive:  891\n","False Negative:   78 | True Positive:   953\n","\n","📋 Classification Report:\n","              precision    recall  f1-score   support\n","\n","No Violation       0.58      0.11      0.18       998\n","   Violation       0.52      0.92      0.66      1031\n","\n","    accuracy                           0.52      2029\n","   macro avg       0.55      0.52      0.42      2029\n","weighted avg       0.55      0.52      0.43      2029\n","\n","Figure(1500x1200)\n","\n","📊 PERFORMANCE BY RULE (Transformers):\n","============================================================\n","Rule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\n","  Samples: 1012\n","  Accuracy: 0.450\n","  F1 Score: 0.602\n","  AUC Score: 0.505\n","\n","Rule: No legal advice: Do not offer or request legal advice.\n","  Samples: 1017\n","  Accuracy: 0.595\n","  F1 Score: 0.721\n","  AUC Score: 0.570\n","\n","✅ TT-11 Transformers Validation completed!\n","📈 Visualizations saved: /kaggle/working/tt11_transformers_validation_results.png\n","📊 Detailed results: /kaggle/working/tt11_transformers_detailed_results.csv\n","📋 Rule metrics: /kaggle/working/tt11_transformers_rule_metrics.csv\n","🎯 Reliable and compatible validation with Unsloth speed!\n"]}],"execution_count":125},{"id":"ef5b5013","cell_type":"code","source":"# Display saved results from TT-11 Transformers Validation\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# Load detailed results from Transformers validation\ntry:\n    detailed_results = pd.read_csv('/kaggle/working/tt11_transformers_detailed_results.csv')\n    print(\"📊 TT-11 Transformers Results Shape:\", detailed_results.shape)\n    print(\"\\n📋 Sample Results:\")\n    print(detailed_results[['rule', 'rule_violation', 'predictions', 'probabilities']].head(10))\n    \n    # Load rule metrics\n    rule_metrics = pd.read_csv('/kaggle/working/tt11_transformers_rule_metrics.csv')\n    print(\"\\n📈 TT-11 Transformers Rule-wise Performance:\")\n    print(rule_metrics)\n    \n    # Performance summary\n    print(\"\\n🎯 TT-11 TRANSFORMERS PERFORMANCE SUMMARY:\")\n    print(\"=\" * 50)\n    overall_accuracy = accuracy_score(detailed_results['rule_violation'], detailed_results['predictions'])\n    avg_probability = detailed_results['probabilities'].mean()\n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Average Confidence: {avg_probability:.4f}\")\n    print(f\"Total Samples: {len(detailed_results)}\")\n    \n    # Compare with vLLM results if available\n    try:\n        vllm_results = pd.read_csv('/kaggle/working/tt11_detailed_results.csv')\n        vllm_accuracy = accuracy_score(vllm_results['rule_violation'], vllm_results['predictions'])\n        vllm_confidence = vllm_results['probabilities'].mean()\n        \n        print(\"\\n🔄 COMPARISON: Transformers vs vLLM:\")\n        print(\"=\" * 50)\n        print(f\"Transformers Accuracy: {overall_accuracy:.4f}\")\n        print(f\"vLLM Accuracy:         {vllm_accuracy:.4f}\")\n        print(f\"Difference:            {abs(overall_accuracy - vllm_accuracy):.4f}\")\n        print(f\"\")\n        print(f\"Transformers Confidence: {avg_probability:.4f}\")\n        print(f\"vLLM Confidence:         {vllm_confidence:.4f}\")\n        print(f\"Difference:              {abs(avg_probability - vllm_confidence):.4f}\")\n        \n    except FileNotFoundError:\n        print(\"\\n💡 Note: Run vLLM validation first to compare results\")\n    \nexcept FileNotFoundError as e:\n    print(f\"❌ Transformers results files not found: {e}\")\n    print(\"Run the Transformers validation cell first to generate results.\")","metadata":{"execution":{"iopub.execute_input":"2025-09-15T05:05:32.906290Z","iopub.status.busy":"2025-09-15T05:05:32.905596Z","iopub.status.idle":"2025-09-15T05:05:33.734588Z","shell.execute_reply":"2025-09-15T05:05:33.733950Z","shell.execute_reply.started":"2025-09-15T05:05:32.906260Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["📊 TT-11 Transformers Results Shape: (2029, 9)\n","\n","📋 Sample Results:\n","                                                rule  rule_violation  \\\n","0  No Advertising: Spam, referral links, unsolici...               0   \n","1  No Advertising: Spam, referral links, unsolici...               0   \n","2  No legal advice: Do not offer or request legal...               1   \n","3  No Advertising: Spam, referral links, unsolici...               1   \n","4  No Advertising: Spam, referral links, unsolici...               1   \n","5  No legal advice: Do not offer or request legal...               0   \n","6  No Advertising: Spam, referral links, unsolici...               0   \n","7  No Advertising: Spam, referral links, unsolici...               0   \n","8  No legal advice: Do not offer or request legal...               1   \n","9  No legal advice: Do not offer or request legal...               1   \n","\n","   predictions  probabilities  \n","0            1       0.997070  \n","1            1       0.965820  \n","2            1       0.979004  \n","3            1       0.988770  \n","4            1       0.998535  \n","5            1       0.997070  \n","6            1       0.988770  \n","7            1       0.994141  \n","8            0       0.458984  \n","9            1       0.991699  \n","\n","📈 TT-11 Transformers Rule-wise Performance:\n","                                                rule  samples  accuracy  \\\n","0  No Advertising: Spam, referral links, unsolici...     1012  0.434783   \n","1  No legal advice: Do not offer or request legal...     1017  0.586037   \n","\n","         f1       auc  \n","0  0.604972  0.570687  \n","1  0.737039  0.562510  \n","\n","🎯 TT-11 TRANSFORMERS PERFORMANCE SUMMARY:\n","==================================================\n","Overall Accuracy: 0.5106\n","Average Confidence: 0.9633\n","Total Samples: 2029\n","\n","💡 Note: Run vLLM validation first to compare results\n"]}],"execution_count":14},{"id":"b1a79e24-3014-49fe-8038-8936dcf13234","cell_type":"code","source":"\n!accelerate launch --config_file accelerate_config.yaml weight_train_unsloth.py\n    \n","metadata":{"execution":{"iopub.status.busy":"2025-09-18T21:28:22.188842Z","iopub.execute_input":"2025-09-18T21:28:22.189431Z","iopub.status.idle":"2025-09-18T21:51:43.801546Z","shell.execute_reply.started":"2025-09-18T21:28:22.189403Z","shell.execute_reply":"2025-09-18T21:51:43.800455Z"},"trusted":true},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-18 21:28:33.303635: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758230913.326328    2525 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758230913.333418    2525 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-18 21:28:40 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-18 21:28:42 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n🦥 Unsloth Zoo will now patch everything to make training faster!\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 50% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n📊 Stratified sampling: 1014 samples (50%)\n📊 Training data size: 1014 samples\n📊 Rule distribution: {'No legal advice: Do not offer or request legal advice.': 508, 'No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.': 506}\n📊 Example-based training dataset: 4056 samples\n📊 Positive examples: 2028\n📊 Negative examples: 2028\nTraining dataset size: 4056 samples\nAvailable GPUs: 2\nUnsloth: WARNING `trust_remote_code` is True.\nAre you certain you want to do remote code execution?\n==((====))==  Unsloth 2025.9.6: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n✅ Unsloth model loaded with 4-bit quantization across 2x T4\nUnsloth 2025.9.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n✅ Unsloth LoRA adapters added\n✅ Unsloth training arguments configured for 2x T4\n📊 Class Weights Mapping:\n   Index 0 ('No'/negative): 0.8\n   Index 1 ('Yes'/positive): 0.2\n📊 False Positive Penalty: 4.0x\n📊 Token IDs: No=2308, Yes=7414\nUnsloth: Tokenizing [\"text\"] (num_proc=8): 100%|█| 4056/4056 [00:04<00:00, 881.0\n[2025-09-18 21:29:03,897] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-18 21:29:04,352] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n🚀 Starting Unsloth training with weighted loss on 2x T4...\n🎯 Heavily penalizing false positives (predicting 'Yes' when should be 'No')\nUnsloth: Enabled auto compiling\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n   \\\\   /|    Num examples = 4,056 | Num Epochs = 1 | Total steps = 254\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n \"-____-\"     Trainable parameters = 17,432,576 of 1,738,007,552 (1.00% trained)\n  0%|                                                   | 0/254 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!\n{'loss': 22.5622, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 0.0}         \n{'loss': 22.0678, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}        \n{'loss': 24.1474, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}        \n{'loss': 23.6672, 'grad_norm': 199.3153533935547, 'learning_rate': 0.0, 'epoch': 0.02}\n{'loss': 21.7059, 'grad_norm': 194.91807556152344, 'learning_rate': 2e-05, 'epoch': 0.02}\n{'loss': 20.8804, 'grad_norm': 145.03021240234375, 'learning_rate': 4e-05, 'epoch': 0.02}\n{'loss': 14.5855, 'grad_norm': 78.20804595947266, 'learning_rate': 6e-05, 'epoch': 0.03}\n  3%|█▏                                         | 7/254 [00:38<21:45,  5.29s/it]❌ ERROR: Could not find logits in model outputs\n   Outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithPast'>\n   Outputs attributes: ['__annotations__', '__class__', '__class_getitem__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__or__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'attentions', 'clear', 'copy', 'fromkeys', 'get', 'hidden_states', 'items', 'keys', 'logits', 'loss', 'move_to_end', 'past_key_values', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']\n{'loss': 14.8524, 'grad_norm': 26.873125076293945, 'learning_rate': 8e-05, 'epoch': 0.03}\n{'loss': 10.9676, 'grad_norm': 17.953510284423828, 'learning_rate': 0.0001, 'epoch': 0.04}\n{'loss': 10.0029, 'grad_norm': 10.251152038574219, 'learning_rate': 9.95983935742972e-05, 'epoch': 0.04}\n{'loss': 10.7638, 'grad_norm': 10.770607948303223, 'learning_rate': 9.919678714859438e-05, 'epoch': 0.04}\n{'loss': 9.108, 'grad_norm': 7.495576858520508, 'learning_rate': 9.879518072289157e-05, 'epoch': 0.05}\n{'loss': 9.1053, 'grad_norm': 7.925576210021973, 'learning_rate': 9.839357429718876e-05, 'epoch': 0.05}\n{'loss': 8.7107, 'grad_norm': 4.499527931213379, 'learning_rate': 9.799196787148595e-05, 'epoch': 0.06}\n{'loss': 8.5625, 'grad_norm': 5.888845920562744, 'learning_rate': 9.759036144578314e-05, 'epoch': 0.06}\n{'loss': 8.759, 'grad_norm': 9.44062328338623, 'learning_rate': 9.718875502008033e-05, 'epoch': 0.06}\n{'loss': 8.4932, 'grad_norm': 5.042121410369873, 'learning_rate': 9.678714859437752e-05, 'epoch': 0.07}\n{'loss': 8.1516, 'grad_norm': 3.5141470432281494, 'learning_rate': 9.638554216867471e-05, 'epoch': 0.07}\n{'loss': 8.0897, 'grad_norm': 3.650179147720337, 'learning_rate': 9.598393574297188e-05, 'epoch': 0.07}\n{'loss': 7.6155, 'grad_norm': 3.7107372283935547, 'learning_rate': 9.558232931726909e-05, 'epoch': 0.08}\n{'loss': 7.4484, 'grad_norm': 3.1843438148498535, 'learning_rate': 9.518072289156626e-05, 'epoch': 0.08}\n{'loss': 7.2193, 'grad_norm': 3.1281509399414062, 'learning_rate': 9.477911646586346e-05, 'epoch': 0.09}\n{'loss': 7.0653, 'grad_norm': 3.0141351222991943, 'learning_rate': 9.437751004016064e-05, 'epoch': 0.09}\n{'loss': 6.8549, 'grad_norm': 4.1949334144592285, 'learning_rate': 9.397590361445784e-05, 'epoch': 0.09}\n{'loss': 6.6605, 'grad_norm': 3.0186097621917725, 'learning_rate': 9.357429718875502e-05, 'epoch': 0.1}\n{'loss': 6.2687, 'grad_norm': 3.4108762741088867, 'learning_rate': 9.317269076305222e-05, 'epoch': 0.1}\n 10%|████▎                                     | 26/254 [02:20<20:39,  5.44s/it]❌ ERROR: Could not find logits in model outputs\n   Outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithPast'>\n   Outputs attributes: ['__annotations__', '__class__', '__class_getitem__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__or__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'attentions', 'clear', 'copy', 'fromkeys', 'get', 'hidden_states', 'items', 'keys', 'logits', 'loss', 'move_to_end', 'past_key_values', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']\n{'loss': 7.5916, 'grad_norm': 3.5300097465515137, 'learning_rate': 9.27710843373494e-05, 'epoch': 0.11}\n{'loss': 6.5949, 'grad_norm': 4.580749034881592, 'learning_rate': 9.23694779116466e-05, 'epoch': 0.11}\n{'loss': 5.8056, 'grad_norm': 3.3286054134368896, 'learning_rate': 9.196787148594378e-05, 'epoch': 0.11}\n{'loss': 5.7146, 'grad_norm': 3.4777095317840576, 'learning_rate': 9.156626506024096e-05, 'epoch': 0.12}\n{'loss': 5.5829, 'grad_norm': 5.738706111907959, 'learning_rate': 9.116465863453815e-05, 'epoch': 0.12}\n{'loss': 5.3679, 'grad_norm': 4.225428104400635, 'learning_rate': 9.076305220883534e-05, 'epoch': 0.13}\n{'loss': 5.0837, 'grad_norm': 4.939783573150635, 'learning_rate': 9.036144578313253e-05, 'epoch': 0.13}\n{'loss': 5.0698, 'grad_norm': 4.090095043182373, 'learning_rate': 8.995983935742972e-05, 'epoch': 0.13}\n{'loss': 5.291, 'grad_norm': 6.290660381317139, 'learning_rate': 8.955823293172691e-05, 'epoch': 0.14}\n{'loss': 4.7556, 'grad_norm': 4.431188106536865, 'learning_rate': 8.91566265060241e-05, 'epoch': 0.14}\n{'loss': 4.7741, 'grad_norm': 3.1289501190185547, 'learning_rate': 8.875502008032129e-05, 'epoch': 0.15}\n{'loss': 4.7476, 'grad_norm': 6.35581636428833, 'learning_rate': 8.835341365461848e-05, 'epoch': 0.15}\n{'loss': 4.7388, 'grad_norm': 4.250038146972656, 'learning_rate': 8.795180722891567e-05, 'epoch': 0.15}\n{'loss': 4.6914, 'grad_norm': 4.362948894500732, 'learning_rate': 8.755020080321286e-05, 'epoch': 0.16}\n{'loss': 4.4761, 'grad_norm': 3.302304983139038, 'learning_rate': 8.714859437751005e-05, 'epoch': 0.16}\n{'loss': 5.0739, 'grad_norm': 4.005172252655029, 'learning_rate': 8.674698795180724e-05, 'epoch': 0.17}\n{'loss': 4.6187, 'grad_norm': 3.036689519882202, 'learning_rate': 8.634538152610442e-05, 'epoch': 0.17}\n{'loss': 4.8562, 'grad_norm': 4.207761287689209, 'learning_rate': 8.594377510040161e-05, 'epoch': 0.17}\n{'loss': 4.6078, 'grad_norm': 4.919865608215332, 'learning_rate': 8.55421686746988e-05, 'epoch': 0.18}\n{'loss': 4.1486, 'grad_norm': 2.5034775733947754, 'learning_rate': 8.514056224899599e-05, 'epoch': 0.18}\n{'loss': 4.4123, 'grad_norm': 2.7359583377838135, 'learning_rate': 8.473895582329318e-05, 'epoch': 0.19}\n{'loss': 4.4941, 'grad_norm': 2.4359796047210693, 'learning_rate': 8.433734939759037e-05, 'epoch': 0.19}\n{'loss': 4.7206, 'grad_norm': 5.054510116577148, 'learning_rate': 8.393574297188756e-05, 'epoch': 0.19}\n{'loss': 4.2133, 'grad_norm': 3.1312317848205566, 'learning_rate': 8.353413654618474e-05, 'epoch': 0.2}\n{'loss': 4.4314, 'grad_norm': 2.9531211853027344, 'learning_rate': 8.313253012048194e-05, 'epoch': 0.2}\n{'loss': 4.6078, 'grad_norm': 3.2981016635894775, 'learning_rate': 8.273092369477911e-05, 'epoch': 0.21}\n{'loss': 4.5627, 'grad_norm': 5.894777774810791, 'learning_rate': 8.232931726907632e-05, 'epoch': 0.21}\n{'loss': 4.0187, 'grad_norm': 3.3854219913482666, 'learning_rate': 8.192771084337349e-05, 'epoch': 0.21}\n{'loss': 4.2503, 'grad_norm': 2.5280802249908447, 'learning_rate': 8.15261044176707e-05, 'epoch': 0.22}\n{'loss': 3.9437, 'grad_norm': 1.9548381567001343, 'learning_rate': 8.112449799196787e-05, 'epoch': 0.22}\n{'loss': 4.2645, 'grad_norm': 2.919415235519409, 'learning_rate': 8.072289156626507e-05, 'epoch': 0.22}\n{'loss': 4.7497, 'grad_norm': 7.081940174102783, 'learning_rate': 8.032128514056225e-05, 'epoch': 0.23}\n{'loss': 4.6077, 'grad_norm': 7.712799072265625, 'learning_rate': 7.991967871485944e-05, 'epoch': 0.23}\n{'loss': 3.9765, 'grad_norm': 1.6295632123947144, 'learning_rate': 7.951807228915663e-05, 'epoch': 0.24}\n{'loss': 4.2863, 'grad_norm': 2.1869099140167236, 'learning_rate': 7.911646586345382e-05, 'epoch': 0.24}\n{'loss': 4.0187, 'grad_norm': 2.901627779006958, 'learning_rate': 7.8714859437751e-05, 'epoch': 0.24}\n{'loss': 4.2317, 'grad_norm': 2.3253016471862793, 'learning_rate': 7.83132530120482e-05, 'epoch': 0.25}\n{'loss': 4.3635, 'grad_norm': 3.1777994632720947, 'learning_rate': 7.791164658634539e-05, 'epoch': 0.25}\n{'loss': 4.3534, 'grad_norm': 2.238694906234741, 'learning_rate': 7.751004016064257e-05, 'epoch': 0.26}\n{'loss': 4.1317, 'grad_norm': 2.229375123977661, 'learning_rate': 7.710843373493976e-05, 'epoch': 0.26}\n{'loss': 4.7437, 'grad_norm': 6.962571144104004, 'learning_rate': 7.670682730923695e-05, 'epoch': 0.26}\n{'loss': 4.7663, 'grad_norm': 9.47457218170166, 'learning_rate': 7.630522088353414e-05, 'epoch': 0.27}\n{'loss': 4.2543, 'grad_norm': 5.301083564758301, 'learning_rate': 7.590361445783133e-05, 'epoch': 0.27}\n{'loss': 4.2619, 'grad_norm': 2.582641363143921, 'learning_rate': 7.550200803212851e-05, 'epoch': 0.28}\n{'loss': 3.9862, 'grad_norm': 2.9293484687805176, 'learning_rate': 7.510040160642571e-05, 'epoch': 0.28}\n{'loss': 4.3981, 'grad_norm': 2.148381471633911, 'learning_rate': 7.469879518072289e-05, 'epoch': 0.28}\n{'loss': 4.3575, 'grad_norm': 2.0917956829071045, 'learning_rate': 7.429718875502009e-05, 'epoch': 0.29}\n{'loss': 4.4545, 'grad_norm': 1.8917502164840698, 'learning_rate': 7.389558232931726e-05, 'epoch': 0.29}\n{'loss': 4.1378, 'grad_norm': 1.9112430810928345, 'learning_rate': 7.349397590361447e-05, 'epoch': 0.3}\n{'loss': 4.0175, 'grad_norm': 2.9991180896759033, 'learning_rate': 7.309236947791164e-05, 'epoch': 0.3}\n{'loss': 4.197, 'grad_norm': 1.4699350595474243, 'learning_rate': 7.269076305220885e-05, 'epoch': 0.3}\n{'loss': 4.1241, 'grad_norm': 1.778432846069336, 'learning_rate': 7.228915662650602e-05, 'epoch': 0.31}\n{'loss': 4.2876, 'grad_norm': 3.2356600761413574, 'learning_rate': 7.188755020080321e-05, 'epoch': 0.31}\n{'loss': 4.2247, 'grad_norm': 1.4534872770309448, 'learning_rate': 7.14859437751004e-05, 'epoch': 0.32}\n{'loss': 4.0243, 'grad_norm': 1.7233473062515259, 'learning_rate': 7.108433734939759e-05, 'epoch': 0.32}\n{'loss': 4.2649, 'grad_norm': 1.9932243824005127, 'learning_rate': 7.068273092369478e-05, 'epoch': 0.32}\n{'loss': 3.7966, 'grad_norm': 2.4206695556640625, 'learning_rate': 7.028112449799197e-05, 'epoch': 0.33}\n{'loss': 4.1803, 'grad_norm': 2.2070698738098145, 'learning_rate': 6.987951807228917e-05, 'epoch': 0.33}\n{'loss': 4.0963, 'grad_norm': 2.015537738800049, 'learning_rate': 6.947791164658635e-05, 'epoch': 0.34}\n{'loss': 4.1658, 'grad_norm': 3.2609975337982178, 'learning_rate': 6.907630522088355e-05, 'epoch': 0.34}\n{'loss': 4.1755, 'grad_norm': 1.557289481163025, 'learning_rate': 6.867469879518072e-05, 'epoch': 0.34}\n 34%|██████████████▍                           | 87/254 [07:48<14:38,  5.26s/it]❌ ERROR: Could not find logits in model outputs\n   Outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithPast'>\n   Outputs attributes: ['__annotations__', '__class__', '__class_getitem__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__or__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'attentions', 'clear', 'copy', 'fromkeys', 'get', 'hidden_states', 'items', 'keys', 'logits', 'loss', 'move_to_end', 'past_key_values', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']\n{'loss': 5.2554, 'grad_norm': 5.725850582122803, 'learning_rate': 6.827309236947793e-05, 'epoch': 0.35}\n{'loss': 4.4612, 'grad_norm': 3.4696521759033203, 'learning_rate': 6.78714859437751e-05, 'epoch': 0.35}\n{'loss': 4.218, 'grad_norm': 1.4098854064941406, 'learning_rate': 6.746987951807229e-05, 'epoch': 0.36}\n{'loss': 4.3197, 'grad_norm': 3.204791784286499, 'learning_rate': 6.706827309236948e-05, 'epoch': 0.36}\n{'loss': 4.0558, 'grad_norm': 2.6238045692443848, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.36}\n{'loss': 3.8244, 'grad_norm': 4.625447750091553, 'learning_rate': 6.626506024096386e-05, 'epoch': 0.37}\n{'loss': 3.9137, 'grad_norm': 2.1881885528564453, 'learning_rate': 6.586345381526105e-05, 'epoch': 0.37}\n{'loss': 3.9806, 'grad_norm': 3.8620481491088867, 'learning_rate': 6.546184738955824e-05, 'epoch': 0.37}\n{'loss': 4.3375, 'grad_norm': 7.409235000610352, 'learning_rate': 6.506024096385543e-05, 'epoch': 0.38}\n{'loss': 3.7267, 'grad_norm': 4.822749137878418, 'learning_rate': 6.465863453815262e-05, 'epoch': 0.38}\n{'loss': 3.7028, 'grad_norm': 2.5419867038726807, 'learning_rate': 6.42570281124498e-05, 'epoch': 0.39}\n{'loss': 3.8155, 'grad_norm': 2.2521040439605713, 'learning_rate': 6.385542168674698e-05, 'epoch': 0.39}\n{'loss': 4.1615, 'grad_norm': 3.932819366455078, 'learning_rate': 6.345381526104418e-05, 'epoch': 0.39}\n{'loss': 4.0784, 'grad_norm': 1.875806450843811, 'learning_rate': 6.305220883534136e-05, 'epoch': 0.4}\n{'loss': 4.1068, 'grad_norm': 2.67822265625, 'learning_rate': 6.265060240963856e-05, 'epoch': 0.4}\n{'loss': 4.0676, 'grad_norm': 2.6070303916931152, 'learning_rate': 6.224899598393574e-05, 'epoch': 0.41}\n{'loss': 3.8844, 'grad_norm': 3.82487154006958, 'learning_rate': 6.184738955823294e-05, 'epoch': 0.41}\n{'loss': 3.7501, 'grad_norm': 1.4980868101119995, 'learning_rate': 6.144578313253012e-05, 'epoch': 0.41}\n{'loss': 3.8559, 'grad_norm': 2.4998481273651123, 'learning_rate': 6.104417670682732e-05, 'epoch': 0.42}\n{'loss': 4.0093, 'grad_norm': 2.6484994888305664, 'learning_rate': 6.06425702811245e-05, 'epoch': 0.42}\n{'loss': 4.0574, 'grad_norm': 1.7544668912887573, 'learning_rate': 6.02409638554217e-05, 'epoch': 0.43}\n 43%|█████████████████▍                       | 108/254 [09:40<13:08,  5.40s/it]❌ ERROR: Could not find logits in model outputs\n   Outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithPast'>\n   Outputs attributes: ['__annotations__', '__class__', '__class_getitem__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__or__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'attentions', 'clear', 'copy', 'fromkeys', 'get', 'hidden_states', 'items', 'keys', 'logits', 'loss', 'move_to_end', 'past_key_values', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']\n{'loss': 5.5964, 'grad_norm': 2.558375120162964, 'learning_rate': 5.983935742971888e-05, 'epoch': 0.43}\n{'loss': 3.985, 'grad_norm': 4.98406982421875, 'learning_rate': 5.943775100401606e-05, 'epoch': 0.43}\n{'loss': 3.7898, 'grad_norm': 3.898005723953247, 'learning_rate': 5.903614457831326e-05, 'epoch': 0.44}\n{'loss': 3.6617, 'grad_norm': 2.5712618827819824, 'learning_rate': 5.863453815261044e-05, 'epoch': 0.44}\n{'loss': 3.8715, 'grad_norm': 1.840831995010376, 'learning_rate': 5.823293172690764e-05, 'epoch': 0.45}\n{'loss': 3.8499, 'grad_norm': 2.020963430404663, 'learning_rate': 5.783132530120482e-05, 'epoch': 0.45}\n{'loss': 3.9082, 'grad_norm': 3.982898235321045, 'learning_rate': 5.7429718875502015e-05, 'epoch': 0.45}\n{'loss': 3.9991, 'grad_norm': 7.6981964111328125, 'learning_rate': 5.70281124497992e-05, 'epoch': 0.46}\n{'loss': 4.0042, 'grad_norm': 1.550803303718567, 'learning_rate': 5.6626506024096394e-05, 'epoch': 0.46}\n{'loss': 3.7713, 'grad_norm': 4.392800807952881, 'learning_rate': 5.6224899598393576e-05, 'epoch': 0.47}\n{'loss': 4.0024, 'grad_norm': 1.6150023937225342, 'learning_rate': 5.582329317269076e-05, 'epoch': 0.47}\n{'loss': 3.8815, 'grad_norm': 1.4280189275741577, 'learning_rate': 5.5421686746987955e-05, 'epoch': 0.47}\n{'loss': 3.6589, 'grad_norm': 2.0116732120513916, 'learning_rate': 5.502008032128514e-05, 'epoch': 0.48}\n{'loss': 3.9406, 'grad_norm': 1.7464871406555176, 'learning_rate': 5.461847389558233e-05, 'epoch': 0.48}\n{'loss': 3.4649, 'grad_norm': 1.7064906358718872, 'learning_rate': 5.4216867469879516e-05, 'epoch': 0.49}\n{'loss': 3.9885, 'grad_norm': 2.4881832599639893, 'learning_rate': 5.381526104417671e-05, 'epoch': 0.49}\n{'loss': 4.0176, 'grad_norm': 2.1617722511291504, 'learning_rate': 5.3413654618473894e-05, 'epoch': 0.49}\n{'loss': 3.5117, 'grad_norm': 1.6721075773239136, 'learning_rate': 5.301204819277109e-05, 'epoch': 0.5}\n{'loss': 3.7805, 'grad_norm': 13.40438175201416, 'learning_rate': 5.261044176706827e-05, 'epoch': 0.5}\n{'loss': 3.7909, 'grad_norm': 1.6522949934005737, 'learning_rate': 5.220883534136547e-05, 'epoch': 0.5}\n{'loss': 3.8543, 'grad_norm': 2.321256637573242, 'learning_rate': 5.180722891566265e-05, 'epoch': 0.51}\n{'loss': 3.9327, 'grad_norm': 6.506166458129883, 'learning_rate': 5.140562248995984e-05, 'epoch': 0.51}\n{'loss': 3.654, 'grad_norm': 7.677914142608643, 'learning_rate': 5.100401606425703e-05, 'epoch': 0.52}\n{'loss': 3.9235, 'grad_norm': 2.9735567569732666, 'learning_rate': 5.060240963855422e-05, 'epoch': 0.52}\n{'loss': 3.6979, 'grad_norm': 1.7926788330078125, 'learning_rate': 5.020080321285141e-05, 'epoch': 0.52}\n{'loss': 3.9898, 'grad_norm': 5.310945510864258, 'learning_rate': 4.97991967871486e-05, 'epoch': 0.53}\n{'loss': 3.5768, 'grad_norm': 5.520442962646484, 'learning_rate': 4.9397590361445786e-05, 'epoch': 0.53}\n{'loss': 4.1027, 'grad_norm': 7.143337249755859, 'learning_rate': 4.8995983935742975e-05, 'epoch': 0.54}\n{'loss': 4.0317, 'grad_norm': 3.326300859451294, 'learning_rate': 4.8594377510040165e-05, 'epoch': 0.54}\n{'loss': 3.6724, 'grad_norm': 1.8586920499801636, 'learning_rate': 4.8192771084337354e-05, 'epoch': 0.54}\n{'loss': 3.9795, 'grad_norm': 2.5854780673980713, 'learning_rate': 4.779116465863454e-05, 'epoch': 0.55}\n{'loss': 3.421, 'grad_norm': 2.833045244216919, 'learning_rate': 4.738955823293173e-05, 'epoch': 0.55}\n{'loss': 3.957, 'grad_norm': 1.8407360315322876, 'learning_rate': 4.698795180722892e-05, 'epoch': 0.56}\n{'loss': 3.8773, 'grad_norm': 1.6150760650634766, 'learning_rate': 4.658634538152611e-05, 'epoch': 0.56}\n{'loss': 3.7829, 'grad_norm': 1.816931128501892, 'learning_rate': 4.61847389558233e-05, 'epoch': 0.56}\n{'loss': 3.5687, 'grad_norm': 1.5021413564682007, 'learning_rate': 4.578313253012048e-05, 'epoch': 0.57}\n{'loss': 3.7077, 'grad_norm': 1.6377415657043457, 'learning_rate': 4.538152610441767e-05, 'epoch': 0.57}\n{'loss': 3.8995, 'grad_norm': 2.8074238300323486, 'learning_rate': 4.497991967871486e-05, 'epoch': 0.58}\n{'loss': 3.6296, 'grad_norm': 1.7366883754730225, 'learning_rate': 4.457831325301205e-05, 'epoch': 0.58}\n{'loss': 3.587, 'grad_norm': 2.0134944915771484, 'learning_rate': 4.417670682730924e-05, 'epoch': 0.58}\n{'loss': 3.4327, 'grad_norm': 1.3092460632324219, 'learning_rate': 4.377510040160643e-05, 'epoch': 0.59}\n{'loss': 4.0485, 'grad_norm': 2.5251076221466064, 'learning_rate': 4.337349397590362e-05, 'epoch': 0.59}\n 59%|████████████████████████▏                | 150/254 [13:23<09:26,  5.45s/it]❌ ERROR: Could not find logits in model outputs\n   Outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithPast'>\n   Outputs attributes: ['__annotations__', '__class__', '__class_getitem__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__or__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'attentions', 'clear', 'copy', 'fromkeys', 'get', 'hidden_states', 'items', 'keys', 'logits', 'loss', 'move_to_end', 'past_key_values', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']\n{'loss': 4.86, 'grad_norm': 1.8051433563232422, 'learning_rate': 4.297188755020081e-05, 'epoch': 0.6}\n{'loss': 3.408, 'grad_norm': 1.222104787826538, 'learning_rate': 4.2570281124497996e-05, 'epoch': 0.6}\n{'loss': 3.573, 'grad_norm': 2.3784542083740234, 'learning_rate': 4.2168674698795186e-05, 'epoch': 0.6}\n{'loss': 3.7611, 'grad_norm': 6.153679847717285, 'learning_rate': 4.176706827309237e-05, 'epoch': 0.61}\n{'loss': 4.0165, 'grad_norm': 9.4581880569458, 'learning_rate': 4.136546184738956e-05, 'epoch': 0.61}\n{'loss': 3.7192, 'grad_norm': 2.052899122238159, 'learning_rate': 4.0963855421686746e-05, 'epoch': 0.62}\n{'loss': 3.3215, 'grad_norm': 2.192805290222168, 'learning_rate': 4.0562248995983936e-05, 'epoch': 0.62}\n{'loss': 3.4047, 'grad_norm': 1.9347572326660156, 'learning_rate': 4.0160642570281125e-05, 'epoch': 0.62}\n{'loss': 3.6054, 'grad_norm': 2.4281108379364014, 'learning_rate': 3.9759036144578314e-05, 'epoch': 0.63}\n{'loss': 3.8405, 'grad_norm': 2.4388906955718994, 'learning_rate': 3.93574297188755e-05, 'epoch': 0.63}\n{'loss': 3.4421, 'grad_norm': 1.6184107065200806, 'learning_rate': 3.895582329317269e-05, 'epoch': 0.64}\n{'loss': 3.697, 'grad_norm': 2.6032698154449463, 'learning_rate': 3.855421686746988e-05, 'epoch': 0.64}\n{'loss': 3.5386, 'grad_norm': 2.558924913406372, 'learning_rate': 3.815261044176707e-05, 'epoch': 0.64}\n{'loss': 3.4141, 'grad_norm': 1.295316219329834, 'learning_rate': 3.7751004016064253e-05, 'epoch': 0.65}\n{'loss': 3.8368, 'grad_norm': 1.4947272539138794, 'learning_rate': 3.734939759036144e-05, 'epoch': 0.65}\n{'loss': 3.6369, 'grad_norm': 1.525251030921936, 'learning_rate': 3.694779116465863e-05, 'epoch': 0.65}\n{'loss': 3.281, 'grad_norm': 1.7862730026245117, 'learning_rate': 3.654618473895582e-05, 'epoch': 0.66}\n{'loss': 3.9848, 'grad_norm': 1.735741376876831, 'learning_rate': 3.614457831325301e-05, 'epoch': 0.66}\n{'loss': 3.7049, 'grad_norm': 13.597679138183594, 'learning_rate': 3.57429718875502e-05, 'epoch': 0.67}\n{'loss': 3.5418, 'grad_norm': 3.3782002925872803, 'learning_rate': 3.534136546184739e-05, 'epoch': 0.67}\n{'loss': 3.4131, 'grad_norm': 3.558291435241699, 'learning_rate': 3.4939759036144585e-05, 'epoch': 0.67}\n{'loss': 3.7145, 'grad_norm': 2.4142096042633057, 'learning_rate': 3.4538152610441774e-05, 'epoch': 0.68}\n{'loss': 3.8692, 'grad_norm': 9.526121139526367, 'learning_rate': 3.413654618473896e-05, 'epoch': 0.68}\n{'loss': 3.4623, 'grad_norm': 5.373696327209473, 'learning_rate': 3.3734939759036146e-05, 'epoch': 0.69}\n{'loss': 4.1221, 'grad_norm': 4.3614325523376465, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.69}\n{'loss': 3.2691, 'grad_norm': 2.5926170349121094, 'learning_rate': 3.2931726907630524e-05, 'epoch': 0.69}\n{'loss': 3.7733, 'grad_norm': 4.684669017791748, 'learning_rate': 3.253012048192771e-05, 'epoch': 0.7}\n{'loss': 3.769, 'grad_norm': 13.009817123413086, 'learning_rate': 3.21285140562249e-05, 'epoch': 0.7}\n{'loss': 3.6184, 'grad_norm': 8.251226425170898, 'learning_rate': 3.172690763052209e-05, 'epoch': 0.71}\n{'loss': 3.6531, 'grad_norm': 1.9068788290023804, 'learning_rate': 3.132530120481928e-05, 'epoch': 0.71}\n{'loss': 3.5241, 'grad_norm': 2.5165915489196777, 'learning_rate': 3.092369477911647e-05, 'epoch': 0.71}\n{'loss': 3.2206, 'grad_norm': 3.1295337677001953, 'learning_rate': 3.052208835341366e-05, 'epoch': 0.72}\n{'loss': 3.2785, 'grad_norm': 1.6864655017852783, 'learning_rate': 3.012048192771085e-05, 'epoch': 0.72}\n{'loss': 3.4745, 'grad_norm': 12.406009674072266, 'learning_rate': 2.971887550200803e-05, 'epoch': 0.73}\n 72%|█████████████████████████████▋           | 184/254 [16:26<06:10,  5.29s/it]❌ ERROR: Could not find logits in model outputs\n   Outputs type: <class 'transformers.modeling_outputs.CausalLMOutputWithPast'>\n   Outputs attributes: ['__annotations__', '__class__', '__class_getitem__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__or__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'attentions', 'clear', 'copy', 'fromkeys', 'get', 'hidden_states', 'items', 'keys', 'logits', 'loss', 'move_to_end', 'past_key_values', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']\n{'loss': 4.7042, 'grad_norm': 10.164504051208496, 'learning_rate': 2.931726907630522e-05, 'epoch': 0.73}\n{'loss': 3.7301, 'grad_norm': 2.2159526348114014, 'learning_rate': 2.891566265060241e-05, 'epoch': 0.73}\n{'loss': 3.8065, 'grad_norm': 1.8604590892791748, 'learning_rate': 2.85140562248996e-05, 'epoch': 0.74}\n{'loss': 3.1496, 'grad_norm': 1.536139965057373, 'learning_rate': 2.8112449799196788e-05, 'epoch': 0.74}\n{'loss': 3.4536, 'grad_norm': 2.8877012729644775, 'learning_rate': 2.7710843373493977e-05, 'epoch': 0.75}\n{'loss': 3.5826, 'grad_norm': 3.840235948562622, 'learning_rate': 2.7309236947791167e-05, 'epoch': 0.75}\n{'loss': 3.5231, 'grad_norm': 4.258662700653076, 'learning_rate': 2.6907630522088356e-05, 'epoch': 0.75}\n{'loss': 3.4404, 'grad_norm': 1.5189000368118286, 'learning_rate': 2.6506024096385545e-05, 'epoch': 0.76}\n{'loss': 3.6024, 'grad_norm': 2.333887815475464, 'learning_rate': 2.6104417670682734e-05, 'epoch': 0.76}\n{'loss': 3.626, 'grad_norm': 2.899031400680542, 'learning_rate': 2.570281124497992e-05, 'epoch': 0.77}\n{'loss': 3.4793, 'grad_norm': 1.9774951934814453, 'learning_rate': 2.530120481927711e-05, 'epoch': 0.77}\n{'loss': 3.3787, 'grad_norm': 2.0757155418395996, 'learning_rate': 2.48995983935743e-05, 'epoch': 0.77}\n{'loss': 3.3283, 'grad_norm': 2.0862514972686768, 'learning_rate': 2.4497991967871488e-05, 'epoch': 0.78}\n{'loss': 3.3928, 'grad_norm': 2.2103240489959717, 'learning_rate': 2.4096385542168677e-05, 'epoch': 0.78}\n{'loss': 3.0333, 'grad_norm': 1.5668363571166992, 'learning_rate': 2.3694779116465866e-05, 'epoch': 0.79}\n{'loss': 3.5726, 'grad_norm': 2.0308494567871094, 'learning_rate': 2.3293172690763055e-05, 'epoch': 0.79}\n{'loss': 3.5256, 'grad_norm': 2.983088731765747, 'learning_rate': 2.289156626506024e-05, 'epoch': 0.79}\n{'loss': 3.3194, 'grad_norm': 1.8730612993240356, 'learning_rate': 2.248995983935743e-05, 'epoch': 0.8}\n{'loss': 3.5811, 'grad_norm': 1.7207835912704468, 'learning_rate': 2.208835341365462e-05, 'epoch': 0.8}\n{'loss': 3.7106, 'grad_norm': 7.408384323120117, 'learning_rate': 2.168674698795181e-05, 'epoch': 0.8}\n{'loss': 3.2362, 'grad_norm': 1.5874911546707153, 'learning_rate': 2.1285140562248998e-05, 'epoch': 0.81}\n{'loss': 3.2913, 'grad_norm': 9.226300239562988, 'learning_rate': 2.0883534136546184e-05, 'epoch': 0.81}\n{'loss': 3.5746, 'grad_norm': 4.405093669891357, 'learning_rate': 2.0481927710843373e-05, 'epoch': 0.82}\n{'loss': 3.3549, 'grad_norm': 1.8683310747146606, 'learning_rate': 2.0080321285140562e-05, 'epoch': 0.82}\n{'loss': 3.4575, 'grad_norm': 2.02990460395813, 'learning_rate': 1.967871485943775e-05, 'epoch': 0.82}\n{'loss': 3.1464, 'grad_norm': 1.8102781772613525, 'learning_rate': 1.927710843373494e-05, 'epoch': 0.83}\n{'loss': 3.5827, 'grad_norm': 4.543581008911133, 'learning_rate': 1.8875502008032127e-05, 'epoch': 0.83}\n{'loss': 3.3666, 'grad_norm': 4.499917507171631, 'learning_rate': 1.8473895582329316e-05, 'epoch': 0.84}\n{'loss': 3.4402, 'grad_norm': 2.718402147293091, 'learning_rate': 1.8072289156626505e-05, 'epoch': 0.84}\n{'loss': 3.6552, 'grad_norm': 3.2553811073303223, 'learning_rate': 1.7670682730923694e-05, 'epoch': 0.84}\n{'loss': 3.3183, 'grad_norm': 2.7254855632781982, 'learning_rate': 1.7269076305220887e-05, 'epoch': 0.85}\n{'loss': 3.534, 'grad_norm': 4.525612831115723, 'learning_rate': 1.6867469879518073e-05, 'epoch': 0.85}\n{'loss': 3.383, 'grad_norm': 1.701809048652649, 'learning_rate': 1.6465863453815262e-05, 'epoch': 0.86}\n{'loss': 3.5835, 'grad_norm': 1.796531319618225, 'learning_rate': 1.606425702811245e-05, 'epoch': 0.86}\n{'loss': 3.2119, 'grad_norm': 2.297138214111328, 'learning_rate': 1.566265060240964e-05, 'epoch': 0.86}\n{'loss': 3.2791, 'grad_norm': 2.4650228023529053, 'learning_rate': 1.526104417670683e-05, 'epoch': 0.87}\n{'loss': 3.0833, 'grad_norm': 1.6714907884597778, 'learning_rate': 1.4859437751004016e-05, 'epoch': 0.87}\n{'loss': 3.4963, 'grad_norm': 1.5913070440292358, 'learning_rate': 1.4457831325301205e-05, 'epoch': 0.88}\n{'loss': 3.1204, 'grad_norm': 8.223370552062988, 'learning_rate': 1.4056224899598394e-05, 'epoch': 0.88}\n{'loss': 3.4307, 'grad_norm': 1.74069082736969, 'learning_rate': 1.3654618473895583e-05, 'epoch': 0.88}\n{'loss': 3.6307, 'grad_norm': 1.6253787279129028, 'learning_rate': 1.3253012048192772e-05, 'epoch': 0.89}\n{'loss': 3.2697, 'grad_norm': 2.9480597972869873, 'learning_rate': 1.285140562248996e-05, 'epoch': 0.89}\n{'loss': 3.6129, 'grad_norm': 1.6403472423553467, 'learning_rate': 1.244979919678715e-05, 'epoch': 0.9}\n{'loss': 3.6972, 'grad_norm': 2.305699348449707, 'learning_rate': 1.2048192771084338e-05, 'epoch': 0.9}\n{'loss': 3.201, 'grad_norm': 1.5528377294540405, 'learning_rate': 1.1646586345381528e-05, 'epoch': 0.9}\n{'loss': 3.4847, 'grad_norm': 3.7164804935455322, 'learning_rate': 1.1244979919678715e-05, 'epoch': 0.91}\n{'loss': 3.4704, 'grad_norm': 4.205365180969238, 'learning_rate': 1.0843373493975904e-05, 'epoch': 0.91}\n{'loss': 3.3572, 'grad_norm': 1.6573156118392944, 'learning_rate': 1.0441767068273092e-05, 'epoch': 0.92}\n{'loss': 3.2812, 'grad_norm': 1.687441110610962, 'learning_rate': 1.0040160642570281e-05, 'epoch': 0.92}\n{'loss': 3.3437, 'grad_norm': 2.5480918884277344, 'learning_rate': 9.63855421686747e-06, 'epoch': 0.92}\n{'loss': 3.3667, 'grad_norm': 2.343578577041626, 'learning_rate': 9.236947791164658e-06, 'epoch': 0.93}\n{'loss': 3.5436, 'grad_norm': 1.6803799867630005, 'learning_rate': 8.835341365461847e-06, 'epoch': 0.93}\n{'loss': 3.2827, 'grad_norm': 5.565554141998291, 'learning_rate': 8.433734939759036e-06, 'epoch': 0.93}\n{'loss': 3.4706, 'grad_norm': 3.1095311641693115, 'learning_rate': 8.032128514056226e-06, 'epoch': 0.94}\n{'loss': 3.6351, 'grad_norm': 2.2749369144439697, 'learning_rate': 7.630522088353415e-06, 'epoch': 0.94}\n{'loss': 3.4188, 'grad_norm': 7.007221221923828, 'learning_rate': 7.228915662650602e-06, 'epoch': 0.95}\n{'loss': 3.5429, 'grad_norm': 1.6074250936508179, 'learning_rate': 6.827309236947792e-06, 'epoch': 0.95}\n{'loss': 3.5247, 'grad_norm': 2.094966411590576, 'learning_rate': 6.42570281124498e-06, 'epoch': 0.95}\n{'loss': 3.2765, 'grad_norm': 2.995973587036133, 'learning_rate': 6.024096385542169e-06, 'epoch': 0.96}\n{'loss': 3.3453, 'grad_norm': 1.9932258129119873, 'learning_rate': 5.622489959839358e-06, 'epoch': 0.96}\n{'loss': 3.3249, 'grad_norm': 2.9865658283233643, 'learning_rate': 5.220883534136546e-06, 'epoch': 0.97}\n{'loss': 3.5509, 'grad_norm': 2.5571296215057373, 'learning_rate': 4.819277108433735e-06, 'epoch': 0.97}\n{'loss': 3.3233, 'grad_norm': 8.334443092346191, 'learning_rate': 4.417670682730924e-06, 'epoch': 0.97}\n{'loss': 3.36, 'grad_norm': 1.721516728401184, 'learning_rate': 4.016064257028113e-06, 'epoch': 0.98}\n{'loss': 3.433, 'grad_norm': 3.9321749210357666, 'learning_rate': 3.614457831325301e-06, 'epoch': 0.98}\n{'loss': 3.5518, 'grad_norm': 1.8881679773330688, 'learning_rate': 3.21285140562249e-06, 'epoch': 0.99}\n{'loss': 3.324, 'grad_norm': 1.79371178150177, 'learning_rate': 2.811244979919679e-06, 'epoch': 0.99}\n{'loss': 3.0848, 'grad_norm': 1.609375238418579, 'learning_rate': 2.4096385542168676e-06, 'epoch': 0.99}\n{'loss': 3.0305, 'grad_norm': 2.287431001663208, 'learning_rate': 2.0080321285140564e-06, 'epoch': 1.0}\n{'loss': 1.7792, 'grad_norm': 1.2318973541259766, 'learning_rate': 1.606425702811245e-06, 'epoch': 1.0}\n{'train_runtime': 1351.4834, 'train_samples_per_second': 3.001, 'train_steps_per_second': 0.188, 'train_loss': 4.738576080855422, 'epoch': 1.0}\n100%|█████████████████████████████████████████| 254/254 [22:31<00:00,  5.32s/it]\n✅ Unsloth training completed!\nTraining time: 1351.48 seconds\nSamples/second: 3.00\nGPU utilization optimized for 2x T4 setup\n💾 Saving LoRA adapters for vLLM compatibility...\nTraceback (most recent call last):\n  File \"/kaggle/working/weight_train_unsloth.py\", line 255, in <module>\n    main()\n  File \"/kaggle/working/weight_train_unsloth.py\", line 247, in main\n    model.save_pretrained_merged(folder, tokenizer, save_method=\"merged_4bit\")\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/save.py\", line 2450, in unsloth_generic_save_pretrained_merged\n    unsloth_generic_save(**arguments)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/unsloth/save.py\", line 2387, in unsloth_generic_save\n    raise RuntimeError(\nRuntimeError: Unsloth: Merging into 4bit will cause your model to lose accuracy if you plan\nto merge to GGUF or others later on. I suggest you to do this as a final step\nif you're planning to do multiple saves.\nIf you are certain, change `save_method` to `merged_4bit_forced`.\nTraceback (most recent call last):\n  File \"/usr/local/bin/accelerate\", line 10, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n    args.func(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1235, in launch_command\n    simple_launcher(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 823, in simple_launcher\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\nsubprocess.CalledProcessError: Command '['/usr/bin/python3', 'weight_train_unsloth.py']' returned non-zero exit status 1.\n","output_type":"stream"}],"execution_count":148},{"id":"dc238475-7452-412f-a485-b8924c8cee47","cell_type":"code","source":"!python merge_lora.py\n!python validation_transformers.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T21:51:43.803386Z","iopub.execute_input":"2025-09-18T21:51:43.803705Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"2025-09-18 21:51:49.772405: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758232309.797140    2658 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758232309.804393    2658 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 50% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n🔄 Loading base model...\n🔗 Loading LoRA adapters...\n🔀 Merging LoRA weights...\n/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n💾 Saving merged model...\n[2025-09-18 21:52:02,242] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-09-18 21:52:03,618] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n✅ Merged model saved to: /kaggle/working/qwen3_1.7b_merged\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2025-09-18 21:52:17.647960: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758232337.672517    2717 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758232337.680061    2717 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO 09-18 21:52:24 [__init__.py:235] Automatically detected platform cuda.\nERROR 09-18 21:52:26 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n🦥 Unsloth Zoo will now patch everything to make training faster!\n✅ Using Qwen3 1.7B model from local Kaggle input\n🎯 TT-12: Unsloth training + vLLM inference with 50% of data\n📊 Stratified sampling: True\n🎯 NORMAL MODE: Training on both positive and negative examples\n🔬 TT-11: Unsloth Training + Transformers Validation\n🚀 Ultra-fast training + Universal compatibility!\n📚 Training: Model learned from examples with Unsloth speed\n🧪 Validation: Testing on real comments with standard Transformers\n======================================================================\n📊 Real comment validation dataset: 2029 samples\n📊 Rule violations: 1031 positive, 998 negative\n🔍 Running validation on 2029 real comments (Unsloth Fast Inference)\n==((====))==  Unsloth 2025.9.6: Fast Qwen3 patching. Transformers: 4.55.4. vLLM: 0.10.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n🎯 Token IDs: Yes=7414, No=2308\n🚀 Running fast inference with Unsloth...\n 33%|█████████████▉                            | 42/127 [01:07<02:06,  1.49s/it]","output_type":"stream"}],"execution_count":null},{"id":"1b603081","cell_type":"code","source":"# Display saved results from TT-11\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# Load detailed results\ntry:\n    detailed_results = pd.read_csv('/kaggle/working/tt11_detailed_results.csv')\n    print(\"📊 TT-11 Detailed Results Shape:\", detailed_results.shape)\n    print(\"\\n📋 Sample Results:\")\n    print(detailed_results[['rule', 'rule_violation', 'predictions', 'probabilities']].head(10))\n    \n    # Load rule metrics\n    rule_metrics = pd.read_csv('/kaggle/working/tt11_rule_metrics.csv')\n    print(\"\\n📈 TT-11 Rule-wise Performance:\")\n    print(rule_metrics)\n    \n    # Performance summary\n    print(\"\\n🎯 TT-11 PERFORMANCE SUMMARY:\")\n    print(\"=\" * 50)\n    overall_accuracy = accuracy_score(detailed_results['rule_violation'], detailed_results['predictions'])\n    avg_probability = detailed_results['probabilities'].mean()\n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Average Confidence: {avg_probability:.4f}\")\n    print(f\"Total Samples: {len(detailed_results)}\")\n    \nexcept FileNotFoundError as e:\n    print(f\"❌ Results files not found: {e}\")\n    print(\"Run the validation cell first to generate results.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"48250c83","cell_type":"markdown","source":"# 📊 TT-11 Analysis Guide\n\n## 🎯 **What TT-11 Optimizes:**\n- **🚀 Training Speed**: Unsloth provides 2x-5x faster fine-tuning than standard PEFT\n- **🎯 Inference Precision**: vLLM gives most accurate probability calculations for AUC\n- **💾 Memory Efficiency**: Optimized 4-bit quantization for 2x T4 GPU setup\n- **⚡ Best Performance**: Fastest training + most accurate validation workflow\n\n## 🔧 **How to Adjust Training Data:**\n\n### **Change Data Percentage** (Cell 4 - `constants.py`):\n```python\nTRAINING_DATA_PERCENTAGE = 0.5  # Use 50% of training data\nTRAINING_DATA_PERCENTAGE = 0.1  # Use 10% of training data\nTRAINING_DATA_PERCENTAGE = 1.0  # Use 100% of training data (default)\n```\n\n### **Toggle Stratified Sampling** (Cell 4 - `constants.py`):\n```python\nUSE_STRATIFIED_SAMPLING = True   # Maintain rule distribution (recommended)\nUSE_STRATIFIED_SAMPLING = False  # Random sampling\n```\n\n## 🚀 **Unsloth Training Optimizations:**\n\n### **Speed Tuning** (Cell 6 - `train_unsloth.py`):\n```python\n# For maximum speed\nper_device_train_batch_size=1,  # Smaller batches for Unsloth\nmax_steps=30,                   # Unsloth converges faster\nlearning_rate=3e-4,             # Higher LR works with Unsloth\n\n# For best quality  \nper_device_train_batch_size=2,  # Balanced approach\nmax_steps=60,                   # More training steps\nr=32,                          # Higher LoRA rank\n```\n\n### **Memory Optimization**:\n```python\n# If running out of memory\nper_device_train_batch_size=1,\ngradient_accumulation_steps=8,\nmax_seq_length=1024,\n```\n\n## 🎯 **vLLM Inference Advantages:**\n\n### **High-Precision AUC Calculation**:\n- **Log Probability Processing**: vLLM's optimized probability calculations\n- **Numerical Stability**: Better handling of edge cases\n- **Temperature Scaling**: More consistent probability distributions\n\n### **Performance Monitoring**:\n```python\n# Check probability quality\nviolation_probs = results[results['rule_violation'] == 1]['probabilities']\nno_violation_probs = results[results['rule_violation'] == 0]['probabilities']\nseparation = abs(violation_probs.mean() - no_violation_probs.mean())\nprint(f\"Probability separation: {separation:.3f}\")  # Higher = better discrimination\n```\n\n## 📈 **Understanding TT-11 Results:**\n\n### **Key Metrics:**\n- **AUC Score**: Most accurate with vLLM's precise probabilities (0.5 = random, 1.0 = perfect)\n- **F1 Score**: Balance of precision and recall\n- **Probability Separation**: How well the model discriminates between classes\n- **Confidence Analysis**: vLLM provides more reliable confidence estimates\n\n### **Visualizations Generated:**\n1. **Confusion Matrix**: Shows prediction accuracy breakdown\n2. **ROC Curve**: High-precision curve with vLLM probabilities\n3. **Probability Distribution**: Clean separation with vLLM precision\n4. **Metrics Bar Chart**: Visual comparison of all performance metrics\n\n## ⚡ **Speed Expectations:**\n\n### **Unsloth Training Speed:**\n- **2x-5x faster** than standard PEFT training\n- **Faster convergence** - often needs 50% fewer steps\n- **Better memory efficiency** - same quality with less VRAM\n\n### **vLLM Inference Benefits:**\n- **Most accurate AUC** calculations available\n- **Stable probabilities** for reliable metrics\n- **Batch processing** for faster validation\n\n## 🚀 **Optimization Tips:**\n\n### **If Training is Too Slow:**\n1. **Reduce max_steps**: Try `max_steps=30` instead of 60\n2. **Smaller batches**: `per_device_train_batch_size=1`\n3. **Reduce data**: `TRAINING_DATA_PERCENTAGE = 0.5`\n4. **Lower rank**: `r=8` instead of `r=16`\n\n### **If AUC is Lower Than Expected:**\n1. **More training steps**: `max_steps=100`\n2. **Higher LoRA rank**: `r=32`\n3. **More data**: `TRAINING_DATA_PERCENTAGE = 1.0`\n4. **Adjust learning rate**: Try `learning_rate=1e-4`\n\n### **If Memory Issues:**\n1. **Reduce sequence length**: `max_seq_length=1024`\n2. **Smaller batches**: `per_device_train_batch_size=1`\n3. **Lower GPU utilization**: `gpu_memory_utilization=0.90`\n\n## 💡 **TT-11 vs TT-10 Advantages:**\n\n| Aspect | TT-10 (Standard) | TT-11 (Unsloth + vLLM) |\n|--------|------------------|-------------------------|\n| **Training Speed** | Standard | 🚀 2x-5x faster |\n| **AUC Precision** | Good | 🎯 Most accurate |\n| **Memory Usage** | Standard | 💾 More efficient |\n| **Setup Complexity** | Medium | 🛠️ Optimized |\n| **Total Time** | Baseline | ⚡ 50-80% faster |\n\n## 🎯 **Key Insights:**\n- **High AUC (>0.8)**: Unsloth training + vLLM inference working optimally\n- **Fast Convergence**: Unsloth often achieves better results with fewer steps\n- **Precise Probabilities**: vLLM gives most reliable confidence estimates\n- **Scalable**: This approach works well for larger datasets and models\n\n**TT-11 represents the optimal workflow for validation-focused training: combining Unsloth's training speed with vLLM's inference precision for the best of both worlds!** 🚀🎯","metadata":{}},{"id":"dc3f8f0c","cell_type":"markdown","source":"# 🚀 TT-11 vs TT-10 Performance Comparison\n\n## ⚡ **Expected Performance Improvements**\n\n### **Training Speed (Unsloth Advantage)**\n| Metric | TT-10 (Standard PEFT) | TT-11 (Unsloth) | Improvement |\n|--------|----------------------|------------------|-------------|\n| **Training Time** | 15-30 minutes | 5-10 minutes | 🚀 **2x-3x faster** |\n| **Memory Usage** | 12-14GB VRAM | 10-12GB VRAM | 💾 **15-20% less** |\n| **Convergence** | 100+ steps | 50-60 steps | ⚡ **50% fewer steps** |\n| **Samples/Second** | 2-4 samples/sec | 8-15 samples/sec | 🎯 **4x faster** |\n\n### **Inference Precision (vLLM Advantage)**\n| Metric | TT-10 (Standard) | TT-11 (vLLM) | Improvement |\n|--------|------------------|--------------|-------------|\n| **AUC Precision** | ±0.005 variance | ±0.001 variance | 🎯 **5x more stable** |\n| **Probability Quality** | Good | Excellent | 📊 **Better separation** |\n| **Log Prob Handling** | Basic | Optimized | 🔧 **More reliable** |\n| **Edge Case Handling** | Standard | Advanced | ✅ **Fewer errors** |\n\n### **Overall Workflow**\n| Aspect | TT-10 | TT-11 | Improvement |\n|--------|-------|-------|-------------|\n| **Total Time** | 20-35 minutes | 8-15 minutes | ⚡ **60-70% faster** |\n| **Result Quality** | Good | Excellent | 🎯 **More accurate** |\n| **Memory Efficiency** | Standard | Optimized | 💾 **Better utilization** |\n| **Reliability** | Good | Excellent | ✅ **More consistent** |\n\n## 🎯 **When to Use Each Approach**\n\n### **Use TT-11 (Unsloth + vLLM) When:**\n- ✅ You want **maximum speed and accuracy**\n- ✅ You need **publication-quality AUC** calculations\n- ✅ You're running **multiple experiments**\n- ✅ You have **Kaggle/cloud GPU** time constraints\n- ✅ You want the **most reliable results**\n\n### **Use TT-10 (Standard) When:**\n- ✅ You want **simpler setup** without extra dependencies\n- ✅ You're **learning the approach** first\n- ✅ You have **unlimited time** for training\n- ✅ You're using **very old hardware**\n\n## 🚀 **Migration from TT-10 to TT-11**\n\n### **Simple Migration Steps:**\n1. **Add Unsloth**: Install unsloth package\n2. **Update training**: Use `train_unsloth.py` instead of `train.py`\n3. **Keep validation**: Use same vLLM validation (already optimized)\n4. **Same analysis**: All metrics and visualizations work the same\n\n### **Code Changes Required:**\n```python\n# TT-10 (old)\nfrom trl import SFTTrainer\nfrom transformers import AutoModelForCausalLM\n\n# TT-11 (new)  \nfrom unsloth import FastLanguageModel\nfrom trl import SFTTrainer  # Still used, but with Unsloth model\n```\n\n**Result: Same methodology, much faster execution, more accurate results!** 🎯\n\nThis makes TT-11 the **recommended approach** for production validation workflows where both speed and accuracy matter.","metadata":{}}]}